@inproceedings{10.1109/ICSE-Companion52605.2021.00138,
author = {Daniel, Gwendal and Cabot, Jordi},
title = {The software challenges of building smart chatbots},
year = {2021},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-Companion52605.2021.00138},
doi = {10.1109/ICSE-Companion52605.2021.00138},
abstract = {Chatbots are becoming complex software artifacts that require a high-level of expertise in a variety of technical domains. This technical briefing will cover the software engineering challenges of developing high-quality chatbots. Attendees will be able to create their own bots leveraging the open source chatbot development platform Xatkit.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering: Companion Proceedings},
pages = {324–325},
numpages = {2},
location = {Virtual Event, Spain},
series = {ICSE '21}
}

@inproceedings{10.1145/3387940.3391534,
author = {Dominic, James and Houser, Jada and Steinmacher, Igor and Ritter, Charles and Rodeghero, Paige},
title = {Conversational Bot for Newcomers Onboarding to Open Source Projects},
year = {2020},
isbn = {9781450379632},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387940.3391534},
doi = {10.1145/3387940.3391534},
abstract = {This paper targets the problems newcomers face when onboarding to open source projects and the low retention rate of newcomers. Open source software projects are becoming increasingly more popular. Many major companies have started building open source software. Unfortunately, many newcomers only commit once to an open source project before moving on to another project. Even worse, many novices struggle with joining open source communities and end up leaving quickly, sometimes before their first successful contribution. In this paper, we propose a conversational bot that would recommend projects to newcomers and assist in the onboarding to the open source community. The bot would be able to provide helpful resources, such as Stack Overflow related content. It would also be able to recommend human mentors. We believe that this bot would improve newcomers' experience by providing support not only during their first contribution, but by acting as an agent to engage them to the project.},
booktitle = {Proceedings of the IEEE/ACM 42nd International Conference on Software Engineering Workshops},
pages = {46–50},
numpages = {5},
keywords = {bot, newcomer, onboarding, open source software},
location = {Seoul, Republic of Korea},
series = {ICSEW'20}
}

@inproceedings{10.1145/3540250.3558922,
author = {He, Hao and Su, Haonan and Xiao, Wenxin and He, Runzhi and Zhou, Minghui},
title = {GFI-bot: automated good first issue recommendation on GitHub},
year = {2022},
isbn = {9781450394130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3540250.3558922},
doi = {10.1145/3540250.3558922},
abstract = {To facilitate newcomer onboarding, GitHub recommends the use of "good first issue" (GFI) labels to signal issues suitable for newcomers to resolve. However, previous research shows that manually labeled GFIs are scarce and inappropriate, showing a need for automated recommendations. In this paper, we present GFI-Bot (accessible at https://gfibot.io), a proof-of-concept machine learning powered bot for automated GFI recommendation in practice. Project maintainers can configure GFI-Bot to discover and label possible GFIs so that newcomers can easily locate issues for making their first contributions. GFI-Bot also provides a high-quality, up-to-date dataset for advancing GFI recommendation research.},
booktitle = {Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1751–1755},
numpages = {5},
keywords = {good first issue, onboarding, open-source software, software bot},
location = {Singapore, Singapore},
series = {ESEC/FSE 2022}
}

@article{10.1145/3274451,
author = {Wessel, Mairieli and de Souza, Bruno Mendes and Steinmacher, Igor and Wiese, Igor S. and Polato, Ivanilton and Chaves, Ana Paula and Gerosa, Marco A.},
title = {The Power of Bots: Characterizing and Understanding Bots in OSS Projects},
year = {2018},
issue_date = {November 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {CSCW},
url = {https://doi.org/10.1145/3274451},
doi = {10.1145/3274451},
abstract = {Leveraging the pull request model of social coding platforms, Open Source Software (OSS) integrators review developers' contributions, checking aspects like license, code quality, and testability. Some projects use bots to automate predefined, sometimes repetitive tasks, thereby assisting integrators' and contributors' work. Our research investigates the usage and impact of such bots. We sampled 351 popular projects from GitHub and found that 93 (26%) use bots. We classified the bots, collected metrics from before and after bot adoption, and surveyed 228 developers and integrators. Our results indicate that bots perform numerous tasks. Although integrators reported that bots are useful for maintenance tasks, we did not find a consistent, statistically significant difference between before and after bot adoption across the analyzed projects in terms of number of comments, commits, changed files, and time to close pull requests. Our survey respondents deem the current bots as not smart enough and provided insights into the bots' relevance for specific tasks, challenges, and potential new features. We discuss some of the raised suggestions and challenges in light of the literature in order to help GitHub bot designers reuse and test ideas and technologies already investigated in other contexts.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = {nov},
articleno = {182},
numpages = {19},
keywords = {automated agents, bots, chatbots, open source software, pull request, pull-based model}
}

@inproceedings{10.1145/3334480.3382998,
author = {Liu, Dongyu and Smith, Micah J. and Veeramachaneni, Kalyan},
title = {Understanding User-Bot Interactions for Small-Scale Automation in Open-Source Development},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382998},
doi = {10.1145/3334480.3382998},
abstract = {Small-scale automation tools, or "bots," have been widely deployed in open-source software development to support manual project maintenance tasks. Though interactions between these bots and human developers can have significant effects on user experience, previous research has instead mostly focused on project outcomes. We reviewed existing small-scale bots in wide use on GitHub. After an in-depth qualitative and quantitative evaluation, we compiled several important design principles for human-bot interaction in this context. Following the requirements, we further propose a workflow to support bot developers.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {HCI design and evaluation methods, human-centered computing, software and its engineering, software creation and management},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3460620.3460739,
author = {Faek, Rana and Al-Fawa'reh, Mohammad and Al-Fayoumi, Mustafa},
title = {Exposing Bot Attacks Using Machine Learning and Flow Level Analysis},
year = {2021},
isbn = {9781450388382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3460620.3460739},
doi = {10.1145/3460620.3460739},
abstract = {Botnets represent a major threat to Internet security that have continuously developed in scale and complexity. Command-and-control servers (C&amp;C) send commands to bots that execute and perform these commands, thereby implementing attacks such as distributed denial-of-service (DDoS), spam campaigns, or the scanning of compromised hosts. The detection of volumetric attacks in large and complex networks requires an efficient mechanism. Botnet behavior should be analyzed in order to save the network from attack, and preventive measures should be implemented in time. Anomalous botnet tracking strategies are more efficient than signature-based ones, since botnet detection methods rely on anomalies and do not need pre-constructed botnet signatures, therefore they can detect new or unidentified botnets. We use Netflow and machine learning algorithms in this paper to also improve the detection process for intrusion detection algorithms with a novel dataset. We implemented a number of algorithms in our lightweight model to show that Random Forests get the highest accuracy for the algorithms used.},
booktitle = {International Conference on Data Science, E-Learning and Information Systems 2021},
pages = {99–106},
numpages = {8},
keywords = {Anomaly Detection, IDS, Net Flow},
location = {Ma'an, Jordan},
series = {DATA'21}
}

@inproceedings{10.1145/3422392.3422459,
author = {Wessel, Mairieli and Serebrenik, Alexander and Wiese, Igor and Steinmacher, Igor and Gerosa, Marco A.},
title = {What to Expect from Code Review Bots on GitHub? A Survey with OSS Maintainers},
year = {2020},
isbn = {9781450387538},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3422392.3422459},
doi = {10.1145/3422392.3422459},
abstract = {Software bots are used by Open Source Software (OSS) projects to streamline the code review process. Interfacing between developers and automated services, code review bots report continuous integration failures, code quality checks, and code coverage. However, the impact of such bots on maintenance tasks is still neglected. In this paper, we study how project maintainers experience code review bots. We surveyed 127 maintainers and asked about their expectations and perception of changes incurred by code review bots. Our findings reveal that the most frequent expectations include enhancing the feedback bots provide to developers, reducing the maintenance burden for developers, and enforcing code coverage. While maintainers report that bots satisfied their expectations, they also perceived unexpected effects, such as communication noise and newcomers' dropout. Based on these results, we provide a series of implications for bot developers, as well as insights for future research.},
booktitle = {Proceedings of the XXXIV Brazilian Symposium on Software Engineering},
pages = {457–462},
numpages = {6},
keywords = {code review, open source software, pull-based model, software bots},
location = {Natal, Brazil},
series = {SBES '20}
}

@article{10.1145/3522587,
author = {Rombaut, Benjamin and Cogo, Filipe R. and Adams, Bram and Hassan, Ahmed E.},
title = {There’s no Such Thing as a Free Lunch: Lessons Learned from Exploring the Overhead Introduced by the Greenkeeper Dependency Bot in Npm},
year = {2023},
issue_date = {January 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {32},
number = {1},
issn = {1049-331X},
url = {https://doi.org/10.1145/3522587},
doi = {10.1145/3522587},
abstract = {Dependency management bots are increasingly being used to support the software development process, for example, to automatically update a dependency when a new version is available. Yet, human intervention is often required to either accept or reject any action or recommendation the bot creates. In this article, our objective is to study the extent to which dependency management bots create additional, and sometimes unnecessary, work for their users. To accomplish this, we analyze 93,196 issue reports opened by Greenkeeper, a popular dependency management bot used in open source software projects in the npm ecosystem. We find that Greenkeeper is responsible for half of all issues reported in client projects, inducing a significant amount of overhead that must be addressed by clients, since many of these issues were created as a result of Greenkeeper taking incorrect action on a dependency update (i.e., false alarms). Reverting a broken dependency update to an older version, which is a potential solution that requires the least overhead and is automatically attempted by Greenkeeper, turns out to not be an effective mechanism. Finally, we observe that 56% of the commits referenced by Greenkeeper issue reports only change the client’s dependency specification file to resolve the issue. Based on our findings, we argue that dependency management bots should (i) be configurable to allow clients to reduce the amount of generated activity by the bots, (ii) take into consideration more sources of information than only the pass/fail status of the client’s build pipeline to help eliminate false alarms, and (iii) provide more effective incentives to encourage clients to resolve dependency issues.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = {feb},
articleno = {11},
numpages = {40},
keywords = {Dependency management, software bots, mining software repositories, greenkeeper, overhead}
}

@inproceedings{10.1109/BotSE.2019.00018,
author = {Wessel, Mairieli and Steinmacher, Igor and Wiese, Igor and Gerosa, Marco A.},
title = {Should I stale or should I close? an analysis of a bot that closes abandoned issues and pull requests},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/BotSE.2019.00018},
doi = {10.1109/BotSE.2019.00018},
abstract = {On GitHub, projects use bots to automate predefined and repetitive tasks related to issues and pull requests. Our research investigates the adoption of the stale bot, which helps maintainers triaging abandoned issues and pull requests. We analyzed the bots' configuration settings and their modifications over time. These settings define the time for tagging issues and pull request as stale and closing them. We collected data from 765 OSS projects hosted on GitHub. Our results indicate that most of the studied projects made no more than three modifications in the configurations file, issues tagged as bug reports are exempt from being considered stale, while the same occurs with pull requests that need some input to be processed.},
booktitle = {Proceedings of the 1st International Workshop on Bots in Software Engineering},
pages = {38–42},
numpages = {5},
keywords = {abandoned issues, bots, open source software},
location = {Montreal, Quebec, Canada},
series = {BotSE '19}
}

@inproceedings{10.1145/3387940.3391504,
author = {Wessel, Mairieli and Steinmacher, Igor},
title = {The Inconvenient Side of Software Bots on Pull Requests},
year = {2020},
isbn = {9781450379632},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387940.3391504},
doi = {10.1145/3387940.3391504},
abstract = {Software bots are applications that integrate their work with humans' tasks, serving as conduits between users and other tools. Due to their ability to automate tasks, bots have been widely adopted by Open Source Software (OSS) projects hosted on GitHub. Commonly, OSS projects use bots to automate a variety of routine tasks to save time from maintainers and contributors. Although bots can be useful for supporting maintainers' work, sometimes their comments are seen as spams, and are quickly ignored by contributors. In fact, the way that these bots interact on pull requests can be disruptive and perceived as unwelcoming. In this paper, we propose the concept of a meta-bot to deal with current problems on the human-bot interaction on pull requests. Besides providing additional value to this interaction, meta-bot will reduce interruptions and help maintainers and contributors stay aware of important information.},
booktitle = {Proceedings of the IEEE/ACM 42nd International Conference on Software Engineering Workshops},
pages = {51–55},
numpages = {5},
keywords = {bots, meta-bot, open source software, pull-based model, software bots},
location = {Seoul, Republic of Korea},
series = {ICSEW'20}
}

@inproceedings{10.1145/3510003.3512765,
author = {Wessel, Mairieli and Abdellatif, Ahmad and Wiese, Igor and Conte, Tayana and Shihab, Emad and Gerosa, Marco A. and Steinmacher, Igor},
title = {Bots for pull requests: the good, the bad, and the promising},
year = {2022},
isbn = {9781450392211},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3510003.3512765},
doi = {10.1145/3510003.3512765},
abstract = {Software bots automate tasks within Open Source Software (OSS) projects' pull requests and save reviewing time and effort ("the good"). However, their interactions can be disruptive and noisy and lead to information overload ("the bad"). To identify strategies to overcome such problems, we applied Design Fiction as a participatory method with 32 practitioners. We elicited 22 design strategies for a bot mediator or the pull request user interface ("the promising"). Participants envisioned a separate place in the pull request interface for bot interactions and a bot mediator that can summarize and customize other bots' actions to mitigate noise. We also collected participants' perceptions about a prototype implementing the envisioned strategies. Our design strategies can guide the development of future bots and social coding platforms.},
booktitle = {Proceedings of the 44th International Conference on Software Engineering},
pages = {274–286},
numpages = {13},
keywords = {GitHub bots, automation, collaborative development, design fiction, human-bot interaction, open source software, software bots},
location = {Pittsburgh, Pennsylvania},
series = {ICSE '22}
}

@article{10.1145/3476042,
author = {Wessel, Mairieli and Wiese, Igor and Steinmacher, Igor and Gerosa, Marco Aurelio},
title = {Don't Disturb Me: Challenges of Interacting with Software Bots on Open Source Software Projects},
year = {2021},
issue_date = {October 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {CSCW2},
url = {https://doi.org/10.1145/3476042},
doi = {10.1145/3476042},
abstract = {Software bots are used to streamline tasks in Open Source Software (OSS) projects' pull requests, saving development cost, time, and effort. However, their presence can be disruptive to the community. We identified several challenges caused by bots in pull request interactions by interviewing 21 practitioners, including project maintainers, contributors, and bot developers. In particular, our findings indicate noise as a recurrent and central problem. Noise affects both human communication and development workflow by overwhelming and distracting developers. Our main contribution is a theory of how human developers perceive annoying bot behaviors as noise on social coding platforms. This contribution may help practitioners understand the effects of adopting a bot, and researchers and tool designers may leverage our results to better support human-bot interaction on social coding platforms.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = {oct},
articleno = {301},
numpages = {21},
keywords = {collaborative development, github bots, human-bot interaction, open source software, software bots, software engineering}
}

@inproceedings{10.1109/ICSE-SEET52601.2021.00009,
author = {Tan, Shin Hwei and Hu, Chunfeng and Li, Ziqiang and Zhang, Xiaowen and Zhou, Ying},
title = {GitHub-OSS fixit},
year = {2021},
isbn = {9780738133201},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-SEET52601.2021.00009},
doi = {10.1109/ICSE-SEET52601.2021.00009},
abstract = {Many studies have shown the benefits of introducing open-source projects into teaching Software Engineering (SE) courses. However, there are several limitations of existing studies that limit the wide adaptation of open-source projects in a classroom setting, including (1) the selected project is limited to one particular project, (2) most studies only investigated on its effect on teaching a specific SE concept, and (3) students may make mistakes in their contribution which leads to poor quality code. Meanwhile, software companies have successfully launched programs like Google Summer of Code (GSoC) and FindBugs "fixit" to contribute to open-source projects. Inspired by the success of these programs, we propose GitHub-OSS Fixit, a team-based course project where students are taught to contribute to open-source Java projects by fixing bugs reported in GitHub. We described our course outline to teach students SE concepts by encouraging the usages of several automated program analysis tools. We also included the carefully designed instructions that we gave to students for participating in GitHub-OSS Fixit. As all lectures and labs are conducted online, we think that our course design could help in guiding future online SE courses. Overall, our survey results show that students think that GitHub-OSS Fixit could help them to improve many skills and apply the knowledge taught in class. In total, 154 students have submitted 214 pull requests to 24 different Java projects, in which 93 of them have been merged, and 46 have been closed by developers.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering: Joint Track on Software Engineering Education and Training},
pages = {1–10},
numpages = {10},
keywords = {open-source software, program repair, software engineering},
location = {Virtual Event, Spain},
series = {ICSE-JSEET '21}
}

@inproceedings{10.1145/3368089.3418539,
author = {Wessel, Mairieli},
title = {Enhancing developers’ support on pull requests activities with software bots},
year = {2020},
isbn = {9781450370431},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368089.3418539},
doi = {10.1145/3368089.3418539},
abstract = {Software bots are employed to support developers' activities, serving as conduits between developers and other tools. Due to their focus on task automation, bots have become particularly relevant for Open Source Software (OSS) projects hosted on GitHub. While bots are adopted to save development cost, time, and effort, the bots' presence can be disruptive to the community. My research goal is two-fold: (i) identify problems caused by bots that interact in pull requests, and (ii) help bot designers enhance existing bots. Toward this end, we are interviewing maintainers, contributors, and bot developers to understand the problems in the human-bot interaction and how they affect the collaboration in a project. Afterward, we will employ Design Fiction to capture the developers' vision of bots' capabilities, in order to define guidelines for the design of bots on social coding platforms, and derive requirements for a meta-bot to deal with the problems. This work contributes more broadly to the design and use of software bots to enhance developers' collaboration and interaction.},
booktitle = {Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1674–1677},
numpages = {4},
keywords = {GitHub Bots, Open-source Software, Software Bots},
location = {Virtual Event, USA},
series = {ESEC/FSE 2020}
}

@inproceedings{10.1145/3623476.3623524,
author = {Ait, Adem and C\'{a}novas Izquierdo, Javier Luis and Cabot, Jordi},
title = {A Tool for the Definition and Deployment of Platform-Independent Bots on Open Source Projects},
year = {2023},
isbn = {9798400703966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3623476.3623524},
doi = {10.1145/3623476.3623524},
abstract = {The development of Open Source Software (OSS) projects is a collaborative process that heavily relies on active contributions by passionate developers. Creating, retaining and nurturing an active community of developers is a challenging task; and finding the appropriate expertise to drive the development process is not always easy. To alleviate this situation, many OSS projects try to use bots to automate some development tasks, thus helping community developers to cope with the daily workload of their projects. However, the techniques and support for developing bots is specific to the code hosting platform where the project is being developed (e.g., GitHub or GitLab). Furthermore, there is no support for orchestrating bots deployed in different platforms nor for building bots that go beyond pure development activities. In this paper, we propose a tool to define and deploy bots for OSS projects, which besides automation tasks they offer a more social facet, improving community interactions. The tool includes a Domain-Specific Language (DSL) which allows defining bots that can be deployed on top of several platforms and that can be triggered by different events (e.g., creation of a new issue or a pull request). We describe the design and the implementation of the tool, and illustrate its use with examples.},
booktitle = {Proceedings of the 16th ACM SIGPLAN International Conference on Software Language Engineering},
pages = {214–219},
numpages = {6},
keywords = {Bot, Domain-Specific Language, Open Source},
location = {Cascais, Portugal},
series = {SLE 2023}
}

@inproceedings{10.1109/ICSE48619.2023.00123,
author = {Ghorbani, Amir and Cassee, Nathan and Robinson, Derek and Alami, Adam and Ernst, Neil A. and Serebrenik, Alexander and W\k{a}sowski, Andrzej},
title = {Autonomy Is an Acquired Taste: Exploring Developer Preferences for GitHub Bots},
year = {2023},
isbn = {9781665457019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE48619.2023.00123},
doi = {10.1109/ICSE48619.2023.00123},
abstract = {Software bots fulfill an important role in collective software development, and their adoption by developers promises increased productivity. Past research has identified that bots that communicate too often can irritate developers, which affects the utility of the bot. However, it is not clear what other properties of human-bot collaboration affect developers' preferences, or what impact these properties might have. The main idea of this paper is to explore characteristics affecting developer preferences for interactions between humans and bots, in the context of GitHub pull requests. We carried out an exploratory sequential study with interviews and a subsequent vignette-based survey. We find developers generally prefer bots that are personable but show little autonomy, however, more experienced developers tend to prefer more autonomous bots. Based on this empirical evidence, we recommend bot developers increase configuration options for bots so that individual developers and projects can configure bots to best align with their own preferences and project cultures.},
booktitle = {Proceedings of the 45th International Conference on Software Engineering},
pages = {1405–1417},
numpages = {13},
keywords = {human aspects, pull request, software bot},
location = {Melbourne, Victoria, Australia},
series = {ICSE '23}
}

@inproceedings{10.1145/3406865.3418368,
author = {Wessel, Mairieli},
title = {Leveraging Software Bots to Enhance Developers' Collaboration in Online Programming Communities},
year = {2020},
isbn = {9781450380591},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3406865.3418368},
doi = {10.1145/3406865.3418368},
abstract = {Software bots are applications that are integrated into human communication channels, serving as an interface between users and other tools. Due to their focus on task automation, bots have become particularly relevant for Open Source Software (OSS) projects hosted on GitHub. While bots are adopted to save developers' costs, time, and effort, the interaction of these bots can be disruptive to the community. My research goal is two-fold: (i) identify problems caused by bots that interact in pull requests, and (ii) help bot designers to enhance existing bots, thereby improving the partnership with contributors and maintainers. Toward this end, we are interviewing developers to understand what are the problems on the human-bot interaction and how they affect human collaboration. Afterwards, we will employ Design Fiction to capture the developers' vision of bots' capabilities, in order to define guidelines for the design of bots on social coding platforms, and derive requirements for a meta-bot to deal with the problems. This work contributes more broadly to the design and use of software bots to enhance developers' collaboration and interaction.},
booktitle = {Companion Publication of the 2020 Conference on Computer Supported Cooperative Work and Social Computing},
pages = {183–188},
numpages = {6},
keywords = {software engineering, software bots, open source software, github bots},
location = {Virtual Event, USA},
series = {CSCW '20 Companion}
}

@inproceedings{10.1145/3379597.3387478,
author = {Dey, Tapajit and Mousavi, Sara and Ponce, Eduardo and Fry, Tanner and Vasilescu, Bogdan and Filippova, Anna and Mockus, Audris},
title = {Detecting and Characterizing Bots that Commit Code},
year = {2020},
isbn = {9781450375177},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3379597.3387478},
doi = {10.1145/3379597.3387478},
abstract = {Background: Some developer activity traditionally performed manually, such as making code commits, opening, managing, or closing issues is increasingly subject to automation in many OSS projects. Specifically, such activity is often performed by tools that react to events or run at specific times. We refer to such automation tools as bots and, in many software mining scenarios related to developer productivity or code quality, it is desirable to identify bots in order to separate their actions from actions of individuals. Aim: Find an automated way of identifying bots and code committed by these bots, and to characterize the types of bots based on their activity patterns. Method and Result: We propose BIMAN, a systematic approach to detect bots using author names, commit messages, files modified by the commit, and projects associated with the commits. For our test data, the value for AUC-ROC was 0.9. We also characterized these bots based on the time patterns of their code commits and the types of files modified, and found that they primarily work with documentation files and web pages, and these files are most prevalent in HTML and JavaScript ecosystems. We have compiled a shareable dataset containing detailed information about 461 bots we found (all of which have more than 1000 commits) and 13,762,430 commits they created.},
booktitle = {Proceedings of the 17th International Conference on Mining Software Repositories},
pages = {209–219},
numpages = {11},
keywords = {software engineering, social coding platforms, random forest, ensemble model, bots, automated commits},
location = {Seoul, Republic of Korea},
series = {MSR '20}
}

@article{10.1145/3359317,
author = {Zheng, Lei (Nico) and Albano, Christopher M. and Vora, Neev M. and Mai, Feng and Nickerson, Jeffrey V.},
title = {The Roles Bots Play in Wikipedia},
year = {2019},
issue_date = {November 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {CSCW},
url = {https://doi.org/10.1145/3359317},
doi = {10.1145/3359317},
abstract = {Bots are playing an increasingly important role in the creation of knowledge in Wikipedia. In many cases, editors and bots form tightly knit teams. Humans develop bots, argue for their approval, and maintain them, performing tasks such as monitoring activity, merging similar bots, splitting complex bots, and turning off malfunctioning bots. Yet this is not the entire picture. Bots are designed to perform certain functions and can acquire new functionality over time. They play particular roles in the editing process. Understanding these roles is an important step towards understanding the ecosystem, and designing better bots and interfaces between bots and humans. This is important for understanding Wikipedia along with other kinds of work in which autonomous machines affect tasks performed by humans. In this study, we use unsupervised learning to build a nine category taxonomy of bots based on their functions in English Wikipedia. We then build a multi-class classifier to classify 1,601 bots based on labeled data. We discuss different bot activities, including their edit frequency, their working spaces, and their software evolution. We use a model to investigate how bots playing certain roles will have differential effects on human editors. In particular, we build on previous research on newcomers by studying the relationship between the roles bots play, the interactions they have with newcomers, and the ensuing survival rate of the newcomers.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = {nov},
articleno = {215},
numpages = {20},
keywords = {wikipedia, taxonomy, roles, online communities, governance, bots}
}

@inproceedings{10.1145/3287324.3293787,
author = {Hu, Zhewei and Gehringer, Edward},
title = {Use Bots to Improve GitHub Pull-Request Feedback},
year = {2019},
isbn = {9781450358903},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3287324.3293787},
doi = {10.1145/3287324.3293787},
abstract = {Rising enrollments make it difficult for instructors and teaching assistants to give adequate feedback on each student's work. In our software engineering course, we have 50-120 students each semester. Our course projects require students to submit GitHub pull requests as deliverables for their open-source software (OSS) projects. We have set up a static code analyzer and a continuous integration service on GitHub to help students check code style and functionality. However, these tools cannot enforce system-specific customized guidelines and do not explicitly display detailed information. In this study, we discuss how we bypass the limitations of existing tools by implementing three Internet bots. The Expertiza Bot can help detect violations of more than 35 system-specific guidelines. The Travis CI Bot can explicitly display instant test execution results on the GitHub pull-request page. The Code Climate Bot can insert pull-request comments to remind students to fix issues detected by the static code analyzer. These bots are either open source or free for OSS projects, and can be easily integrated with GitHub repositories. Our survey results show that more than 70% of students think the advice given by the bots is useful. We tallied the amount of feedback given by the bots and the teaching staff for each GitHub pull request. Results show that bots can provide significantly more feedback (six times more on average) than teaching staff. Bots can also offer more timely feedback than teaching staff and help student contributions avoid more than 33% system-specific guideline violations.},
booktitle = {Proceedings of the 50th ACM Technical Symposium on Computer Science Education},
pages = {1262–1263},
numpages = {2},
keywords = {software engineering, open-source software, open-source curriculum, internet bots, expertiza},
location = {Minneapolis, MN, USA},
series = {SIGCSE '19}
}

@article{10.1145/3610092,
author = {Hsieh, Jane and Kim, Joselyn and Dabbish, Laura and Zhu, Haiyi},
title = {"Nip it in the Bud": Moderation Strategies in Open Source Software Projects and the Role of Bots},
year = {2023},
issue_date = {October 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {CSCW2},
url = {https://doi.org/10.1145/3610092},
doi = {10.1145/3610092},
abstract = {Much of our modern digital infrastructure relies critically upon open sourced software. The communities responsible for building this cyberinfrastructure require maintenance and moderation, which is often supported by volunteer efforts. Moderation, as a non-technical form of labor, is a necessary but often overlooked task that maintainers undertake to sustain the community around an OSS project. This study examines the various structures and norms that support community moderation, describes the strategies moderators use to mitigate conflicts, and assesses how bots can play a role in assisting these processes. We interviewed 14 practitioners to uncover existing moderation practices and ways that automation can provide assistance. Our main contributions include a characterization of moderated content in OSS projects, moderation techniques, as well as perceptions of and recommendations for improving the automation of moderation tasks. We hope that these findings will inform the implementation of more effective moderation practices in open source communities.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = {oct},
articleno = {301},
numpages = {29},
keywords = {automation, coordination, moderation, open source}
}

@inproceedings{10.1145/2652524.2652544,
author = {Bosu, Amiangshu and Carver, Jeffrey C.},
title = {Impact of developer reputation on code review outcomes in OSS projects: an empirical investigation},
year = {2014},
isbn = {9781450327749},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2652524.2652544},
doi = {10.1145/2652524.2652544},
abstract = {&lt;u&gt;Context:&lt;/u&gt; Gaining an identity and building a good reputation are important motivations for Open Source Software (OSS) developers. It is unclear whether these motivations have any actual impact on OSS project success. &lt;u&gt;Goal:&lt;/u&gt; To identify how an OSS developer's reputation affects the outcome of his/her code review requests. &lt;u&gt;Method:&lt;/u&gt; We conducted a social network analysis (SNA) of the code review data from eight popular OSS projects. Working on the assumption that core developers have better reputation than peripheral developers, we developed an approach, Core Identification using K-means (CIK) to divide the OSS developers into core and periphery groups based on six SNA centrality measures. We then compared the outcome of the code review process for members of the two groups. &lt;u&gt;Results:&lt;/u&gt; The results suggest that the core developers receive quicker first feedback on their review request, complete the review process in shorter time, and are more likely to have their code changes accepted into the project codebase. Peripheral developers may have to wait 2 - 19 times (or 12 - 96 hours) longer than core developers for the review process of their code to complete. &lt;u&gt;Conclusion:&lt;/u&gt; We recommend that projects allocate resources or create tool support to triage the code review requests to motivate prospective developers through quick feedback.},
booktitle = {Proceedings of the 8th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
articleno = {33},
numpages = {10},
keywords = {social network analysis, peer impression, open source, network structure, code review},
location = {Torino, Italy},
series = {ESEM '14}
}

@inproceedings{10.1145/3611643.3613077,
author = {Ehsani, Ramtin and Rezapour, Rezvaneh and Chatterjee, Preetha},
title = {Exploring Moral Principles Exhibited in OSS: A Case Study on GitHub Heated Issues},
year = {2023},
isbn = {9798400703270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611643.3613077},
doi = {10.1145/3611643.3613077},
abstract = {To foster collaboration and inclusivity in Open Source Software (OSS) projects, it is crucial to understand and detect patterns of toxic language that may drive contributors away, especially those from underrepresented communities. Although machine learning-based toxicity detection tools trained on domain-specific data have shown promise, their design lacks an understanding of the unique nature and triggers of toxicity in OSS discussions, highlighting the need for further investigation. In this study, we employ Moral Foundations Theory to examine the relationship between moral principles and toxicity in OSS. Specifically, we analyze toxic communications in GitHub issue threads to identify and understand five types of moral principles exhibited in text, and explore their potential association with toxic behavior. Our preliminary findings suggest a possible link between moral principles and toxic comments in OSS communications, with each moral principle associated with at least one type of toxicity. The potential of MFT in toxicity detection warrants further investigation.},
booktitle = {Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {2092–2096},
numpages = {5},
keywords = {moral principles, open source, textual analysis, toxicity},
location = {San Francisco, CA, USA},
series = {ESEC/FSE 2023}
}

@inproceedings{10.1145/3510003.3510196,
author = {Xiao, Wenxin and He, Hao and Xu, Weiwei and Tan, Xin and Dong, Jinhao and Zhou, Minghui},
title = {Recommending good first issues in GitHub OSS projects},
year = {2022},
isbn = {9781450392211},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3510003.3510196},
doi = {10.1145/3510003.3510196},
abstract = {Attracting and retaining newcomers is vital for the sustainability of an open-source software project. However, it is difficult for newcomers to locate suitable development tasks, while existing "Good First Issues" (GFI) in GitHub are often insufficient and inappropriate. In this paper, we propose RecGFI, an effective practical approach for the recommendation of good first issues to newcomers, which can be used to relieve maintainers' burden and help newcomers onboard. RecGFI models an issue with features from multiple dimensions (content, background, and dynamics) and uses an XGBoost classifier to generate its probability of being a GFI. To evaluate RecGFI, we collect 53,510 resolved issues among 100 GitHub projects and carefully restore their historical states to build ground truth datasets. Our evaluation shows that RecGFI can achieve up to 0.853 AUC in the ground truth dataset and outperforms alternative models. Our interpretable analysis of the trained model further reveals interesting observations about GFI characteristics. Finally, we report latest issues (without GFI-signaling labels but recommended as GFI by our approach) to project maintainers among which 16 are confirmed as real GFIs and five have been resolved by a newcomer.},
booktitle = {Proceedings of the 44th International Conference on Software Engineering},
pages = {1830–1842},
numpages = {13},
keywords = {open-source software, onboarding, good first issues},
location = {Pittsburgh, Pennsylvania},
series = {ICSE '22}
}

@inproceedings{10.1145/1134650.1134678,
author = {Pandey, Raju and Wu, Jeffrey},
title = {BOTS: a constraint-based component system for synthesizing scalable software systems},
year = {2006},
isbn = {159593362X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1134650.1134678},
doi = {10.1145/1134650.1134678},
abstract = {Embedded application developers create applications for a wide range of devices with different resource constraints. Developers want to maximize the use of the limited resources available on the device while still not exceeding the capabilities of the device. To do this, the developer must be able to scale his software for different platforms. In this paper, we present a software engineering methodology that automatically scales software to different platforms. We intend to have the application developer write high level functional specifications of his software and have tools that automatically scale the underlying runtime. These tools will use the functional and non-functional constraints of both the hardware and client application to produce an appropriate runtime. Our initial results show that the proposed approach can scale operating systems and virtual machines that satisfy the constraints of varying hardware/application combinations.},
booktitle = {Proceedings of the 2006 ACM SIGPLAN/SIGBED Conference on Language, Compilers, and Tool Support for Embedded Systems},
pages = {189–198},
numpages = {10},
keywords = {wireless sensor networks, runtime systems, generative programming, embedded systems, constraints, components},
location = {Ottawa, Ontario, Canada},
series = {LCTES '06}
}

@inproceedings{10.1145/3387940.3391506,
author = {Brown, Chris and Parnin, Chris},
title = {Sorry to Bother You Again: Developer Recommendation Choice Architectures for Designing Effective Bots},
year = {2020},
isbn = {9781450379632},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387940.3391506},
doi = {10.1145/3387940.3391506},
abstract = {Software robots, or bots, are useful for automating a wide variety of programming and software development tasks. Despite the advantages of using bots throughout the software engineering process, research shows that developers often face challenges interacting with these systems. To improve automated developer recommendations from bots, this work introduces developer recommendation choice architectures. Choice architecture is a behavioral science concept that suggests the presentation of options impacts the decisions humans make. To evaluate the impact of framing recommendations for software engineers, we examine the impact of one choice architecture, actionability, for improving the design of bot recommendations. We present the results of a preliminary study evaluating this choice architecture in a bot and provide implications for integrating choice architecture into the design of future software engineering bots.},
booktitle = {Proceedings of the IEEE/ACM 42nd International Conference on Software Engineering Workshops},
pages = {56–60},
numpages = {5},
keywords = {software engineering, recommendations, developer behavior, choice architecture},
location = {Seoul, Republic of Korea},
series = {ICSEW'20}
}

@inproceedings{10.1145/3524842.3527959,
author = {Abdellatif, Ahmad and Wessel, Mairieli and Steinmacher, Igor and Gerosa, Marco A. and Shihab, Emad},
title = {BotHunter: an approach to detect software bots in GitHub},
year = {2022},
isbn = {9781450393034},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3524842.3527959},
doi = {10.1145/3524842.3527959},
abstract = {Bots have become popular in software projects as they play critical roles, from running tests to fixing bugs/vulnerabilities. However, the large number of software bots adds extra effort to practitioners and researchers to distinguish human accounts from bot accounts to avoid bias in data-driven studies. Researchers developed several approaches to identify bots at specific activity levels (issue/pull request or commit), considering a single repository and disregarding features that showed to be effective in other domains. To address this gap, we propose using a machine learning-based approach to identify the bot accounts regardless of their activity level. We selected and extracted 19 features related to the account's profile information, activities, and comment similarity. Then, we evaluated the performance of five machine learning classifiers using a dataset that has more than 5,000 GitHub accounts. Our results show that the Random Forest classifier performs the best, with an F1-score of 92.4% and AUC of 98.7%. Furthermore, the account profile information (e.g., account login) contains the most relevant features to identify the account type. Finally, we compare the performance of our Random Forest classifier to the state-of-the-art approaches, and our results show that our model outperforms the state-of-the-art techniques in identifying the account type regardless of their activity level.},
booktitle = {Proceedings of the 19th International Conference on Mining Software Repositories},
pages = {6–17},
numpages = {12},
location = {Pittsburgh, Pennsylvania},
series = {MSR '22}
}

@inproceedings{10.1145/3524842.3528528,
author = {Moharil, Ambarish and Orlov, Dmitrii and Jameel, Samar and Trouwen, Tristan and Cassee, Nathan and Serebrenik, Alexander},
title = {Between JIRA and GitHub: ASFBot and its influence on human comments in issue trackers},
year = {2022},
isbn = {9781450393034},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3524842.3528528},
doi = {10.1145/3524842.3528528},
abstract = {Open-Source Software (OSS) projects have adopted various automations for repetitive tasks in recent years. One common type of automation in OSS is bots. In this exploratory case study, we seek to understand how the adoption of one particular bot (ASFBot) by the Apache Software Foundation (ASF) impacts the discussions in the issue-trackers of these projects. We use the SmartShark dataset to investigate whether the ASFBot affects (i) human comments mentioning pull requests and fixes in issue comments and (ii) the general human comment rate on issues. We apply a regression discontinuity design (RDD) on nine ASF projects that have been active both before and after the ASFBot adoption. Our results indicate (i) an immediate decrease in the number of median comments mentioning pull requests and fixes after the bot adoption, but the trend of a monthly decrease in this comment count is reversed, and (ii) no effect in the number of human comments after the bot adoption. We make an effort to gather first insights in understanding the impact of adopting the ASFBot on the commenting behavior of developers who are working on ASF projects.},
booktitle = {Proceedings of the 19th International Conference on Mining Software Repositories},
pages = {112–116},
numpages = {5},
keywords = {issue-trackers, bots, apache, ASFBot},
location = {Pittsburgh, Pennsylvania},
series = {MSR '22}
}

@inproceedings{10.1145/2482991.2482999,
author = {M\"{u}ller-Birn, Claudia and Dobusch, Leonhard and Herbsleb, James D.},
title = {Work-to-rule: the emergence of algorithmic governance in Wikipedia},
year = {2013},
isbn = {9781450321044},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2482991.2482999},
doi = {10.1145/2482991.2482999},
abstract = {Research has shown the importance of a functioning governance system for the success of peer production communities. It particularly highlights the role of human coordination and communication within the governance regime. In this article, we extend this line of research by differentiating two categories of governance mechanisms. The first category is based primarily on communication, in which social norms emerge that are often formalized by written rules and guidelines. The second category refers to the technical infrastructure that enables users to access artifacts, and that allows the community to communicate and coordinate their collective actions to create those artifacts. We collected qualitative and quantitative data from Wikipedia in order to show how a community's consensus gradually converts social mechanisms into algorithmic mechanisms. In detail, we analyze algorithmic governance mechanisms in two embedded cases: the software extension "flagged revisions" and the bot "xqbot". Our insights point towards a growing relevance of algorithmic governance in the realm of governing large-scale peer production communities. This extends previous research, in which algorithmic governance is almost absent. Further research is needed to unfold, understand, and also modify existing interdependencies between social and algorithmic governance mechanisms.},
booktitle = {Proceedings of the 6th International Conference on Communities and Technologies},
pages = {80–89},
numpages = {10},
keywords = {wiki, software, qualitative, governance, bots, Wikipedia},
location = {Munich, Germany},
series = {C&amp;T '13}
}

@inproceedings{10.1145/2398776.2398778,
author = {Dainotti, Alberto and King, Alistair and Claffy, kc and Papale, Ferdinando and Pescap\`{e}, Antonio},
title = {Analysis of a "/0" stealth scan from a botnet},
year = {2012},
isbn = {9781450317054},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2398776.2398778},
doi = {10.1145/2398776.2398778},
abstract = {Botnets are the most common vehicle of cyber-criminal activity. They are used for spamming, phishing, denial of service attacks, brute-force cracking, stealing private information, and cyber warfare. Botnets carry out network scans for several reasons, including searching for vulnerable machines to infect and recruit into the botnet, probing networks for enumeration or penetration, etc. We present the measurement and analysis of a horizontal scan of the entire IPv4 address space conducted by the Sality botnet in February of last year. This 12-day scan originated from approximately 3 million distinct IP addresses, and used a heavily coordinated and unusually covert scanning strategy to try to discover and compromise VoIP-related (SIP server) infrastructure. We observed this event through the UCSD Network Telescope, a /8 darknet continuously receiving large amounts of unsolicited traffic, and we correlate this traffic data with other public sources of data to validate our inferences. Sality is one of the largest botnets ever identified by researchers, its behavior represents ominous advances in the evolution of modern malware: the use of more sophisticated stealth scanning strategies by millions of coordinated bots, targeting critical voice communications infrastructure. This work offers a detailed dissection of the botnet's scanning behavior, including general methods to correlate, visualize, and extrapolate botnet behavior across the global Internet.},
booktitle = {Proceedings of the 2012 Internet Measurement Conference},
pages = {1–14},
numpages = {14},
keywords = {voip, stealth, sip, scan, sality, probing, network telescope, internet background radiation, darknet, covert, coordination, botnet, bot},
location = {Boston, Massachusetts, USA},
series = {IMC '12}
}

@article{10.1145/3555129,
author = {Yin, Likang and Chakraborti, Mahasweta and Yan, Yibo and Schweik, Charles and Frey, Seth and Filkov, Vladimir},
title = {Open Source Software Sustainability: Combining Institutional Analysis and Socio-Technical Networks},
year = {2022},
issue_date = {November 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {CSCW2},
url = {https://doi.org/10.1145/3555129},
doi = {10.1145/3555129},
abstract = {Sustainable Open Source Software (OSS) forms much of the fabric of our digital society, especially successful and sustainable ones. But many OSS projects do not become sustainable, resulting in abandonment and even risks for the world's digital infrastructure. Prior work has looked at the reasons for this mainly from two very different perspectives. In software engineering, the focus has been on understanding success and sustainability from the socio-technical perspective: the OSS programmers' day-to-day activities and the artifacts they create. In institutional analysis, on the other hand, emphasis has been on institutional designs (e.g., policies, rules, and norms) that structure project governance. Even though each is necessary for a comprehensive understanding of OSS projects, the connection and interaction between the two approaches have been barely explored.In this paper, we make the first effort toward understanding OSS project sustainability using a dual-view analysis, by combining institutional analysis with socio-technical systems analysis. In particular, we (i) use linguistic approaches to extract institutional rules and norms from OSS contributors' communications to represent the evolution of their governance systems, and (ii) construct socio-technical networks based on longitudinal collaboration records to represent each project's organizational structure. We combined the two methods and applied them to a dataset of developer digital traces from 253 nascent OSS projects within the Apache Software Foundation (ASF) incubator. We find that the socio-technical and institutional features relate to each other, and provide complimentary views into the progress of the ASF's OSS projects. Refining these combined analyses can help provide a more precise understanding of the synchronization between the evolution of institutional governance and organizational structure.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = {nov},
articleno = {404},
numpages = {23},
keywords = {socio-technical systems, institutional design, OSS sustainability}
}

@inproceedings{10.1145/3468264.3468563,
author = {Yin, Likang and Chen, Zhuangzhi and Xuan, Qi and Filkov, Vladimir},
title = {Sustainability forecasting for Apache incubator projects},
year = {2021},
isbn = {9781450385626},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3468264.3468563},
doi = {10.1145/3468264.3468563},
abstract = {Although OSS development is very popular, ultimately more than 80% of OSS projects fail. Identifying the factors associated with OSS success can help in devising interventions when a project takes a downturn. OSS success has been studied from a variety of angles, more recently in empirical studies of large numbers of diverse projects, using proxies for sustainability, e.g., internal metrics related to productivity and external ones, related to community popularity. The internal socio-technical structure of projects has also been shown important, especially their dynamics. This points to another angle on evaluating software success, from the perspective of self-sustaining and self-governing communities. To uncover the dynamics of how a project at a nascent development stage gradually evolves into a sustainable one, here we apply a socio-technical network modeling perspective to a dataset of Apache Software Foundation Incubator (ASFI), sustainability-labeled projects. To identify and validate the determinants of sustainability, we undertake a mix of quantitative and qualitative studies of ASFI projects’ socio-technical network trajectories. We develop interpretable models which can forecast a project becoming sustainable with 93+% accuracy, within 8 months of incubation start. Based on the interpretable models we describe a strategy for real-time monitoring and suggesting actions, which can be used by projects to correct their sustainability trajectories.},
booktitle = {Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1056–1067},
numpages = {12},
keywords = {Sociotechnical System, OSS Sustainability, Apache Incubator},
location = {Athens, Greece},
series = {ESEC/FSE 2021}
}

@inproceedings{10.1145/3139937.3139950,
author = {Nagara, Keigo and Aoki, Katsunori and Matsubara, Yutaka and Takada, Hiroaki},
title = {Portable DoS Test Tool for IoT Devices},
year = {2017},
isbn = {9781450353960},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3139937.3139950},
doi = {10.1145/3139937.3139950},
abstract = {In the recent years, internet-of-things (IoT) devices have attracted an increasing share of attention, and the vulnerability of IoT devices has been clarified. For example, the IoT malware {¥it Mirai} constructs a bot using the vulnerability of IoT equipment embedded with Linux and exploits it for distributed denial of service (DDoS) attacks. Meanwhile, as reported in papers, examples of denial of service (DoS) attacks targeting IoT/embedded devices have emerged. Therefore, the DoS test at the stage of product design and development stage is very important. We then created an open source software (OSS) based portable DoS test tool for IoT devices.},
booktitle = {Proceedings of the 2017 Workshop on Internet of Things Security and Privacy},
pages = {57–58},
numpages = {2},
keywords = {test tool, security, iot, embedded system, dos attack},
location = {Dallas, Texas, USA},
series = {IoTS&amp;P '17}
}

@inproceedings{10.1145/3368089.3409724,
author = {Silva, Jefferson and Wiese, Igor and German, Daniel M. and Treude, Christoph and Gerosa, Marco Aur\'{e}lio and Steinmacher, Igor},
title = {A theory of the engagement in open source projects via summer of code programs},
year = {2020},
isbn = {9781450370431},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368089.3409724},
doi = {10.1145/3368089.3409724},
abstract = {Summer of code programs connect students to open source software (OSS) projects, typically during the summer break from school. Analyzing consolidated summer of code programs can reveal how college students, who these programs usually target, can be motivated to participate in OSS, and what onboarding strategies OSS communities adopt to receive these students. In this paper, we study the well-established Google Summer of Code (GSoC) and devise an integrated engagement theory grounded in multiple data sources to explain motivation and onboarding in this context. Our analysis shows that OSS communities employ several strategies for planning and executing student participation, socially integrating the students, and rewarding student’s contributions and achievements. Students are motivated by a blend of rewards, which are moderated by external factors. We presented these rewards and the motivation theory to students who had never participated in a summer of code program and collected their shift in motivation after learning about the theory. New students can benefit from the former students' experiences detailed in our results, and OSS stakeholders can leverage both the insight into students’ motivations for joining such programs as well as the onboarding strategies we identify to devise actions to attract and retain newcomers.},
booktitle = {Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {421–431},
numpages = {11},
keywords = {Summer of Code, Process Theory, Onboarding, OSS, Motivation, Mentoring, Engagement},
location = {Virtual Event, USA},
series = {ESEC/FSE 2020}
}

@inproceedings{10.1145/3377811.3380376,
author = {Zhang, Yuxia and Zhou, Minghui and Stol, Klaas-Jan and Wu, Jianyu and Jin, Zhi},
title = {How do companies collaborate in open source ecosystems? an empirical study of OpenStack},
year = {2020},
isbn = {9781450371216},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377811.3380376},
doi = {10.1145/3377811.3380376},
abstract = {Open Source Software (OSS) has come to play a critical role in the software industry. Some large ecosystems enjoy the participation of large numbers of companies, each of which has its own focus and goals. Indeed, companies that otherwise compete, may become collaborators within the OSS ecosystem they participate in. Prior research has largely focused on commercial involvement in OSS projects, but there is a scarcity of research focusing on company collaborations within OSS ecosystems. Some of these ecosystems have become critical building blocks for organizations worldwide; hence, a clear understanding of how companies collaborate within large ecosystems is essential. This paper presents the results of an empirical study of the OpenStack ecosystem, in which hundreds of companies collaborate on thousands of project repositories to deliver cloud distributions. Based on a detailed analysis, we identify clusters of collaborations, and identify four strategies that companies adopt to engage with the OpenStack ecosystem. We alsofind that companies may engage in intentional or passive collaborations, or may work in an isolated fashion. Further, wefi nd that a company's position in the collaboration network is positively associated with its productivity in OpenStack. Our study sheds light on how large OSS ecosystems work, and in particular on the patterns of collaboration within one such large ecosystem.},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering},
pages = {1196–1208},
numpages = {13},
keywords = {software development, openstack, open source software, open collaboration, company participation, OSS ecosystem},
location = {Seoul, South Korea},
series = {ICSE '20}
}

@inproceedings{10.1145/3598469.3598489,
author = {Eibl, Gregor and Thurnay, L\H{o}rinc},
title = {The promises and perils of open source software release and usage by government – evidence from GitHub and literature},
year = {2023},
isbn = {9798400708374},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3598469.3598489},
doi = {10.1145/3598469.3598489},
abstract = {Abstract: Open Source Software (OSS) is extensively utilized in industry and government because it allows for open access to the source code and allows for external involvement in the software development process. There are several factors driving this movement in a government setting, making it difficult to assess the adoption's success. Through a study of billions of rows of GitHub activity data, this research analyzes the production of OSS by administrations in German-speaking countries in detail and analyses the motivating factors and challenges to OSS adoption through a literature review. Similar studies have been conducted in other nations, with somewhat different approaches, foci, and different ways to identify public GitHub users as well as insiders and outsiders of OSS projects. 16 consequences of OSS usage and development are listed in the paper. On GitHub, we found 1021 OSS projects run by public agencies in largly German-speaking nations. We then compiled a list of the most popular projects based on commits and the most active public agencies in terms of projects. The research also finds automatic contributions by bots, which have not been taken into account in the literature so far, and demonstrates highly substantial positive correlations between commits, forks, and stars as proxy for the popularity of these projects. This research introduces a new method for identifying government organizations in OSS platforms and illuminates the possible positive and negative effects of the public sector's release and adoption of open source software.},
booktitle = {Proceedings of the 24th Annual International Conference on Digital Government Research},
pages = {180–190},
numpages = {11},
keywords = {GitHub, barriers, benefits, citizen engagement, evidence, government, open source software},
location = {Gda?sk, Poland},
series = {dg.o '23}
}

@inproceedings{10.1145/3306446.3340823,
author = {de Lacerda, Arthur R. T. and Aguiar, Carla S. R.},
title = {FLOSS FAQ chatbot project reuse: how to allow nonexperts to develop a chatbot},
year = {2019},
isbn = {9781450363198},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3306446.3340823},
doi = {10.1145/3306446.3340823},
abstract = {FAQ chatbots possess the capability to provide answers to frequently asked questions of a particular service, platform, or system. Currently, FAQ chatbot is the most popular domain of use of dialog assistants. However, developing a chatbot project requires a full-stack team formed by numerous specialists, such as dialog designer, data scientist, software engineer, DevOps, business strategist and experts from the domain, which can be both time and resources consuming. Language processing can be particularly challenging in languages other than English due to the scarcity of training datasets.Most of the requirements of FAQ chatbots are similar, domain-specific, and projects could profit from Open Source Software (OSS) reuse. In this paper, we examine how OSS FAQ chatbot projects can benefit from reuse at the project level (black-box reuse). We present an experience report of a FLOSS FAQ chatbot project developed in Portuguese to an e-government service in Brazil. It comprises of the chatbot distribution service, as well as for analytics tool integrated and deployed on-premises. We identified assets that could be reused as a black-box and the assets that should be customized for a particular application. We categorized these assets in architecture, corpus, dialog flows, machine learning models, and documentation. This paper discusses how automation, pre-configuration, and templates can aid newcomers to develop chatbots in Portuguese without the need for specialized skills required from tools in chatbot architecture. Our main contribution is to highlight the issues non-English FAQ chatbots projects will likely face and the assets that can be reused. It allows non-chatbot experts to develop a quality-assured OSS FAQ chatbot in a shorter project cycle.},
booktitle = {Proceedings of the 15th International Symposium on Open Collaboration},
articleno = {3},
numpages = {8},
keywords = {portuguese chatbot, open source, experience report, e-government, conversational agents, black-box reuse, OSS, FLOSS FAQ chatbot, FLOSS},
location = {Sk\"{o}vde, Sweden},
series = {OpenSym '19}
}

@inproceedings{10.1145/3510003.3510116,
author = {Shimada, Naomichi and Xiao, Tao and Hata, Hideaki and Treude, Christoph and Matsumoto, Kenichi},
title = {GitHub sponsors: exploring a new way to contribute to open source},
year = {2022},
isbn = {9781450392211},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3510003.3510116},
doi = {10.1145/3510003.3510116},
abstract = {GitHub Sponsors, launched in 2019, enables donations to individual open source software (OSS) developers. Financial support for OSS maintainers and developers is a major issue in terms of sustaining OSS projects, and the ability to donate to individuals is expected to support the sustainability of developers, projects, and community. In this work, we conducted a mixed-methods study of GitHub Sponsors, including quantitative and qualitative analyses, to understand the characteristics of developers who are likely to receive donations and what developers think about donations to individuals. We found that: (1) sponsored developers are more active than non-sponsored developers, (2) the possibility to receive donations is related to whether there is someone in their community who is donating, and (3) developers are sponsoring as a new way to contribute to OSS. Our findings are the first step towards data-informed guidance for using GitHub Sponsors, opening up avenues for future work on this new way of financially sustaining the OSS community.},
booktitle = {Proceedings of the 44th International Conference on Software Engineering},
pages = {1058–1069},
numpages = {12},
keywords = {sponsorship, open source, GitHub sponsors},
location = {Pittsburgh, Pennsylvania},
series = {ICSE '22}
}

@inproceedings{10.1145/2635868.2661682,
author = {Yang, Xin},
title = {Social network analysis in open source software peer review},
year = {2014},
isbn = {9781450330565},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2635868.2661682},
doi = {10.1145/2635868.2661682},
abstract = {Software peer review (aka. code review) is regarded as one of the most important approaches to keep software quality and productivity. Due to the distributed collaborations and communication nature of Open Source Software (OSS), OSS review differs from traditional industry review. Unlike other related works, this study investigated OSS peer review pro- cesses from social perspective by using social network anal- ysis (SNA). We analyzed the review history from three typi- cal OSS projects. The results provide hints on relationships among the OSS reviewers which can help to understand how developers work and communicate with each other.},
booktitle = {Proceedings of the 22nd ACM SIGSOFT International Symposium on Foundations of Software Engineering},
pages = {820–822},
numpages = {3},
keywords = {social network, peer review, open source},
location = {Hong Kong, China},
series = {FSE 2014}
}

@inproceedings{10.1109/CHASE.2019.00011,
author = {Cheng, Jinghui and Guo, Jin L. C.},
title = {Activity-based analysis of open source software contributors: roles and dynamics},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/CHASE.2019.00011},
doi = {10.1109/CHASE.2019.00011},
abstract = {Contributors to open source software (OSS) communities assume diverse roles to take different responsibilities. One major limitation of the current OSS tools and platforms is that they provide a uniform user interface regardless of the activities performed by the various types of contributors. This paper serves as a non-trivial first step towards resolving this challenge by demonstrating a methodology and establishing knowledge to understand how the contributors' roles and their dynamics, reflected in the activities contributors perform, are exhibited in OSS communities. Based on an analysis of user action data from 29 GitHub projects, we extracted six activities that distinguished four Active roles and five Supporting roles of OSS contributors, as well as patterns in role changes. Through the lens of the Activity Theory, these findings provided rich design guidelines for OSS tools to support diverse contributor roles.},
booktitle = {Proceedings of the 12th International Workshop on Cooperative and Human Aspects of Software Engineering},
pages = {11–18},
numpages = {8},
keywords = {open source software, open source community, contributor roles, activity-based analysis},
location = {Montreal, Quebec, Canada},
series = {CHASE '19}
}

@inproceedings{10.1145/3540250.3549117,
author = {Zhang, Yuxia and Stol, Klaas-Jan and Liu, Hui and Zhou, Minghui},
title = {Corporate dominance in open source ecosystems: a case study of OpenStack},
year = {2022},
isbn = {9781450394130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3540250.3549117},
doi = {10.1145/3540250.3549117},
abstract = {Corporate participation plays an increasing role in Open Source Software (OSS) development. Unlike volunteers in OSS projects, companies are driven by business objectives. To pursue corporate interests, companies may try to dominate the development direction of OSS projects. One company's domination in OSS may 'crowd out' other contributors, changing the nature of the project, and jeopardizing the sustainability of the OSS ecosystem. Prior studies of corporate involvement in OSS have primarily focused on predominately positive aspects such as business strategies, contribution models, and collaboration patterns. However, there is a scarcity of research on the potential drawbacks of corporate engagement. In this paper, we investigate corporate dominance in OSS ecosystems. We draw on the field of Economics and quantify company domination using a dominance measure; we investigate the prevalence, patterns, and impact of domination in the evolution of the OpenStack ecosystem. We find evidence of company domination in over 73% of the repositories in OpenStack, and approximately 25% of companies dominate one or more repositories per version. We identify five patterns of corporate dominance: Early incubation, Full-time hosting, Growing domination, Occasional domination, and Last remaining. We find that domination has a significantly negative relationship with the survival probability of OSS projects. This study provides insights for building sustainable relationships between companies and the OSS ecosystems in which they seek to get involved.},
booktitle = {Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1048–1060},
numpages = {13},
keywords = {survival analysis, software development, corporate participation, company domination, Open source ecosystem},
location = {Singapore, Singapore},
series = {ESEC/FSE 2022}
}

@inproceedings{10.1145/3641822.3641875,
author = {Frluckaj, Hana and Qiu, Huilian Sophie and Vasilescu, Bogdan and Dabbish, Laura},
title = {From the Inside Out: Organizational Impact on Open-Source Communities and Women's Representation},
year = {2024},
isbn = {9798400705335},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641822.3641875},
doi = {10.1145/3641822.3641875},
abstract = {The involvement of companies and public institutions in open-source software (OSS) has become widespread. While studies have explored the business models of for-profit organizations and their impact on software quality, little is known about their influence on OSS communities, especially in terms of diversity and inclusion. This knowledge gap is significant, considering that many organizations have the resources to enhance diversity and inclusion internally, but whether these efforts extend to OSS remains uncertain. To address this gap, we conducted interviews with maintainers of community-owned and organization-owned OSS projects, revealing tensions between organizations and their projects and identifying the impact of internal policies on OSS communities. Our findings reveal that, on the one hand, organization-owned projects often restrict external contributions due to stringent operating procedures and segmented communication, leading to limited external engagement. On the other hand, these organizations positively influence diversity and inclusion, notably in the representation and roles of women and the implementation of mentorship programs.},
booktitle = {Proceedings of the 2024 IEEE/ACM 17th International Conference on Cooperative and Human Aspects of Software Engineering},
pages = {36–50},
numpages = {15},
location = {Lisbon, Portugal},
series = {CHASE '24}
}

@inproceedings{10.1145/3377811.3380335,
author = {Mirsaeedi, Ehsan and Rigby, Peter C.},
title = {Mitigating turnover with code review recommendation: balancing expertise, workload, and knowledge distribution},
year = {2020},
isbn = {9781450371216},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377811.3380335},
doi = {10.1145/3377811.3380335},
abstract = {Developer turnover is inevitable on software projects and leads to knowledge loss, a reduction in productivity, and an increase in defects. Mitigation strategies to deal with turnover tend to disrupt and increase workloads for developers. In this work, we suggest that through code review recommendation we can distribute knowledge and mitigate turnover with minimal impacton the development process. We evaluate review recommenders in the context of ensuring expertise during review, Expertise, reducing the review workload of the core team, CoreWorkload, and reducing the Files at Risk to turnover, FaR. We find that prior work that assigns reviewers based on file ownership concentrates knowledge on a small group of core developers increasing risk of knowledge loss from turnover by up to 65%. We propose learning and retention aware review recommenders that when combined are effective at reducing the risk of turnover by -29% but they unacceptably reduce the overall expertise during reviews by -26%. We develop the Sofia recommender that suggests experts when none of the files under review are hoarded by developers, but distributes knowledge when files are at risk. In this way, we are able to simultaneously increase expertise during review with a ΔExpertise of 6%, with a negligible impact on workload of ΔCoreWorkload of 0.09%, and reduce the files at risk by ΔFaR -28%. Sofia is integrated into GitHub pull requests allowing developers to select an appropriate expert or "learner" based on the context of the review. We release the Sofia bot as well as the code and data for replication purposes.},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering},
pages = {1183–1195},
numpages = {13},
keywords = {turnover, tool support, recommenders, knowledge distribution, code review},
location = {Seoul, South Korea},
series = {ICSE '20}
}

@inproceedings{10.1145/3196398.3196429,
author = {Middleton, Justin and Murphy-Hill, Emerson and Green, Demetrius and Meade, Adam and Mayer, Roger and White, David and McDonald, Steve},
title = {Which contributions predict whether developers are accepted into github teams},
year = {2018},
isbn = {9781450357166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3196398.3196429},
doi = {10.1145/3196398.3196429},
abstract = {Open-source software (OSS) often evolves from volunteer contributions, so OSS development teams must cooperate with their communities to attract new developers. However, in view of the myriad ways that developers interact over platforms for OSS development, observers of these communities may have trouble discerning, and thus learning from, the successful patterns of developer-to-team interactions that lead to eventual team acceptance. In this work, we study project communities on GitHub to discover which forms of software contribution characterize developers who begin as development team outsiders and eventually join the team, in contrast to developers who remain team outsiders. From this, we identify and compare the forms of contribution, such as pull requests and several forms of discussion comments, that influence whether new developers join OSS teams, and we discuss the implications that these behavioral patterns have for the focus of designers and educators.},
booktitle = {Proceedings of the 15th International Conference on Mining Software Repositories},
pages = {403–413},
numpages = {11},
location = {Gothenburg, Sweden},
series = {MSR '18}
}

@inproceedings{10.1145/133057.133102,
author = {Owicki, Susan S. and Karlin, Anna R.},
title = {Factors in the performance of the AN1 computer network},
year = {1992},
isbn = {0897915070},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/133057.133102},
doi = {10.1145/133057.133102},
abstract = {AN1 (formerly known as Autonet) is a local area network composed of crossbar switches interconnected by 100Mbit/second, full-duplex links. In this paper, we evaluate the performance impact of certain choices in the AN1 design. These include the use of FIFO input buffering in the crossbar switch, the deadlock-avoidance mechanism, cut-through routing, back-pressure for flow control, and multi-path routing. AN1's performance goals were to provide low latency and high bandwidth in a lightly loaded network. In this it is successful. Under heavy load, the most serious impediment to good performance is the use of FIFO input buffers. The deadlock-avoidance technique has an adverse effect on the performance of some topologies, but it seems to be the best alternative, given the goals and  constraints of the AN1 design. Cut-through switching performs well relative to store-and-forward switching, even under heavy load. Back-pressure deals adequately with congestion in a lightly-loaded network; under moderate load, performance is acceptable when coupled with end-to-end flow control for bursts. Multi-path routing successfully exploits redundant paths between hosts to improve performance in the face of congestion.},
booktitle = {Proceedings of the 1992 ACM SIGMETRICS Joint International Conference on Measurement and Modeling of Computer Systems},
pages = {167–180},
numpages = {14},
location = {Newport, Rhode Island, USA},
series = {SIGMETRICS '92/PERFORMANCE '92}
}

@inproceedings{10.1145/3487351.3488278,
author = {Moradi-Jamei, Behnaz and Kramer, Brandon L. and Calder\'{o}n, J. Bayo\'{a}n Santiago and Korkmaz, Gizem},
title = {Community formation and detection on GitHub collaboration networks},
year = {2022},
isbn = {9781450391283},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3487351.3488278},
doi = {10.1145/3487351.3488278},
abstract = {This paper studies community formation in OSS collaboration networks. While most current work examines the emergence of small-scale OSS projects, our approach draws on a large-scale historical dataset of 1.8 million GitHub users and their repository contributions. OSS collaborations are characterized by small groups of users that work closely together, leading to the presence of communities defined by short cycles in the underlying network structure. To understand the impact of this phenomenon, we apply a pre-processing step that accounts for the cyclic network structure by using Renewal-Nonbacktracking Random Walks (RNBRW) and the strength of pairwise collaborations before implementing the Louvain method to identify communities within the network. Equipping Louvain with RNBRW and the contribution strength provides a more assertive approach for detecting small-scale teams and reveals nontrivial differences in community detection such as users' tendencies toward preferential attachment to more established collaboration communities. Using this method, we also identify key factors that affect community formation, including the effect of users' location and primary programming language, which was determined using a comparative method of contribution activities. Overall, this paper offers several promising methodological insights for both open-source software experts and network scholars interested in studying team formation.},
booktitle = {Proceedings of the 2021 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining},
pages = {244–251},
numpages = {8},
keywords = {open source software, community formation, community detection},
location = {Virtual Event, Netherlands},
series = {ASONAM '21}
}

@inproceedings{10.1109/ICSE-Companion58688.2023.00082,
author = {Zhao, Zihe H},
title = {The Distribution and Disengagement of Women Contributors in Open-Source: 2008--2021},
year = {2023},
isbn = {9798350322637},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-Companion58688.2023.00082},
doi = {10.1109/ICSE-Companion58688.2023.00082},
abstract = {The underrepresentation of women contributors in the open-source software (OSS) community has been a widely recognized problem. Past research has found that, in OSS collaboration, a gender-diverse team can enhance productivity and lower community smell [1]--[3]. However, these benefits will be hindered when a team lacks gender diversity. To better address this gender imbalance, we need to first understand the overall gender representation.},
booktitle = {Proceedings of the 45th International Conference on Software Engineering: Companion Proceedings},
pages = {305–307},
numpages = {3},
location = {Melbourne, Victoria, Australia},
series = {ICSE '23}
}

@article{10.1145/3569949,
author = {Joblin, Mitchell and Eckl, Barbara and Bock, Thomas and Schmid, Angelika and Siegmund, Janet and Apel, Sven},
title = {Hierarchical and Hybrid Organizational Structures in Open-source Software Projects: A Longitudinal Study},
year = {2023},
issue_date = {July 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {32},
number = {4},
issn = {1049-331X},
url = {https://doi.org/10.1145/3569949},
doi = {10.1145/3569949},
abstract = {Despite the absence of a formal process and a central command-and-control structure, developer organization in open-source software (OSS) projects are far from being a purely random process. Prior work indicates that, over time, highly successful OSS projects develop a hybrid organizational structure that comprises a hierarchical part and a non-hierarchical part. This suggests that hierarchical organization is not necessarily a global organizing principle and that a fundamentally different principle is at play below the lowest positions in the hierarchy. Given the vast proportion of developers are in the non-hierarchical part, we seek to understand the interplay between these two fundamentally differently organized groups, how this hybrid structure evolves, and the trajectory individual developers take through these structures over the course of their participation. We conducted a longitudinal study of the full histories of 20&nbsp;popular OSS projects, modeling their organizational structures as networks of developers connected by communication ties and characterizing developers’ positions in terms of hierarchical (sub)structures in these networks. We observed a number of notable trends and patterns in the subject projects: (1)&nbsp;hierarchy is a pervasive structural feature of developer networks of OSS projects; (2)&nbsp;OSS projects tend to form hybrid organizational structures, consisting of a hierarchical and a non-hierarchical part; and (3)&nbsp;the positional trajectory of a developer starts loosely connected in the non-hierarchical part and then tightly integrate into the hierarchical part, which is associated with the acquisition of experience (tenure), in addition to coordination and coding activities. Our study (a)&nbsp;provides a methodological basis for further investigations of hierarchy formation, (b)&nbsp;suggests a number of hypotheses on prevalent organizational patterns and trends in OSS projects to be addressed in further work, and (c)&nbsp;may ultimately guide the governance of organizational structures.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = {may},
articleno = {86},
numpages = {29},
keywords = {hierarchy, organizational structure, developer networks, Open-source software projects}
}

@inproceedings{10.1145/3611643.3616314,
author = {Win, Hsu Myat and Wang, Haibo and Tan, Shin Hwei},
title = {Towards Automated Detection of Unethical Behavior in Open-Source Software Projects},
year = {2023},
isbn = {9798400703270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611643.3616314},
doi = {10.1145/3611643.3616314},
abstract = {Given the rapid growth of Open-Source Software (OSS) projects, ethical considerations are becoming more important. Past studies focused on specific ethical issues (e.g., gender bias and fairness in OSS). There is little to no study on the different types of unethical behavior in OSS projects. We present the first study of unethical behavior in OSS projects from the stakeholders’ perspective. Our study of 316 GitHub issues provides a taxonomy of 15 types of unethical behavior guided by six ethical principles (e.g., autonomy). Examples of new unethical behavior include soft forking (copying a repository without forking) and self-promotion (promoting a repository without self-identifying as contributor to the repository). We also identify 18 types of software artifacts affected by the unethical behavior. The diverse types of unethical behavior identified in our study (1) call for attentions of developers and researchers when making contributions in GitHub, and (2) point to future research on automated detection of unethical behavior in OSS projects. From our study, we propose Etor, an approach that can automatically detect six types of unethical behavior by using ontological engineering and Semantic Web Rule Language (SWRL) rules to model GitHub attributes and software artifacts. Our evaluation on 195,621 GitHub issues (1,765 GitHub repositories) shows that Etor can automatically detect 548 unethical behavior with 74.8% average true positive rate (up to 100% true positive rate). This shows the feasibility of automated detection of unethical behavior in OSS projects.},
booktitle = {Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {644–656},
numpages = {13},
keywords = {Ethics in Software Engineering, Open-source software projects},
location = {San Francisco, CA, USA},
series = {ESEC/FSE 2023}
}

@inproceedings{10.1145/2593702.2593705,
author = {Thongtanunam, Patanamon and Kula, Raula Gaikovina and Cruz, Ana Erika Camargo and Yoshida, Norihiro and Iida, Hajimu},
title = {Improving code review effectiveness through reviewer recommendations},
year = {2014},
isbn = {9781450328609},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2593702.2593705},
doi = {10.1145/2593702.2593705},
abstract = {Effectively performing code review increases the quality of software and reduces occurrence of defects. However, this requires reviewers with experiences and deep understandings of system code. Manual selection of such reviewers can be a costly and time-consuming task. To reduce this cost, we propose a reviewer recommendation algorithm determining file path similarity called FPS algorithm. Using three OSS projects as case studies, FPS algorithm was accurate up to 77.97%, which significantly outperformed the previous approach.},
booktitle = {Proceedings of the 7th International Workshop on Cooperative and Human Aspects of Software Engineering},
pages = {119–122},
numpages = {4},
keywords = {Software Quality, Recommendation System, Peer Code Review, Open Source Software},
location = {Hyderabad, India},
series = {CHASE 2014}
}

@inproceedings{10.1145/3639478.3639805,
author = {Sun, Jiayi},
title = {Sustaining Scientific Open-Source Software Ecosystems: Challenges, Practices, and Opportunities},
year = {2024},
isbn = {9798400705021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639478.3639805},
doi = {10.1145/3639478.3639805},
abstract = {Scientific open-source software (scientific OSS) has facilitated scientific research due to its transparent and collaborative nature. The sustainability of such software is becoming crucial given its pivotal role in scientific endeavors. While past research has proposed strategies for the sustainability of the scientific software or general OSS communities in isolation, it remains unclear when the two scenarios are merged if these approaches are directly applicable to developing scientific OSS. In this research, we propose to investigate the unique challenges in sustaining the scientific OSS ecosystems. We first conduct a case study to empirically understand the interdisciplinary team's collaboration in scientific OSS ecosystems and identify the collaboration challenges. Further, to generalize our findings, we plan to conduct a large-scale quantitative study in broader scientific OSS ecosystems to identify the cross-project collaboration inefficiencies. Finally, we would like to design and develop interventions to mitigate the problems identified.},
booktitle = {Proceedings of the 2024 IEEE/ACM 46th International Conference on Software Engineering: Companion Proceedings},
pages = {234–236},
numpages = {3},
location = {Lisbon, Portugal},
series = {ICSE-Companion '24}
}

@inproceedings{10.1145/3468264.3468562,
author = {Shi, Lin and Chen, Xiao and Yang, Ye and Jiang, Hanzhi and Jiang, Ziyou and Niu, Nan and Wang, Qing},
title = {A first look at developers’ live chat on Gitter},
year = {2021},
isbn = {9781450385626},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3468264.3468562},
doi = {10.1145/3468264.3468562},
abstract = {Modern communication platforms such as Gitter and Slack play an increasingly critical role in supporting software teamwork, especially in open source development.Conversations on such platforms often contain intensive, valuable information that may be used for better understanding OSS developer communication and collaboration. However, little work has been done in this regard. To bridge the gap, this paper reports a first comprehensive empirical study on developers' live chat, investigating when they interact, what community structures look like, which topics are discussed, and how they interact. We manually analyze 749 dialogs in the first phase, followed by an automated analysis of over 173K dialogs in the second phase. We find that developers tend to converse more often on weekdays, especially on Wednesdays and Thursdays (UTC), that there are three common community structures observed, that developers tend to discuss topics such as API usages and errors, and that six dialog interaction patterns are identified in the live chat communities. Based on the findings, we provide recommendations for individual developers and OSS communities, highlight desired features for platform vendors, and shed light on future research directions. We believe that the findings and insights will enable a better understanding of developers' live chat, pave the way for other researchers, as well as a better utilization and mining of knowledge embedded in the massive chat history.},
booktitle = {Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {391–403},
numpages = {13},
keywords = {Team communication, Open source, Live chat, Empirical Study},
location = {Athens, Greece},
series = {ESEC/FSE 2021}
}

@article{10.1145/3449249,
author = {Geiger, R. Stuart and Howard, Dorothy and Irani, Lilly},
title = {The Labor of Maintaining and Scaling Free and Open-Source Software Projects},
year = {2021},
issue_date = {April 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {CSCW1},
url = {https://doi.org/10.1145/3449249},
doi = {10.1145/3449249},
abstract = {Free and/or open-source software (or F/OSS) projects now play a major and dominant role in society, constituting critical digital infrastructure relied upon by companies, academics, non-profits, activists, and more. As F/OSS has become larger and more established, we investigate the labor of maintaining and sustaining those projects at various scales. We report findings from an interview-based study with contributors and maintainers working in a wide range of F/OSS projects. Maintainers of F/OSS projects do not just maintain software code in a more traditional software engineering understanding of the term: fixing bugs, patching security vulnerabilities, and updating dependencies. F/OSS maintainers also perform complex and often-invisible interpersonal and organizational work to keep their projects operating as active communities of users and contributors. We particularly focus on how this labor of maintaining and sustaining changes as projects and their software grow and scale across many dimensions. In understanding F/OSS to be as much about maintaining a communal project as it is maintaining software code, we discuss broadly applicable considerations for peer production communities and other socio-technical systems more broadly.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = {apr},
articleno = {175},
numpages = {28},
keywords = {free software, infrastructure, labor, maintenance, open source}
}

@article{10.1145/3387111,
author = {Wang, Zhendong and Feng, Yang and Wang, Yi and Jones, James A. and Redmiles, David},
title = {Unveiling Elite Developers’ Activities in Open Source Projects},
year = {2020},
issue_date = {July 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {29},
number = {3},
issn = {1049-331X},
url = {https://doi.org/10.1145/3387111},
doi = {10.1145/3387111},
abstract = {Open source developers, particularly the elite developers who own the administrative privileges for a project, maintain a diverse portfolio of contributing activities. They not only commit source code but also exert significant efforts on other communicative, organizational, and supportive activities. However, almost all prior research focuses on specific activities and fails to analyze elite developers’ activities in a comprehensive way. To bridge this gap, we conduct an empirical study with fine-grained event data from 20 large open source projects hosted on GITHUB. We investigate elite developers’ contributing activities and their impacts on project outcomes. Our analyses reveal three key findings: (1) elite developers participate in a variety of activities, of which technical contributions (e.g., coding) only account for a small proportion; (2) as the project grows, elite developers tend to put more effort into supportive and communicative activities and less effort into coding; and (3) elite developers’ efforts in nontechnical activities are negatively correlated with the project’s outcomes in terms of productivity and quality in general, except for a positive correlation with the bug fix rate (a quality indicator). These results provide an integrated view of elite developers’ activities and can inform an individual’s decision making about effort allocation, which could lead to improved project outcomes. The results also provide implications for supporting these elite developers.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = {jun},
articleno = {16},
numpages = {35},
keywords = {software quality, project outcomes, productivity, open source software (OSS), developers’ activity, Elite developers}
}

@inproceedings{10.1109/ICSE.2019.00088,
author = {Ramsauer, Ralf and Lohmann, Daniel and Mauerer, Wolfgang},
title = {The list is the process: reliable pre-integration tracking of commits on mailing lists},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE.2019.00088},
doi = {10.1109/ICSE.2019.00088},
abstract = {A considerable corpus of research on software evolution focuses on mining changes in software repositories, but omits their pre-integration history.We present a novel method for tracking this otherwise invisible evolution of software changes on mailing lists by connecting all early revisions of changes to their final version in repositories. Since artefact modifications on mailing lists are communicated by updates to fragments (i.e., patches) only, identifying semantically similar changes is a non-trivial task that our approach solves in a language-independent way. We evaluate our method on high-profile open source software (OSS) projects like the Linux kernel, and validate its high accuracy using an elaborately created ground truth.Our approach can be used to quantify properties of OSS development processes, which is an essential requirement for using OSS in reliable or safety-critical industrial products, where certifiability and conformance to processes are crucial. The high accuracy of our technique allows, to the best of our knowledge, for the first time to quantitatively determine if an open development process effectively aligns with given formal process requirements.},
booktitle = {Proceedings of the 41st International Conference on Software Engineering},
pages = {807–818},
numpages = {12},
location = {Montreal, Quebec, Canada},
series = {ICSE '19}
}

@inproceedings{10.1145/3372224.3380893,
author = {Perino, Diego and Yang, Xiaoyuan and Serra, Joan and Lutu, Andra and Leontiadis, Ilias},
title = {Experience: advanced network operations in (Un)-connected remote communities},
year = {2020},
isbn = {9781450370851},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3372224.3380893},
doi = {10.1145/3372224.3380893},
abstract = {The Internet Para Todos program is working to provide sustainable mobile broadband to 100 M unconnected people in Latin America. In this paper we present our commercial deployment in thousands remote small communities and describe the unique experience of maintaining this infrastructure. We describe the challenges related to managing operations containing the cost in these extreme geographical conditions. We also analyze operational data to understand outage patterns and present typical operational issues in this unique remote community environment. Finally, we present an extension of the operations support system (OSS) leveraging advanced analytics and machine learning with the goal of optimizing network maintenance while reducing costs.},
booktitle = {Proceedings of the 26th Annual International Conference on Mobile Computing and Networking},
articleno = {16},
numpages = {10},
keywords = {remote communities, network operations, mobile networks},
location = {London, United Kingdom},
series = {MobiCom '20}
}

@inproceedings{10.1145/3383219.3383240,
author = {Sharma, Pankajeshwara and Savarimuthu, Bastin Tony Roy and Stanger, Nigel},
title = {Mining Decision-Making Processes in Open Source Software Development: A Study of Python Enhancement Proposals (PEPs) using Email Repositories},
year = {2020},
isbn = {9781450377317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3383219.3383240},
doi = {10.1145/3383219.3383240},
abstract = {Open source software (OSS) communities are often able to produce high quality software comparable to proprietary software. The success of an open source software development (OSSD) community is often attributed to the underlying governance model, and a key component of these models is the decision-making (DM) process. While there have been studies on the decision-making processes publicized by OSS communities (e.g., through published process diagrams), little has been done to study decision-making processes that can be extracted using a bottom-up, data-driven approach, which can then be used to assess whether the publicized processes conform to the extracted processes. To bridge this gap, we undertook a large-scale data-driven study to understand how decisions are made in an OSSD community, using the case study of Python Enhancement Proposals (PEPs), which embody decisions made during the evolution of the Python language. Our main contributions are:(a) the design and development of a framework using information retrieval and natural language processing techniques to analyze the Python email archives (comprising 1.48 million emails), and(b) the extraction of decision-making processes that reveal activities that are neither explicitly mentioned in documentation published by the Python community nor identified in prior research work. Our results provide insights into the actual decision-making process employed by the Python community.},
booktitle = {Proceedings of the 24th International Conference on Evaluation and Assessment in Software Engineering},
pages = {200–209},
numpages = {10},
keywords = {decision-making, Python, process extraction, process mining, Open Source software development (OSSD), Mining repositories},
location = {Trondheim, Norway},
series = {EASE '20}
}

@inproceedings{10.1145/3364510.3364521,
author = {Agbo, Friday Joseph and Oyelere, Solomon Sunday and Suhonen, Jarkko and Adewumi, Sunday},
title = {A Systematic Review of Computational Thinking Approach for Programming Education in Higher Education Institutions},
year = {2019},
isbn = {9781450377157},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3364510.3364521},
doi = {10.1145/3364510.3364521},
abstract = {This study examined how computational thinking (CT) has been used to teach problem-solving skills and programming education in the recent past. This study specifically (i) identified articles that discussed CT approach for programming education at higher education institutions (HEIs), (ii) classified the different CT approaches and tools employed for programming education at HEIs, (iii) synthesised and discussed results that are reported by relevant studies that utilized CT for teaching programming at HEIs. A systematic literature review methodology was adopted in this study. Out of 161 articles retrieved, 33 of them that met the inclusion criteria were reviewed. Our study revealed that the use of CT at HEIs for programming education began in 2010; many studies did not specify the context of use, but the use of CT is found to be gaining grounds in many contexts, especially the developed countries; course design approach was mostly employed by educators to introduce CT at HEIs for programming education. Furthermore, this study pointed out how CT approach can be explored for designing a smart learning environment to support students in learning computer programming.},
booktitle = {Proceedings of the 19th Koli Calling International Conference on Computing Education Research},
articleno = {12},
numpages = {10},
keywords = {undergraduates, smart learning, programming, problem-solving, higher education, computational thinking},
location = {Koli, Finland},
series = {Koli Calling '19}
}

@inproceedings{10.1145/3643991.3644924,
author = {Kola-Olawuyi, Ajiromola and Weeraddana, Nimmi Rashinika and Nagappan, Meiyappan},
title = {The Impact of Code Ownership of DevOps Artefacts on the Outcome of DevOps CI Builds},
year = {2024},
isbn = {9798400705878},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643991.3644924},
doi = {10.1145/3643991.3644924},
abstract = {DevOps is a key element in sustaining the quality and efficiency of software development. Yet, the effectiveness of DevOps methodologies extends beyond just technological expertise. It is greatly affected by the manner in which teams handle and engage with DevOps artefacts. Grasping the intricacies of code ownership and contribution patterns within DevOps artefacts is vital for refining strategies and ensuring they deliver their full potential.There are two main strategies to manage DevOps artefacts as suggested in prior work: (1) all project developers need to contribute to DevOps artefacts, and (2) a dedicated group of developers needs to be authoring DevOps artefacts. To analyze which strategy works best for Open-Source Software (OSS) projects, we conduct an empirical analysis on a dataset of 892,193 CircleCI builds spanning 1,689 OSS projects. We employ a two-pronged approach to our study. First, we investigate the impact of chronological code ownership of DevOps artefacts on the outcome of a CI build on a build level. Second, we study the impact of the Skewness of DevOps contributions on the success rate of CI builds at the project level.Our findings reveal that, in general, larger chronological ownership and higher Skewness values of DevOps contributions are related to more successful build outcomes and higher rates of successful build outcomes, respectively. We further find that projects with low Skewness values could have high build success rates when the number of developers in the project is relatively small. Thus, our results suggest that while larger software organizations are better off having dedicated DevOps developers, smaller organizations would benefit from having all developers involved in DevOps.},
booktitle = {Proceedings of the 21st International Conference on Mining Software Repositories},
pages = {543–555},
numpages = {13},
keywords = {DevOps, code ownership, continuous integrations, empirical study},
location = {Lisbon, Portugal},
series = {MSR '24}
}

@inproceedings{10.1145/3597503.3639197,
author = {Zhang, Yuxia and Qin, Mian and Stol, Klaas-Jan and Zhou, Minghui and Liu, Hui},
title = {How Are Paid and Volunteer Open Source Developers Different? A Study of the Rust Project},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3639197},
doi = {10.1145/3597503.3639197},
abstract = {It is now commonplace for organizations to pay developers to work on specific open source software (OSS) projects to pursue their business goals. Such paid developers work alongside voluntary contributors, but given the different motivations of these two groups of developers, conflict may arise, which may pose a threat to a project's sustainability. This paper presents an empirical study of paid developers and volunteers in Rust, a popular open source programming language project. Rust is a particularly interesting case given considerable concerns about corporate participation. We compare volunteers and paid developers through contribution characteristics and long-term participation, and solicit volunteers' perceptions on paid developers. We find that core paid developers tend to contribute more frequently; commits contributed by onetime paid developers have bigger sizes; peripheral paid developers implement more features; and being paid plays a positive role in becoming a long-term contributor. We also find that volunteers do have some prejudices against paid developers. This study suggests that the dichotomous view of paid vs. volunteer developers is too simplistic and that further subgroups can be identified. Companies should become more sensitive to how they engage with OSS communities, in certain ways as suggested by this study.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {195},
numpages = {13},
keywords = {open source software, paid developers, volunteers, sustainability},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inproceedings{10.1109/ICSE48619.2023.00064,
author = {Tan, Xin and Chen, Yiran and Wu, Haohua and Zhou, Minghui and Zhang, Li},
title = {Is it Enough to Recommend Tasks to Newcomers? Understanding Mentoring on Good First Issues},
year = {2023},
isbn = {9781665457019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE48619.2023.00064},
doi = {10.1109/ICSE48619.2023.00064},
abstract = {Newcomers are critical for the success and continuity of open source software (OSS) projects. To attract newcomers and facilitate their onboarding, many OSS projects recommend tasks for newcomers, such as good first issues (GFIs). Previous studies have preliminarily investigated the effects of GFIs and techniques to identify suitable GFIs. However, it is still unclear whether just recommending tasks is enough and how significant mentoring is for newcomers. To better understand mentoring in OSS communities, we analyze the resolution process of 48,402 GFIs from 964 repositories through a mix-method approach. We investigate the extent, the mentorship structures, the discussed topics, and the relevance of expert involvement. We find that ~70% of GFIs have expert participation, with each GFI usually having one expert who makes two comments. Half of GFIs will receive their first expert comment within 8.5 hours after a newcomer comment. Through analysis of the collaboration networks of newcomers and experts, we observe that community mentorship presents four types of structure: centralized mentoring, decentralized mentoring, collaborative mentoring, and distributed mentoring. As for discussed topics, we identify 14 newcomer challenges and 18 expert mentoring content. By fitting the generalized linear models, we find that expert involvement positively correlates with newcomers' successful contributions but negatively correlates with newcomers' retention. Our study manifests the status and significance of mentoring in the OSS projects, which provides rich practical implications for optimizing the mentoring process and helping newcomers contribute smoothly and successfully.},
booktitle = {Proceedings of the 45th International Conference on Software Engineering},
pages = {653–664},
numpages = {12},
keywords = {good first issue, open source, mentoring, newcomer},
location = {Melbourne, Victoria, Australia},
series = {ICSE '23}
}

@inproceedings{10.1109/ICSE48619.2023.00066,
author = {Yin, Likang and Zhang, Xiyu and Filkov, Vladimir},
title = {On the Self-Governance and Episodic Changes in Apache Incubator Projects: An Empirical Study},
year = {2023},
isbn = {9781665457019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE48619.2023.00066},
doi = {10.1109/ICSE48619.2023.00066},
abstract = {Sustainable Open Source Software (OSS) projects are characterized by the ability to attract new project members and maintain an energetic project community. Building sustainable OSS projects from a nascent state requires effective project governance and socio-technical structure to be interleaved, in a complex and dynamic process. Although individual disciplines have studied each separately, little is known about how governance and software development work together in practice toward sustainability. Prior work has shown that many OSS projects experience large, episodic changes over short periods of time, which can propel them or drag them down. However, sustainable projects typically manage to come out unscathed from such changes, while others do not. The natural questions arise: Can we identify the back-and-forth between governance and socio-technical structure that lead to sustainability following episodic events? And, how about those that do not lead to sustainability?From a data set of social, technical, and policy digital traces from 262 sustainability-labeled ASF incubator projects, here we employ a large-scale empirical study to characterize episodic changes in socio-technical aspects measured by Change Intervals (CI), governance rules and regulations in a form of Institutional Statements (IS), and the temporal relationships between them. We find that sustainable projects during episodic changes can adapt themselves to institutional statements more efficiently, and that institutional discussions can lead to episodic changes intervals in socio-technical aspects of the projects, and vice versa. In practice, these results can provide timely guidance beyond socio-technical considerations, adding rules and regulations in the mix, toward a unified analytical framework for OSS project sustainability.},
booktitle = {Proceedings of the 45th International Conference on Software Engineering},
pages = {678–689},
numpages = {12},
location = {Melbourne, Victoria, Australia},
series = {ICSE '23}
}

@inproceedings{10.1145/3530019.3530041,
author = {Das, Ajoy and Uddin, Gias and Ruhe, Guenther},
title = {An Empirical Study of Blockchain Repositories in GitHub},
year = {2022},
isbn = {9781450396134},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3530019.3530041},
doi = {10.1145/3530019.3530041},
abstract = {Blockchain is a distributed ledger technique that guarantees the traceability of transactions. Blockchain is adopted in multiple domains like finance (e.g., cryptocurrency), healthcare, security, and supply chain. In the open-source software (OSS) portal GitHub, we observe a growing adoption of Blockchain-based solutions. Given the rapid emergence of Blockchain-based solutions in our daily life and the evolving cryptocurrency market, it is important to know the status quo, how developers generally interact in those repos, and how much freedom they have in applying code changes. We report an empirical study of 3,664 Blockchain software repositories from GitHub. We divide the Blockchain repositories into two categories: Tool (e.g., SDKs) and Applications (e.g., service/solutions developed using SDKs). The Application category is further divided into two sub-categories: Crypto and Non-Crypto applications. In all Blockchain repository categories, the contribution interactions on commits are the most common interaction type. We found that more organizations contributing to the Blockchain repos than individual users. The median numbers of internal and external users in tools are higher than the application repos. We observed a higher degree of collaboration (e.g., for maintenance efforts) among users in Blockchain tools than those in the application repos. Among the artifacts, issues have a greater number of interactions than commits and pull requests. Related to autonomy we found that less than half of total project contributions are autonomous. Our findings offer implications to Blockchain stakeholders, like developers to stay aware of OSS practices around Blockchain software.},
booktitle = {Proceedings of the 26th International Conference on Evaluation and Assessment in Software Engineering},
pages = {211–220},
numpages = {10},
keywords = {Repositories, GitHub, Cryptocurrency, Blockchain, Bitcoin},
location = {Gothenburg, Sweden},
series = {EASE '22}
}

@inproceedings{10.1145/3551349.3559570,
author = {Sarker, Jaydeb},
title = {Identification and Mitigation of Toxic Communications Among Open Source Software Developers},
year = {2023},
isbn = {9781450394758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3551349.3559570},
doi = {10.1145/3551349.3559570},
abstract = {Toxic and unhealthy conversations during the developer’s communication may reduce the professional harmony and productivity of Free and Open Source Software (FOSS) projects. For example, toxic code review comments may raise pushback from an author to complete suggested changes. A toxic communication with another person may hamper future communication and collaboration. Research also suggests that toxicity disproportionately impacts newcomers, women, and other participants from marginalized groups. Therefore, toxicity is a barrier to promote diversity, equity, and inclusion. Since the occurrence of toxic communications is not uncommon among FOSS communities and such communications may have serious repercussions, the primary objective of my proposed dissertation is to automatically identify and mitigate toxicity during developers’ textual interactions. On this goal, I aim to: i) build an automated toxicity detector for Software Engineering (SE) domain, ii) identify the notion of toxicity across demographics, and iii) analyze the impacts of toxicity on the outcomes of Open Source Software (OSS) projects.},
booktitle = {Proceedings of the 37th IEEE/ACM International Conference on Automated Software Engineering},
articleno = {124},
numpages = {5},
keywords = {toxicity, developers’ interactions, deep learning, NLP},
location = {Rochester, MI, USA},
series = {ASE '22}
}

@article{10.1109/TNET.2013.2297678,
author = {Dainotti, Alberto and King, Alistair and Claffy, Kimberly and Papale, Ferdinando and Pescap\'{e}, Antonio},
title = {Analysis of a "/0" stealth scan from a botnet},
year = {2015},
issue_date = {April 2015},
publisher = {IEEE Press},
volume = {23},
number = {2},
issn = {1063-6692},
url = {https://doi.org/10.1109/TNET.2013.2297678},
doi = {10.1109/TNET.2013.2297678},
abstract = {Botnets are the most common vehicle of cyber-criminal activity. They are used for spamming, phishing, denial-of-service attacks, brute-force cracking, stealing private information, and cyber warfare. Botnets carry out network scans for several reasons, including searching for vulnerable machines to infect and recruit into the botnet, probing networks for enumeration or penetration, etc. We present the measurement and analysis of a horizontal scan of the entire IPv4 address space conducted by the Sality botnet in February 2011. This 12-day scan originated from approximately 3 million distinct IP addresses and used a heavily coordinated and unusually covert scanning strategy to try to discover and compromise VoIP-related (SIP server) infrastructure. We observed this event through the UCSD Network Telescope, a /8 darknet continuously receiving large amounts of unsolicited traffic, and we correlate this traffic data with other public sources of data to validate our inferences. Sality is one of the largest botnets ever identified by researchers. Its behavior represents ominous advances in the evolution of modern malware: the use of more sophisticated stealth scanning strategies by millions of coordinated bots, targeting critical voice communications infrastructure. This paper offers a detailed dissection of the botnet's scanning behavior, including general methods to correlate, visualize, and extrapolate botnet behavior across the global Internet},
journal = {IEEE/ACM Trans. Netw.},
month = {apr},
pages = {341–354},
numpages = {14},
keywords = {scanning, network probing, darknet, communication system security, VoIP, Network Telescope, Internet telephony, Internet background radiation, Botnet}
}

@inproceedings{10.1109/ICSE-SEET52601.2021.00024,
author = {Alves, Isaque and Rocha, Carla},
title = {Qualifying software engineers undergraduates in DevOps - challenges of introducing technical and non-technical concepts in a project-oriented course},
year = {2021},
isbn = {9780738133201},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-SEET52601.2021.00024},
doi = {10.1109/ICSE-SEET52601.2021.00024},
abstract = {The constant changes in the software industry, practices, and methodologies impose challenges to teaching and learning current software engineering concepts and skills. DevOps is particularly challenging because it covers technical concepts, such as pipeline automation, and non-technical ones, such as team roles and project management. The present study investigates a course setup to introduce these concepts to software engineering undergraduates. We designed the course by employing coding to associate DevOps concepts to Agile, Lean, and Open source practices and tools. We present the main aspects of this project-oriented DevOps course, with 240 students enrolled it since its first offering in 2016. We conducted an empirical study, with both a quantitative and qualitative analysis, to evaluate this project-oriented course setup. We collected the data from the projects repository and students' perceptions from a questionnaire. We mined 148 repositories (corresponding to 72 projects) and obtained 86 valid responses to the questionnaire. We also mapped the concepts which are more challenging to students learn from experience. The results evidence that first-hand experience facilitates the comprehension of DevOps concepts and enriches classes discussions. we present a set of lessons learned, which may help professors better design and conduct project-oriented courses to cover DevOps concepts.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering: Joint Track on Software Engineering Education and Training},
pages = {144–153},
numpages = {10},
keywords = {tools and environments, open source, empirical software engineering, emerging domains of software, education, OSS, FOSS, DevOps, Agile software development},
location = {Virtual Event, Spain},
series = {ICSE-JSEET '21}
}

@inproceedings{10.1145/143365.143495,
author = {Anderson, Thomas E. and Owicki, Susan S. and Saxe, James B. and Thacker, Charles P.},
title = {High speed switch scheduling for local area networks},
year = {1992},
isbn = {0897915348},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/143365.143495},
doi = {10.1145/143365.143495},
booktitle = {Proceedings of the Fifth International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {98–110},
numpages = {13},
location = {Boston, Massachusetts, USA},
series = {ASPLOS V}
}

@article{10.1145/3449232,
author = {Klug, Daniel and Bogart, Christopher and Herbsleb, James D.},
title = {"They Can Only Ever Guide": How an Open Source Software Community Uses Roadmaps to Coordinate Effort},
year = {2021},
issue_date = {April 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {CSCW1},
url = {https://doi.org/10.1145/3449232},
doi = {10.1145/3449232},
abstract = {Unlike in commercial software development, open source software (OSS) projects do not generally have managers with direct control over how developers spend their time, yet for projects with large, diverse sets of contributors, the need exists to focus and steer development in a particular direction in a coordinated way. This is especially important for "infrastructure" projects, such as critical libraries and programming languages that many other people depend on. Some projects have taken the approach of borrowing planning tools that originated in commercial development, despite the fact that these techniques were designed for very different contexts, e.g. strong top-down control and profit motives. Little research has been done to understand how these practices are adapted to a new context. In this paper, we examine the Rust project's use of roadmaps: how has an important OSS infrastructure project adapted an inherently top-down tool to the freewheeling world of OSS? We find that because Rust's roadmaps are built in part by summarizing what motivated developers most prefer to work on, they are in some ways more a description of the motivated labor available than they are a directive that the community move in a particular direction. They allow the community to avoid wasting time on unpopular proposals by revealing that there will be little help in building them, and encouraging work on popular features by making visible the amount of consensus in those features. Roadmaps generate a collective focus without limiting the full scope of what developers work on: roadmap issues consume proportionally more effort than other issues, but constitute a minority of the work done (i.e issues and pull requests made) by both central and peripheral participants. They also create transparency among and beyond the community into what central contributors' plans are, and allow more rational decision-making by providing a way for evidence about community needs to be linked to decision-making.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = {apr},
articleno = {158},
numpages = {28},
keywords = {collaboration, common pool resources, open source, rust language}
}

@article{10.1145/1275986.1275989,
author = {Wagner, Fl\'{a}vio R. and Ces\'{a}rio, Wander and Jerraya, Ahmed A.},
title = {Hardware/software IP integration using the ROSES design environment},
year = {2007},
issue_date = {July 2007},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {3},
issn = {1539-9087},
url = {https://doi.org/10.1145/1275986.1275989},
doi = {10.1145/1275986.1275989},
abstract = {Considering current time-to-market pressures, IP reuse is mandatory for the design of complex embedded systems-on-chip (SoC). The integration of IP components into a given design is the most complex task in the whole reuse process. This paper describes the IP integration approach implemented in the ROSES design environment, which presents a unique combination of features that enhance IP reuse: automatic assembly of interfaces between heterogeneous software and hardware IP components; easy adaptation to different on-chip communication structures and bus and core standards; generation of customized and minimal OSs for programmable components; and an architecture-independent high-level API embedded into SystemC that makes application software independent from system implementation. Application code is written by using communication functions available in this API. ROSES automatically assembles wrappers that implement these functions, such that the application code does not need to be modified in order to run in the final synthesized system.},
journal = {ACM Trans. Embed. Comput. Syst.},
month = {jul},
pages = {17–es},
numpages = {23},
keywords = {Systems-on-chip, IP integration}
}

@inproceedings{10.1109/ASE51524.2021.9678923,
author = {Pan, Shengyi and Bao, Lingfeng and Ren, Xiaoxue and Xia, Xin and Lo, David and Li, Shanping},
title = {Automating developer chat mining},
year = {2022},
isbn = {9781665403375},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE51524.2021.9678923},
doi = {10.1109/ASE51524.2021.9678923},
abstract = {Online chatrooms are gaining popularity as a communication channel between widely distributed developers of Open Source Software (OSS) projects. Most discussion threads in chatrooms follow a Q&amp;A format, with some developers (askers) raising an initial question and others (respondents) joining in to provide answers. These discussion threads are embedded with rich information that can satisfy the diverse needs of various OSS stakeholders. However, retrieving information from threads is challenging as it requires a thread-level analysis to understand the context. Moreover, the chat data is transient and unstructured, consisting of entangled informal conversations. In this paper, we address this challenge by identifying the information types available in developer chats and further introducing an automated mining technique. Through manual examination of chat data from three chatrooms on Gitter, using card sorting, we build a thread-level taxonomy with nine information categories and create a labeled dataset with 2,959 threads. We propose a classification approach (named F2Chat) to structure the vast amount of threads based on the information type automatically, helping stakeholders quickly acquire their desired information. F2Chat effectively combines handcrafted non-textual features with deep textual features extracted by neural models. Specifically, it has two stages with the first one leveraging the siamese architecture to pretrain the textual feature encoder, and the second one facilitating an in-depth fusion of two types of features. Evaluation results suggest that our approach achieves an average F1-score of 0.628, which improves the baseline by 57%. Experiments also verify the effectiveness of our identified non-textual features under both intra-project and cross-project validations.},
booktitle = {Proceedings of the 36th IEEE/ACM International Conference on Automated Software Engineering},
pages = {854–866},
numpages = {13},
keywords = {information mining, gitter, developer chatrooms, deep learning},
location = {Melbourne, Australia},
series = {ASE '21}
}

@inproceedings{10.1145/1600176.1600186,
author = {Solworth, Jon A.},
title = {Robustly secure computer systems: a new security paradigm of system discontinuity},
year = {2008},
isbn = {9781605580807},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1600176.1600186},
doi = {10.1145/1600176.1600186},
abstract = {For over 30 years, system software has been bound by compatibility with legacy applications. The system software base, whether proprietary or open source, is dominated by the programming language C and the POSIX operating system specification. Even when commercial operating systems stray from this model, they don't go very far.Unfortunately, the POSIX/C base was constructed in a more benign environment than today and before many security issues were widely understood. Rather than fix these issues, compatibility has been deemed more important than security, and so this base has been kept intact with all its flaws. As a result, programmers routinely create software with security holes---even in the most security critical software---and today's systems are easily attacked.We propose a new paradigm of system discontinuity which emphasizes security over compatibility by removing those constructs in our system software which lead to security holes in applications. Of course, removing parts of the interface will break applications, and hence the discontinuity. To deal with this situation, we advocate the use of virtual machines to enable multiple operating systems to run concurrently. Thus high security OSs can be used for the most security sensitive applications. Compatibility is maintained for less security sensitive applications using legacy operating systems. Over time, legacy applications can migrate to a more secure OS, thus raising the security of all applications.},
booktitle = {Proceedings of the 2007 Workshop on New Security Paradigms},
pages = {55–65},
numpages = {11},
keywords = {virtual machines, security, operating systems, design for security, application programming interface},
location = {New Hampshire},
series = {NSPW '07}
}

@inproceedings{10.1109/ICSE43902.2021.00124,
author = {Paul, Rajshakhar and Turzo, Asif Kamal and Bosu, Amiangshu},
title = {Why Security Defects Go Unnoticed during Code Reviews? A Case-Control Study of the Chromium OS Project},
year = {2021},
isbn = {9781450390859},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE43902.2021.00124},
doi = {10.1109/ICSE43902.2021.00124},
abstract = {Peer code review has been found to be effective in identifying security vulnerabilities. However, despite practicing mandatory code reviews, many Open Source Software (OSS) projects still encounter a large number of post-release security vulnerabilities, as some security defects escape those. Therefore, a project manager may wonder if there was any weakness or inconsistency during a code review that missed a security vulnerability. Answers to this question may help a manager pinpointing areas of concern and taking measures to improve the effectiveness of his/her project's code reviews in identifying security defects. Therefore, this study aims to identify the factors that differentiate code reviews that successfully identified security defects from those that missed such defects.With this goal, we conduct a case-control study of Chromium OS project. Using multi-stage semi-automated approaches, we build a dataset of 516 code reviews that successfully identified security defects and 374 code reviews where security defects escaped. The results of our empirical study suggest that the are significant differences between the categories of security defects that are identified and that are missed during code reviews. A logistic regression model fitted on our dataset achieved an AUC score of 0.91 and has identified nine code review attributes that influence identifications of security defects. While time to complete a review, the number of mutual reviews between two developers, and if the review is for a bug fix have positive impacts on vulnerability identification, opposite effects are observed from the number of directories under review, the number of total reviews by a developer, and the total number of prior commits for the file under review.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering},
pages = {1373–1385},
numpages = {13},
keywords = {vulnerability, security, code review},
location = {Madrid, Spain},
series = {ICSE '21}
}

@article{10.1109/TNET.2015.2447492,
author = {Shamsi, Zain and Nandwani, Ankur and Leonard, Derek and Loguinov, Dmitri and Shamsi, Zain and Nandwani, Ankur and Leonard, Derek and Loguinov, Dmitri},
title = {Hershel: Single-Packet OS Fingerprinting},
year = {2016},
issue_date = {August 2016},
publisher = {IEEE Press},
volume = {24},
number = {4},
issn = {1063-6692},
url = {https://doi.org/10.1109/TNET.2015.2447492},
doi = {10.1109/TNET.2015.2447492},
abstract = {Traditional TCP/IP fingerprinting tools e.g., nmap are poorly suited for Internet-wide use due to the large amount of traffic and intrusive nature of the probes. This can be overcome by approaches that rely on a single SYN packet to elicit a vector of features from the remote server. However, these methods face difficult classification problems due to the high volatility of the features and severely limited amounts of information contained therein. Since these techniques have not been studied before, we first pioneer stochastic theory of single-packet OS fingerprinting, build a database of 116 OSs, design a classifier based on our models, evaluate its accuracy in simulations, and then perform OS classification of 37.8M hosts from an Internet-wide scan.},
journal = {IEEE/ACM Trans. Netw.},
month = {aug},
pages = {2196–2209},
numpages = {14}
}

@inproceedings{10.1109/ICSE43902.2021.00094,
author = {Dey, Tapajit and Karnauch, Andrey and Mockus, Audris},
title = {Representation of Developer Expertise in Open Source Software},
year = {2021},
isbn = {9781450390859},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE43902.2021.00094},
doi = {10.1109/ICSE43902.2021.00094},
abstract = {Background: Accurate representation of developer expertise has always been an important research problem. While a number of studies proposed novel methods of representing expertise within individual projects, these methods are difficult to apply at an ecosystem level. However, with the focus of software development shifting from monolithic to modular, a method of representing developers' expertise in the context of the entire OSS development becomes necessary when, for example, a project tries to find new maintainers and look for developers with relevant skills. Aim: We aim to address this knowledge gap by proposing and constructing the Skill Space where each API, developer, and project is represented and postulate how the topology of this space should reflect what developers know (and projects need). Method: we use the World of Code infrastructure to extract the complete set of APIs in the files changed by open source developers and, based on that data, employ Doc2Vec embeddings for vector representations of APIs, developers, and projects. We then evaluate if these embeddings reflect the postulated topology of the Skill Space by predicting what new APIs/projects developers use/join, and whether or not their pull requests get accepted. We also check how the developers' representations in the Skill Space align with their self-reported API expertise. Result: Our results suggest that the proposed embeddings in the Skill Space appear to satisfy the postulated topology and we hope that such representations may aid in the construction of signals that increase trust (and efficiency) of open source ecosystems at large and may aid investigations of other phenomena related to developer proficiency and learning.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering},
pages = {995–1007},
numpages = {13},
keywords = {World of Code, Vector Embedding, Skill Space, Project embedding, Open Source, Machine Learning, Expertise, Doc2Vec, Developer embedding, Developer Expertise, API embedding, API},
location = {Madrid, Spain},
series = {ICSE '21}
}

@inproceedings{10.1145/3379597.3387500,
author = {Fry, Tanner and Dey, Tapajit and Karnauch, Andrey and Mockus, Audris},
title = {A Dataset and an Approach for Identity Resolution of 38 Million Author IDs extracted from 2B Git Commits},
year = {2020},
isbn = {9781450375177},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3379597.3387500},
doi = {10.1145/3379597.3387500},
abstract = {The data collected from open source projects provide means to model large software ecosystems, but often suffer from data quality issues, specifically, multiple author identification strings in code commits might actually be associated with one developer. While many methods have been proposed for addressing this problem, they are either heuristics requiring manual tweaking, or require too much calculation time to do pairwise comparisons for 38M author IDs in, for example, the World of Code collection. In this paper, we propose a method that finds all author IDs belonging to a single developer in this entire dataset, and share the list of all author IDs that were found to have aliases. To do this, we first create blocks of potentially connected author IDs and then use a machine learning model to predict which of these potentially related IDs belong to the same developer. We processed around 38 million author IDs and found around 14.8 million IDs to have an alias, which belong to 5.4 million different developers, with the median number of aliases being 2 per developer. This dataset can be used to create more accurate models of developer behaviour at the entire OSS ecosystem level and can be used to provide a service to rapidly resolve new author IDs.},
booktitle = {Proceedings of the 17th International Conference on Mining Software Repositories},
pages = {518–522},
numpages = {5},
keywords = {Machine Learning, Identity Resolution, Heuristics, Git Commits, Data Sharing},
location = {Seoul, Republic of Korea},
series = {MSR '20}
}

@inproceedings{10.1145/3183440.3190332,
author = {Beller, Moritz},
title = {Toward an empirical theory of feedback-driven development},
year = {2018},
isbn = {9781450356633},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3183440.3190332},
doi = {10.1145/3183440.3190332},
abstract = {Software developers today crave for feedback, be it from their peers or even bots in the form of code review, static analysis tools like their compiler, or the local or remote execution of their tests in the Continuous Integration (CI) environment. With the advent of social coding sites like GitHub and tight integration of CI services like Travis CI, software development practices have fundamentally changed. Despite a highly changed software engineering landscape, however, we still lack a suitable description of an individual's contemporary software development practices, that is how an individual code contribution comes to be. Existing descriptions like the v-model are either too coarse-grained to describe an individual contributor's workflow, or only regard a sub-part of the development process like Test-Driven Development. In addition, most existing models are pre- rather than de-scriptive. By contrast, in our thesis, we perform a series of empirical studies to describe the individual constituents of Feedback-Driven Development (FDD) and then compile the evidence into an initial framework on how modern software development works. Our thesis culminates in the finding that feedback loops are the characterizing criterion of contemporary software development. Our model is flexible enough to accommodate a broad bandwidth of contemporary workflows, despite large variances in how projects use and configure parts of FDD.},
booktitle = {Proceedings of the 40th International Conference on Software Engineering: Companion Proceeedings},
pages = {503–505},
numpages = {3},
location = {Gothenburg, Sweden},
series = {ICSE '18}
}

@inproceedings{10.1145/3560835.3564557,
author = {Hejderup, Joseph},
title = {On the Use of Tests for Software Supply Chain Threats},
year = {2022},
isbn = {9781450398855},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560835.3564557},
doi = {10.1145/3560835.3564557},
abstract = {Development teams are increasingly investing in automating the updating of third-party libraries to limit the patch time of zero-day exploits such as the Equifax breach. GitHub bots such as Dependabot and Renovate build such functionality by leveraging existing test infrastructure in repositories to test and evaluate new library updates. However, two recent studies suggest that test suites in projects lack effectiveness and coverage to reliably find regressions in third-party libraries. Adequate test coverage and effectiveness are critical in discovering new vulnerabilities and weaknesses from third-party libraries. The recent Log4Shell incident exemplifies this, as projects will likely not have adequate tests for logging libraries. This position paper discusses the weaknesses and challenges of current testing practices and techniques from a supply chain security perspective. We highlight two key challenges that researchers and practitioners need to address: (1) the lack of resources and best practices for testing the uses of third-party libraries and (2) enhancing the reliability of automating library updates.},
booktitle = {Proceedings of the 2022 ACM Workshop on Software Supply Chain Offensive Research and Ecosystem Defenses},
pages = {47–49},
numpages = {3},
keywords = {dependency updates, package repositories, software supply chain threats, testing practices},
location = {Los Angeles, CA, USA},
series = {SCORED'22}
}

@inproceedings{10.1145/2659651.2659671,
author = {Weldemariam, Komminist and Shahriar, Hossain and Devendran, VamsheeKrishna},
title = {Dynamic Analysis of Web Objects},
year = {2014},
isbn = {9781450330336},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2659651.2659671},
doi = {10.1145/2659651.2659671},
abstract = {Various reports show that web browsers are known for being insecure, with growing amount of flaws that make them vulnerable to various attacks. Such attacks can be used to execute arbitrary procedures on the victims' computer and silently install malicious software, turning them into bots. In addition, browsers are complex and typically incorporate third-party libraries installed on-demand. This makes it very difficult for security experts to analyze the causes of such flaws or devise countermeasures. In this paper, we present an approach to detect and prevent attacks against a browser by intercepting the interactions between its core libraries and the underlying operating system. We then build mathematical models that capture the behavior of the browser during the rendering of web objects. Finally, we show that such models can be leveraged to automatically classify web objects as malicious or benign using real-world malicious websites.},
booktitle = {Proceedings of the 7th International Conference on Security of Information and Networks},
pages = {423–428},
numpages = {6},
keywords = {Malicious Webpages, HMM, Detection, Browser, Analysis},
location = {Glasgow, Scotland, UK},
series = {SIN '14}
}

@article{10.1145/3611668,
author = {Nourry, Olivier and Kashiwa, Yutaro and Lin, Bin and Bavota, Gabriele and Lanza, Michele and Kamei, Yasutaka},
title = {The Human Side of Fuzzing: Challenges Faced by Developers during Fuzzing Activities},
year = {2023},
issue_date = {January 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {1},
issn = {1049-331X},
url = {https://doi.org/10.1145/3611668},
doi = {10.1145/3611668},
abstract = {Fuzz testing, also known as fuzzing, is a software testing technique aimed at identifying software vulnerabilities. In recent decades, fuzzing has gained increasing popularity in the research community. However, existing studies led by fuzzing experts mainly focus on improving the coverage and performance of fuzzing techniques. That is, there is still a gap in empirical knowledge regarding fuzzing, especially about the challenges developers face when they adopt fuzzing. Understanding these challenges can provide valuable insights to both practitioners and researchers on how to further improve fuzzing processes and techniques.We conducted a study to understand the challenges encountered by developers during fuzzing. More specifically, we first manually analyzed 829 randomly sampled fuzzing-related GitHub issues and constructed a taxonomy consisting of 39 types of challenges (22 related to the fuzzing process itself, 17 related to using external fuzzing providers). We then surveyed 106 fuzzing practitioners to verify the validity of our taxonomy and collected feedback on how the fuzzing process can be improved. Our taxonomy, accompanied with representative examples and highlighted implications, can serve as a reference point on how to better adopt fuzzing techniques for practitioners, and indicates potential directions researchers can work on toward better fuzzing approaches and practices.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = {nov},
articleno = {14},
numpages = {26},
keywords = {empirical software engineering, software testing, Fuzzing}
}

@article{10.1145/3593803,
author = {Bock, Thomas and Alznauer, Nils and Joblin, Mitchell and Apel, Sven},
title = {Automatic Core-Developer Identification on GitHub: A Validation Study},
year = {2023},
issue_date = {November 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {32},
number = {6},
issn = {1049-331X},
url = {https://doi.org/10.1145/3593803},
doi = {10.1145/3593803},
abstract = {Many open-source software projects are self-organized and do not maintain official lists with information on developer roles. So, knowing which developers take core and maintainer roles is, despite being relevant, often tacit knowledge. We propose a method to automatically identify core developers based on role permissions of privileged events triggered in GitHub issues and pull requests. In an empirical study on 25/GitHub projects, (1) we validate the set of automatically identified core developers with a sample of project-reported developer lists, and (2) we use our set of identified core developers to assess the accuracy of state-of-the-art unsupervised developer classification methods. Our results indicate that the set of core developers, which we extracted from privileged issue events, is sound and the accuracy of state-of-the-art unsupervised classification methods depends mainly on the data source (commit data versus issue data) rather than the network-construction method (directed versus undirected, etc.). In perspective, our results shall guide research and practice to choose appropriate unsupervised classification methods, and our method can help create reliable ground-truth data for training supervised classification methods.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = {sep},
articleno = {138},
numpages = {29},
keywords = {developer networks, developer classification, Open-source software projects}
}

@article{10.1145/3579639,
author = {Rahman, Akond and Shamim, Shazibul Islam and Bose, Dibyendu Brinto and Pandita, Rahul},
title = {Security Misconfigurations in Open Source Kubernetes Manifests: An Empirical Study},
year = {2023},
issue_date = {July 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {32},
number = {4},
issn = {1049-331X},
url = {https://doi.org/10.1145/3579639},
doi = {10.1145/3579639},
abstract = {Context: Kubernetes has emerged as the de-facto tool for automated container orchestration. Business and government organizations are increasingly adopting Kubernetes for automated software deployments. Kubernetes is being used to provision applications in a wide range of domains, such as time series forecasting, edge computing, and high-performance computing. Due to such a pervasive presence, Kubernetes-related security misconfigurations can cause large-scale security breaches. Thus, a systematic analysis of security misconfigurations in Kubernetes manifests, i.e., configuration files used for Kubernetes, can help practitioners secure their Kubernetes clusters.Objective: The goal of this paper is to help practitioners secure their Kubernetes clusters by identifying security misconfigurations that occur in Kubernetes manifests.Methodology: We conduct an empirical study with 2,039 Kubernetes manifests mined from 92 open-source software repositories to systematically characterize security misconfigurations in Kubernetes manifests. We also construct a static analysis tool called Security Linter for Kubernetes Manifests (SLI-KUBE) to quantify the frequency of the identified security misconfigurations.Results: In all, we identify 11 categories of security misconfigurations, such as absent resource limit, absent securityContext, and activation of hostIPC. Specifically, we identify 1,051 security misconfigurations in 2,039 manifests. We also observe the identified security misconfigurations affect entities that perform mesh-related load balancing, as well as provision pods and stateful applications. Furthermore, practitioners agreed to fix 60% of 10 misconfigurations reported by us.Conclusion: Our empirical study shows Kubernetes manifests to include security misconfigurations, which necessitates security-focused code reviews and application of static analysis when Kubernetes manifests are developed.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = {may},
articleno = {99},
numpages = {36},
keywords = {security, misconfiguration, Kubernetes, empirical study, devsecops, devops, container orchestration, Configuration}
}

@inproceedings{10.1145/3524842.3527941,
author = {Ait, Adem and Izquierdo, Javier Luis C\'{a}novas and Cabot, Jordi},
title = {An empirical study on the survival rate of GitHub projects},
year = {2022},
isbn = {9781450393034},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3524842.3527941},
doi = {10.1145/3524842.3527941},
abstract = {The number of Open Source projects hosted in social coding platforms such as GitHub is constantly growing. However, many of these projects are not regularly maintained and some are even abandoned shortly after they were created. In this paper we analyze early project development dynamics in software projects hosted on GitHub, including their survival rate. To this aim, we collected all 1,127 GitHub repositories from four different ecosystems (i.e., NPM packages, R packages, WordPress plugins and Laravel packages) created in 2016. We stored their activity in a time series database and analyzed their activity evolution along their lifespan, from 2016 to now. Our results reveal that the prototypical development process consists of intensive coding-driven active periods followed by long periods of inactivity. More importantly, we have found that a significant number of projects die in the first year of existence with the survival rate decreasing year after year. In fact, the probability of surviving longer than five years is less than 50% though some types of projects have better chances of survival.},
booktitle = {Proceedings of the 19th International Conference on Mining Software Repositories},
pages = {365–375},
numpages = {11},
keywords = {survival analysis, open source analysis, mining software repositories, empirical study},
location = {Pittsburgh, Pennsylvania},
series = {MSR '22}
}

@inproceedings{10.1145/3510003.3510205,
author = {Tian, Yingchen and Zhang, Yuxia and Stol, Klaas-Jan and Jiang, Lin and Liu, Hui},
title = {What makes a good commit message?},
year = {2022},
isbn = {9781450392211},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3510003.3510205},
doi = {10.1145/3510003.3510205},
abstract = {A key issue in collaborative software development is communication among developers. One modality of communication is a commit message, in which developers describe the changes they make in a repository. As such, commit messages serve as an "audit trail" by which developers can understand how the source code of a project has changed---and why. Hence, the quality of commit messages affects the effectiveness of communication among developers. Commit messages are often of poor quality as developers lack time and motivation to craft a good message. Several automatic approaches have been proposed to generate commit messages. However, these are based on uncurated datasets including considerable proportions of poorly phrased commit messages. In this multi-method study, we first define what constitutes a "good" commit message, and then establish what proportion of commit messages lack information using a sample of almost 1,600 messages from five highly active open source projects. We find that an average of circa 44% of messages could be improved, suggesting the use of uncurated datasets may be a major threat when commit message generators are trained with such data. We also observe that prior work has not considered semantics of commit messages, and there is surprisingly little guidance available for writing good commit messages. To that end, we develop a taxonomy based on recurring patterns in commit messages' expressions. Finally, we investigate whether "good" commit messages can be automatically identified; such automation could prompt developers to write better commit messages.},
booktitle = {Proceedings of the 44th International Conference on Software Engineering},
pages = {2389–2401},
numpages = {13},
keywords = {open collaboration, commit-based software development, commit message quality},
location = {Pittsburgh, Pennsylvania},
series = {ICSE '22}
}

@inproceedings{10.1145/1460563.1460573,
author = {Kriplean, Travis and Beschastnikh, Ivan and McDonald, David W.},
title = {Articulations of wikiwork: uncovering valued work in wikipedia through barnstars},
year = {2008},
isbn = {9781605580074},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1460563.1460573},
doi = {10.1145/1460563.1460573},
abstract = {Successful online communities have complex cooperative arrangements, articulations of work, and integration practices. They require technical infrastructure to support a broad division of labor. Yet the research literature lacks empirical studies that detail which types of work are valued by participants in an online community. A content analysis of Wikipedia barnstars -- personalized tokens of appreciation given to participants -- reveals a wide range of valued work extending far beyond simple editing to include social support, administrative actions, and types of articulation work. Our analysis develops a theoretical lens for understanding how wiki software supports the creation of articulations of work. We give implications of our results for communities engaged in large-scale collaborations.},
booktitle = {Proceedings of the 2008 ACM Conference on Computer Supported Cooperative Work},
pages = {47–56},
numpages = {10},
keywords = {wikipedia, online community, commons-based peer production, barnstars, articulation work},
location = {San Diego, CA, USA},
series = {CSCW '08}
}

@inproceedings{10.1145/3341105.3374056,
author = {Rath, Michael and M\"{a}der, Patrick},
title = {Request for comments: conversation patterns in issue tracking systems of open-source projects},
year = {2020},
isbn = {9781450368667},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341105.3374056},
doi = {10.1145/3341105.3374056},
abstract = {Issue tracking systems play an important role in developing software systems. They provide a central place to store and maintain different development artifacts. Various studies are concerned with the contained bug reports, features, the relations among them and traces to the projects code base. However, an issue tracker can also be used as a communication channel between project contributors by attaching comments to issues. Less is known on how users actually utilize this functionality. In this paper, we study more than 270,000 comments from twelve open-source projects. We analyze to what extend comments are used and then study the structure occurring in threads of comments. Based on the order of comments and participating contributors, we identified three patterns of conversation: monolog, feedback, and collaboration. Our results show that most conversations are collaborations among two or more developers discussing the issue.},
booktitle = {Proceedings of the 35th Annual ACM Symposium on Applied Computing},
pages = {1414–1417},
numpages = {4},
keywords = {issue tracking systems, human factors, developer communication, comments},
location = {Brno, Czech Republic},
series = {SAC '20}
}

@inproceedings{10.5555/324493.325090,
author = {Weikum, Gerhard},
title = {Pros and cons of operating system transactions for data base systems},
year = {1986},
isbn = {0818647434},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
booktitle = {Proceedings of 1986 ACM Fall Joint Computer Conference},
pages = {1219–1225},
numpages = {7},
location = {Dallas, Texas, USA},
series = {ACM '86}
}

@inproceedings{10.1109/ICSE-SEIS58686.2023.00025,
author = {Qiu, Huilian Sophie and Zhao, Zihe H and Yu, Tielin Katy and Wang, Justin and Ma, Alexander and Fang, Hongbo and Dabbish, Laura and Vasilescu, Bogdan},
title = {Gender Representation Among Contributors to Open-Source Infrastructure: An Analysis of 20 Package Manager Ecosystems},
year = {2023},
isbn = {9798350322613},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-SEIS58686.2023.00025},
doi = {10.1109/ICSE-SEIS58686.2023.00025},
abstract = {While the severe underrepresentation of women and non-binary people in open source is widely recognized, there is little empirical data on how the situation has changed over time and which subcommunities have been more effectively reducing the gender imbalance. To obtain a clearer image of gender representation in open source, we compiled and synthesized existing empirical data from the literature, and computed historical trends in the representation of women across 20 open source ecosystems. While inherently limited by the ability of automatic name-based gender inference to capture true gender identities at an individual level, our census still provides valuable populationlevel insights. Across all and in most ecosystems, we observed a promising upward trend in the percentage of women among code contributors over time, but also high variation in the percentage of women contributors across ecosystems. We also found that, in most ecosystems, women withdraw earlier from open-source participation than men.The representation of women and non-binary people has been extremely low in the open-source software community. Most of the statistics reported by prior studies are below 10%. However, the majority of the prior works were based on subsamples instead of the entire population. Our work started with a review of the gender distributions reported in the literature. Then we provided an overview of the gender distribution in 20 of the largest open-source ecosystem, i.e., grouped by package managers such as npm and PyPI, and investigated its change over time. Moreover, we analyzed the turnover rate between men and women contributors. Across all and in most ecosystems, we observed a promising upward trend in the percentage of women among code contributors over time, but also high variation in the percentage of women contributors across ecosystems. We also found that, in most ecosystems, women withdraw earlier from open-source participation than men.},
booktitle = {Proceedings of the 45th International Conference on Software Engineering: Software Engineering in Society},
pages = {180–187},
numpages = {8},
keywords = {gender diversity, open-source software},
location = {Melbourne, Australia},
series = {ICSE-SEIS '23}
}

@inproceedings{10.1145/3639476.3639777,
author = {Mishra, Shyamal and Chatterjee, Preetha},
title = {Exploring ChatGPT for Toxicity Detection in GitHub},
year = {2024},
isbn = {9798400705007},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639476.3639777},
doi = {10.1145/3639476.3639777},
abstract = {Fostering a collaborative and inclusive environment is crucial for the sustained progress of open source development. However, the prevalence of negative discourse, often manifested as toxic comments, poses significant challenges to developer well-being and productivity. To identify such negativity in project communications, especially within large projects, automated toxicity detection models are necessary. To train these models effectively, we need large software engineering-specific toxicity datasets. However, such datasets are limited in availability and often exhibit imbalance (e.g., only 6 in 1000 GitHub issues are toxic) [1], posing challenges for training effective toxicity detection models. To address this problem, we explore a zero-shot LLM (ChatGPT) that is pre-trained on massive datasets but without being fine-tuned specifically for the task of detecting toxicity in software-related text. Our preliminary evaluation indicates that ChatGPT shows promise in detecting toxicity in GitHub, and warrants further investigation. We experimented with various prompts, including those designed for justifying model outputs, thereby enhancing model interpretability and paving the way for potential integration of ChatGPT-enabled toxicity detection into developer communication channels.},
booktitle = {Proceedings of the 2024 ACM/IEEE 44th International Conference on Software Engineering: New Ideas and Emerging Results},
pages = {6–10},
numpages = {5},
location = {Lisbon, Portugal},
series = {ICSE-NIER'24}
}

@inproceedings{10.1145/3524842.3528432,
author = {Kudrjavets, Gunnar and Kumar, Aditya and Nagappan, Nachiappan and Rastogi, Ayushi},
title = {Mining code review data to understand waiting times between acceptance and merging: an empirical analysis},
year = {2022},
isbn = {9781450393034},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3524842.3528432},
doi = {10.1145/3524842.3528432},
abstract = {Increasing code velocity (or the speed with which code changes are reviewed and merged) is integral to speeding up development and contributes to the work satisfaction of engineers. While factors affecting code change acceptance have been investigated in the past, solutions to decrease the code review lifetime are less understood. This study investigates the code review process to quantify delays and investigate opportunities to potentially increase code velocity. We study the temporal characteristics of half a million code reviews hosted on Gerrit and Phabricator, starting from the first response, to a decision to accept or reject the changes, and until the changes are merged into a target branch. We identified two types of time delays: (a) the wait time from the proposal of code changes until first response, and (b) the wait time between acceptance and merging. Our study indicates that reducing the time between acceptance and merging has the potential to speed up Phabricator code reviews by 29--63%. Small code changes and changes made by authors with a large number of previously accepted code reviews have a higher chance of being immediately accepted, without code review iterations. Our analysis suggests that switching from manual to automatic merges can help increase code velocity.},
booktitle = {Proceedings of the 19th International Conference on Mining Software Repositories},
pages = {579–590},
numpages = {12},
keywords = {non-productive time, developer productivity, code velocity, code review},
location = {Pittsburgh, Pennsylvania},
series = {MSR '22}
}

@inproceedings{10.1145/3345629.3345637,
author = {S\"{u}l\"{u}n, Emre and T\"{u}z\"{u}n, Eray and Do\u{g}rus\"{o}z, U\u{g}ur},
title = {Reviewer Recommendation using Software Artifact Traceability Graphs},
year = {2019},
isbn = {9781450372336},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3345629.3345637},
doi = {10.1145/3345629.3345637},
abstract = {Various types of artifacts (requirements, source code, test cases, documents, etc.) are produced throughout the lifecycle of a software. These artifacts are often related with each other via traceability links that are stored in modern application lifecycle management repositories. Throughout the lifecycle of a software, various types of changes can arise in any one of these artifacts. It is important to review such changes to minimize their potential negative impacts. To maximize benefits of the review process, the reviewer(s) should be chosen appropriately.In this study, we reformulate the reviewer suggestion problem using software artifact traceability graphs. We introduce a novel approach, named RSTrace, to automatically recommend reviewers that are best suited based on their familiarity with a given artifact. The proposed approach, in theory, could be applied to all types of artifacts. For the purpose of this study, we focused on the source code artifact and conducted an experiment on finding the appropriate code reviewer(s). We initially tested RSTrace on an open source project and achieved top-3 recall of 0.85 with an MRR (mean reciprocal ranking) of 0.73. In a further empirical evaluation of 37 open source projects, we confirmed that the proposed reviewer recommendation approach yields promising top-k and MRR scores on the average compared to the existing reviewer recommendation approaches.},
booktitle = {Proceedings of the Fifteenth International Conference on Predictive Models and Data Analytics in Software Engineering},
pages = {66–75},
numpages = {10},
keywords = {suggesting reviewers, software traceability, reviewer recommendation, pull-request review, modern code review, code review},
location = {Recife, Brazil},
series = {PROMISE'19}
}

@inproceedings{10.1145/3629479.3629500,
author = {Perp\'{e}tua, Sueli Pereira and Vieira, S\'{a}vio Luiz and Portela, Carlos dos Santos and Souza, Maur\'{\i}cio Ronny de Almeida},
title = {A Systematic Mapping Study of the Onboarding Process in Software Development Organizations},
year = {2023},
isbn = {9798400707865},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3629479.3629500},
doi = {10.1145/3629479.3629500},
abstract = {The onboarding process refers to the organizational integration or socialization of new employees to the company and their role. This includes training, orientation, support, and communication, seeking to help newcomers to adapt to the new culture and work environment. Since software development is a human activity that requires collaboration and teamwork, especially in the professional environment, onboarding is a critical process to ensure the proper integration of new employees in software projects. Thus, this paper aims to identify the main approaches, practices, trends, and challenges related to the onboarding process in the Software Engineering context. We conducted a Systematic Mapping Study, which resulted in the selection of 23 primary studies. The main findings include the observation that onboarding process is context-sensitive, affected by characterisctics such as organization size, work model, and development methodologies. We also found that there is a lack of studies evaluating models and tools. Finally, there is a heavy focus on oboarding activities related to learning and socialization, in contrast to developing the confidence of newcomers.},
booktitle = {Proceedings of the XXII Brazilian Symposium on Software Quality},
pages = {11–20},
numpages = {10},
keywords = {Employee Onboarding, Onboarding, Organizational Socialization, Software Development.},
location = {Bras\'{\i}lia, Brazil},
series = {SBQS '23}
}

@inproceedings{10.1145/3639478.3639785,
author = {Wintersgill, Nathan},
title = {Studying and Improving Software License Compliance in Practice},
year = {2024},
isbn = {9798400705021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639478.3639785},
doi = {10.1145/3639478.3639785},
abstract = {As the process of software development has matured, the reuse of open-source software has become commonplace. Open-source software licenses can both provide permissions and impose restrictions regarding software's distribution, modification, and reuse. Modern systems can have many such licensed components, complicating the task of license compliance and compounding the risk associated with reusing open source components. To address these issues, this dissertation seeks to identify weaknesses in current processes and automated tools, such as in handling license conflicts, exceptions, and interpretations, in order to develop new compliance tools and resources grounded in the realities of software compliance as revealed by software developers and legal practitioners.},
booktitle = {Proceedings of the 2024 IEEE/ACM 46th International Conference on Software Engineering: Companion Proceedings},
pages = {225–227},
numpages = {3},
keywords = {software licensing, legal practitioners, open source software},
location = {Lisbon, Portugal},
series = {ICSE-Companion '24}
}

@inproceedings{10.1145/3159450.3159606,
author = {Bhatt, Manish and Ahmed, Irfan and Lin, Zhiqiang},
title = {Using Virtual Machine Introspection for Operating Systems Security Education},
year = {2018},
isbn = {9781450351034},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3159450.3159606},
doi = {10.1145/3159450.3159606},
abstract = {Historically, hands-on cybersecurity exercises helped reinforce the basic cybersecurity concepts. However, most of them focused on the user level attacks and defenses and did not provide a convenient way of studying the kernel level security. Since OS kernels provide foundations for applications, any compromise to OS kernels will lead to a computer that cannot be trusted. Moreover, there has been a great interest in using virtualization to profile, characterize, and observe kernel events including security incidents. Virtual Machine Introspection (VMI) is a technique that has been deeply investigated in intrusion detection, malware analysis, and memory forensics. Inspired by the great success of VMI, we used it to develop hands-on labs for teaching kernel level security. In this work, we present three VMI-based labs on (1) stack-based buffer over-flow, (2) direct kernel object manipulation (DKOM), and (3) kernel integrity checker which have been made available online. Then, we analyze the differences in approaches taken by VMI-based labs and traditional labs and conclude that VMI-based labs are better as opposed to traditional labs from a teaching standpoint because they provide more visibility than the traditional labs and superior ability to manipulate kernel memory which provides more insight into kernel security concepts.},
booktitle = {Proceedings of the 49th ACM Technical Symposium on Computer Science Education},
pages = {396–401},
numpages = {6},
location = {Baltimore, Maryland, USA},
series = {SIGCSE '18}
}

@inproceedings{10.1145/3106237.3117769,
author = {Lam, Wing and Wu, Zhengkai and Li, Dengfeng and Wang, Wenyu and Zheng, Haibing and Luo, Hui and Yan, Peng and Deng, Yuetang and Xie, Tao},
title = {Record and replay for Android: are we there yet in industrial cases?},
year = {2017},
isbn = {9781450351058},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3106237.3117769},
doi = {10.1145/3106237.3117769},
abstract = {Mobile applications, or apps for short, are gaining popularity. The input sources (e.g., touchscreen, sensors, transmitters) of the smart devices that host these apps enable the apps to offer a rich experience to the users, but these input sources pose testing complications to the developers (e.g., writing tests to accurately utilize multiple input sources together and be able to replay such tests at a later time). To alleviate these complications, researchers and practitioners in recent years have developed a variety of record-and-replay tools to support the testing expressiveness of smart devices. These tools allow developers to easily record and automate the replay of complicated usage scenarios of their app. Due to Android's large share of the smart-device market, numerous record-and-replay tools have been developed using a variety of techniques to test Android apps. To better understand the strengths and weaknesses of these tools, we present a comparison of popular record-and-replay tools from researchers and practitioners, by applying these tools to test three popular industrial apps downloaded from the Google Play store. Our comparison is based on three main metrics: (1) ability to reproduce common usage scenarios, (2) space overhead of traces created by the tools, and (3) robustness of traces created by the tools (when being replayed on devices with different resolutions). The results from our comparison show which record-and-replay tools may be the best for developers and identify future directions for improving these tools to better address testing complications of smart devices.},
booktitle = {Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering},
pages = {854–859},
numpages = {6},
keywords = {Record-and-replay, GUI testing, Android},
location = {Paderborn, Germany},
series = {ESEC/FSE 2017}
}

@inproceedings{10.1145/2696454.2696463,
author = {Kato, Yusuke and Kanda, Takayuki and Ishiguro, Hiroshi},
title = {May I help you? Design of Human-like Polite Approaching Behavior},
year = {2015},
isbn = {9781450328838},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2696454.2696463},
doi = {10.1145/2696454.2696463},
abstract = {When should service staff initiate interaction with a visitor? Neither simply-proactive (e.g. talk to everyone in a sight) nor passive (e.g. wait until being talked to) strategies are desired. This paper reports our modeling of polite approaching behavior. In a shopping mall, there are service staff members who politely approach visitors who need help. Our analysis revealed that staff members are sensitive to "intentions" of nearby visitors. That is, when a visitor intends to talk to a staff member and starts to approach, the staff member also walks a few steps toward the visitors in advance to being talked. Further, even when not being approached, staff members exhibit "availability" behavior in the case that a visitor's intention seems uncertain. We modeled these behaviors that are adaptive to pedestrians' intentions, occurred prior to initiation of conversation. The model was implemented into a robot and tested in a real shopping mall. The experiment confirmed that the proposed method is less intrusive to pedestrians, and that our robot successfully initiated interaction with pedestrians.},
booktitle = {Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction},
pages = {35–42},
numpages = {8},
keywords = {intention estimation, initiation of interaction, behavior design},
location = {Portland, Oregon, USA},
series = {HRI '15}
}

@inproceedings{10.5555/3162110.3162125,
author = {Asakura, Rei and Watanabe, Tetsuya},
title = {Touchscreen Device Size Suitable for Icon Search by Blind Users},
year = {2017},
publisher = {Singapore Therapeutic, Assistive &amp; Rehabilitative Technologies (START) Centre},
address = {Midview City, SGP},
abstract = {Blind smartphones users are on the rise and they need to know which device is easy to use for them. Thus, to explore the optimal touchscreen device size for blind people, we conducted an experiment in which six blind participants searched for the target icons with four different-sized touchscreen devices. We analyzed the search time, search strategies and subjective evaluations. As a result, devices with a screen size of 4.7 inches had the shortest search time and obtained the highest subjective evaluation among the four devices. This finding is useful for blind people at the stage of purchasing smartphones.},
booktitle = {Proceedings of the 11th International Convention on Rehabilitation Engineering and Assistive Technology},
articleno = {12},
numpages = {4},
keywords = {Blind People, Icon Search, Screen Reader, Touchscreen, User Interface},
series = {i-CREATe '17}
}

@inproceedings{10.1145/3540250.3560885,
author = {Gu, Taotao and Li, Xiang and Lu, Shuaibing and Tian, Jianwen and Nie, Yuanping and Kuang, Xiaohui and Lin, Zhechao and Liu, Chenyifan and Liang, Jie and Jiang, Yu},
title = {Group-based corpus scheduling for parallel fuzzing},
year = {2022},
isbn = {9781450394130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3540250.3560885},
doi = {10.1145/3540250.3560885},
abstract = {Parallel fuzzing relies on hardware resources to guarantee test throughput and efficiency. In industrial practice, it is well known that parallel fuzzing faces the challenge of task division, but most works neglect the important process of corpus allocation. In this paper, we proposed a group-based corpus scheduling strategy to address these two issues, which has been accepted by the LLVM community. And we implement a parallel fuzzer based on this strategy called glibFuzzer. glibFuzzer first groups the global corpus into different subsets and then assigns different energy scores and different scores to them. The energy scores were mainly determined by the seed size and the length of coverage information, and the difference score can describe the degree of difference in the code covered by different subsets of seeds. In each round of key local corpus construction, the master node selects high-quality seeds by combining the two scores to improve test efficiency and avoid task conflict. To prove the effectiveness of the strategy, we conducted an extensive evaluation on the real-world programs and FuzzBench. After 4\texttimes{}24 CPU-hours, glibFuzzer covered 22.02% more branches and executed 19.42 times more test cases than libFuzzer in 18 real-world programs. glibFuzzer showed an average branch coverage increase of 73.02%, 55.02%, 55.86% over AFL, PAFL, UniFuzz, respectively. More importantly, glibFuzzer found over 100 unique vulnerabilities.},
booktitle = {Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1521–1532},
numpages = {12},
keywords = {Vulnerability detection, Seed scheduling, Parallel fuzzing},
location = {Singapore, Singapore},
series = {ESEC/FSE 2022}
}

@inproceedings{10.1145/3382494.3410685,
author = {Dey, Tapajit and Mockus, Audris},
title = {Effect of Technical and Social Factors on Pull Request Quality for the NPM Ecosystem},
year = {2020},
isbn = {9781450375801},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382494.3410685},
doi = {10.1145/3382494.3410685},
abstract = {Background: Pull request (PR) based development, which is a norm for the social coding platforms, entails the challenge of evaluating the contributions of, often unfamiliar, developers from across the open source ecosystem and, conversely, submitting a contribution to a project with unfamiliar maintainers. Previous studies suggest that the decision of accepting or rejecting a PR may be influenced by a diverging set of technical and social factors, but often focus on relatively few projects, do not consider ecosystem-wide measures, or the possible non-monotonic relationships between the predictors and PR acceptance probability. Aim: We aim to shed light on this important decision making process by testing which measures significantly affect the probability of PR acceptance on a significant fraction of a large ecosystem, rank them by their relative importance in predicting PR acceptance, and determine the shape of the functions that map each predictor to PR acceptance. Method: We proposed seven hypotheses regarding which technical and social factors might affect PR acceptance and created 17 measures based on them. Our dataset consisted of 470,925 PRs from 3349 popular NPM packages and 79,128 GitHub users who created those. We tested which of the measures affect PR acceptance and ranked the significant measures by their importance in a predictive model. Results: Our predictive model had and AUC of 0.94, and 15 of the 17 measures were found to matter, including five novel ecosystem-wide measures. Measures describing the number of PRs submitted to a repository and what fraction of those get accepted, and signals about the PR review phase were most significant. We also discovered that only four predictors have a linear influence on the PR acceptance probability while others showed a more complicated response. Conclusion: Our findings should be helpful for PR creators, integrators, as well as tool designers to focus on the important factors affecting PR acceptance.},
booktitle = {Proceedings of the 14th ACM / IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM)},
articleno = {11},
numpages = {11},
keywords = {Social Factors, Pull Request, Predictive Model, NPM Packages},
location = {Bari, Italy},
series = {ESEM '20}
}

@inproceedings{10.1145/3445034.3460509,
author = {Yuhas, Michael and Feng, Yeli and Ng, Daniel Jun Xian and Rahiminasab, Zahra and Easwaran, Arvind},
title = {Embedded out-of-distribution detection on an autonomous robot platform},
year = {2021},
isbn = {9781450383165},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3445034.3460509},
doi = {10.1145/3445034.3460509},
abstract = {Machine learning (ML) is actively finding its way into modern cyber-physical systems (CPS), many of which are safety-critical real-time systems. It is well known that ML outputs are not reliable when testing data are novel with regards to model training and validation data, i.e., out-of-distribution (OOD) test data. We implement an unsupervised deep neural network-based OOD detector on a real-time embedded autonomous Duckiebot and evaluate detection performance. Our OOD detector produces a success rate of 87.5% for emergency stopping a Duckiebot on a braking test bed we designed. We also provide case analysis on computing resource challenges specific to the Robot Operating System (ROS) middleware on the Duckiebot.},
booktitle = {Proceedings of the Workshop on Design Automation for CPS and IoT},
pages = {13–18},
numpages = {6},
location = {Nashville, Tennessee},
series = {Destion '21}
}

@inproceedings{10.1145/3366423.3380272,
author = {Maldeniya, Danaja and Budak, Ceren and Robert Jr., Lionel P. and Romero, Daniel M.},
title = {Herding a Deluge of Good Samaritans: How GitHub Projects Respond to Increased Attention},
year = {2020},
isbn = {9781450370233},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3366423.3380272},
doi = {10.1145/3366423.3380272},
abstract = {Collaborative crowdsourcing is a well-established model of work, especially in the case of open source software development. The structure and operation of these virtual and loosely-knit teams differ from traditional organizations. As such, little is known about how their behavior may change in response to an increase in external attention. To understand these dynamics, we analyze millions of actions of thousands of contributors in over 1100 open source software projects that topped the GitHub Trending Projects page and thus experienced a large increase in attention, in comparison to a control group of projects identified through propensity score matching. In carrying out our research, we use the lens of organizational change, which considers the challenges teams face during rapid growth and how they adapt their work routines, organizational structure, and management style. We show that trending results in an explosive growth in the effective team size. However, most newcomers make only shallow and transient contributions. In response, the original team transitions towards administrative roles, responding to requests and reviewing work done by newcomers. Projects evolve towards a more distributed coordination model with newcomers becoming more central, albeit in limited ways. Additionally, teams become more modular with subgroups specializing in different aspects of the project. We discuss broader implications for collaborative crowdsourcing teams that face attention shocks.},
booktitle = {Proceedings of The Web Conference 2020},
pages = {2055–2065},
numpages = {11},
keywords = {GitHub, PSM, attention shocks, coordination, crowdsourcing},
location = {Taipei, Taiwan},
series = {WWW '20}
}

@inproceedings{10.1145/3540250.3549115,
author = {Pandya, Prahar and Tiwari, Saurabh},
title = {CORMS: a GitHub and Gerrit based hybrid code reviewer recommendation approach for modern code review},
year = {2022},
isbn = {9781450394130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3540250.3549115},
doi = {10.1145/3540250.3549115},
abstract = {Modern Code review (MCR) techniques are widely adopted in both open-source software platforms and organizations to ensure the quality of their software products. However, the selection of reviewers for code review is cumbersome with the increasing size of development teams. The recommendation of inappropriate reviewers for code review can take more time and effort to complete the task effectively. In this paper, we extended the baseline of reviewers' recommendation framework - RevFinder - to handle issues with newly created files, retired reviewers, the external validity of results, and the accuracies of the state-of-the-art RevFinder. Our proposed hybrid approach, CORMS, works on similarity analysis to compute similarities among file paths, projects/sub-projects, author information, and prediction models to recommend reviewers based on the subject of the change. We conducted a detailed analysis on the widely used 20 projects of both Gerrit and GitHub to compare our results with RevFinder. Our results reveal that on average, CORMS, can achieve top-1, top-3, top-5, and top-10 accuracies, and Mean Reciprocal Rank (MRR) of 45.1%, 67.5%, 74.6%, 79.9% and 0.58 for the 20 projects, consequently improves the RevFinder approach by 44.9%, 34.4%, 20.8%, 12.3% and 18.4%, respectively.},
booktitle = {Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {546–557},
numpages = {12},
keywords = {Data Mining, Gerrit, GitHub, Modern Code Review (MCR), Reviewer Recommendations},
location = {Singapore, Singapore},
series = {ESEC/FSE 2022}
}

@inproceedings{10.1145/1957656.1957778,
author = {You, Sangseok and Nie, Jiaqi and Suh, Kiseul and Sundar, S. Shyam},
title = {When the robot criticizes you...: self-serving bias in human-robot interaction},
year = {2011},
isbn = {9781450305617},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1957656.1957778},
doi = {10.1145/1957656.1957778},
abstract = {This study explores how human users respond to feedback and evaluation from a robot. A between-subjects experiment was conducted using the Wizard of Oz method, with 63 participants randomly assigned to one of three evaluations (good evaluation vs. neutral evaluation vs. bad evaluation) following a training session. When participants attempted to reproduce the physical motion taught by the robot, they were given a verbal evaluation of their performance by the robot. They showed a strong negative response to the robot when it gave a bad evaluation, while showing positive attraction when it gave a good or neutral evaluation. Participants tended to dismiss criticism from the robot and attributed blame to the robot, while claiming credit to themselves when their performance was rated positively. These results have theoretical implications for the psychology of self-serving bias and practical implications for designing and deploying trainer robots as well as conducting user studies of such robots.},
booktitle = {Proceedings of the 6th International Conference on Human-Robot Interaction},
pages = {295–296},
numpages = {2},
keywords = {self-serving bias, human-robot interaction, criticism},
location = {Lausanne, Switzerland},
series = {HRI '11}
}

@inproceedings{10.1145/3630106.3659019,
author = {Choksi, Madiha Zahrah and Mandel, Ilan and Widder, David and Shvartzshnaider, Yan},
title = {The Emerging Artifacts of Centralized Open-Code},
year = {2024},
isbn = {9798400704505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3630106.3659019},
doi = {10.1145/3630106.3659019},
abstract = {In 2022, generative model based coding assistants became widely available with the public release of GitHub Copilot. Approaches to generative coding are often critiqued within the context of advances in machine learning. We argue that tools such as Copilot are better understood when contextualized against technologies derived from the same communities and datasets. Our work traces the historical and ideological origins of free and open source code and characterizes the process of centralization. We examine three case studies —Dependabot, Crater, and Copilot— to compare the engineering, social, and legal qualities of technical artifacts derived from shared community-based labor. Our analysis focuses on the implications these artifacts create for infrastructural dependencies, community adoption, and intellectual property. Reframing generative coding assistants through a set of peer technologies broadens considerations for academics and policymakers beyond machine learning, to include the ways technical artifacts are derived from communities.},
booktitle = {Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency},
pages = {1971–1983},
numpages = {13},
keywords = {Artificial Intelligence, Commons, Ethics, Free Software, Governance, Licenses, Political Economy},
location = {Rio de Janeiro, Brazil},
series = {FAccT '24}
}

@inproceedings{10.1145/1995966.1995997,
author = {Nemoto, Keiichi and Gloor, Peter and Laubacher, Robert},
title = {Social capital increases efficiency of collaboration among Wikipedia editors},
year = {2011},
isbn = {9781450302562},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1995966.1995997},
doi = {10.1145/1995966.1995997},
abstract = {In this study we measure the impact of pre-existing social capital on the efficiency of collaboration among Wikipedia editors. To construct a social network among Wikipedians we look to mutual interaction on the user talk pages of Wikipedia editors. As our data set, we analyze the communication networks associated with 3085 featured articles - the articles of highest quality in the English Wikipedia, comparing it to the networks of 80154 articles of lower quality. As the metric to assess the quality of collaboration, we measure the time of quality promotion from when an article is started until it is promoted to featured article. The study finds that the higher pre-existing social capital of editors working on an article is, the faster the articles they work on reach higher quality status, such as featured articles. The more cohesive and more centralized the collaboration network, and the more network members were already collaborating before starting to work together on an article, the faster the article they work on will be promoted or featured.},
booktitle = {Proceedings of the 22nd ACM Conference on Hypertext and Hypermedia},
pages = {231–240},
numpages = {10},
keywords = {Wikipedia, collaboration, community governance, open source projects, social capital, social media, social network analysis, social networks, time-to-market},
location = {Eindhoven, The Netherlands},
series = {HT '11}
}

@inproceedings{10.1109/MSR.2017.54,
author = {Rausch, Thomas and Hummer, Waldemar and Leitner, Philipp and Schulte, Stefan},
title = {An empirical analysis of build failures in the continuous integration workflows of Java-based open-source software},
year = {2017},
isbn = {9781538615447},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MSR.2017.54},
doi = {10.1109/MSR.2017.54},
abstract = {Continuous Integration (CI) has become a common practice in both industrial and open-source software development. While CI has evidently improved aspects of the software development process, errors during CI builds pose a threat to development efficiency. As an increasing amount of time goes into fixing such errors, failing builds can significantly impair the development process and become very costly. We perform an in-depth analysis of build failures in CI environments. Our approach links repository commits to data of corresponding CI builds. Using data from 14 open-source Java projects, we first identify 14 common error categories. Besides test failures, which are by far the most common error category (up to &gt;80% per project), we also identify noisy build data, e.g., induced by transient Git interaction errors, or general infrastructure flakiness. Second, we analyze which factors impact the build results, taking into account general process and specific CI metrics. Our results indicate that process metrics have a significant impact on the build outcome in 8 of the 14 projects on average, but the strongest influencing factor across all projects is overall stability in the recent build history. For 10 projects, more than 50% (up to 80%) of all failed builds follow a previous build failure. Moreover, the fail ratio of the last k=10 builds has a significant impact on build results for all projects in our dataset.},
booktitle = {Proceedings of the 14th International Conference on Mining Software Repositories},
pages = {345–355},
numpages = {11},
keywords = {build errors, continuous integration, correlation analysis, mining software repositories},
location = {Buenos Aires, Argentina},
series = {MSR '17}
}

@inproceedings{10.1145/3555228.3555244,
author = {Souza, Hugo Henrique Fumero de and Wiese, Igor and Steinmacher, Igor and R\'{e}, Reginaldo},
title = {A characterization study of testing contributors and their contributions in open source projects.},
year = {2022},
isbn = {9781450397353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3555228.3555244},
doi = {10.1145/3555228.3555244},
abstract = {Even though open source projects have some different characteristics from projects in the industry, the commitment of maintainers and contributors to achieve a high level of software quality is constant. Therefore, tests are among the main practices of the communities. Thus, motivating contributors to write new tests and maintain regression tests during testing activities is essential for the project’s health. The objective of our work is to characterize testers and their contributions to open source projects as part of a broad study about testers’ motivation. Thus, we conducted a study with 3,936 repositories and 7 different and important programming languages (C, C++, C#, Java, Javascript, Python, and Ruby), analyzing a total of 4,409,142 contributions to classify contributing members and their contributions. Our results show that test-only contributors exist, regardless of programming language or project. We conclude that, despite the unfavorable scenario, there are contributors who feel motivated and dedicate their time and effort to contribute to new tests or to the evolution of existing tests.},
booktitle = {Proceedings of the XXXVI Brazilian Symposium on Software Engineering},
pages = {95–105},
numpages = {11},
location = {Virtual Event, Brazil},
series = {SBES '22}
}

@inproceedings{10.1145/3387940.3391481,
author = {Brown, Chris and Parnin, Chris},
title = {Comparing Different Developer Behavior Recommendation Styles},
year = {2020},
isbn = {9781450379632},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387940.3391481},
doi = {10.1145/3387940.3391481},
abstract = {Research shows that one of the most effective ways software engineers discover useful developer behaviors, or tools and practices designed to help developers complete programming tasks, is through human-to-human recommendations from coworkers during work activities. However, due to the increasingly distributed nature of the software industry and development teams, opportunities for these peer interactions are in decline. To overcome the deprecation of peer interactions in software engineering, we explore the impact of several system-to-human recommendation systems, including the recently introduced suggested changes feature on GitHub which allows users to propose code changes to developers on contributions to repositories, to discover their impact on developer recommendations. In this work, we aim to study the effectiveness of suggested changes for recommending developer behaviors by performing a user study with professional software developers to compare static analysis tool recommendations from emails, pull requests, issues, and suggested changes. Our results provide insight into creating systems for recommendations between developers and design implications for improving automated recommendations to software engineers.},
booktitle = {Proceedings of the IEEE/ACM 42nd International Conference on Software Engineering Workshops},
pages = {78–85},
numpages = {8},
keywords = {developer behavior, developer recommendations, software engineering, tool adoption},
location = {Seoul, Republic of Korea},
series = {ICSEW'20}
}

@inproceedings{10.1109/ICSE48619.2023.00076,
author = {Li, Jiawei and Ahmed, Iftekhar},
title = {Commit Message Matters: Investigating Impact and Evolution of Commit Message Quality},
year = {2023},
isbn = {9781665457019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE48619.2023.00076},
doi = {10.1109/ICSE48619.2023.00076},
abstract = {Commit messages play an important role in communication among developers. To measure the quality of commit messages, researchers have defined what semantically constitutes a Good commit message: it should have both the summary of the code change (What) and the motivation/reason behind it (Why). The presence of the issue report/pull request links referenced in a commit message has been treated as a way of providing Why information. In this study, we found several quality issues that could hamper the links' ability to provide Why information. Based on this observation, we developed a machine learning classifier for automatically identifying whether a commit message has What and Why information by considering both the commit messages and the link contents. This classifier outperforms state-of-the-art machine learning classifiers by 12 percentage points improvement in the F1 score. With the improved classifier, we conducted a mixed method empirical analysis and found that: (1) Commit message quality has an impact on software defect proneness, and (2) the overall quality of the commit messages decreases over time, while developers believe they are writing better commit messages. All the research artifacts (i.e., tools, scripts, and data) of this study are available on the accompanying website [2].},
booktitle = {Proceedings of the 45th International Conference on Software Engineering},
pages = {806–817},
numpages = {12},
keywords = {commit message quality, software defect proneness, empirical analysis},
location = {Melbourne, Victoria, Australia},
series = {ICSE '23}
}

@proceedings{10.1145/3540250,
title = {ESEC/FSE 2022: Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
year = {2022},
isbn = {9781450394130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {On behalf of all members of the organizing committee, we are delighted to welcome everyone to the ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE) 2022. The event continues the long, distinguished ESEC/FSE tradition of presenting the most innovative research, and facilitating interactions between scientists and engineers who are passionate about advancing the theory and practice of software engineering.},
location = {Singapore, Singapore}
}

@inproceedings{10.1145/3468264.3468589,
author = {Soto-Valero, C\'{e}sar and Durieux, Thomas and Baudry, Benoit},
title = {A longitudinal analysis of bloated Java dependencies},
year = {2021},
isbn = {9781450385626},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3468264.3468589},
doi = {10.1145/3468264.3468589},
abstract = {We study the evolution and impact of bloated dependencies in a single software ecosystem: Java/Maven. Bloated dependencies are third-party libraries that are packaged in the application binary but are not needed to run the application. We analyze the history of 435 Java projects. This historical data includes 48,469 distinct dependencies, which we study across a total of 31,515 versions of Maven dependency trees. Bloated dependencies steadily increase over time, and 89.2% of the direct dependencies that are bloated remain bloated in all subsequent versions of the studied projects. This empirical evidence suggests that developers can safely remove a bloated dependency. We further report novel insights regarding the unnecessary maintenance efforts induced by bloat. We find that 22% of dependency updates performed by developers are made on bloated dependencies, and that Dependabot suggests a similar ratio of updates on bloated dependencies.},
booktitle = {Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1021–1031},
numpages = {11},
keywords = {dependencies, java, software bloat},
location = {Athens, Greece},
series = {ESEC/FSE 2021}
}

@inproceedings{10.1109/ICGSE.2017.11,
author = {Lin, Bin and Robles, Gregorio and Serebrenik, Alexander},
title = {Developer turnover in global, industrial open source projects: insights from applying survival analysis},
year = {2017},
isbn = {9781538615874},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICGSE.2017.11},
doi = {10.1109/ICGSE.2017.11},
abstract = {Large open source software projects often have a globally distributed development team. Studies have shown developer turnover has a significant impact on the project success. Frequent developer turnover may lead to loss of productivity due to lacking relevant knowledge and spending extra time learning how projects work. Thus, lots of attention has been paid to which factors are related to developer retention; however, few of them focus on the impact of activities of individual developers.In this paper, we study five open source projects from different organizations and examine whether developer turnover is affected by when they start contributing and what types of contributions they are making. Our study reveals that developers have higher chances to survive in software projects when they 1) start contributing to the project earlier; 2) mainly modify instead of creating files; 3) mainly code instead of dealing with documentations. Our results also shed lights on the potential approaches to improving developer retention.},
booktitle = {Proceedings of the 12th International Conference on Global Software Engineering},
pages = {66–75},
numpages = {10},
location = {Buenos Aires, Argentina},
series = {ICGSE '17}
}

@inproceedings{10.1145/3510003.3510121,
author = {Fang, Hongbo and Lamba, Hemank and Herbsleb, James and Vasilescu, Bogdan},
title = {"This is damn slick!": estimating the impact of tweets on open source project popularity and new contributors},
year = {2022},
isbn = {9781450392211},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3510003.3510121},
doi = {10.1145/3510003.3510121},
abstract = {Twitter is widely used by software developers. But how effective are tweets at promoting open source projects? How could one use Twitter to increase a project's popularity or attract new contributors? In this paper we report on a mixed-methods empirical study of 44,544 tweets containing links to 2,370 open-source GitHub repositories, looking for evidence of causal effects of these tweets on the projects attracting new GitHub stars and contributors, as well as characterizing the high-impact tweets, the people likely being attracted by them, and how they differ from contributors attracted otherwise. Among others, we find that tweets have a statistically significant and practically sizable effect on obtaining new stars and a small average effect on attracting new contributors. The popularity, content of the tweet, as well as the identity of tweet authors all affect the scale of the attraction effect. In addition, our qualitative analysis suggests that forming an active Twitter community for an open source project plays an important role in attracting new committers via tweets. We also report that developers who are new to GitHub or have a long history of Twitter usage but few tweets posted are most likely to be attracted as contributors to the repositories mentioned by tweets. Our work contributes to the literature on open source sustainability.},
booktitle = {Proceedings of the 44th International Conference on Software Engineering},
pages = {2116–2129},
numpages = {14},
location = {Pittsburgh, Pennsylvania},
series = {ICSE '22}
}

@inproceedings{10.1145/3643991.3644918,
author = {Tufano, Rosalia and Mastropaolo, Antonio and Pepe, Federica and Dabic, Ozren and Di Penta, Massimiliano and Bavota, Gabriele},
title = {Unveiling ChatGPT's Usage in Open Source Projects: A Mining-based Study},
year = {2024},
isbn = {9798400705878},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643991.3644918},
doi = {10.1145/3643991.3644918},
abstract = {Large Language Models (LLMs) have gained significant attention in the software engineering community. Nowadays developers have the possibility to exploit these models through industrial-grade tools providing a handy interface toward LLMs, such as OpenAI's ChatGPT. While the potential of LLMs in assisting developers across several tasks has been documented in the literature, there is a lack of empirical evidence mapping the actual usage of LLMs in software projects. In this work, we aim at filling such a gap. First, we mine 1,501 commits, pull requests (PRs), and issues from open-source projects by matching regular expressions likely to indicate the usage of ChatGPT to accomplish the task. Then, we manually analyze these instances, discarding false positives (i.e., instances in which ChatGPT was mentioned but not actually used) and categorizing the task automated in the 467 true positive instances (165 commits, 159 PRs, 143 issues). This resulted in a taxonomy of 45 tasks which developers automate via ChatGPT. The taxonomy, accompanied with representative examples, provides (i) developers with valuable insights on how to exploit LLMs in their workflow and (ii) researchers with a clear overview of tasks that, according to developers, could benefit from automated solutions.},
booktitle = {Proceedings of the 21st International Conference on Mining Software Repositories},
pages = {571–583},
numpages = {13},
keywords = {ChatGPT, empirical study},
location = {Lisbon, Portugal},
series = {MSR '24}
}

@inproceedings{10.1145/3313831.3376151,
author = {Seering, Joseph and Hammer, Jessica and Kaufman, Geoff and Yang, Diyi},
title = {Proximate Social Factors in First-Time Contribution to Online Communities},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376151},
doi = {10.1145/3313831.3376151},
abstract = {In the course of every member's integration into an online community, a decision must be made to participate for the first time. The challenges of effective recruitment, management, and retention of new users have been extensively explored in social computing research. However, little work has looked at in-the-moment factors that lead users to decide to participate instead of "lurk", conditions which can be shaped to draw new users in at crucial moments. In this work we analyze 183 million messages scraped from chatrooms on the livestreaming platform Twitch in order to understand differences between first-time participants' and regulars' behaviors and to identify conditions that encourage first-time participation. We find that presence of diverse types of users increases likelihood of new participation, with effects depending on the size of the community. We also find that information-seeking behaviors in first-time participation are negatively associated with retention in the short and medium term.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {newcomers, online communities, participation, retention, social roles, twitch},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@proceedings{10.1145/3643991,
title = {MSR '24: Proceedings of the 21st International Conference on Mining Software Repositories},
year = {2024},
isbn = {9798400705878},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {MSR is a thriving research community that organizes a yearly conference with a solid reputation amongst software engineering researchers.},
location = {Lisbon, Portugal}
}

@article{10.1177/26339137241231912,
author = {Schueller, William and Wachs, Johannes},
title = {Modeling interconnected social and technical risks in open source software ecosystems},
year = {2024},
issue_date = {January-March 2024},
publisher = {Sage Publications, Inc.},
address = {USA},
volume = {3},
number = {1},
url = {https://doi.org/10.1177/26339137241231912},
doi = {10.1177/26339137241231912},
abstract = {Open source software ecosystems consist of thousands of interdependent libraries, which users can combine to great effect. Recent work has pointed out two kinds of risks in these systems: that technical problems like bugs and vulnerabilities can spread through dependency links, and that relatively few developers are responsible for maintaining even the most widely used libraries. However, a more holistic diagnosis of systemic risk in software ecosystem should consider how these social and technical sources of risk interact and amplify one another. Motivated by the observation that the same individuals maintain several libraries within dependency networks, we present a methodological framework to measure risk in software ecosystems as a function of both dependencies and developers. In our models, a library’s chance of failure increases as its developers leave and as its upstream dependencies fail. We apply our method to data from the Rust ecosystem, highlighting several systemically important libraries that are overlooked when only considering technical dependencies. We compare potential interventions, seeking better ways to deploy limited developer resources with a view to improving overall ecosystem health and software supply chain resilience.},
journal = {Collective Intelligence},
month = {feb},
numpages = {16},
keywords = {Open source software, decentralized collaboration, systemic risk, networks, social-technical systems}
}

@inproceedings{10.1145/3377811.3380920,
author = {Tan, Xin and Zhou, Minghui and Fitzgerald, Brian},
title = {Scaling open source communities: an empirical study of the Linux kernel},
year = {2020},
isbn = {9781450371216},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377811.3380920},
doi = {10.1145/3377811.3380920},
abstract = {Large-scale open source communities, such as the Linux kernel, have gone through decades of development, substantially growing in scale and complexity. In the traditional workflow, maintainers serve as "gatekeepers" for the subsystems that they maintain. As the number of patches and authors significantly increases, maintainers come under considerable pressure, which may hinder the operation and even the sustainability of the community. A few subsystems have begun to use new workflows to address these issues. However, it is unclear to what extent these new workflows are successful, or how to apply them. Therefore, we conduct an empirical study on the multiple-committer model (MCM) that has provoked extensive discussion in the Linux kernel community. We explore the effect of the model on the i915 subsystem with respect to four dimensions: pressure, latency, complexity, and quality assurance. We find that after this model was adopted, the burden of the i915 maintainers was significantly reduced. Also, the model scales well to allow more committers. After analyzing the online documents and interviewing the maintainers of i915, we propose that overloaded subsystems which have trustworthy candidate committers are suitable for adopting the model. We further suggest that the success of the model is closely related to a series of measures for risk mitigation---sufficient precommit testing, strict review process, and the use of tools to simplify work and reduce errors. We employ a network analysis approach to locate candidate committers for the target subsystems and validate this approach and contextual success factors through email interviews with their maintainers. To the best of our knowledge, this is the first study focusing on how to scale open source communities. We expect that our study will help the rapidly growing Linux kernel and other similar communities to adapt to changes and remain sustainable.},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering},
pages = {1222–1234},
numpages = {13},
keywords = {Linux kernel, maintainer, multiple committers, open source communities, scalability, sustainability, workload},
location = {Seoul, South Korea},
series = {ICSE '20}
}

@article{10.1145/141800.141806,
title = {Report of the International Workshop on Distributed Systems: operations &amp; management},
year = {1992},
issue_date = {April 1992},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {22},
number = {2},
issn = {0146-4833},
url = {https://doi.org/10.1145/141800.141806},
doi = {10.1145/141800.141806},
journal = {SIGCOMM Comput. Commun. Rev.},
month = {apr},
pages = {72–82},
numpages = {11}
}

@inproceedings{10.1145/3320326.3320383,
author = {Bouziani, Ossama and Benaboud, Hafssa and Chamkar, Achraf Samir and Lazaar, Saiida},
title = {A Comparative study of Open Source IDSs according to their Ability to Detect Attacks},
year = {2019},
isbn = {9781450366458},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3320326.3320383},
doi = {10.1145/3320326.3320383},
abstract = {In this paper, we focus on the important role of intrusion detection systems for detecting unauthorized actions initiated from both internal and external network by collecting and monitoring network traffic. We give a study of the open source Next-Generation of IDS (SNORT, SURICATA, BRO). We test and compare their ability to detect attacks and performance by implementing the three IDSs individually.},
booktitle = {Proceedings of the 2nd International Conference on Networking, Information Systems &amp; Security},
articleno = {51},
numpages = {5},
keywords = {Attacks, BRO, Intrusion Detection Systems, Malware, Network Security, SNORT, SURICATA},
location = {Rabat, Morocco},
series = {NISS '19}
}

@inproceedings{10.1145/3540250.3549127,
author = {Robe, Peter and Kuttal, Sandeep K. and AuBuchon, Jake and Hart, Jacob},
title = {Pair programming conversations with agents vs. developers: challenges and opportunities for SE community},
year = {2022},
isbn = {9781450394130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3540250.3549127},
doi = {10.1145/3540250.3549127},
abstract = {Recent research has shown feasibility of an interactive pair-programming conversational agent, but implementing such an agent poses three challenges: a lack of benchmark datasets, absence of software engineering specific labels, and the need to understand developer conversations. To address these challenges, we conducted a Wizard of Oz study with 14 participants pair programming with a simulated agent and collected 4,443 developer-agent utterances. Based on this dataset, we created 26 software engineering labels using an open coding process to develop a hierarchical classification scheme. To understand labeled developer-agent conversations, we compared the accuracy of three state-of-the-art transformer-based language models, BERT, GPT-2, and XLNet, which performed interchangeably. In order to begin creating a developer-agent dataset, researchers and practitioners need to conduct resource intensive Wizard of Oz studies. Presently, there exists vast amounts of developer-developer conversations on video hosting websites. To investigate the feasibility of using developer-developer conversations, we labeled a publicly available developer-developer dataset (3,436 utterances) with our hierarchical classification scheme and found that a BERT model trained on developer-developer data performed ~10% worse than the BERT trained on developer-agent data, but when using transfer-learning, accuracy improved. Finally, our qualitative analysis revealed that developer-developer conversations are more implicit, neutral, and opinionated than developer-agent conversations. Our results have implications for software engineering researchers and practitioners developing conversational agents.},
booktitle = {Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {319–331},
numpages = {13},
keywords = {Pair programming questions, Pair programming conversations, Language models, Labels, Datasets, Conversational agents, Classification},
location = {Singapore, Singapore},
series = {ESEC/FSE 2022}
}

@inproceedings{10.1145/3180155.3180217,
author = {German, Daniel M. and Robles, Gregorio and Poo-Caama\~{n}o, Germ\'{a}n and Yang, Xin and Iida, Hajimu and Inoue, Katsuro},
title = {"Was my contribution fairly reviewed?": a framework to study the perception of fairness in modern code reviews},
year = {2018},
isbn = {9781450356381},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3180155.3180217},
doi = {10.1145/3180155.3180217},
abstract = {Modern code reviews improve the quality of software products. Although modern code reviews rely heavily on human interactions, little is known regarding whether they are performed fairly. Fairness plays a role in any process where decisions that affect others are made. When a system is perceived to be unfair, it affects negatively the productivity and motivation of its participants. In this paper, using fairness theory we create a framework that describes how fairness affects modern code reviews. To demonstrate its applicability, and the importance of fairness in code reviews, we conducted an empirical study that asked developers of a large industrial open source ecosystem (OpenStack) what their perceptions are regarding fairness in their code reviewing process. Our study shows that, in general, the code review process in OpenStack is perceived as fair; however, a significant portion of respondents perceive it as unfair. We also show that the variability in the way they prioritize code reviews signals a lack of consistency and the existence of bias (potentially increasing the perception of unfairness). The contributions of this paper are: (1) we propose a framework---based on fairness theory---for studying and managing social behaviour in modern code reviews, (2) we provide support for the framework through the results of a case study on a large industrial-backed open source project, (3) we present evidence that fairness is an issue in the code review process of a large open source ecosystem, and, (4) we present a set of guidelines for practitioners to address unfairness in modern code reviews.},
booktitle = {Proceedings of the 40th International Conference on Software Engineering},
pages = {523–534},
numpages = {12},
keywords = {fairness, human and social aspects, modern code review, open source software, software development, transparency},
location = {Gothenburg, Sweden},
series = {ICSE '18}
}

@proceedings{10.1145/3611643,
title = {ESEC/FSE 2023: Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
year = {2023},
isbn = {9798400703270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {We are pleased to welcome all delegates to ESEC/FSE 2023, the ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering. ESEC/FSE is an internationally renowned forum for researchers, practitioners, and educators to present and discuss the most recent innovations, trends, experiences, and challenges in the field of software engineering. ESEC/FSE brings together experts from academia and industry to exchange the latest research results and trends as well as their practical application in all areas of software engineering.},
location = {San Francisco, CA, USA}
}

@inproceedings{10.1145/3611643.3613873,
author = {Mockus, Audris and Rigby, Peter C. and Abreu, Rui and Suresh, Parth and Chen, Yifen and Nagappan, Nachiappan},
title = {Modeling the Centrality of Developer Output with Software Supply Chains},
year = {2023},
isbn = {9798400703270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611643.3613873},
doi = {10.1145/3611643.3613873},
abstract = {Raw developer output, as measured by the number of changes a developer makes to the system, is simplistic and potentially misleading measure of productivity as new developers tend to work on peripheral and experienced developers on more central parts of the system. In this work, we use Software Supply Chain (SSC) networks and Katz centrality and PageRank on these networks to suggest a more nuanced measure of developer productivity. Our SSC is a network that represents the relationships between developers and artifacts that make up a system. We combine author-to-file, co-changing files, call hierarchies, and reporting structure into a single SSC and calculate the centrality of each node. The measures of centrality can be used to better understand variations in the impact of developer output at Meta. We start by partially replicating prior work and show that the raw number of developer commits plateaus over a project-specific period. However, the centrality of developer work grows for the entire period of study, but the growth slows after one year. This implies that while raw output might plateau, more experienced developers work on more central parts of the system. Finally, we investigate the incremental contribution of SSC attributes in modeling developer output. We find that local attributes such as the number of reports and the specific project do not explain much variation (𝑅2 = 5.8%). In contrast, adding Katz centrality or PageRank produces a model with an 𝑅2 above 30%. SSCs and their centrality provide valuable insights into the centrality and importance of a developer’s work.},
booktitle = {Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1809–1819},
numpages = {11},
keywords = {Developer productivity, Software supply chains},
location = {San Francisco, CA, USA},
series = {ESEC/FSE 2023}
}

@inproceedings{10.1145/1971519.1971595,
author = {Park, PyungKoo and Yi, HeeKyoung and Hong, SangJin and Ryu, JaeCheul},
title = {An effective defense mechanism against DoS/DDoS attacks in flow-based routers},
year = {2010},
isbn = {9781450304405},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1971519.1971595},
doi = {10.1145/1971519.1971595},
abstract = {Due to proliferation of diverse network applications, DoS/DDoS attacks are evolving. Many studies have been performed and implemented in on/off-line network devices such as routers and IDS/IPS. While IDS/IPS is powerful enough to handle deep packet inspection (DPI) tasks, routers are better suited in real-time and line-speed processing requirements. Since the routers are designed to handle IP packet header information, if one can devise an DoS/DDoS detection/prevention methods that utilizes the router specific features it will be best for the in-line and real-time processing. We introduce a Flow based DoS/DDoS detection algorithm(FDDA) that detects Distributed Denial of Service (DDoS) attacks by monitoring TTL and ID fields of incoming packet's IP header. As DDoS attacks are based on IP source address spoofing, the TTL and ID fields may have abnormal behavior. The device keeps track of 8-tuple flow table. The behavior of these two fields is monitored to determine DoS/DDoS attack situation. The effectiveness of our method is such that it is implemented flow-based routers and devices.},
booktitle = {Proceedings of the 8th International Conference on Advances in Mobile Computing and Multimedia},
pages = {442–446},
numpages = {5},
keywords = {identification, flow-based router, TTL, DoS/DDoS},
location = {Paris, France},
series = {MoMM '10}
}

@inproceedings{10.1145/3571473.3571508,
author = {Ferreira, M\'{\i}vian and Gon\c{c}alves, Diego and Bigonha, Mariza and Ferreira, Kecia},
title = {Characterizing Commits in Open-Source Software},
year = {2023},
isbn = {9781450399999},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3571473.3571508},
doi = {10.1145/3571473.3571508},
abstract = {Mining software repositories has been the basis of many studies on software engineering. Many of these works rely on commits’ data extracted since commit is the basic unit of information about activities performed on the projects. However, not knowing the characteristics of commits may introduce biases and threats in studies that consider commits’ data. This work presents an empirical study to characterize commits in terms of four aspects: the size of commits in the total number of files; the size of commits in the number of source-code files, the size of commits by category; and the time interval of commits performed by contributors. We analyzed 1M commits from the 24 most popular and active Java-based projects hosted on GitHub. The main findings of this work show that: the size of commits follows a heavy-tailed distribution; most commits involve one to 10 files; most commits affect one to four source-code files; the commits involving hundreds of files not only refer to merge or management activities; the distribution of the time intervals is approximately a Normal distribution, i.e., the distribution tends to be symmetric, and the mean is representative; in the average, a developer proceed a commit every eight hours. The results of this study should be considered by researchers in empirical works to avoid biases when analyzing commits’ data. Besides, the results provide information that practitioners may apply to improve the management and the planning of software activities.},
booktitle = {Proceedings of the XXI Brazilian Symposium on Software Quality},
articleno = {7},
numpages = {10},
keywords = {open-source, mining software repositories, empirical study, commit, Java},
location = {Curitiba, Brazil},
series = {SBQS '22}
}

@article{10.1145/3143560,
author = {Wasik, Szymon and Antczak, Maciej and Badura, Jan and Laskowski, Artur and Sternal, Tomasz},
title = {A Survey on Online Judge Systems and Their Applications},
year = {2018},
issue_date = {January 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/3143560},
doi = {10.1145/3143560},
abstract = {Online judges are systems designed for the reliable evaluation of algorithm source code submitted by users, which is next compiled and tested in a homogeneous environment. Online judges are becoming popular in various applications. Thus, we would like to review the state of the art for these systems. We classify them according to their principal objectives into systems supporting organization of competitive programming contests, enhancing education and recruitment processes, facilitating the solving of data mining challenges, online compilers and development platforms integrated as components of other custom systems. Moreover, we introduce a formal definition of an online judge system and summarize the common evaluation methodology supported by such systems. Finally, we briefly discuss an Optil.io platform as an example of an online judge system, which has been proposed for the solving of complex optimization problems. We also analyze the competition results conducted using this platform. The competition proved that online judge systems, strengthened by crowdsourcing concepts, can be successfully applied to accurately and efficiently solve complex industrial- and science-driven challenges.},
journal = {ACM Comput. Surv.},
month = {jan},
articleno = {3},
numpages = {34},
keywords = {evaluation as a service, crowdsourcing, contest, challenge, Online judge}
}

@inproceedings{10.1145/3524610.3527884,
author = {Fu, Liming and Liang, Peng and Zhang, Beiqi},
title = {Understanding code snippets in code reviews: a preliminary study of the OpenStack community},
year = {2022},
isbn = {9781450392983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3524610.3527884},
doi = {10.1145/3524610.3527884},
abstract = {Code review is a mature practice for software quality assurance in software development with which reviewers check the code that has been committed by developers, and verify the quality of code. During the code review discussions, reviewers and developers might use code snippets to provide necessary information (e.g., suggestions or explanations). However, little is known about the intentions and impacts of code snippets in code reviews. To this end, we conducted a preliminary study to investigate the nature of code snippets and their purposes in code reviews. We manually collected and checked 10,790 review comments from the Nova and Neutron projects of the OpenStack community, and finally obtained 626 review comments that contain code snippets for further analysis. The results show that: (1) code snippets are not prevalently used in code reviews, and most of the code snippets are provided by reviewers. (2) We identified two high-level purposes of code snippets provided by reviewers (i.e., Suggestion and Citation) with six detailed purposes, among which, Improving Code Implementation is the most common purpose. (3) For the code snippets in code reviews with the aim of suggestion, around 68.1% was accepted by developers. The results highlight promising research directions on using code snippets in code reviews.},
booktitle = {Proceedings of the 30th IEEE/ACM International Conference on Program Comprehension},
pages = {152–156},
numpages = {5},
keywords = {code snippet, code review, OpenStack},
location = {Virtual Event},
series = {ICPC '22}
}

@inproceedings{10.1145/2897667.2897673,
author = {Mercaldo, Francesco and Nardone, Vittoria and Santone, Antonella and Visaggio, Corrado Aaron},
title = {Download malware? no, thanks: how formal methods can block update attacks},
year = {2016},
isbn = {9781450341592},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2897667.2897673},
doi = {10.1145/2897667.2897673},
abstract = {In mobile malware landscape there are many techniques to inject malicious payload in a trusted application: one of the most common is represented by the so-called update attack. After an apparently innocuous application is installed on the victim's device, the user is asked to update the application, and a malicious behavior is added to the application. In this paper we propose a static method based on model checking able to identify this kind of attack. In addiction, our method is able to localize the malicious payload at method-level. We obtain an accuracy very close to 1 in identifying families implementing update attack using a real Android dataset composed by 2,581 samples.},
booktitle = {Proceedings of the 4th FME Workshop on Formal Methods in Software Engineering},
pages = {22–28},
numpages = {7},
keywords = {temporal logic, security, model checking, malware, android},
location = {Austin, Texas},
series = {FormaliSE '16}
}

@article{10.1145/3512982,
author = {Zhang, Charles Chuankai and Houtti, Mo and Smith, C. Estelle and Kong, Ruoyan and Terveen, Loren},
title = {Working for the Invisible Machines or Pumping Information into an Empty Void? An Exploration of Wikidata Contributors' Motivations},
year = {2022},
issue_date = {April 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {CSCW1},
url = {https://doi.org/10.1145/3512982},
doi = {10.1145/3512982},
abstract = {Structured data peer production (SDPP) platforms like Wikidata play an important role in knowledge production. Compared to traditional peer production platforms like Wikipedia, Wikidata data is more structured and intended to be used by machines, not (directly) by people; end-user interactions with Wikidata often happen through intermediary "invisible machines." Given this distinction, we wanted to understand Wikidata contributor motivations and how they are affected by usage invisibility caused by the machine intermediaries. Through an inductive thematic analysis of 15 interviews, we find that: (i) Wikidata editors take on two archetypes---Architects who define the ontological infrastructure of Wikidata, and Masons who build the database through data entry and editing; (ii) the structured nature of Wikidata reveals novel editor motivations, such as an innate drive for organizational work; (iii) most Wikidata editors have little understanding of how their contributions are used, which may demotivate some. We synthesize these insights to help guide the future design of SDPP platforms in supporting the engagement of different types of editors.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = {apr},
articleno = {135},
numpages = {21},
keywords = {wikidata, structured data, social computing, peer production, interview study}
}

@article{10.1145/3563943,
author = {Hu, Jingmei and Lu, Eric and Holland, David A. and Kawaguchi, Ming and Chong, Stephen and Seltzer, Margo},
title = {Towards Porting Operating Systems with Program Synthesis},
year = {2023},
issue_date = {March 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {45},
number = {1},
issn = {0164-0925},
url = {https://doi.org/10.1145/3563943},
doi = {10.1145/3563943},
abstract = {The end of Moore’s Law has ushered in a diversity of hardware not seen in decades. Operating system (OS) (and system software) portability is accordingly becoming increasingly critical. Simultaneously, there has been tremendous progress in program synthesis. We set out to explore the feasibility of using modern program synthesis to generate the machine-dependent parts of an operating system. Our ultimate goal is to generate new ports automatically from descriptions of new machines.One of the issues involved is writing specifications, both for machine-dependent operating system functionality and for instruction set architectures. We designed two domain-specific languages: Alewife for machine-independent specifications of machine-dependent operating system functionality and Cassiopea for describing instruction set architecture semantics. Automated porting also requires an implementation. We developed a toolchain that, given an Alewife specification and a Cassiopea machine description, specializes the machine-independent specification to the target instruction set architecture and synthesizes an implementation in assembly language with a customized symbolic execution engine. Using this approach, we demonstrate the successful synthesis of a total of 140 OS components from two pre-existing OSes for four real hardware platforms. We also developed several optimization methods for OS-related assembly synthesis to improve scalability.The effectiveness of our languages and ability to synthesize code for all 140 specifications is evidence of the feasibility of program synthesis for machine-dependent OS code. However, many research challenges remain; we also discuss the benefits and limitations of our synthesis-based approach to automated OS porting.},
journal = {ACM Trans. Program. Lang. Syst.},
month = {mar},
articleno = {2},
numpages = {70},
keywords = {operating systems, assembly languages, Program synthesis}
}

@inproceedings{10.1145/1460877.1460893,
author = {Bose, Abhijit and Shin, Kang G.},
title = {On capturing malware dynamics in mobile power-law networks},
year = {2008},
isbn = {9781605582412},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1460877.1460893},
doi = {10.1145/1460877.1460893},
abstract = {The increasing convergence of power-law networks such as social networking and peer-to-peer sites, web applications and mobile platforms makes today's users highly vulnerable to entirely new generations of malware that exploit vulnerabilities in web applications and mobile platforms for new infections, while using the power-law connectivity for finding new victims. The traditional epidemic models based on assumptions of homogeneity, averagedegree distributions, and perfect-mixing are inadequate to model this type of malware propagation. In this paper, we study three aspects crucial to modeling malware propagation in such environments: application-level interactions among users of such networks, local network structure, and user mobility.Since closed-form solutions of malware propagation in such environments are difficult to obtain, we describe an open-source, flexible agent-based emulation framework that can be used by malware researchers for studying today's complex malware. The framework, called Agent-Based Malware Modeling (AMM), allows different applications, network structure and user mobility in either a geographic or a logical domain to study various infection and propagation scenarios. The majority of the parameters used in the framework can be derived from real-life network traces collected from these networks, and therefore, represent realistic malware propagation and infection scenarios. As representative examples, we examine two well-known malware spreading mechanisms: (i) a malicious virus such as Cabir spreading among the subscribers of a cellular network using Bluetooth, and (ii) a hybrid worm that exploit email and file-sharing to infect users of a social network. In both cases, we identify the parameters most important to the spread of the epidemic based upon our extensive simulation results.},
booktitle = {Proceedings of the 4th International Conference on Security and Privacy in Communication Netowrks},
articleno = {12},
numpages = {10},
keywords = {worms, social networking, power-law networks, mobile viruses, malware, agent-based modeling},
location = {Istanbul, Turkey},
series = {SecureComm '08}
}

@inproceedings{10.1145/3475960.3475985,
author = {Bhandari, Guru and Naseer, Amara and Moonen, Leon},
title = {CVEfixes: automated collection of vulnerabilities and their fixes from open-source software},
year = {2021},
isbn = {9781450386807},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3475960.3475985},
doi = {10.1145/3475960.3475985},
abstract = {Data-driven research on the automated discovery and repair of security vulnerabilities in source code requires comprehensive datasets of real-life vulnerable code and their fixes. To assist in such research, we propose a method to automatically collect and curate a comprehensive vulnerability dataset from Common Vulnerabilities and Exposures (CVE) records in the National Vulnerability Database (NVD). We implement our approach in a fully automated dataset collection tool and share an initial release of the resulting vulnerability dataset named CVEfixes. The CVEfixes collection tool automatically fetches all available CVE records from the NVD, gathers the vulnerable code and corresponding fixes from associated open-source repositories, and organizes the collected information in a relational database. Moreover, the dataset is enriched with meta-data such as programming language, and detailed code and security metrics at five levels of abstraction. The collection can easily be repeated to keep up-to-date with newly discovered or patched vulnerabilities. The initial release of CVEfixes spans all published CVEs up to 9 June 2021, covering 5365 CVE records for 1754 open-source projects that were addressed in a total of 5495 vulnerability fixing commits. CVEfixes supports various types of data-driven software security research, such as vulnerability prediction, vulnerability classification, vulnerability severity prediction, analysis of vulnerability-related code changes, and automated vulnerability repair.},
booktitle = {Proceedings of the 17th International Conference on Predictive Models and Data Analytics in Software Engineering},
pages = {30–39},
numpages = {10},
keywords = {vulnerability prediction, vulnerability classification, source code repair, software repository mining, dataset, Security vulnerabilities},
location = {Athens, Greece},
series = {PROMISE 2021}
}

@inproceedings{10.1145/1952222.1952330,
author = {Mori, Joji},
title = {Memorialising day-to-day content: bushfire affected communities},
year = {2010},
isbn = {9781450305020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1952222.1952330},
doi = {10.1145/1952222.1952330},
abstract = {Memorialising allows communities to commemorate or honour anything of significance, especially after tragic events which result in a large number of fatalities. This project will explore the use of day-to-day content of a digital nature to determine the role it can play in memorialising for communities. This could be content created of and by the deceas ed or survivors. It may also have been created be fore, during or after the disaster. Examples of relevant content could include digital photos, emails, mobile phone content and even social networking pages. The research approach will usea "Black Saturday" bus hfire affected township in Victoria. Australia as a vehicle to 1. develop and deploy a memorial and 2. explore the role this day-to-day content may have in memorialising for the community.},
booktitle = {Proceedings of the 22nd Conference of the Computer-Human Interaction Special Interest Group of Australia on Computer-Human Interaction},
pages = {435–437},
numpages = {3},
keywords = {memorials, digital memorial, death, community loss, community grieving, bushfires},
location = {Brisbane, Australia},
series = {OZCHI '10}
}

@inproceedings{10.1145/3543873.3587636,
author = {Guo, Zhen and Wang, Pei and Cho, Jin-Hee and Huang, Lifu},
title = {Text Mining-based Social-Psychological Vulnerability Analysis of Potential Victims To Cybergrooming: Insights and Lessons Learned},
year = {2023},
isbn = {9781450394192},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3543873.3587636},
doi = {10.1145/3543873.3587636},
abstract = {Cybergrooming is a serious cybercrime that primarily targets youths through online platforms. Although reactive predator detection methods have been studied, proactive victim protection and crime prevention can also be achieved through vulnerability analysis of potential youth victims. Despite its significance, vulnerability analysis has not been thoroughly studied in the data science literature, while several social science studies used survey-based methods. To address this gap, we investigate humans’ social-psychological traits and quantify key vulnerability factors to cybergrooming by analyzing text features in the Linguistic Inquiry and Word Count (LIWC). Through pairwise correlation studies, we demonstrate the degrees of key vulnerability dimensions to cybergrooming from youths’ conversational features. Our findings reveal that victims have negative correlations with family and community traits, contrasting with previous social survey studies that indicated family relationships or social support as key vulnerability factors. We discuss the current limitations of text mining analysis and suggest cross-validation methods to increase the validity of research findings. Overall, this study provides valuable insights into understanding the vulnerability factors to cybergrooming and highlights the importance of adopting multidisciplinary approaches.},
booktitle = {Companion Proceedings of the ACM Web Conference 2023},
pages = {1381–1388},
numpages = {8},
keywords = {Natural language processing, and vulnerability., cybergrooming, online social deception, social-psychological analysis, text mining},
location = {Austin, TX, USA},
series = {WWW '23 Companion}
}

@inproceedings{10.1145/1460563.1460572,
author = {Kittur, Aniket and Kraut, Robert E.},
title = {Harnessing the wisdom of crowds in wikipedia: quality through coordination},
year = {2008},
isbn = {9781605580074},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1460563.1460572},
doi = {10.1145/1460563.1460572},
abstract = {Wikipedia's success is often attributed to the large numbers of contributors who improve the accuracy, completeness and clarity of articles while reducing bias. However, because of the coordination needed to write an article collaboratively, adding contributors is costly. We examined how the number of editors in Wikipedia and the coordination methods they use affect article quality. We distinguish between explicit coordination, in which editors plan the article through communication, and implicit coordination, in which a subset of editors structure the work by doing the majority of it. Adding more editors to an article improved article quality only when they used appropriate coordination techniques and was harmful when they did not. Implicit coordination through concentrating the work was more helpful when many editors contributed, but explicit coordination through communication was not. Both types of coordination improved quality more when an article was in a formative stage. These results demonstrate the critical importance of coordination in effectively harnessing the "wisdom of the crowd" in online production environments.},
booktitle = {Proceedings of the 2008 ACM Conference on Computer Supported Cooperative Work},
pages = {37–46},
numpages = {10},
keywords = {wikipedia, wiki, social computing, distributed cognition, coordination, collective intelligence, collaboration},
location = {San Diego, CA, USA},
series = {CSCW '08}
}

@inproceedings{10.1145/3508398.3511507,
author = {Hristozov, Stefan and Wettermann, Moritz and Huber, Manuel},
title = {A TOCTOU Attack on DICE Attestation},
year = {2022},
isbn = {9781450392204},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3508398.3511507},
doi = {10.1145/3508398.3511507},
abstract = {A major security challenge for modern IoT deployments is to ensure that the devices run legitimate firmware free from malware. This challenge can be addressed through a security primitive called attestation which allows a remote backend to verify the firmware integrity of the devices it manages. In order to accelerate broad attestation adoption in the IoT domain the Trusted Computing Group (TCG) has introduced the Device Identifier Composition Engine (DICE) series of specifications. DICE is a hardware-software architecture for constrained, e.g., microcontroller-based IoT devices where the firmware is divided into successively executed layers. In this paper, we demonstrate a remote Time-Of-Check Time-Of-Use (TOCTOU) attack on DICE-based attestation. We demonstrate that it is possible to install persistent malware in the flash memory of a constrained microcontroller that cannot be detected through DICE-based attestation. The main idea of our attack is to install malware during runtime of application logic in the top firmware layer. The malware reads the valid attestation key and stores it on the device's flash memory. After reboot, the malware uses the previously stored key for all subsequent attestations to the backend. We conduct the installation of malware and copying of the key through Return-Oriented Programming (ROP). As a platform for our demonstration, we use the Cortex-M-based nRF52840 microcontroller. We provide a discussion of several possible countermeasures which can mitigate the shortcomings of the DICE specifications.},
booktitle = {Proceedings of the Twelfth ACM Conference on Data and Application Security and Privacy},
pages = {226–235},
numpages = {10},
keywords = {trusted computing, toctou, tcg, rop, malware, iot, dice, attestation},
location = {Baltimore, MD, USA},
series = {CODASPY '22}
}

@proceedings{10.1145/3639474,
title = {ICSE-SEET '24: Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training},
year = {2024},
isbn = {9798400704987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Lisbon, Portugal}
}

@article{10.1145/1017720.1017721,
author = {Yadav, Surya B.},
title = {Determining an organization's information requirements: a state of the art survey},
year = {1983},
issue_date = {Spring 1983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {3},
issn = {0095-0033},
url = {https://doi.org/10.1145/1017720.1017721},
doi = {10.1145/1017720.1017721},
abstract = {The issue of information requirements of an organization and their specifications span two isolated territories. One territory is that of organization and management and the other belongs to technicians. There is a considerable gap between these two territories. Research in requirements engineering (technician's side) has primarily concentrated on designing and developing formal languages to document and analyze user requirements, once they have been determined. This research has ignored the organizational issues involved in information requirements determination. Research in the field of organization and management has addressed the organizational issues which affect information requirements of an organization. Various frameworks reported in the literature provide insights, but they cannot be considered as methods of determining requirements. Little work has been done on the process of determining requirements. This process must start with the understanding of an organization and end with a formal specification of information requirements. Here, it is worth emphasizing the fact that the process of determining and specifying information requirements of an organization is very different from the process of specifying design requirements of an information system. Therefore, program design methodologies, which are helpful in designing a system are not suitable for the process of determining and specifying information requirements of an organization.This paper discusses the state of the art in information requirements determination methodologies. Excluded are those methodologies which emphasize system design and have little to offer for requirements determination of an organization.},
journal = {SIGMIS Database},
month = {apr},
pages = {3–20},
numpages = {18},
keywords = {systems analysis, requirement determination methodology, information system, information requirements determination}
}

@proceedings{10.1145/3623476,
title = {SLE 2023: Proceedings of the 16th ACM SIGPLAN International Conference on Software Language Engineering},
year = {2023},
isbn = {9798400703966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 16th ACM SIGPLAN International Conference on Software Language Engineering (SLE) held in October 2023 as part of SPLASH 2023. Software Language Engineering (SLE) is a thriving research discipline targeted at establishing an engineering approach to the development, use, and maintenance of software languages, that is, of languages for the specification, modeling and tooling of software. Key topics of interest for SLE include approaches, methodologies and tools for language design and implementation with a focus on techniques for static and behavioral semantics, generative or interpretative approaches (including transformation languages and code generation) as well as meta-languages and tools (including language workbenches). Techniques enabling the testing, simulation or formal verification for language validation purposes are also of particular interest. SLE also accommodates empirical evaluation and experience reports of language engineering tools, such as user studies evaluating usability, performance benchmarks or industrial applications.},
location = {Cascais, Portugal}
}

@article{10.1145/3585004,
author = {Badampudi, Deepika and Unterkalmsteiner, Michael and Britto, Ricardo},
title = {Modern Code Reviews—Survey of Literature and Practice},
year = {2023},
issue_date = {July 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {32},
number = {4},
issn = {1049-331X},
url = {https://doi.org/10.1145/3585004},
doi = {10.1145/3585004},
abstract = {Background: Modern Code Review (MCR) is a lightweight alternative to traditional code inspections. While secondary studies on MCR exist, it is uanknown whether the research community has targeted themes that practitioners consider important.Objectives: The objectives are to provide an overview of MCR research, analyze the practitioners’ opinions on the importance of MCR research, investigate the alignment between research and practice, and propose future MCR research avenues.Method: We conducted a systematic mapping study to survey state of the art until and including 2021, employed the Q-Methodology to analyze the practitioners’ perception of the relevance of MCR research, and analyzed the primary studies’ research impact.Results: We analyzed 244 primary studies, resulting in five themes. As a result of the 1,300 survey data points, we found that the respondents are positive about research investigating the impact of MCR on product quality and MCR process properties. In contrast, they are negative about human factor– and support systems–related research.Conclusion: These results indicate a misalignment between the state of the art and the themes deemed important by most survey respondents. Researchers should focus on solutions that can improve the state of MCR practice. We provide an MCR research agenda that can potentially increase the impact of MCR research.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = {may},
articleno = {107},
numpages = {61},
keywords = {practitioner survey, literature survey, Modern code review}
}

@proceedings{10.1145/3593434,
title = {EASE '23: Proceedings of the 27th International Conference on Evaluation and Assessment in Software Engineering},
year = {2023},
isbn = {9798400700446},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Oulu, Finland}
}

@inproceedings{10.1145/3475716.3475769,
author = {Imtiaz, Nasif and Thorn, Seaver and Williams, Laurie},
title = {A comparative study of vulnerability reporting by software composition analysis tools},
year = {2021},
isbn = {9781450386654},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3475716.3475769},
doi = {10.1145/3475716.3475769},
abstract = {Background: Modern software uses many third-party libraries and frameworks as dependencies. Known vulnerabilities in these dependencies are a potential security risk. Software composition analysis (SCA) tools, therefore, are being increasingly adopted by practitioners to keep track of vulnerable dependencies. Aim: The goal of this study is to understand the difference in vulnerability reporting by various SCA tools. Understanding if and how existing SCA tools differ in their analysis may help security practitioners to choose the right tooling and identify future research needs. Method: We present an in-depth case study by comparing the analysis reports of 9 industry-leading SCA tools on a large web application, OpenMRS, composed of Maven (Java) and npm (JavaScript) projects. Results: We find that the tools vary in their vulnerability reporting. The count of reported vulnerable dependencies ranges from 17 to 332 for Maven and from 32 to 239 for npm projects across the studied tools. Similarly, the count of unique known vulnerabilities reported by the tools ranges from 36 to 313 for Maven and from 45 to 234 for npm projects. Our manual analysis of the tools' results suggest that accuracy of the vulnerability database is a key differentiator for SCA tools. Conclusion: We recommend that practitioners should not rely on any single tool at the present, as that can result in missing known vulnerabilities. We point out two research directions in the SCA space: i) establishing frameworks and metrics to identify false positives for dependency vulnerabilities; and ii) building automation technologies for continuous monitoring of vulnerability data from open source package ecosystems.},
booktitle = {Proceedings of the 15th ACM / IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM)},
articleno = {5},
numpages = {11},
keywords = {vulnerability, supply chain security, software composition analysis, security tools, dependency, case study},
location = {Bari, Italy},
series = {ESEM '21}
}

@inproceedings{10.1145/3475716.3475778,
author = {Klotzman, Vanessa and Farmahinifarahani, Farima and Lopes, Cristina},
title = {Public Software Development Activity During the Pandemic},
year = {2021},
isbn = {9781450386654},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3475716.3475778},
doi = {10.1145/3475716.3475778},
abstract = {Background The emergence of the COVID-19 pandemic has impacted all human activity, including software development. Early reports seem to indicate that the pandemic may have had a negative effect on software developers, socially and personally, but that their software development productivity may not have been negatively impacted. Aims: Early reports about the effects of the pandemic on software development focused on software developers' well-being and on their productivity as employees. We are interested in a different aspect of software development: the developers' public contributions, as seen in GitHub and Stack Overflow activities. Did the pandemic affect the developers' public contributions and, of so, in what way? Method: Considering the data from between 2017 and till 2020, we study the trends within GitHub's push, create, pull request, and release events, and within Stack Overflow's new users, posts, votes, and comments. We performed linear regressions, correlation analyses, outlier analyses, hypothesis testing, and we also contacted individual developers in order to gather qualitative insights about their unusual public contributions. Results: Our study shows that within GitHub and Stack Overflow, the onset of the pandemic (March/April 2020) is reflected in a set of outliers in developers' contributions that point to an increase in activity. The distributions of contributions during the entire year of 2020 were, in some aspects, different, but, in other aspects, similar from the recent past. Additionally, we found one noticeably disrupted pattern of contribution in Stack Overflow, namely the ratio Questions/Answers, which was much higher in 2020 than before. Testimonials from the developers we contacted were mixed: while some developers reported that their increase in activity was due to the pandemic, others reported that it was not. Conclusion: In Github, there was a noticeable increase in public software development activity in 2020, as well as more abrupt changes in daily activities; in Stack Overflow, there was a noticeable increase in new users and new questions at the onset of the pandemic, and in the ratio of Questions/Answers during 2020. The results may be attributed to the pandemic, but other factors could have come into play.},
booktitle = {Proceedings of the 15th ACM / IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM)},
articleno = {18},
numpages = {12},
keywords = {Stack Overflow, Pandemic, GitHub, Developer activity},
location = {Bari, Italy},
series = {ESEM '21}
}

@inproceedings{10.1145/3568562.3568628,
author = {Nguyen, Anh T. V. and Ogawa, Mizuhito},
title = {Automatic Stub Generation for Dynamic Symbolic Execution of ARM binary},
year = {2022},
isbn = {9781450397254},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3568562.3568628},
doi = {10.1145/3568562.3568628},
abstract = {Recently, dynamic symbolic execution (DSE) tools for binary codes (mostly for x86) have been developed, e.g., McVeto, CoDisasm, MAYHEM, KLEE-MC, BE-PUM, angr, BINSEC and CORANA. When a process stays in the uniform context, DSE simply obeys the formal semantics of an instruction set. Practical binary code like malware often uses system functions, which are beyond the user-level context, which requires stubs to simulate them. This paper proposed an automatic generation of Linux API Stub from the C function interface, which extends the DSE tool CORANA for ARM. The API stub is an under-approximation of a system function call by spawning its execution in the real Linux environment, and its Hoare logic deduction rule is defined and justified in terms of awareness. We implement CORANA/API and its experiments on real-world IoT malware, such as Mirai, is reported.},
booktitle = {Proceedings of the 11th International Symposium on Information and Communication Technology},
pages = {352–359},
numpages = {8},
keywords = {Linux on ARM, IoT malware analysis, Dynamic Symbolic Execution, API Stub Generation},
location = {Hanoi, Vietnam},
series = {SoICT '22}
}

@inproceedings{10.1145/2702123.2702409,
author = {Kim, SeungJun and Chun, Jaemin and Dey, Anind K.},
title = {Sensors Know When to Interrupt You in the Car: Detecting Driver Interruptibility Through Monitoring of Peripheral Interactions},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702409},
doi = {10.1145/2702123.2702409},
abstract = {Interruptions while driving can be quite dangerous, whether these are self-interruptions or external interruptions. They increase driver workload and reduce performance on the primary driving task. Being able to identify when a driver is interruptible is critical for building systems that can mediate these interruptions. In this paper, we collect sensor and human-annotated data from 15 drivers, including vehicle motion, traffic states, physiological responses and driver motion. We demonstrate that this data can be used to build a machine learning classifier that can determine interruptibility every second with a 94% accuracy. We present both population and individual models and discuss the features that contribute to the high performance of this system. Such a classifier can be used to build systems that mediate when drivers use technology to self-interrupt and when drivers are interrupted by technology.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {487–496},
numpages = {10},
keywords = {sensor data mining, naturalistic driving, interruptions},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/1985793.1985831,
author = {Zhou, Minghui and Mockus, Audris},
title = {Does the initial environment impact the future of developers?},
year = {2011},
isbn = {9781450304450},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1985793.1985831},
doi = {10.1145/1985793.1985831},
abstract = {Software developers need to develop technical and social skills to be successful in large projects. We model the relative sociality of developer as a ratio between the size of her communication network and the number of tasks she participates in. We obtain both measures from the problem tracking systems. We use her workflow peer network to represent her social learning, and the issues she has worked on to represent her technical learning. Using three open source and three traditional projects we investigate how the project environment reflected by the sociality measure at the time a developer joins, affects her future participation. We find: a) the probability that a new developer will become one of long-term and productive developers is highest when the project sociality is low; b) times of high sociality are associated with a higher intensity of new contributors joining the project; c) there are significant differences between the social learning trajectories of the developers who join in low and in high sociality environments; d) the open source and commercial projects exhibit different nature in the relationship between developer's tenure and the project's environment at the time she joins. These findings point out the importance of the initial environment in determining the future of the developers and may lead to better training and learning strategies in software organizations.},
booktitle = {Proceedings of the 33rd International Conference on Software Engineering},
pages = {271–280},
numpages = {10},
keywords = {socio-technical balance, relative sociality, learning trajectory, initial environment},
location = {Waikiki, Honolulu, HI, USA},
series = {ICSE '11}
}

@proceedings{10.5555/3606010,
title = {ICSE '23: Proceedings of the 45th International Conference on Software Engineering},
year = {2023},
isbn = {9781665457019},
publisher = {IEEE Press},
abstract = {ICSE is the leading and by far the largest conference in Software Engineering, attracting researchers, practitioners and students from around the world. ICSE2023 is co-located with 10 conferences and symposia this year, many long-established and prestigious venues in their own right.},
location = {Melbourne, Victoria, Australia}
}

@inproceedings{10.1145/2745197.2755520,
author = {Eversman, Dillon and Major, Timothy and Tople, Mithila and Schaffer, Lauren and Murray, Janet},
title = {United Universe: A Second Screen Transmedia Experience},
year = {2015},
isbn = {9781450335263},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2745197.2755520},
doi = {10.1145/2745197.2755520},
abstract = {United Universe is a second screen transmedia experience aimed at supporting understanding of a complex storyworld presented across media artifacts. Using the highly interconnected and allusive Marvel Cinematic Universe as a primary example, United Universe abstracts a story into the fundamental elements of characters, events, items, and locations, and presents them in a "glanceable" manner to the interactor. As significant story elements are referenced, the application provides explanatory information on the second screen. Drawing from the larger story world made up of multiple comic books, movies, games, and television shows, United Universe aims to provide clarity and background for the novice, and depth and engagement for more knowledgeable viewers.},
booktitle = {Proceedings of the ACM International Conference on Interactive Experiences for TV and Online Video},
pages = {173–178},
numpages = {6},
keywords = {transmedia, television, second screen, media evolution, interactive television, film, cinematic universe},
location = {Brussels, Belgium},
series = {TVX '15}
}

@inproceedings{10.1145/2388676.2388727,
author = {Read, Janet C.},
title = {Evaluating artefacts with children: age and technology effects in the reporting of expected and experienced fun},
year = {2012},
isbn = {9781450314671},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2388676.2388727},
doi = {10.1145/2388676.2388727},
abstract = {In interaction design, there are several metrics used to gather user experience data. A common approach is to use surveys with the usual method being to ask users after they have experienced a product as to their opinion and satisfaction. This paper describes the use of the Smileyometer (a product from the Fun Toolkit) to test for user experience with children by asking for opinions in relation to expected as well as experienced fun.Two studies looked at the ratings that children, from two different age groups and in two different contexts, gave to a set of varied age-appropriate interactive technology installations. The ratings given before use (expectations) are compared with ratings given after use (experience) across the age groups and across installations.The studies show that different ratings were given for the different installations and that there were age-related differences in the use of the Smileyometer to rate user experience; these firstly evidence that children can, and do, discriminate between different experiences and that children do reflect on user experience after using technologies. In most cases, across both age groups, children expected a lot from the technologies and their after use (experienced) rating confirmed that this was what they had got.The paper concludes by considering the implications of the collective findings for the design and evaluation of technologies with children},
booktitle = {Proceedings of the 14th ACM International Conference on Multimodal Interaction},
pages = {241–248},
numpages = {8},
keywords = {user experience, fun toolkit, evaluation methods, children},
location = {Santa Monica, California, USA},
series = {ICMI '12}
}

@inproceedings{10.1145/3510003.3510108,
author = {Shi, Lin and Mu, Fangwen and Zhang, Yumin and Yang, Ye and Chen, Junjie and Chen, Xiao and Jiang, Hanzhi and Jiang, Ziyou and Wang, Qing},
title = {BugListener: identifying and synthesizing bug reports from collaborative live chats},
year = {2022},
isbn = {9781450392211},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3510003.3510108},
doi = {10.1145/3510003.3510108},
abstract = {In community-based software development, developers frequently rely on live-chatting to discuss emergent bugs/errors they encounter in daily development tasks. However, it remains a challenging task to accurately record such knowledge due to the noisy nature of interleaved dialogs in live chat data. In this paper, we first formulate the task of identifying and synthesizing bug reports from community live chats, and propose a novel approach, named BugListener, to address the challenges. Specifically, BugListener automates three sub-tasks: 1) Disentangle the dialogs from massive chat logs by using a Feed-Forward neural network; 2) Identify the bug-report dialogs from separated dialogs by leveraging the Graph neural network to learn the contextual information; 3) Synthesize the bug reports by utilizing Transfer Learning techniques to classify the sentences into: observed behaviors (OB), expected behaviors (EB), and steps to reproduce the bug (SR). BugListener is evaluated on six open source projects. The results show that: for bug report identification, BugListener achieves the average F1 of 77.74%, improving the best baseline by 12.96%; and for bug report synthesis task, BugListener could classify the OB, EB, and SR sentences with the F1 of 84.62%, 71.46%, and 73.13%, improving the best baselines by 9.32%, 12.21%, 10.91%, respectively. A human evaluation study also confirms the effectiveness of BugListener in generating relevant and accurate bug reports. These demonstrate the significant potential of applying BugListener in community-based software development, for promoting bug discovery and quality improvement.},
booktitle = {Proceedings of the 44th International Conference on Software Engineering},
pages = {299–311},
numpages = {13},
keywords = {open source, live chats mining, bug report generation},
location = {Pittsburgh, Pennsylvania},
series = {ICSE '22}
}

@proceedings{10.1145/3555051,
title = {OpenSym '22: Proceedings of the 18th International Symposium on Open Collaboration},
year = {2022},
isbn = {9781450398459},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Madrid, Spain}
}

@article{10.1145/3479497,
author = {Ferreira, Isabella and Cheng, Jinghui and Adams, Bram},
title = {The "Shut the f**k up" Phenomenon: Characterizing Incivility in Open Source Code Review Discussions},
year = {2021},
issue_date = {October 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {CSCW2},
url = {https://doi.org/10.1145/3479497},
doi = {10.1145/3479497},
abstract = {Code review is an important quality assurance activity for software development. Code review discussions among developers and maintainers can be heated and sometimes involve personal attacks and unnecessary disrespectful comments, demonstrating, therefore, incivility. Although incivility in public discussions has received increasing attention from researchers in different domains, the knowledge about the characteristics, causes, and consequences of uncivil communication is still very limited in the context of software development, and more specifically, code review. To address this gap in the literature, we leverage the mature social construct of incivility as a lens to understand confrontational conflicts in open source code review discussions. For that, we conducted a qualitative analysis on 1,545 emails from the Linux Kernel Mailing List (LKML) that were associated with rejected changes. We found that more than half (66.66%) of the non-technical emails included uncivil features. Particularly, frustration, name calling, and impatience are the most frequent features in uncivil emails. We also found that there are civil alternatives to address arguments, while uncivil comments can potentially be made by any people when discussing any topic. Finally, we identified various causes and consequences of such uncivil communication. Our work serves as the first study about the phenomenon of in(civility) in open source software development, paving the road for a new field of research about collaboration and communication in the context of software engineering activities.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = {oct},
articleno = {353},
numpages = {35},
keywords = {civility, code review, communication, incivility, online communities, open source}
}

@inproceedings{10.1145/3292006.3300029,
author = {Toffalini, Flavio and Ochoa, Mart\'{\i}n and Sun, Jun and Zhou, Jianying},
title = {Careful-Packing: A Practical and Scalable Anti-Tampering Software Protection enforced by Trusted Computing},
year = {2019},
isbn = {9781450360999},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3292006.3300029},
doi = {10.1145/3292006.3300029},
abstract = {Ensuring the correct behaviour of an application is a critical security issue. One of the most popular ways to modify the intended behaviour of a program is to tamper its binary. Several solutions have been proposed to solve this problem, including trusted computing and anti-tampering techniques. Both can substantially increase security, and yet both have limitations. In this work, we propose an approach which combines trusted computing technologies and anti-tampering techniques, and that synergistically overcomes some of their inherent limitations. In our approach critical software regions are protected by leveraging on trusted computing technologies and cryptographic packing, without introducing additional software layers. To illustrate our approach we implemented a secure monitor which collects user activities, such as keyboard and mouse events for insider attack detection. We show how our solution provides a strong anti-tampering guarantee with a low overhead: around 10 lines of code added to the entire application, an average execution time overhead of 5.7% and only 300KB of memory allocated for the trusted module.},
booktitle = {Proceedings of the Ninth ACM Conference on Data and Application Security and Privacy},
pages = {231–242},
numpages = {12},
keywords = {trusted computing, software guard extension, sgx, anti-tampering},
location = {Richardson, Texas, USA},
series = {CODASPY '19}
}

@article{10.1145/3479575,
author = {Smith, Micah J. and Cito, J\"{u}rgen and Lu, Kelvin and Veeramachaneni, Kalyan},
title = {Enabling Collaborative Data Science Development with the Ballet Framework},
year = {2021},
issue_date = {October 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {CSCW2},
url = {https://doi.org/10.1145/3479575},
doi = {10.1145/3479575},
abstract = {While the open-source software development model has led to successful large-scale collaborations in building software systems, data science projects are frequently developed by individuals or small teams. We describe challenges to scaling data science collaborations and present a conceptual framework and ML programming model to address them. We instantiate these ideas in Ballet, the first lightweight framework for collaborative, open-source data science through a focus on feature engineering, and an accompanying cloud-based development environment. Using our framework, collaborators incrementally propose feature definitions to a repository which are each subjected to software and ML performance validation and can be automatically merged into an executable feature engineering pipeline. We leverage Ballet to conduct a case study analysis of an income prediction problem with 27 collaborators, and discuss implications for future designers of collaborative projects.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = {oct},
articleno = {431},
numpages = {39},
keywords = {collaborative framework, data science, feature definition, feature engineering, feature validation, machine learning, mutual information, streaming feature selection}
}

@inproceedings{10.5555/1082161.1082186,
author = {Eisman, Gerry and Ravikumar, B.},
title = {Approximate recognition of non-regular languages by finite automata},
year = {2005},
isbn = {1920682201},
publisher = {Australian Computer Society, Inc.},
address = {AUS},
abstract = {Approximate computation is a central concept in algorithms and computation theory. Our notion of approximation is that the algorithm perform correctly on most of the inputs. We propose some finite automata models to study the question of how well a finite automaton can approximately recognize a non-regular language. On the one hand, we show that there are natural problems for which a DFA can correctly solve almost all the instances. The design of these DFA's leads to a linear time randomized algorithm for approximate integer multiplication. On the other hand, we show that some languages (such as Lmajority = {x ∈ (0 + 1)* | x has more 1's than 0's}) can't be approximated by any regular language in a strong sense. We also present results comparing different models of approximation.},
booktitle = {Proceedings of the Twenty-Eighth Australasian Conference on Computer Science - Volume 38},
pages = {219–227},
numpages = {9},
keywords = {approximation, finite automata, majority language, squaring},
location = {Newcastle, Australia},
series = {ACSC '05}
}

@article{10.1145/3555183,
author = {Gunawardena, Sanuri Dananja and Devine, Peter and Beaumont, Isabelle and Garden, Lola Piper and Murphy-Hill, Emerson and Blincoe, Kelly},
title = {Destructive Criticism in Software Code Review Impacts Inclusion},
year = {2022},
issue_date = {November 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {CSCW2},
url = {https://doi.org/10.1145/3555183},
doi = {10.1145/3555183},
abstract = {The software industry lacks gender diversity. Recent research has suggested that a toxic working culture is to blame. Studies have found that communications in software repositories directed towards women are more negative in general. In this study, we use a destructive criticism lens to examine gender differences in software code review feedback. Software code review is a practice where code is peer reviewed and negative feedback is often delivered. We explore differences in perceptions, frequency, and impact of destructive criticism across genders. We surveyed 93 software practitioners eliciting perceived reactions to hypothetical scenarios (or vignettes) where participants are asked to imagine receiving either constructive or destructive criticism. In addition, the survey collected general opinions on feedback obtained during software code review as well as the frequency that participants give and receive destructive criticism.We found that opinions on destructive criticism vary. Women perceive destructive criticism as less appropriate and are less motivated to continue working with the developer after receiving destructive criticism. Destructive criticism is fairly common with more than half of respondents having received nonspecific negative feedback and nearly a quarter having received inconsiderate negative feedback in the past year. Our results suggest that destructive criticism in code review could be a contributing factor to the lack of gender diversity observed in the software industry.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = {nov},
articleno = {292},
numpages = {29},
keywords = {software engineering, software code review, diversity and inclusion, destructive criticism}
}

@inproceedings{10.1145/2393132.2393152,
author = {Ampatzoglou, Apostolos and Stamelos, Ioannis and Gkortzis, Antonios and Deligiannis, Ignatios},
title = {A methodology on extracting reusable software candidate components from open source games},
year = {2012},
isbn = {9781450316378},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2393132.2393152},
doi = {10.1145/2393132.2393152},
abstract = {Component-Based Software Engineering (CBSE) focuses on the development of reusable components in order to enable their reuse in more systems, rather than only to be used to the original ones for which they have been implemented in the first place (i.e. development for reuse) and the development of new systems with reusable components (i.e. development with reuse). This paper aims at introducing a methodology for the extraction of candidate reusable software components from open source games. The extracted components have been empirically evaluated through a case study. Additionally, the component candidates that have been extracted are available for reuse through a web service.},
booktitle = {Proceeding of the 16th International Academic MindTrek Conference},
pages = {93–100},
numpages = {8},
keywords = {metrics, component selection, class dependencies, case study},
location = {Tampere, Finland},
series = {MindTrek '12}
}

@article{10.1145/3510424,
author = {Bradbury, Matthew and Jhumka, Arshad and Watson, Tim and Flores, Denys and Burton, Jonathan and Butler, Matthew},
title = {Threat-modeling-guided Trust-based Task Offloading for Resource-constrained Internet of Things},
year = {2022},
issue_date = {May 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {2},
issn = {1550-4859},
url = {https://doi.org/10.1145/3510424},
doi = {10.1145/3510424},
abstract = {There is an increasing demand for Internet of Things (IoT) networks consisting of resource-constrained devices executing increasingly complex applications. Due to these resource constraints, IoT devices will not be able to execute expensive tasks. One solution is to offload expensive tasks to resource-rich edge nodes, which requires a framework that facilitates the selection of suitable edge nodes to perform task offloading. Therefore, in this article, we present a novel trust-model-driven system architecture, based on behavioral evidence, that is suitable for resource-constrained IoT devices and supports computation offloading. We demonstrate the viability of the proposed architecture with an example deployment of the Beta Reputation System trust model on real hardware to capture node behaviors. The open environment of edge-based IoT networks means that threats against edge nodes can lead to deviation from expected behavior. Hence, we perform a threat modeling to identify such threats. The proposed system architecture includes threat handling mechanisms that provide security properties such as confidentiality, authentication, and non-repudiation of messages in required scenarios and operate within the resource constraints. We evaluate the efficacy of the threat handling mechanisms and identify future work for the standards used.},
journal = {ACM Trans. Sen. Netw.},
month = {feb},
articleno = {29},
numpages = {41},
keywords = {threat modelling, edge computing, resource constrained, Internet of Things, computation offloading, Trust}
}

@article{10.5555/146384.146390,
author = {Batagelj, Vladimir and Pisanski, Toma\v{z} and Ker\v{z}i\v{c}, Damijana},
title = {Automatic clustering of languages},
year = {1992},
issue_date = {September 1992},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
volume = {18},
number = {3},
issn = {0891-2017},
abstract = {Automatic clustering of languages seems to be one possible application that arose during our study of mathematical methods for computing dissimilarities between strings. The results of this experiment are discussed.},
journal = {Comput. Linguist.},
month = {sep},
pages = {339–352},
numpages = {14}
}

@inproceedings{10.1145/3377811.3380414,
author = {Egelman, Carolyn D. and Murphy-Hill, Emerson and Kammer, Elizabeth and Hodges, Margaret Morrow and Green, Collin and Jaspan, Ciera and Lin, James},
title = {Predicting developers' negative feelings about code review},
year = {2020},
isbn = {9781450371216},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377811.3380414},
doi = {10.1145/3377811.3380414},
abstract = {During code review, developers critically examine each others' code to improve its quality, share knowledge, and ensure conformance to coding standards. In the process, developers may have negative interpersonal interactions with their peers, which can lead to frustration and stress; these negative interactions may ultimately result in developers abandoning projects. In this mixed-methods study at one company, we surveyed 1,317 developers to characterize the negative experiences and cross-referenced the results with objective data from code review logs to predict these experiences. Our results suggest that such negative experiences, which we call "pushback", are relatively rare in practice, but have negative repercussions when they occur. Our metrics can predict feelings of pushback with high recall but low precision, making them potentially appropriate for highlighting interactions that may benefit from a self-intervention.},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering},
pages = {174–185},
numpages = {12},
keywords = {interpersonal conflict, code review},
location = {Seoul, South Korea},
series = {ICSE '20}
}

@inproceedings{10.1145/2998181.2998360,
author = {Arciniegas-Mendez, Maryi and Zagalsky, Alexey and Storey, Margaret-Anne and Hadwin, Allyson Fiona},
title = {Using the Model of Regulation to Understand Software Development Collaboration Practices and Tool Support},
year = {2017},
isbn = {9781450343350},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2998181.2998360},
doi = {10.1145/2998181.2998360},
abstract = {We developed the Model of Regulation to provide a vocabulary for comparing and analyzing collaboration practices and tools in software engineering. This paper discusses the model's ability to capture how individuals self-regulate their own tasks and activities, how they regulate one another, and how they achieve a shared understanding of project goals and tasks. Using the model, we created an "action-oriented" instrument that individuals, teams, and organizations can use to reflect on how they regulate their work and on the various tools they use as part of regulation. We applied this instrument to two industrial software projects, interviewing one or two stakeholders from each project. The model allowed us to identify where certain processes and communication channels worked well, while recognizing friction points, communication breakdowns, and regulation gaps. We believe this model also shows potential for application in other domains.},
booktitle = {Proceedings of the 2017 ACM Conference on Computer Supported Cooperative Work and Social Computing},
pages = {1049–1065},
numpages = {17},
keywords = {theory, regulation, collaboration},
location = {Portland, Oregon, USA},
series = {CSCW '17}
}

@proceedings{10.1145/3641822,
title = {CHASE '24: Proceedings of the 2024 IEEE/ACM 17th International Conference on Cooperative and Human Aspects of Software Engineering},
year = {2024},
isbn = {9798400705335},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {CHASE 2024 continues the tradition of a high-quality venue for research related to the cooperative and human aspects of software engineering. Researchers and practitioners have long recognized the need to investigate the cooperative and human aspects. However, their articles have been scattered across many conferences and communities. The CHASE conference provides academics and practitioners with a unified forum for discussing high-quality research studies, models, methods, and tools for human and cooperative aspects of software engineering.},
location = {Lisbon, Portugal}
}

@article{10.1145/3530785,
author = {Khatoonabadi, Sayedhassan and Costa, Diego Elias and Abdalkareem, Rabe and Shihab, Emad},
title = {On Wasted Contributions: Understanding the Dynamics of Contributor-Abandoned Pull Requests–A Mixed-Methods Study of 10 Large Open-Source Projects},
year = {2023},
issue_date = {January 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {32},
number = {1},
issn = {1049-331X},
url = {https://doi.org/10.1145/3530785},
doi = {10.1145/3530785},
abstract = {Pull-based development has enabled numerous volunteers to contribute to open-source projects with fewer barriers. Nevertheless, a considerable amount of pull requests (PRs) with valid contributions are abandoned by their contributors, wasting the effort and time put in by both the contributors and maintainers. To better understand the underlying dynamics of contributor-abandoned PRs, we conduct a mixed-methods study using both quantitative and qualitative methods. We curate a dataset consisting of 265,325 PRs including 4,450 abandoned ones from ten popular and mature GitHub projects and measure 16 features characterizing PRs, contributors, review processes, and projects. Using statistical and machine learning techniques, we find that complex PRs, novice contributors, and lengthy reviews have a higher probability of abandonment and the rate of PR abandonment fluctuates alongside the projects’ maturity or workload. To identify why contributors abandon their PRs, we also manually examine a random sample of 354 abandoned PRs. We observe that the most frequent abandonment reasons are related to the obstacles faced by contributors, followed by the hurdles imposed by maintainers during the review process. Finally, we survey the top core maintainers of the studied projects to understand their perspectives on dealing with PR abandonment and on our findings.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = {feb},
articleno = {15},
numpages = {39},
keywords = {mixed-methods research, open-source software, social coding platforms, modern code review, pull-based development, Socio-technical factors}
}

@article{10.1145/3318162,
author = {Goues, Claire Le and Pradel, Michael and Roychoudhury, Abhik},
title = {Automated program repair},
year = {2019},
issue_date = {December 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {62},
number = {12},
issn = {0001-0782},
url = {https://doi.org/10.1145/3318162},
doi = {10.1145/3318162},
abstract = {Automated program repair can relieve programmers from the burden of manually fixing the ever-increasing number of programming mistakes.},
journal = {Commun. ACM},
month = {nov},
pages = {56–65},
numpages = {10}
}

@inproceedings{10.1109/ICSE.2019.00099,
author = {Sarker, Farhana and Vasilescu, Bogdan and Blincoe, Kelly and Filkov, Vladimir},
title = {Socio-technical work-rate increase associates with changes in work patterns in online projects},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE.2019.00099},
doi = {10.1109/ICSE.2019.00099},
abstract = {Software developers work on a variety of tasks ranging from the technical, e.g., writing code, to the social, e.g., participating in issue resolution discussions. The amount of work developers perform per week (their work-rate) also varies and depends on project needs and developer schedules. Prior work has shown that while moderate levels of increased technical work and multitasking lead to higher productivity, beyond a certain threshold, they can lead to lowered performance.Here, we study how increases in the short-term work-rate along both the technical and social dimensions are associated with changes in developers' work patterns, in particular communication sentiment, technical productivity, and social productivity. We surveyed active and prolific developers on GitHub to understand the causes and impacts of increased work-rates. Guided by the responses, we developed regression models to study how communication and committing patterns change with increased work-rates and fit those models to large-scale data gathered from traces left by thousands of GitHub developers. From our survey and models, we find that most developers do experience work-rate-increase-related changes in behavior. Most notably, our models show that there is a sizable effect when developers comment much more than their average: the negative sentiment in their comments increases, suggesting an increased level of stress. Our models also show that committing patterns do not change with increased commenting, and vice versa, suggesting that technical and social activities tend not to be multitasked.},
booktitle = {Proceedings of the 41st International Conference on Software Engineering},
pages = {936–947},
numpages = {12},
location = {Montreal, Quebec, Canada},
series = {ICSE '19}
}

@inproceedings{10.1109/ICSE48619.2023.00108,
author = {Nejati, Mahtab and Alfadel, Mahmoud and McIntosh, Shane},
title = {Code Review of Build System Specifications: Prevalence, Purposes, Patterns, and Perceptions},
year = {2023},
isbn = {9781665457019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE48619.2023.00108},
doi = {10.1109/ICSE48619.2023.00108},
abstract = {Build systems automate the integration of source code into executables. Maintaining build systems is known to be challenging. Lax build maintenance can lead to costly build breakages or unexpected software behaviour. Code review is a broadly adopted practice to improve software quality. Yet, little is known about how code review is applied to build specifications.In this paper, we present the first empirical study of how code review is practiced in the context of build specifications. Through quantitative analysis of 502,931 change sets from the Qt and Eclipse communities, we observe that changes to build specifications are at least two times less frequently discussed during code review when compared to production and test code changes. A qualitative analysis of 500 change sets reveals that (i) comments on changes to build specifications are more likely to point out defects than rates reported in the literature for production and test code, and (ii) evolvability and dependency-related issues are the most frequently raised patterns of issues. Follow-up interviews with nine developers with 1--40 years of experience point out social and technical factors that hinder rigorous review of build specifications, such as a prevailing lack of understanding of and interest in build systems among developers, and the lack of dedicated tooling to support the code review of build specifications.},
booktitle = {Proceedings of the 45th International Conference on Software Engineering},
pages = {1213–1224},
numpages = {12},
keywords = {code review, build specifications, build systems},
location = {Melbourne, Victoria, Australia},
series = {ICSE '23}
}

@article{10.1145/3583562,
author = {Sarker, Jaydeb and Turzo, Asif Kamal and Dong, Ming and Bosu, Amiangshu},
title = {Automated Identification of Toxic Code Reviews Using ToxiCR},
year = {2023},
issue_date = {September 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {32},
number = {5},
issn = {1049-331X},
url = {https://doi.org/10.1145/3583562},
doi = {10.1145/3583562},
abstract = {Toxic conversations during software development interactions may have serious repercussions on a Free and Open Source Software (FOSS) development project. For example, victims of toxic conversations may become afraid to express themselves, therefore get demotivated, and may eventually leave the project. Automated filtering of toxic conversations may help a FOSS community maintain healthy interactions among its members. However, off-the-shelf toxicity detectors perform poorly on a software engineering dataset, such as one curated from code review comments. To counter this challenge, we present ToxiCR, a supervised learning based toxicity identification tool for code review interactions. ToxiCR includes a choice to select one of the 10 supervised learning algorithms, an option to select text vectorization techniques, eight preprocessing steps, and a large-scale labeled dataset of 19,651 code review comments. Two out of those eight preprocessing steps are software engineering domain specific. With our rigorous evaluation of the models with various combinations of preprocessing steps and vectorization techniques, we have identified the best combination for our dataset that boosts 95.8% accuracy and an 88.9% F1-score in identifying toxic texts. ToxiCR significantly outperforms existing toxicity detectors on our dataset. We have released our dataset, pre-trained models, evaluation results, and source code publicly, which is available at .},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = {jul},
articleno = {118},
numpages = {32},
keywords = {tool development, Natural Language Processing, sentiment analysis, code review, Toxicity}
}

@article{10.1145/2661642,
author = {Ziaie, Pujan},
title = {A Model for Context in the Design of Open Production Communities},
year = {2014},
issue_date = {January 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {47},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/2661642},
doi = {10.1145/2661642},
abstract = {Open production communities (OPCs) provide technical features and social norms for a vast but dispersed and diverse crowd to collectively accumulate content. In OPCs, certain mechanisms, policies, and technologies are provided for voluntary users to participate in community-related activities including content generation, evaluation, qualification, and distribution and in some cases even community governance. Due to the known complexities and dynamism of online communities, designing a successful community is deemed more an art than a science. Numerous studies have investigated different aspects of certain types of OPCs. Most of these studies, however, fall short of delivering a general view or prescription due to their narrow focus on a certain type of OPCs. In contribution to theories on technology-mediated social participation (TMSP), this study synthesizes the streams of research in the particular area of OPCs and delivers a theoretical framework as a baseline for adapting findings from one specific type of community on another. This framework consists of four primary dimensions, namely, platform features, content, user, and community. The corresponding attributes of these dimensions and the existing interdependencies are discussed in detail. Furthermore, a decision diagram for selecting features and a design guideline for “decontextualizing” findings are introduced as possible applications of the framework. The framework also provides a new and reliable foundation on which future research can extend its findings and prescriptions in a systematic way.},
journal = {ACM Comput. Surv.},
month = {nov},
articleno = {29},
numpages = {29},
keywords = {user-generated content, knowledge sharing, design, TMSP}
}

@inproceedings{10.1145/2857705.2857749,
author = {Mohamed, Manar and Shrestha, Babins and Saxena, Nitesh},
title = {SMASheD: Sniffing and Manipulating Android Sensor Data},
year = {2016},
isbn = {9781450339353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2857705.2857749},
doi = {10.1145/2857705.2857749},
abstract = {The current Android sensor security model either allows only restrictive read access to sensitive sensors (e.g., an app can only read its own touch data) or requires special install-time permissions (e.g., to read microphone, camera or GPS). Moreover, Android does not allow write access to any of the sensors. Sensing-based security applications therefore crucially rely upon the sanity of the Android sensor security model.In this paper, we show that such a model can be effectively circumvented. Specifically, we build SMASheD, a legitimate framework under the current Android ecosystem that can be used to stealthily sniff as well as manipulate many of the Android's restricted sensors (even touch input). SMASheD exploits the Android Debug Bridge (ADB) functionality and enables a malicious app with only the INTERNET permission to read, and write to, multiple different sensor data files at will. SMASheD is the first framework, to our knowledge, that can sniff and manipulate protected sensors on unrooted Android devices, without user awareness, without constant device-PC connection and without the need to infect the PC.The primary contributions of this work are two-fold. First, we design and develop the SMASheD framework. Second, as an offensive implication of the SMASheD framework, we introduce a wide array of potentially devastating attacks. Our attacks against the touchsensor range from accurately logging the touchscreen input (TouchLogger) to injecting touch events for accessing restricted sensors and resources, installing and granting special permissions to other malicious apps, accessing user accounts, and authenticating on behalf of the user --- essentially almost doing whatever the device user can do (secretively). Our attacks against various physical sensors (motion, position and environmental) can subvert the functionality provided by numerous existing sensing-based security applications, including those used for(continuous) authentication, and authorization.},
booktitle = {Proceedings of the Sixth ACM Conference on Data and Application Security and Privacy},
pages = {152–159},
numpages = {8},
keywords = {sensors, android},
location = {New Orleans, Louisiana, USA},
series = {CODASPY '16}
}

@inproceedings{10.1109/ICSE.2019.00079,
author = {Imtiaz, Nasif and Middleton, Justin and Chakraborty, Joymallya and Robson, Neill and Bai, Gina and Murphy-Hill, Emerson},
title = {Investigating the effects of gender bias on GitHub},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE.2019.00079},
doi = {10.1109/ICSE.2019.00079},
abstract = {Diversity, including gender diversity, is valued by many software development organizations, yet the field remains dominated by men. One reason for this lack of diversity is gender bias. In this paper, we study the effects of that bias by using an existing framework derived from the gender studies literature. We adapt the four main effects proposed in the framework by posing hypotheses about how they might manifest on GitHub, then evaluate those hypotheses quantitatively. While our results show that effects of gender bias are largely invisible on the GitHub platform itself, there are still signals of women concentrating their work in fewer places and being more restrained in communication than men.},
booktitle = {Proceedings of the 41st International Conference on Software Engineering},
pages = {700–711},
numpages = {12},
keywords = {open source, gender, GitHub},
location = {Montreal, Quebec, Canada},
series = {ICSE '19}
}

@inproceedings{10.1145/2491411.2491444,
author = {Rigby, Peter C. and Bird, Christian},
title = {Convergent contemporary software peer review practices},
year = {2013},
isbn = {9781450322379},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2491411.2491444},
doi = {10.1145/2491411.2491444},
abstract = {Software peer review is practiced on a diverse set of software projects that have drastically different settings, cultures, incentive systems, and time pressures. In an effort to characterize and understand these differences we examine two Google-led projects, Android and Chromium OS, three Microsoft projects, Bing, Office, and MS SQL, and projects internal to AMD. We contrast our findings with data taken from traditional software inspection conducted on a Lucent project and from open source software peer review on six projects, including Apache, Linux, and KDE. Our measures of interest include the review interval, the number of developers involved in review, and proxy measures for the number of defects found during review. We find that despite differences among projects, many of the characteristics of the review process have independently converged to similar values which we think indicate general principles of code review practice. We also introduce a measure of the degree to which knowledge is shared during review. This is an aspect of review practice that has traditionally only had experiential support. Our knowledge sharing measure shows that conducting peer review increases the number of distinct files a developer knows about by 66% to 150% depending on the project. This paper is one of the first studies of contemporary review in software firms and the most diverse study of peer review to date.},
booktitle = {Proceedings of the 2013 9th Joint Meeting on Foundations of Software Engineering},
pages = {202–212},
numpages = {11},
keywords = {Software firms, Peer code review, Open source software, Inspection, Empirical Software Engineering},
location = {Saint Petersburg, Russia},
series = {ESEC/FSE 2013}
}

@article{10.1145/3485532,
author = {Lubin, Justin and Chasins, Sarah E.},
title = {How statically-typed functional programmers write code},
year = {2021},
issue_date = {October 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {OOPSLA},
url = {https://doi.org/10.1145/3485532},
doi = {10.1145/3485532},
abstract = {How working statically-typed functional programmers write code is largely understudied. And yet, a better understanding of developer practices could pave the way for the design of more useful and usable tooling, more ergonomic languages, and more effective on-ramps into programming communities. The goal of this work is to address this knowledge gap: to better understand the high-level authoring patterns that statically-typed functional programmers employ. We conducted a grounded theory analysis of 30 programming sessions of practicing statically-typed functional programmers, 15 of which also included a semi-structured interview. The theory we developed gives insight into how the specific affordances of statically-typed functional programming affect domain modeling, type construction, focusing techniques, exploratory and reasoning strategies, and expressions of intent. We conducted a set of quantitative lab experiments to validate our findings, including that statically-typed functional programmers often iterate between editing types and expressions, that they often run their compiler on code even when they know it will not successfully compile, and that they make textual program edits that reliably signal future edits that they intend to make. Lastly, we outline the implications of our findings for language and tool design. The success of this approach in revealing program authorship patterns suggests that the same methodology could be used to study other understudied programmer populations.},
journal = {Proc. ACM Program. Lang.},
month = {oct},
articleno = {155},
numpages = {30},
keywords = {static types, randomized controlled trial, quantitative, qualitative, need-finding, mixed methods, interviews, grounded theory, functional programming}
}

@proceedings{10.5555/3623290,
title = {ICSE-SEIS '23: Proceedings of the 45th International Conference on Software Engineering: Software Engineering in Society},
year = {2023},
isbn = {9798350322613},
publisher = {IEEE Press},
abstract = {We are delighted to introduce the Software Engineering in Society (SEIS) track program as part of the 45th IEEE/ACM International Conference on Software Engineering, to be held in Melbourne, Australia, on May 14-20, 2023. The aim of the track is to bring together researchers studying various roles that software engineering plays in society.},
location = {Melbourne, Australia}
}

@inproceedings{10.1145/2046707.2046751,
author = {Srinivasan, Deepa and Wang, Zhi and Jiang, Xuxian and Xu, Dongyan},
title = {Process out-grafting: an efficient "out-of-VM" approach for fine-grained process execution monitoring},
year = {2011},
isbn = {9781450309486},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2046707.2046751},
doi = {10.1145/2046707.2046751},
abstract = {Recent rapid malware growth has exposed the limitations of traditional in-host malware-defense systems and motivated the development of secure virtualization-based out-of-VM solutions. By running vulnerable systems as virtual machines (VMs) and moving security software from inside the VMs to outside, the out-of-VM solutions securely isolate the anti-malware software from the vulnerable system. However, the presence of semantic gap also leads to the compatibility problem in not supporting existing defense software. In this paper, we present process out-grafting, an architectural approach to address both isolation and compatibility challenges in out-of-VM approaches for fine-grained process-level execution monitoring. Specifically, by relocating a suspect process from inside a VM to run side-by-side with the out-of-VM security tool, our technique effectively removes the semantic gap and supports existing user-mode process monitoring tools without any modification. Moreover, by forwarding the system calls back to the VM, we can smoothly continue the execution of the out-grafted process without weakening the isolation of the monitoring tool. We have developed a KVM-based prototype and used it to natively support a number of existing tools without any modification. The evaluation results including measurement with benchmark programs show it is effective and practical with a small performance overhead.},
booktitle = {Proceedings of the 18th ACM Conference on Computer and Communications Security},
pages = {363–374},
numpages = {12},
keywords = {virtualization, semantic gap, process monitoring},
location = {Chicago, Illinois, USA},
series = {CCS '11}
}

@proceedings{10.5555/3623295,
title = {ICSE-SEET '23: Proceedings of the 45th International Conference on Software Engineering: Software Engineering Education and Training},
year = {2023},
isbn = {9798350322590},
publisher = {IEEE Press},
location = {Melbourne, Australia}
}

@article{10.1145/3449093,
author = {Li, Renee and Pandurangan, Pavitthra and Frluckaj, Hana and Dabbish, Laura},
title = {Code of Conduct Conversations in Open Source Software Projects on Github},
year = {2021},
issue_date = {April 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {CSCW1},
url = {https://doi.org/10.1145/3449093},
doi = {10.1145/3449093},
abstract = {The rapid growth of open source software necessitates a deeper understanding of moderation and governance methods currently used within these projects. The code of conduct, a set of rules articulating standard behavior and responsibilities for participation within a community, is becoming an increasingly common policy document in open source software projects for setting project norms of behavior and discouraging negative or harassing comments and conversation. This study describes the conversations around adopting and crafting a code of conduct as well as those utilizing code of conduct for community governance. We conduct a qualitative analysis of a random sample of GitHub issues that involve the code of conduct. We find that codes of conduct are used both proactively and reactively to govern community behavior in project issues. Oftentimes, the initial addition of a code of conduct does not involve much community participation and input. However, a controversial moderation act is capable of inciting mass community feedback and backlash. Project maintainers balance the tension between disciplining potentially offensive forms of speech and encouraging broad and inclusive participation. These results have implications for the design of inclusive and effective governance practices for open source software communities.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = {apr},
articleno = {19},
numpages = {31},
keywords = {collaboration, open source software}
}

@inproceedings{10.1145/3524842.3527932,
author = {AlOmar, Eman Abdullah and Chouchen, Moataz and Mkaouer, Mohamed Wiem and Ouni, Ali},
title = {Code review practices for refactoring changes: an empirical study on OpenStack},
year = {2022},
isbn = {9781450393034},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3524842.3527932},
doi = {10.1145/3524842.3527932},
abstract = {Modern code review is a widely used technique employed in both industrial and open-source projects to improve software quality, share knowledge, and ensure adherence to coding standards and guidelines. During code review, developers may discuss refactoring activities before merging code changes in the code base. To date, code review has been extensively studied to explore its general challenges, best practices and outcomes, and socio-technical aspects. However, little is known about how refactoring is being reviewed and what developers care about when they review refactored code. Hence, in this work, we present a quantitative and qualitative study to understand what are the main criteria developers rely on to develop a decision about accepting or rejecting a submitted refactored code, and what makes this process challenging. Through a case study of 11,010 refactoring and non-refactoring reviews spread across OpenStack open-source projects, we find that refactoring-related code reviews take significantly longer to be resolved in terms of code review efforts. Moreover, upon performing a thematic analysis on a significant sample of the refactoring code review discussions, we built a comprehensive taxonomy consisting of 28 refactoring review criteria. We envision our findings reaffirming the necessity of developing accurate and efficient tools and techniques that can assist developers in the review process in the presence of refactorings.},
booktitle = {Proceedings of the 19th International Conference on Mining Software Repositories},
pages = {689–701},
numpages = {13},
keywords = {software quality, refactoring, developer perception, code review},
location = {Pittsburgh, Pennsylvania},
series = {MSR '22}
}

@proceedings{10.1145/3598469,
title = {dg.o '23: Proceedings of the 24th Annual International Conference on Digital Government Research},
year = {2023},
isbn = {9798400708374},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Gda?sk, Poland}
}

@proceedings{10.5555/3623288,
title = {ICSE-NIER '23: Proceedings of the 45th International Conference on Software Engineering: New Ideas and Emerging Results},
year = {2023},
isbn = {9798350300390},
publisher = {IEEE Press},
abstract = {ICSE is the leading and by far the largest conference in Software Engineering, attracting researchers, practitioners and students from around the world. ICSE2023 is co-located with 10 conferences and symposia this year, many long-established and prestigious venues in their own right.},
location = {Melbourne, Australia}
}

@inproceedings{10.1145/3236024.3236080,
author = {Ram, Achyudh and Sawant, Anand Ashok and Castelluccio, Marco and Bacchelli, Alberto},
title = {What makes a code change easier to review: an empirical investigation on code change reviewability},
year = {2018},
isbn = {9781450355735},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3236024.3236080},
doi = {10.1145/3236024.3236080},
abstract = {Peer code review is a practice widely adopted in software projects to improve the quality of code. In current code review practices, code changes are manually inspected by developers other than the author before these changes are integrated into a project or put into production. We conducted a study to obtain an empirical understanding of what makes a code change easier to review. To this end, we surveyed published academic literature and sources from gray literature (blogs and white papers), we interviewed ten professional developers, and we designed and deployed a reviewability evaluation tool that professional developers used to rate the reviewability of 98 changes. We find that reviewability is defined through several factors, such as the change description, size, and coherent commit history. We provide recommendations for practitioners and researchers. Public preprint [https://doi.org/10.5281/zenodo.1323659]; data and materials [https://doi.org/10.5281/zenodo.1323659].},
booktitle = {Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {201–212},
numpages = {12},
keywords = {pull request, code review, Code quality},
location = {Lake Buena Vista, FL, USA},
series = {ESEC/FSE 2018}
}

@inproceedings{10.1145/3195836.3195842,
author = {Kovalenko, Vladimir and Bacchelli, Alberto},
title = {Code review for newcomers: is it different?},
year = {2018},
isbn = {9781450357258},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3195836.3195842},
doi = {10.1145/3195836.3195842},
abstract = {Onboarding is a critical stage in the tenure of software developers with a project, because meaningful contribution requires familiarity with the codebase. Some software teams employ practices, such as mentoring, to help new developers get accustomed faster. Code review, i.e., the manual inspection of code changes, is an opportunity for sharing knowledge and helping with onboarding.In this study, we investigate whether and how contributions from developers with low experience in a project do receive a different treatment during code review. We compare reviewers' experience, metrics of reviewers' attention, and change merge rate between changes from newcomers and from more experienced authors in 60 active open source projects. We find that the only phenomenon that is consistent across the vast majority of projects is a lower merge rate for newcomers' changes.},
booktitle = {Proceedings of the 11th International Workshop on Cooperative and Human Aspects of Software Engineering},
pages = {29–32},
numpages = {4},
location = {Gothenburg, Sweden},
series = {CHASE '18}
}

@inproceedings{10.1145/3544548.3581317,
author = {Qiu, Huilian Sophie and Lieb, Anna and Chou, Jennifer and Carneal, Megan and Mok, Jasmine and Amspoker, Emily and Vasilescu, Bogdan and Dabbish, Laura},
title = {Climate Coach: A Dashboard for Open-Source Maintainers to Overview Community Dynamics},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581317},
doi = {10.1145/3544548.3581317},
abstract = {Open-source software projects have become an integral part of our daily life, supporting virtually every software we use today. Since open-source software forms the digital infrastructure, maintaining them is of utmost importance. We present Climate Coach, a dashboard that helps open-source project maintainers monitor the health of their community in terms of team climate and inclusion. Through a literature review and an exploratory survey (N=18), we identified important signals that can reflect a project’s health, and display them on a dashboard. We evaluated and refined our dashboard through two rounds of think-aloud studies (N=19). We then conducted a two-week longitudinal diary study (N=10) to test the usefulness of our dashboard. We found that displaying signals that are related to a project’s inclusion help improve maintainers’ management strategies.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {552},
numpages = {18},
location = {Hamburg, Germany},
series = {CHI '23}
}

@proceedings{10.1145/3544902,
title = {ESEM '22: Proceedings of the 16th ACM / IEEE International Symposium on Empirical Software Engineering and Measurement},
year = {2022},
isbn = {9781450394277},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Helsinki, Finland}
}

@inproceedings{10.1145/3548785.3548805,
author = {Desai, Bipin C.},
title = {Meta-stasis of the Internet},
year = {2022},
isbn = {9781450397094},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3548785.3548805},
doi = {10.1145/3548785.3548805},
abstract = {This paper offers a brief history of the information age in order to demonstrate how the loss of user control and the increase in certain forms of automation have metastasized into imminent and ongoing threats to social order and the democratic way of life. The internet was established after a number of developments which included the interconnection of computers without extensive need of action by the users. It led to the introduction of user communication sub-systems such as text, email, file sharing and systems for searching for files. The so called information age is said to be marked by the adaption of a hypertext transport protocol in the last decade of the twentieth century. The information age was marked by a number of meetings which included the first of the world wide web conference in April 1994 followed by the second (Oct. 1994) and the third(April 1995) in quick succession. Other, by invitation only, meetings which dealt with issue of this era were held in Denver, OH(Metadata) and (America in the Age of Information)Bethesda, MD. However, in just under three decades this information age has meta-stasis-ed into a form that is a threat to our social order and democratic way of life while fostering division. Enormous wealth has been garnered by just a few corporations and individuals at the expense of the harm it is doing to people all over the globe. This is the result of the spreading of fake-news and favouring angry content that result in civil strife and loss of lives. It has led to divisiveness and autocratic governments. Some so called democracies are in name only with the same people continuing in their ’elected’ position from term to term, ad infinitum. Just as in the metastasis of a cancer, until it is checked, this transformed internet will destroy some vital parts of our everyday existence: our privacy and liberty while promoting an inegalitarian spirit.},
booktitle = {Proceedings of the 26th International Database Engineered Applications Symposium},
pages = {43–54},
numpages = {12},
keywords = {tracking, surveillance, smartphones, security, privacy, personal data exploitation, lack of legislative control, big tech, Online Social Networks},
location = {Budapest, Hungary},
series = {IDEAS '22}
}

@inproceedings{10.1145/2187836.2187916,
author = {Lin, Thomas and Pantel, Patrick and Gamon, Michael and Kannan, Anitha and Fuxman, Ariel},
title = {Active objects: actions for entity-centric search},
year = {2012},
isbn = {9781450312295},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2187836.2187916},
doi = {10.1145/2187836.2187916},
abstract = {We introduce an entity-centric search experience, called Active Objects, in which entity-bearing queries are paired with actions that can be performed on the entities. For example, given a query for a specific flashlight, we aim to present actions such as reading reviews, watching demo videos, and finding the best price online. In an annotation study conducted over a random sample of user query sessions, we found that a large proportion of queries in query logs involve actions on entities, calling for an automatic approach to identifying relevant actions for entity-bearing queries. In this paper, we pose the problem of finding actions that can be performed on entities as the problem of probabilistic inference in a graphical model that captures how an entity bearing query is generated. We design models of increasing complexity that capture latent factors such as entity type and intended actions that determine how a user writes a query in a search box, and the URL that they click on. Given a large collection of real-world queries and clicks from a commercial search engine, the models are learned efficiently through maximum likelihood estimation using an EM algorithm. Given a new query, probabilistic inference enables recommendation of a set of pertinent actions and hosts. We propose an evaluation methodology for measuring the relevance of our recommended actions, and show empirical evidence of the quality and the diversity of the discovered actions.},
booktitle = {Proceedings of the 21st International Conference on World Wide Web},
pages = {589–598},
numpages = {10},
keywords = {web search, query log mining, entity-centric search, active objects, actions},
location = {Lyon, France},
series = {WWW '12}
}

@article{10.1145/3555190,
author = {Frluckaj, Hana and Dabbish, Laura and Widder, David Gray and Qiu, Huilian Sophie and Herbsleb, James D.},
title = {Gender and Participation in Open Source Software Development},
year = {2022},
issue_date = {November 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {CSCW2},
url = {https://doi.org/10.1145/3555190},
doi = {10.1145/3555190},
abstract = {Open source software represents an important form of digital infrastructure as well as a pathway to technical careers for many developers, but women are drastically underrepresented in this setting. Although there is a good body of literature on open source participation, there is very little understanding of the participation trajectories and contribution experiences of women developers, and how they compare to those of men developers, in open source software projects. In order to understand their joining and participation trajectories, we conducted interviews with 23 developers (11 men and 12 women) who became core in an open source project. We identify differences in women and men's motivations for initial contributions and joining processes (e.g. women participating in projects that they have been invited to) and sustained involvement in a project. We also describe unique negative experiences faced by women contributors in this setting in each stage of participation. Our results have implications for diversifying participation in open source software and understanding open source as a pathway to technical careers.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = {nov},
articleno = {299},
numpages = {31},
keywords = {open source software, open collaboration, inclusion, gender, diversity}
}

@proceedings{10.1145/3639478,
title = {ICSE-Companion '24: Proceedings of the 2024 IEEE/ACM 46th International Conference on Software Engineering: Companion Proceedings},
year = {2024},
isbn = {9798400705021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {ICSE is the leading and, by far, the largest conference in Software Engineering, attracting researchers, practitioners, and students worldwide. ICSE2024 is co-located with 11 conferences and symposia this year, many long-established and prestigious venues in their own right.},
location = {Lisbon, Portugal}
}

@inproceedings{10.1145/3524842.3528460,
author = {Kochanthara, Sangeeth and Dajsuren, Yanja and Cleophas, Loek and van den Brand, Mark},
title = {Painting the landscape of automotive software in GitHub},
year = {2022},
isbn = {9781450393034},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3524842.3528460},
doi = {10.1145/3524842.3528460},
abstract = {The automotive industry has transitioned from being an electromechanical to a software-intensive industry. A current high-end production vehicle contains 100 million+ lines of code surpassing modern airplanes, the Large Hadron Collider, the Android OS, and Facebook's front-end software, in code size by a huge margin. Today, software companies worldwide, including Apple, Google, Huawei, Baidu, and Sony are reportedly working to bring their vehicles to the road. This paper ventures into the automotive software landscape in open source, providing a first glimpse into this multi-disciplinary industry with a long history of closed source development. We paint the landscape of automotive software on GitHub by describing its characteristics and development styles.The landscape is defined by 15,000+ users contributing to ≈600 actively-developed automotive software projects created in a span of 12 years from 2010 until 2021. These projects range from vehicle dynamics-related software; firmware and drivers for sensors like LiDAR and camera; algorithms for perception and motion control; to complete operating systems integrating the above. Developments in the field are spearheaded by industry and academia alike, with one in three actively developed automotive software repositories owned by an organization. We observe shifts along multiple dimensions, including preferred language from MATLAB to Python and prevalence of perception and decision-related software over traditional automotive software. This study witnesses open source automotive software boom in its infancy with many implications for future research and practice.},
booktitle = {Proceedings of the 19th International Conference on Mining Software Repositories},
pages = {215–226},
numpages = {12},
keywords = {software engineering, safety critical, open source, mining software repositories, cyber-physical systems, automotive software, GitHub},
location = {Pittsburgh, Pennsylvania},
series = {MSR '22}
}

@article{10.1145/3369805,
author = {K\"{u}nzler, Florian and Mishra, Varun and Kramer, Jan-Niklas and Kotz, David and Fleisch, Elgar and Kowatsch, Tobias},
title = {Exploring the State-of-Receptivity for mHealth Interventions},
year = {2020},
issue_date = {December 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {4},
url = {https://doi.org/10.1145/3369805},
doi = {10.1145/3369805},
abstract = {Recent advancements in sensing techniques for mHealth applications have led to successful development and deployments of several mHealth intervention designs, including Just-In-Time Adaptive Interventions (JITAI). JITAIs show great potential because they aim to provide the right type and amount of support, at the right time. Timing the delivery of a JITAI such as the user is receptive and available to engage with the intervention is crucial for a JITAI to succeed. Although previous research has extensively explored the role of context in users' responsiveness towards generic phone notifications, it has not been thoroughly explored for actual mHealth interventions. In this work, we explore the factors affecting users' receptivity towards JITAIs. To this end, we conducted a study with 189 participants, over a period of 6 weeks, where participants received interventions to improve their physical activity levels. The interventions were delivered by a chatbot-based digital coach -Ally - which was available on Android and iOS platforms.We define several metrics to gauge receptivity towards the interventions, and found that (1) several participant-specific characteristics (age, personality, and device type) show significant associations with the overall participant receptivity over the course of the study, and that (2) several contextual factors (day/time, phone battery, phone interaction, physical activity, and location), show significant associations with the participant receptivity, in-the-moment. Further, we explore the relationship between the effectiveness of the intervention and receptivity towards those interventions; based on our analyses, we speculate that being receptive to interventions helped participants achieve physical activity goals, which in turn motivated participants to be more receptive to future interventions. Finally, we build machine-learning models to detect receptivity, with up to a 77% increase in F1 score over a biased random classifier.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = {sep},
articleno = {140},
numpages = {27},
keywords = {Receptivity, Mobile Health, Intervention, Interruption, Engagement}
}

@proceedings{10.1145/3613372,
title = {SBES '23: Proceedings of the XXXVII Brazilian Symposium on Software Engineering},
year = {2023},
isbn = {9798400707872},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Campo Grande, Brazil}
}

@inproceedings{10.1145/3338906.3340449,
author = {Asthana, Sumit and Kumar, Rahul and Bhagwan, Ranjita and Bird, Christian and Bansal, Chetan and Maddila, Chandra and Mehta, Sonu and Ashok, B.},
title = {WhoDo: automating reviewer suggestions at scale},
year = {2019},
isbn = {9781450355728},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3338906.3340449},
doi = {10.1145/3338906.3340449},
abstract = {Today's software development is distributed and involves continuous changes for new features and yet, their development cycle has to be fast and agile. An important component of enabling this agility is selecting the right reviewers for every code-change - the smallest unit of the development cycle. Modern tool-based code review is proven to be an effective way to achieve appropriate code review of software changes. However, the selection of reviewers in these code review systems is at best manual. As software and teams scale, this poses the challenge of selecting the right reviewers, which in turn determines software quality over time. While previous work has suggested automatic approaches to code reviewer recommendations, it has been limited to retrospective analysis. We not only deploy a reviewer suggestions algorithm - WhoDo - and evaluate its effect but also incorporate load balancing as part of it to address one of its major shortcomings: of recommending experienced developers very frequently. We evaluate the effect of this hybrid recommendation + load balancing system on five repositories within Microsoft. Our results are based around various aspects of a commit and how code review affects that. We attempt to quantitatively answer questions which are supposed to play a vital role in effective code review through our data and substantiate it through qualitative feedback of partner repositories.},
booktitle = {Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {937–945},
numpages = {9},
keywords = {software-engineering, recommendation, code-review},
location = {Tallinn, Estonia},
series = {ESEC/FSE 2019}
}

@article{10.1145/188423.188426,
author = {Goslar, Martin D. and Deans, P. Candace},
title = {A comparative study of information system curriculum in U.S. and foreign universities},
year = {1994},
issue_date = {Feb. 1994},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {25},
number = {1},
issn = {0095-0033},
url = {https://doi.org/10.1145/188423.188426},
doi = {10.1145/188423.188426},
abstract = {The continued shift toward a more integrated world economy and the need to be more informed regarding business events outside the domestic (U.S.) marketplace have contributed to a need for better collaboration among IS academicians in both U.S. and foreign schools of business. IS educators are developing new curriculum initiatives, broadening the scope to incorporate international business environment forces.This research provides the IS academic community with insights into IS curriculumin business schools worldwide in order to better understand differences and similarities across programs. These insights will prove valuable as efforts are made to broaden the scope of IS curriculum content to an international dimension. Theoretical foundations for this study are derived primarily from the international business discipline. The methodology incorporates a questionnaire targeted for a representative sample of U.S. and foreign schools of business. The results of this study provide IS academicians with a reference point from which to proceed in developing a more refined international IS component. Insights derived from IS curriculum approaches currently in place in foreign schools of business will contribute to an understanding of international IS issues and encourage collaboration with academicians outside the United States.},
journal = {SIGMIS Database},
month = {feb},
pages = {7–20},
numpages = {14},
keywords = {international curriculum, information systems education, foreign education}
}

@inproceedings{10.1145/3339252.3339272,
author = {Pour, Morteza Safaei and Mangino, Antonio and Friday, Kurt and Rathbun, Matthias and Bou-Harb, Elias and Iqbal, Farkhund and Shaban, Khaled and Erradi, Abdelkarim},
title = {Data-driven Curation, Learning and Analysis for Inferring Evolving IoT Botnets in the Wild},
year = {2019},
isbn = {9781450371643},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3339252.3339272},
doi = {10.1145/3339252.3339272},
abstract = {The insecurity of the Internet-of-Things (IoT) paradigm continues to wreak havoc in consumer and critical infrastructure realms. Several challenges impede addressing IoT security at large, including, the lack of IoT-centric data that can be collected, analyzed and correlated, due to the highly heterogeneous nature of such devices and their widespread deployments in Internet-wide environments. To this end, this paper explores macroscopic, passive empirical data to shed light on this evolving threat phenomena. This not only aims at classifying and inferring Internet-scale compromised IoT devices by solely observing such one-way network traffic, but also endeavors to uncover, track and report on orchestrated "in the wild" IoT botnets. Initially, to prepare the effective utilization of such data, a novel probabilistic model is designed and developed to cleanse such traffic from noise samples (i.e., misconfiguration traffic). Subsequently, several shallow and deep learning models are evaluated to ultimately design and develop a multi-window convolution neural network trained on active and passive measurements to accurately identify compromised IoT devices. Consequently, to infer orchestrated and unsolicited activities that have been generated by well-coordinated IoT botnets, hierarchical agglomerative clustering is deployed by scrutinizing a set of innovative and efficient network feature sets. By analyzing 3.6 TB of recent darknet traffic, the proposed approach uncovers a momentous 440,000 compromised IoT devices and generates evidence-based artifacts related to 350 IoT botnets. While some of these detected botnets refer to previously documented campaigns such as the Hide and Seek, Hajime and Fbot, other events illustrate evolving threats such as those with cryptojacking capabilities and those that are targeting industrial control system communication and control services.},
booktitle = {Proceedings of the 14th International Conference on Availability, Reliability and Security},
articleno = {6},
numpages = {10},
keywords = {network telescopes, network security, deep learning, IoT botnets, Internet-of-Things, Internet measurements},
location = {Canterbury, CA, United Kingdom},
series = {ARES '19}
}

@inproceedings{10.1145/3510458.3513019,
author = {Qiu, Huilian Sophie and Vasilescu, Bogdan and K\"{a}stner, Christian and Egelman, Carolyn and Jaspan, Ciera and Murphy-Hill, Emerson},
title = {Detecting interpersonal conflict in issues and code review: cross pollinating open- and closed-source approaches},
year = {2022},
isbn = {9781450392273},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3510458.3513019},
doi = {10.1145/3510458.3513019},
abstract = {Interpersonal conflict in code review, such as toxic language or an unnecessary pushback, is associated with negative outcomes such as stress and turnover. Automatic detection is one approach to prevent and mitigate interpersonal conflict. Two recent automatic detection approaches were developed in different settings: a toxicity detector using text analytics for open source issue discussions and a pushback detector using logs-based metrics for corporate code reviews. This paper tests how the toxicity detector and the pushback detector can be generalized beyond their respective contexts and discussion types, and how the combination of the two can help improve interpersonal conflict detection. The results reveal connections between the two concepts.Software engineers often communicate with one another on platforms that support tasks like discussing bugs and inspecting each others' code. Such discussions sometimes contain interpersonal conflict, which can lead to stress and abandonment. In this paper, we investigate how to automatically detect interpersonal conflict, both by analyzing the text of the what the engineers are saying and by analyzing the properties of that text.},
booktitle = {Proceedings of the 2022 ACM/IEEE 44th International Conference on Software Engineering: Software Engineering in Society},
pages = {41–55},
numpages = {15},
location = {Pittsburgh, Pennsylvania},
series = {ICSE-SEIS '22}
}

@article{10.1145/1698750.1698752,
author = {Jiang, Xuxian and Wang, Xinyuan and Xu, Dongyan},
title = {Stealthy malware detection and monitoring through VMM-based “out-of-the-box” semantic view reconstruction},
year = {2010},
issue_date = {February 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {2},
issn = {1094-9224},
url = {https://doi.org/10.1145/1698750.1698752},
doi = {10.1145/1698750.1698752},
abstract = {An alarming trend in recent malware incidents is that they are armed with stealthy techniques to detect, evade, and subvert malware detection facilities of the victim. On the defensive side, a fundamental limitation of traditional host-based antimalware systems is that they run inside the very hosts they are protecting (“in-the-box”), making them vulnerable to counter detection and subversion by malware. To address this limitation, recent solutions based on virtual machine (VM) technologies advocate placing the malware detection facilities outside of the protected VM (“out-of-the-box”). However, they gain tamper resistance at the cost of losing the internal semantic view of the host, which is enjoyed by “in-the-box” approaches. This poses a technical challenge known as the semantic gap.In this article, we present the design, implementation, and evaluation of VMwatcher—an “out-of-the-box” approach that overcomes the semantic gap challenge. A new technique called guest view casting is developed to reconstruct internal semantic views (e.g., files, processes, and kernel modules) of a VM nonintrusively from the outside. More specifically, the new technique casts semantic definitions of guest OS data structures and functions on virtual machine monitor (VMM)-level VM states, so that the semantic view can be reconstructed. Furthermore, we extend guest view casting to reconstruct details of system call events (e.g., the process that makes the system call as well as the system call number, parameters, and return value) in the VM, enriching the semantic view. With the semantic gap effectively narrowed, we identify three unique malware detection and monitoring capabilities: (i) view comparison-based malware detection and its demonstration in rootkit detection; (ii) “out-of-the-box” deployment of off-the-shelf anti malware software with improved detection accuracy and tamper-resistance; and (iii) nonintrusive system call monitoring for malware and intrusion behavior observation. We have implemented a proof-of-concept VMwatcher prototype on a number of VMM platforms. Our evaluation experiments with real-world malware, including elusive kernel-level rootkits, demonstrate VMwatcher's practicality and effectiveness.},
journal = {ACM Trans. Inf. Syst. Secur.},
month = {mar},
articleno = {12},
numpages = {28},
keywords = {virtual machines, rootkits, Malware detection}
}

@inproceedings{10.1145/1985793.1985830,
author = {Ramasubbu, Narayan and Cataldo, Marcelo and Balan, Rajesh Krishna and Herbsleb, James D.},
title = {Configuring global software teams: a multi-company analysis of project productivity, quality, and profits},
year = {2011},
isbn = {9781450304450},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1985793.1985830},
doi = {10.1145/1985793.1985830},
abstract = {In this paper, we examined the impact of project-level configurational choices of globally distributed software teams on project productivity, quality, and profits. Our analysis used data from 362 projects of four different firms. These projects spanned a wide range of programming languages, application domain, process choices, and development sites spread over 15 countries and 5 continents. Our analysis revealed fundamental tradeoffs in choosing configurational choices that are optimized for productivity, quality, and/or profits. In particular, achieving higher levels of productivity and quality require diametrically opposed configurational choices. In addition, creating imbalances in the expertise and personnel distribution of project teams significantly helps increase profit margins. However, a profit-oriented imbalance could also significantly affect productivity and/or quality outcomes. Analyzing these complex tradeoffs, we provide actionable managerial insights that can help software firms and their clients choose configurations that achieve desired project outcomes in globally distributed software development.},
booktitle = {Proceedings of the 33rd International Conference on Software Engineering},
pages = {261–270},
numpages = {10},
keywords = {software engineering economics, quality management, globally distributed software development, empirical analysis},
location = {Waikiki, Honolulu, HI, USA},
series = {ICSE '11}
}

@article{10.1145/311457.311487,
author = {de Bondeli, Patrick},
title = {A fully reusable class of objects for synchronization and communication in Ada 95},
year = {1999},
issue_date = {March 1999},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {XIX},
number = {1},
issn = {1094-3641},
url = {https://doi.org/10.1145/311457.311487},
doi = {10.1145/311457.311487},
abstract = {This paper presents a very general class which can be reused to specify and implement any type exporting synchronization or communication properties. The new Ada 95 features modelling inheritance, polymorphism and hierarchies of library units are used extensively in describing the architecture of the class and other new features (access to subprograms, protected types, …) are used for the specification and implementation of the components of the class.Section 2 presents the general architecture of our class. Sections 3, 4, 5 respectively give examples of specification, use and implementation of its components. Section 6 concludes on recalling the full role of formal techniques in our approach (they appear in the present paper only to show that the semantics of our class is defined at a more abstract level than its implementation) and discussing a few interesting points about the way Ada 95 is used here.},
journal = {Ada Lett.},
month = {mar},
pages = {66–96},
numpages = {31}
}

@article{10.1145/3110247,
author = {Breitner, Joachim and Smith, Chris},
title = {Lock-step simulation is child's play (experience report)},
year = {2017},
issue_date = {September 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {ICFP},
url = {https://doi.org/10.1145/3110247},
doi = {10.1145/3110247},
abstract = {Implementing multi-player networked games by broadcasting the player’s input and letting each client calculate the game state -- a scheme known as *lock-step simulation* – is an established technique. However, ensuring that every client in this scheme obtains a consistent state is infamously hard and in general requires great discipline from the game programmer. The thesis of this pearl is that in the realm of functional programming – in particular with Haskell's purity and static pointers – this hard problem becomes almost trivially easy.  We support this thesis by implementing lock-step simulation under very adverse conditions. We extended the educational programming environment CodeWorld, which is used to teach math and programming to middle school students, with the ability to create and run interactive, networked multi-user games. Despite providing a very abstract and high-level interface, and without requiring any discipline from the programmer, we can provide consistent lock-step simulation with client prediction.},
journal = {Proc. ACM Program. Lang.},
month = {aug},
articleno = {3},
numpages = {15},
keywords = {teaching, lock-step simulation, distributed computation}
}

@inproceedings{10.1145/3643916.3644413,
author = {Dhaouadi, Mouna and Oakes, Bentley James and Famelis, Michalis},
title = {Rationale Dataset and Analysis for the Commit Messages of the Linux Kernel Out-of-Memory Killer},
year = {2024},
isbn = {9798400705861},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643916.3644413},
doi = {10.1145/3643916.3644413},
abstract = {Code commit messages can contain useful information on why a developer has made a change. However, the presence and structure of rationale in real-world code commit messages is not well studied. Here, we detail the creation of a labelled dataset to analyze the code commit messages of the Linux Kernel Out-Of-Memory Killer component. We study aspects of rationale information, such as presence, temporal evolution, and structure. We find that 98.9% of commits in our dataset contain sentences with rationale information, and that experienced developers report rationale in about 60% of the sentences in their commits. We report on the challenges we faced and provide examples for our labelling.},
booktitle = {Proceedings of the 32nd IEEE/ACM International Conference on Program Comprehension},
pages = {415–425},
numpages = {11},
keywords = {developer rationale, dataset, Linux kernel, commit messages},
location = {Lisbon, Portugal},
series = {ICPC '24}
}

@article{10.1145/3039868,
author = {Tsvetkova, Milena and Yasseri, Taha and Meyer, Eric T. and Pickering, J. Brian and Engen, Vegard and Walland, Paul and L\"{u}ders, Marika and F\o{}lstad, Asbj\o{}rn and Bravos, George},
title = {Understanding Human-Machine Networks: A Cross-Disciplinary Survey},
year = {2017},
issue_date = {January 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/3039868},
doi = {10.1145/3039868},
abstract = {In the current hyperconnected era, modern Information and Communication Technology (ICT) systems form sophisticated networks where not only do people interact with other people, but also machines take an increasingly visible and participatory role. Such Human-Machine Networks (HMNs) are embedded in the daily lives of people, both for personal and professional use. They can have a significant impact by producing synergy and innovations. The challenge in designing successful HMNs is that they cannot be developed and implemented in the same manner as networks of machines nodes alone, or following a wholly human-centric view of the network. The problem requires an interdisciplinary approach. Here, we review current research of relevance to HMNs across many disciplines. Extending the previous theoretical concepts of socio-technical systems, actor-network theory, cyber-physical-social systems, and social machines, we concentrate on the interactions among humans and between humans and machines. We identify eight types of HMNs: public-resource computing, crowdsourcing, web search engines, crowdsensing, online markets, social media, multiplayer online games and virtual worlds, and mass collaboration. We systematically select literature on each of these types and review it with a focus on implications for designing HMNs. Moreover, we discuss risks associated with HMNs and identify emerging design and development trends.},
journal = {ACM Comput. Surv.},
month = {apr},
articleno = {12},
numpages = {35},
keywords = {social media, peer-to-peer, mass collaboration, human-machine networks, crowdsensing, complex networks, Crowdsourcing}
}

@inproceedings{10.1145/3540250.3549099,
author = {Li, Lingwei and Yang, Li and Jiang, Huaxi and Yan, Jun and Luo, Tiejian and Hua, Zihan and Liang, Geng and Zuo, Chun},
title = {AUGER: automatically generating review comments with pre-training models},
year = {2022},
isbn = {9781450394130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3540250.3549099},
doi = {10.1145/3540250.3549099},
abstract = {Code review is one of the best practices as a powerful safeguard for software quality. In practice, senior or highly skilled reviewers inspect source code and provide constructive comments, consider- ing what authors may ignore, for example, some special cases. The collaborative validation between contributors results in code being highly qualified and less chance of bugs. However, since personal knowledge is limited and varies, the efficiency and effectiveness of code review practice are worthy of further improvement. In fact, it still takes a colossal and time-consuming effort to deliver useful review comments.  
This paper explores a synergy of multiple practical review comments to enhance code review and proposes AUGER (AUtomatically GEnerating Review comments): a review comments generator with pre-training models. We first collect empirical review data from 11 notable Java projects and construct a dataset of 10,882 code changes. By leveraging Text-to-Text Transfer Transformer (T5) models, the framework synthesizes valuable knowledge in the training stage and effectively outperforms baselines by 37.38% in ROUGE-L. 29% of our automatic review comments are considered useful according to prior studies. The inference generates just in 20 seconds and is also open to training further. Moreover, the performance also gets improved when thoroughly analyzed in case study.},
booktitle = {Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1009–1021},
numpages = {13},
keywords = {Text Generation, Review Comments, Machine Learning, Code Review},
location = {Singapore, Singapore},
series = {ESEC/FSE 2022}
}

@inproceedings{10.1145/3411495.3421360,
author = {Ramsauer, Ralf and Bulwahn, Lukas and Lohmann, Daniel and Mauerer, Wolfgang},
title = {The Sound of Silence: Mining Security Vulnerabilities from Secret Integration Channels in Open-Source Projects},
year = {2020},
isbn = {9781450380843},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411495.3421360},
doi = {10.1145/3411495.3421360},
abstract = {Public development processes are a key characteristic of open source projects. However, fixes for vulnerabilities are usually discussed privately among a small group of trusted maintainers, and integrated without prior public involvement. This is supposed to prevent early disclosure, and cope with embargo and non-disclosure agreement (NDA) rules. While regular development activities leave publicly available traces, fixes for vulnerabilities that bypass the standard process do not.We present a data-mining based approach to detect code fragments that arise from such infringements of the standard process. By systematically mapping public development artefacts to source code repositories, we can exclude regular process activities, and infer irregularities that stem from non-public integration channels. For the Linux kernel, the most crucial component of many systems, we apply our method to a period of seven months before the release of Linux 5.4. We find 29 commits that address 12 vulnerabilities. For these vulnerabilities, our approach provides a temporal advantage of 2 to 179 days to design exploits before public disclosure takes place, and fixes are rolled out.Established responsible disclosure approaches in open development processes are supposed to limit premature visibility of security vulnerabilities. However, our approach shows that, instead, they open additional possibilities to uncover such changes that thwart the very premise. We conclude by discussing implications and partial countermeasures.},
booktitle = {Proceedings of the 2020 ACM SIGSAC Conference on Cloud Computing Security Workshop},
pages = {147–157},
numpages = {11},
keywords = {vulnerability mining, software repository mining, process analysis},
location = {Virtual Event, USA},
series = {CCSW'20}
}

@inproceedings{10.1145/1920261.1920301,
author = {Liakh, Siarhei and Grace, Michael and Jiang, Xuxian},
title = {Analyzing and improving Linux kernel memory protection: a model checking approach},
year = {2010},
isbn = {9781450301336},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1920261.1920301},
doi = {10.1145/1920261.1920301},
abstract = {Code injection continues to pose a serious threat to computer systems. Among existing solutions, W ⊕ X is a notable approach to prevent the execution of injected code. In this paper, we focus on the Linux kernel memory protection and systematically check for possible W ⊕ X violations in the Linux kernel design and implementation. In particular, we have developed a Murphi-based abstract model and used it to discover several serious shortcomings in the current Linux kernel that violate the W ⊕ X property. We have confirmed with the Linux community the presence of these problems and accordingly developed five Linux kernel patches. (Four of them are in the process of being integrated into the mainline Linux kernel.) Our evaluation with these patches indicate that they involve only minimal changes to the existing code base and incur negligible performance overhead.},
booktitle = {Proceedings of the 26th Annual Computer Security Applications Conference},
pages = {271–280},
numpages = {10},
location = {Austin, Texas, USA},
series = {ACSAC '10}
}

@proceedings{10.1145/3538969,
title = {ARES '22: Proceedings of the 17th International Conference on Availability, Reliability and Security},
year = {2022},
isbn = {9781450396707},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Vienna, Austria}
}

@inproceedings{10.1145/3180155.3180192,
author = {Spadini, Davide and Aniche, Maur\'{\i}cio and Storey, Margaret-Anne and Bruntink, Magiel and Bacchelli, Alberto},
title = {When testing meets code review: why and how developers review tests},
year = {2018},
isbn = {9781450356381},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3180155.3180192},
doi = {10.1145/3180155.3180192},
abstract = {Automated testing is considered an essential process for ensuring software quality. However, writing and maintaining high-quality test code is challenging and frequently considered of secondary importance. For production code, many open source and industrial software projects employ code review, a well-established software quality practice, but the question remains whether and how code review is also used for ensuring the quality of test code. The aim of this research is to answer this question and to increase our understanding of what developers think and do when it comes to reviewing test code. We conducted both quantitative and qualitative methods to analyze more than 300,000 code reviews, and interviewed 12 developers about how they review test files. This work resulted in an overview of current code reviewing practices, a set of identified obstacles limiting the review of test code, and a set of issues that developers would like to see improved in code review tools. The study reveals that reviewing test files is very different from reviewing production files, and that the navigation within the review itself is one of the main issues developers currently face. Based on our findings, we propose a series of recommendations and suggestions for the design of tools and future research.},
booktitle = {Proceedings of the 40th International Conference on Software Engineering},
pages = {677–687},
numpages = {11},
keywords = {automated testing, code review, gerrit, software testing},
location = {Gothenburg, Sweden},
series = {ICSE '18}
}

@article{10.1145/3664811,
author = {Wang, Haoye and Gao, Zhipeng and Bi, Tingting and Grundy, John and Wang, Xinyu and Wu, Minghui and Yang, Xiaohu},
title = {What Makes a Good TODO Comment?},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {6},
issn = {1049-331X},
url = {https://doi.org/10.1145/3664811},
doi = {10.1145/3664811},
abstract = {Software development is a collaborative process that involves various interactions among individuals and teams. TODO comments in source code play a critical role in managing and coordinating diverse tasks during this process. However, this study finds that a large proportion of open-source project TODO comments are left unresolved or take a long time to be resolved. About 46.7% of TODO comments in open-source repositories are of low-quality (e.g., TODOs that are ambiguous, lack information, or are useless to developers). This highlights the need for better TODO practices. In this study, we investigate four aspects regarding the quality of TODO comments in open-source projects: (1) the prevalence of low-quality TODO comments; (2) the key characteristics of high-quality TODO comments; (3) how are TODO comments of different quality managed in practice; and (4) the feasibility of automatically assessing TODO comment quality. Examining 2,863 TODO comments from Top100 GitHub Java repositories, we propose criteria to identify high-quality TODO comments and provide insights into their optimal composition. We discuss the lifecycle of TODO comments with varying quality. To assist developers, we construct deep learning-based methods that show promising performance in identifying the quality of TODO comments, potentially enhancing development efficiency and code quality.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = {jun},
articleno = {165},
numpages = {30},
keywords = {Documentation, comment quality, comment lifecycle}
}

@inproceedings{10.1145/3133956.3134046,
author = {Xu, Wen and Kashyap, Sanidhya and Min, Changwoo and Kim, Taesoo},
title = {Designing New Operating Primitives to Improve Fuzzing Performance},
year = {2017},
isbn = {9781450349468},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3133956.3134046},
doi = {10.1145/3133956.3134046},
abstract = {Fuzzing is a software testing technique that finds bugs by repeatedly injecting mutated inputs to a target program. Known to be a highly practical approach, fuzzing is gaining more popularity than ever before. Current research on fuzzing has focused on producing an input that is more likely to trigger a vulnerability.In this paper, we tackle another way to improve the performance of fuzzing, which is to shorten the execution time of each iteration. We observe that AFL, a state-of-the-art fuzzer, slows down by 24x because of file system contention and the scalability of fork() system call when it runs on 120 cores in parallel. Other fuzzers are expected to suffer from the same scalability bottlenecks in that they follow a similar design pattern. To improve the fuzzing performance, we design and implement three new operating primitives specialized for fuzzing that solve these performance bottlenecks and achieve scalable performance on multi-core machines. Our experiment shows that the proposed primitives speed up AFL and LibFuzzer by 6.1 to 28.9x and 1.1 to 735.7x, respectively, on the overall number of executions per second when targeting Google's fuzzer test suite with 120 cores. In addition, the primitives improve AFL's throughput up to 7.7x with 30 cores, which is a more common setting in data centers. Our fuzzer-agnostic primitives can be easily applied to any fuzzer with fundamental performance improvement and directly benefit large-scale fuzzing and cloud-based fuzzing services.},
booktitle = {Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security},
pages = {2313–2328},
numpages = {16},
keywords = {fuzzing, operating system, scalability},
location = {Dallas, Texas, USA},
series = {CCS '17}
}

@proceedings{10.1145/3597503,
title = {ICSE '24: Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Lisbon, Portugal}
}

@inproceedings{10.1145/3611643.3613871,
author = {Shackleton, Will and Cohn-Gordon, Katriel and Rigby, Peter C. and Abreu, Rui and Gill, James and Nagappan, Nachiappan and Nakad, Karim and Papagiannis, Ioannis and Petre, Luke and Megreli, Giorgi and Riggs, Patrick and Saindon, James},
title = {Dead Code Removal at Meta: Automatically Deleting Millions of Lines of Code and Petabytes of Deprecated Data},
year = {2023},
isbn = {9798400703270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611643.3613871},
doi = {10.1145/3611643.3613871},
abstract = {Software constantly evolves in response to user needs: new features are built, deployed, mature and grow old, and eventually their usage drops enough to merit switching them off. In any large codebase, this feature lifecycle can naturally lead to retaining unnecessary code and data. Removing these respects users’ privacy expectations, as well as helping engineers to work efficiently. In prior software engineering research, we have found little evidence of code deprecation or dead-code removal at industrial scale. We describe Systematic Code and Asset Removal Framework (SCARF), a product deprecation system to assist engineers working in large codebases. SCARF identifies unused code and data assets and safely removes them. It operates fully automatically, including committing code and dropping database tables. It also gathers developer input where it cannot take automated actions, leading to further removals. Dead code removal increases the quality and consistency of large codebases, aids with knowledge management and improves reliability. SCARF has had an important impact at Meta. In the last year alone, it has removed petabytes of data across 12.8 million distinct assets, and deleted over 104 million lines of code.},
booktitle = {Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1705–1715},
numpages = {11},
keywords = {Automated refactoring, Code transformation, Data cleanup, Data purging},
location = {San Francisco, CA, USA},
series = {ESEC/FSE 2023}
}

@proceedings{10.1145/3599957,
title = {RACS '23: Proceedings of the 2023 International Conference on Research in Adaptive and Convergent Systems},
year = {2023},
isbn = {9798400702280},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {With the expansion of both the Internet and the advanced information technology development profession, reliable and convergent computing has attracted increasing interest in both academia and industry. To cope with this important problem, the Research in Adaptive and Convergent Systems (RACS) provides a forum for exchanging highly original ideas about an important class of computing systems. The RACS aims primarily at researchers who have experience in reliable and convergent computing systems and are engaged in the design and implementation of new computing applications. Each year RACS brings together engineers and scientists from diverse communities with interests in practical computing technologies and creates an environment for them to discuss and report experimental results, novel designs, work-in-progress, experiences, case studies, and trend-setting ideas.},
location = {Gdansk, Poland}
}

@article{10.1145/3329786,
author = {Or-Meir, Ori and Nissim, Nir and Elovici, Yuval and Rokach, Lior},
title = {Dynamic Malware Analysis in the Modern Era—A State of the Art Survey},
year = {2019},
issue_date = {September 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3329786},
doi = {10.1145/3329786},
abstract = {Although malicious software (malware) has been around since the early days of computers, the sophistication and innovation of malware has increased over the years. In particular, the latest crop of ransomware has drawn attention to the dangers of malicious software, which can cause harm to private users as well as corporations, public services (hospitals and transportation systems), governments, and security institutions. To protect these institutions and the public from malware attacks, malicious activity must be detected as early as possible, preferably before it conducts its harmful acts. However, it is not always easy to know what to look for—especially when dealing with new and unknown malware that has never been seen. Analyzing a suspicious file by static or dynamic analysis methods can provide relevant and valuable information regarding a file's impact on the hosting system and help determine whether the file is malicious or not, based on the method's predefined rules. While various techniques (e.g., code obfuscation, dynamic code loading, encryption, and packing) can be used by malware writers to evade static analysis (including signature-based anti-virus tools), dynamic analysis is robust to these techniques and can provide greater understanding regarding the analyzed file and consequently can lead to better detection capabilities. Although dynamic analysis is more robust than static analysis, existing dynamic analysis tools and techniques are imperfect, and there is no single tool that can cover all aspects of malware behavior. The most recent comprehensive survey performed in this area was published in 2012. Since that time, the computing environment has changed dramatically with new types of malware (ransomware, cryptominers), new analysis methods (volatile memory forensics, side-channel analysis), new computing environments (cloud computing, IoT devices), new machine-learning algorithms, and more. The goal of this survey is to provide a comprehensive and up-to-date overview of existing methods used to dynamically analyze malware, which includes a description of each method, its strengths and weaknesses, and its resilience against malware evasion techniques. In addition, we include an overview of prominent studies presenting the usage of machine-learning methods to enhance dynamic malware analysis capabilities aimed at detection, classification, and categorization.},
journal = {ACM Comput. Surv.},
month = {sep},
articleno = {88},
numpages = {48},
keywords = {malware, evasion, detection, behavioral analysis, Dynamic analysis}
}

@inproceedings{10.1145/3639477.3639715,
author = {Wurzel Goncalves, Pavlina and S. V. Goncalves, Joao and Bacchelli, Alberto},
title = {Constructive Code Review: Managing the Impact of Interpersonal Conflicts in Practice},
year = {2024},
isbn = {9798400705014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639477.3639715},
doi = {10.1145/3639477.3639715},
abstract = {Code review is an activity where developers receive feedback on their code contributions from other developers. The frequent and potentially negative feedback developers receive makes code review prone to interpersonal conflicts. There is a consensus about such behavior being anti-social and leading to negative outcomes for the code, team, project, and even the company. However, these conflicts are a naturally occurring phenomenon that can lead to reaping the benefits of code review if managed well. Interpersonal conflicts in code review are not necessarily an issue to avoid, but rather to be managed.In this study, we survey developers in two companies - Adnovum - working predominantly on closed-source projects - and in Red Hat open source projects. Based on a set of 154 respondents, we have found that 77% of developers sometimes experience interpersonal conflicts in code review, even though mostly not very frequently. These conflicts pose some degree of a problem to 64% of developers. However, developers are rather successful in deriving constructive outcomes in the face of conflicts - 24% of developers report that conflicts have more positive than negative outcomes. While they are highly successful in deriving positive outcomes for code quality and maintainability, the motivation of developers and their communication and collaboration in a team has the most potential to be harmed by conflicts. The most effective strategy to have constructive rather than destructive conflicts is managing work effort and re-assigning tasks in the team to reduce stress in review. Data and materials: https://zenodo.org/records/10477537.},
booktitle = {Proceedings of the 46th International Conference on Software Engineering: Software Engineering in Practice},
pages = {334–345},
numpages = {12},
keywords = {code review, human factors, constructive feedback, interpersonal conflicts, conflict management},
location = {Lisbon, Portugal},
series = {ICSE-SEIP '24}
}

@inproceedings{10.1109/SC.2018.00040,
author = {Andreadis, Georgios and Versluis, Laurens and Mastenbroek, Fabian and Iosup, Alexandru},
title = {A reference architecture for datacenter scheduling: design, validation, and experiments},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/SC.2018.00040},
doi = {10.1109/SC.2018.00040},
abstract = {Datacenters act as cloud-infrastructure to stakeholders across industry, government, and academia. To meet growing demand yet operate efficiently, datacenter operators employ increasingly more sophisticated scheduling systems, mechanisms, and policies. Although many scheduling techniques already exist, relatively little research has gone into the abstraction of the scheduling process itself, hampering design, tuning, and comparison of existing techniques. In this work, we propose a reference architecture for datacenter schedulers. The architecture follows five design principles: components with clearly distinct responsibilities, grouping of related components where possible, separation of mechanism from policy, scheduling as complex workflow, and hierarchical multi-scheduler structure. To demonstrate the validity of the reference architecture, we map to it state-of-the-art datacenter schedulers. We find scheduler-stages are commonly underspecified in peer-reviewed publications. Through trace-based simulation and real-world experiments, we show underspecification of scheduler-stages can lead to significant variations in performance.},
booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage, and Analysis},
articleno = {37},
numpages = {15},
keywords = {scheduling, reference architecture, datacenter},
location = {Dallas, Texas},
series = {SC '18}
}

@inproceedings{10.1145/2610384.2610407,
author = {Henderson, Andrew and Prakash, Aravind and Yan, Lok Kwong and Hu, Xunchao and Wang, Xujiewen and Zhou, Rundong and Yin, Heng},
title = {Make it work, make it right, make it fast: building a platform-neutral whole-system dynamic binary analysis platform},
year = {2014},
isbn = {9781450326452},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2610384.2610407},
doi = {10.1145/2610384.2610407},
abstract = {Dynamic binary analysis is a prevalent and indispensable technique in program analysis. While several dynamic binary analysis tools and frameworks have been proposed, all suffer from one or more of: prohibitive performance degradation, semantic gap between the analysis code and the program being analyzed, architecture/OS specificity, being user-mode only, lacking APIs, etc. We present DECAF, a virtual machine based, multi-target, whole-system dynamic binary analysis framework built on top of QEMU. DECAF provides Just-In-Time Virtual Machine Introspection combined with a novel TCG instruction-level tainting at bit granularity, backed by a plugin based, simple-to-use event driven programming interface. DECAF exercises fine control over the TCG instructions to accomplish on-the-fly optimizations. We present 3 platform-neutral plugins - Instruction Tracer, Keylogger Detector, and API Tracer, to demonstrate the ease of use and effectiveness of DECAF in writing cross-platform and system-wide analysis tools. Implementation of DECAF consists of 9550 lines of C++ code and 10270 lines of C code and we evaluate DECAF using CPU2006 SPEC benchmarks and show average overhead of 605% for system wide tainting and 12% for VMI.},
booktitle = {Proceedings of the 2014 International Symposium on Software Testing and Analysis},
pages = {248–258},
numpages = {11},
keywords = {virtual machine introspection, dynamic taint analysis, Dynamic binary analysis},
location = {San Jose, CA, USA},
series = {ISSTA 2014}
}

@article{10.1145/2693841,
author = {Roy, Arpan and Sarkar, Santonu and Ganesan, Rajeshwari and Goel, Geetika},
title = {Secure the Cloud: From the Perspective of a Service-Oriented Organization},
year = {2015},
issue_date = {April 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {47},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/2693841},
doi = {10.1145/2693841},
abstract = {In response to the revival of virtualized technology by Rosenblum and Garfinkel [2005], NIST defined cloud computing, a new paradigm in service computing infrastructures. In cloud environments, the basic security mechanism is ingrained in virtualization—that is, the execution of instructions at different privilege levels. Despite its obvious benefits, the caveat is that a crashed virtual machine (VM) is much harder to recover than a crashed workstation. When crashed, a VM is nothing but a giant corrupt binary file and quite unrecoverable by standard disk-based forensics. Therefore, VM crashes should be avoided at all costs. Security is one of the major contributors to such VM crashes. This includes compromising the hypervisor, cloud storage, images of VMs used infrequently, and remote cloud client used by the customer as well as threat from malicious insiders. Although using secure infrastructures such as private clouds alleviate several of these security problems, most cloud users end up using cheaper options such as third-party infrastructures (i.e., private clouds), thus a thorough discussion of all known security issues is pertinent. Hence, in this article, we discuss ongoing research in cloud security in order of the attack scenarios exploited most often in the cloud environment. We explore attack scenarios that call for securing the hypervisor, exploiting co-residency of VMs, VM image management, mitigating insider threats, securing storage in clouds, abusing lightweight software-as-a-service clients, and protecting data propagation in clouds. Wearing a practitioner's glasses, we explore the relevance of each attack scenario to a service company like Infosys. At the same time, we draw parallels between cloud security research and implementation of security solutions in the form of enterprise security suites for the cloud. We discuss the state of practice in the form of enterprise security suites that include cryptographic solutions, access control policies in the cloud, new techniques for attack detection, and security quality assurance in clouds.},
journal = {ACM Comput. Surv.},
month = {feb},
articleno = {41},
numpages = {30},
keywords = {service-oriented organization, open problems, enterprise security suites, attack scenarios, Cloud security}
}

@inproceedings{10.1145/3324884.3416627,
author = {Li, Mingyang and Shi, Lin and Yang, Ye and Wang, Qing},
title = {A deep multitask learning approach for requirements discovery and annotation from open forum},
year = {2021},
isbn = {9781450367684},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3324884.3416627},
doi = {10.1145/3324884.3416627},
abstract = {The ability in rapidly learning and adapting to evolving user needs is key to modern business successes. Existing methods are based on text mining and machine learning techniques to analyze user comments and feedback, and often constrained by heavy reliance on manually codified rules or insufficient training data. Multitask learning (MTL) is an effective approach with many successful applications, with the potential to address these limitations associated with requirements analysis tasks. In this paper, we propose a deep MTL-based approach, DEMAR, to address these limitations when discovering requirements from massive issue reports and annotating the sentences in support of automated requirements analysis. DEMAR consists of three main phases: (1) data augmentation phase, for data preparation and allowing data sharing beyond single task learning; (2) model construction phase, for constructing the MTL-based model for requirements discovery and requirements annotation tasks; and (3) model training phase, enabling eavesdropping by shared loss function between the two related tasks. Evaluation results from eight open-source projects show that, the proposed multitask learning approach outperforms two state-of-the-art approaches (CNC and FRA) and six common machine learning algorithms, with the precision of 91% and the recall of 83% for requirements discovery task, and the overall accuracy of 83% for requirements annotation task. The proposed approach provides a novel and effective way to jointly learn two related requirements analysis tasks. We believe that it also sheds light on further directions of exploring multitask learning in solving other software engineering problems.},
booktitle = {Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering},
pages = {336–348},
numpages = {13},
keywords = {requirements discovery, requirements annotation, multitask learning, deep learning},
location = {Virtual Event, Australia},
series = {ASE '20}
}

@inproceedings{10.1145/3379597.3387489,
author = {Zhang, Xunhui and Rastogi, Ayushi and Yu, Yue},
title = {On the Shoulders of Giants: A New Dataset for Pull-based Development Research},
year = {2020},
isbn = {9781450375177},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3379597.3387489},
doi = {10.1145/3379597.3387489},
abstract = {Pull-based development is a widely adopted paradigm for collaboration in distributed software development, attracting eyeballs from both academic and industry. To better study pull-based development model, this paper presents a new dataset containing 96 features collected from 11,230 projects and 3,347,937 pull requests. We describe the creation process and explain the features in details. To the best of our knowledge, our dataset is the most comprehensive and largest one toward a complete picture for pull-based development research.},
booktitle = {Proceedings of the 17th International Conference on Mining Software Repositories},
pages = {543–547},
numpages = {5},
keywords = {pull-based development, pull request, distributed software development},
location = {Seoul, Republic of Korea},
series = {MSR '20}
}

@inproceedings{10.5555/3291656.3291706,
author = {Andreadis, Georgios and Versluis, Laurens and Mastenbroek, Fabian and Iosup, Alexandru},
title = {A reference architecture for datacenter scheduling: design, validation, and experiments},
year = {2018},
publisher = {IEEE Press},
abstract = {Datacenters act as cloud-infrastructure to stakeholders across industry, government, and academia. To meet growing demand yet operate efficiently, datacenter operators employ increasingly more sophisticated scheduling systems, mechanisms, and policies. Although many scheduling techniques already exist, relatively little research has gone into the abstraction of the scheduling process itself, hampering design, tuning, and comparison of existing techniques. In this work, we propose a reference architecture for datacenter schedulers. The architecture follows five design principles: components with clearly distinct responsibilities, grouping of related components where possible, separation of mechanism from policy, scheduling as complex workflow, and hierarchical multi-scheduler structure. To demonstrate the validity of the reference architecture, we map to it state-of-the-art datacenter schedulers. We find scheduler-stages are commonly underspecified in peer-reviewed publications. Through trace-based simulation and real-world experiments, we show underspecification of scheduler-stages can lead to significant variations in performance.},
booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage, and Analysis},
articleno = {37},
numpages = {15},
keywords = {scheduling, reference architecture, datacenter},
location = {Dallas, Texas},
series = {SC '18}
}

@inproceedings{10.1145/2077489.2077506,
author = {van Ingen, Kevin and van Ommen, Job and Jansen, Slinger},
title = {Improving activity in communities of practice through software release management},
year = {2011},
isbn = {9781450310475},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2077489.2077506},
doi = {10.1145/2077489.2077506},
abstract = {Keystone players, the company that occupies the crucial hubs, need to nurture its inhabitants to keep the ecosystem active. Many modern ecosystems have communities of practice where knowledge is transferred by collaborative problem solving, sharing of ideas, software components or configurations. In recent years a widely spread medium for communities of practice is the use of online discussion boards. This research proposes a method to analyze the relationship between software releases and activity in a community. This paper explains how software ecosystem Keystone companies can use software product release management to cultivate communities of practice using an illustrative case study. In this case study a comparison is made between two communities in the Android ecosystem. The results show peaks in community activity coinciding with the software releases. The release not only revitalizes the activity of the developers but the heterogeneous community in its entirety.},
booktitle = {Proceedings of the International Conference on Management of Emergent Digital EcoSystems},
pages = {94–98},
numpages = {5},
keywords = {software ecosystems, knowledge management, communities of practice},
location = {San Francisco, California},
series = {MEDES '11}
}

@inproceedings{10.1145/3238147.3238169,
author = {Kovalenko, Vladimir and Palomba, Fabio and Bacchelli, Alberto},
title = {Mining file histories: should we consider branches?},
year = {2018},
isbn = {9781450359375},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3238147.3238169},
doi = {10.1145/3238147.3238169},
abstract = {Modern distributed version control systems, such as Git, offer support for branching — the possibility to develop parts of software outside the master trunk. Consideration of the repository structure in Mining Software Repository (MSR) studies requires a thorough approach to mining, but there is no well-documented, widespread methodology regarding the handling of merge commits and branches. Moreover, there is still a lack of knowledge of the extent to which considering branches during MSR studies impacts the results of the studies. In this study, we set out to evaluate the importance of proper handling of branches when calculating file modification histories. We analyze over 1,400 Git repositories of four open source ecosystems and compute modification histories for over two million files, using two different algorithms. One algorithm only follows the first parent of each commit when traversing the repository, the other returns the full modification history of a file across all branches. We show that the two algorithms consistently deliver different results, but the scale of the difference varies across projects and ecosystems. Further, we evaluate the importance of accurate mining of file histories by comparing the performance of common techniques that rely on file modification history — reviewer recommendation, change recommendation, and defect prediction — for two algorithms of file history retrieval. We find that considering full file histories leads to an increase in the techniques’ performance that is rather modest.},
booktitle = {Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering},
pages = {202–213},
numpages = {12},
keywords = {Version Control Systems, Mining Software Repositories, Branches},
location = {Montpellier, France},
series = {ASE '18}
}

@proceedings{10.5555/3606013,
title = {ICSE '23: Proceedings of the 45th International Conference on Software Engineering: Companion Proceedings},
year = {2023},
isbn = {9798350322637},
publisher = {IEEE Press},
abstract = {ICSE is the leading and by far the largest conference in Software Engineering, attracting researchers, practitioners and students from around the world. ICSE2023 is co-located with 10 conferences and symposia this year, many long-established and prestigious venues in their own right.},
location = {Melbourne, Victoria, Australia}
}

@inproceedings{10.1145/3387940.3391497,
author = {Machado, Leticia S. and Steinmacher, Igor and Marczak, Sabrina and de Souza, Cleidson R. B.},
title = {How Online Forums Complement Task Documentation in Software Crowdsourcing},
year = {2020},
isbn = {9781450379632},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387940.3391497},
doi = {10.1145/3387940.3391497},
abstract = {An issue in software crowdsourcing is the quality of the task documentation and the high number of registered crowd workers to solve tasks but few submitted solutions only. This happens because uncommunicated or misunderstood requirements can lead crowd workers to deliver a solution that does not meet the customers' requirements or, worse, to give up submitting a solution. In this paper, we present an empirical study in which we analyzed task documentation and online forums messages associated with 25 Software Crowdsourcing (SW CS) challenges. The findings corroborate that weak documentation is a challenge in SW CS. Meanwhile, online forums allow crowd workers to gather additional technical and operational information that is not present in the official task documentation. We provide a stepping stone towards understanding the interplay between requirements and communication, to make it possible to improve SW CS development processes, practices, and tools.},
booktitle = {Proceedings of the IEEE/ACM 42nd International Conference on Software Engineering Workshops},
pages = {101–108},
numpages = {8},
keywords = {documentation tasks, communication, Software crowdsourcing},
location = {Seoul, Republic of Korea},
series = {ICSEW'20}
}

@inproceedings{10.1145/3377811.3380410,
author = {Overney, Cassandra and Meinicke, Jens and K\"{a}stner, Christian and Vasilescu, Bogdan},
title = {How to not get rich: an empirical study of donations in open source},
year = {2020},
isbn = {9781450371216},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377811.3380410},
doi = {10.1145/3377811.3380410},
abstract = {Open source is ubiquitous and many projects act as critical infrastructure, yet funding and sustaining the whole ecosystem is challenging. While there are many different funding models for open source and concerted efforts through foundations, donation platforms like PayPal, Patreon, and OpenCollective are popular and low-bar platforms to raise funds for open-source development. With a mixed-method study, we investigate the emerging and largely unexplored phenomenon of donations in open source. Specifically, we quantify how commonly open-source projects ask for donations, statistically model characteristics of projects that ask for and receive donations, analyze for what the requested funds are needed and used, and assess whether the received donations achieve the intended outcomes. We find 25,885 projects asking for donations on GitHub, often to support engineering activities; however, we also find no clear evidence that donations influence the activity level of a project. In fact, we find that donations are used in a multitude of ways, raising new research questions about effective funding.},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering},
pages = {1209–1221},
numpages = {13},
location = {Seoul, South Korea},
series = {ICSE '20}
}

@article{10.1145/3043953,
author = {Solin, Jeff},
title = {TECHNOLOGY THAT EDUCATORS OF COMPUTING HAIL (TECH)Using Cloud9, a powerful cloud-based IDE in the classroom},
year = {2017},
issue_date = {March 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {1},
issn = {2153-2184},
url = {https://doi.org/10.1145/3043953},
doi = {10.1145/3043953},
abstract = {Welcome to the latest TECH column, a column that features a guest columnist, discussing technologies that educators find useful in their classrooms. The guest columnist is selected from those who have presented at a SIGCSE Technical Symposium session. This issue's guest columnist, Jeff Solin, offers his ideas on Cloud9.},
journal = {ACM Inroads},
month = {feb},
pages = {29–30},
numpages = {2}
}

@article{10.1145/3017427,
author = {Tam, Kimberly and Feizollah, Ali and Anuar, Nor Badrul and Salleh, Rosli and Cavallaro, Lorenzo},
title = {The Evolution of Android Malware and Android Analysis Techniques},
year = {2017},
issue_date = {December 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3017427},
doi = {10.1145/3017427},
abstract = {With the integration of mobile devices into daily life, smartphones are privy to increasing amounts of sensitive information. Sophisticated mobile malware, particularly Android malware, acquire or utilize such data without user consent. It is therefore essential to devise effective techniques to analyze and detect these threats. This article presents a comprehensive survey on leading Android malware analysis and detection techniques, and their effectiveness against evolving malware. This article categorizes systems by methodology and date to evaluate progression and weaknesses. This article also discusses evaluations of industry solutions, malware statistics, and malware evasion techniques and concludes by supporting future research paths.},
journal = {ACM Comput. Surv.},
month = {jan},
articleno = {76},
numpages = {41},
keywords = {static analysis, malware, dynamic analysis, detection, classification, Android}
}

@proceedings{10.1145/3634737,
title = {ASIA CCS '24: Proceedings of the 19th ACM Asia Conference on Computer and Communications Security},
year = {2024},
isbn = {9798400704826},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to ACM AsiaCCS 2024, the 19th ACM Asia Conference on Computer and Communications Security. AsiaCCS 2024 takes place in Singapore from 1 July to 5 July.},
location = {Singapore, Singapore}
}

@inproceedings{10.1145/2976749.2978428,
author = {B\"{o}hme, Marcel and Pham, Van-Thuan and Roychoudhury, Abhik},
title = {Coverage-based Greybox Fuzzing as Markov Chain},
year = {2016},
isbn = {9781450341394},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2976749.2978428},
doi = {10.1145/2976749.2978428},
abstract = {Coverage-based Greybox Fuzzing (CGF) is a random testing approach that requires no program analysis. A new test is generated by slightly mutating a seed input. If the test exercises a new and interesting path, it is added to the set of seeds; otherwise, it is discarded. We observe that most tests exercise the same few "high-frequency" paths and develop strategies to explore significantly more paths with the same number of tests by gravitating towards low-frequency paths. We explain the challenges and opportunities of CGF using a Markov chain model which specifies the probability that fuzzing the seed that exercises path i generates an input that exercises path j. Each state (i.e., seed) has an energy that specifies the number of inputs to be generated from that seed. We show that CGF is considerably more efficient if energy is inversely proportional to the density of the stationary distribution and increases monotonically every time that seed is chosen. Energy is controlled with a power schedule.We implemented the exponential schedule by extending AFL. In 24 hours, AFLFAST exposes 3 previously unreported CVEs that are not exposed by AFL and exposes 6 previously unreported CVEs 7x faster than AFL. AFLFAST produces at least an order of magnitude more unique crashes than AFL.},
booktitle = {Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security},
pages = {1032–1043},
numpages = {12},
keywords = {vulnerability detection, testing efficiency, software security, fuzzing, foundations},
location = {Vienna, Austria},
series = {CCS '16}
}

@inproceedings{10.1145/3639477.3639734,
author = {Zhao, Shengyu and Xia, Xiaoya and Fitzgerald, Brian and Li, Xiaozhou and Lenarduzzi, Valentina and Taibi, Davide and Wang, Rong and Wang, Wei and Tian, Chunqi},
title = {OpenRank Leaderboard: Motivating Open Source Collaborations Through Social Network Evaluation in Alibaba},
year = {2024},
isbn = {9798400705014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639477.3639734},
doi = {10.1145/3639477.3639734},
abstract = {Open source has revolutionized how software development is carried out, with a growing number of individuals and organizations contributing to open source projects. As the importance of open source continues to grow, companies also expect to grow thriving and sustainable open source communities with continued contributions and better collaborations. In this study, we applied the contribution leaderboard to seven open source projects initiated by Alibaba. We conducted a case study to investigate the perceptions and facts regarding how to motivate collaboration through gamification. Specifically, we employed a social network algorithm, OpenRank, to evaluate and steer developers' contributions. We validated the effectiveness of OpenRank by comparing it with other evaluation metrics and surveying developers. Through semi-structured interviews and project metric analysis, we found that the OpenRank Leaderboard can promote transparent communication environments, a better community atmosphere, and improved collaboration behavior.},
booktitle = {Proceedings of the 46th International Conference on Software Engineering: Software Engineering in Practice},
pages = {346–357},
numpages = {12},
keywords = {open source contribution, social network, leaderboard, gamification},
location = {Lisbon, Portugal},
series = {ICSE-SEIP '24}
}

@proceedings{10.1145/3605770,
title = {SCORED '23: Proceedings of the 2023 Workshop on Software Supply Chain Offensive Research and Ecosystem Defenses},
year = {2023},
isbn = {9798400702631},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to ACM SCORED '23, the second edition of the ACM Workshop on Software Supply Chain Offensive Research and Ecosystem Defenses. This edition is held in Copenhagen, Denmark with extensive support for in-person and virtual attendance.This year's program includes exciting work along many different dimensions of research on supply chain security: the development of security policies for software supply chains, the use of artificial intelligence and large language models, approaches on software bills of materials, and the proposals of risk mitigation techniques. Consistent with its focus, SCORED brings researchers, legislators and practitioners in both open- and closed-source ecosystems to the center of current and emerging challenges and opportunities in software supply chain security.},
location = {Copenhagen, Denmark}
}

@inproceedings{10.1145/3475716.3475785,
author = {Coelho, Fl\'{a}via and Tsantalis, Nikolaos and Massoni, Tiago and Alves, Everton L. G.},
title = {An Empirical Study on Refactoring-Inducing Pull Requests},
year = {2021},
isbn = {9781450386654},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3475716.3475785},
doi = {10.1145/3475716.3475785},
abstract = {Background: Pull-based development has shaped the practice of Modern Code Review (MCR), in which reviewers can contribute code improvements, such as refactorings, through comments and commits in Pull Requests (PRs). Past MCR studies uniformly treat all PRs, regardless of whether they induce refactoring or not. We define a PR as refactoring-inducing, when refactoring edits are performed after the initial commit(s), as either a result of discussion among reviewers or spontaneous actions carried out by the PR developer. Aims: This mixed study (quantitative and qualitative) explores code reviewing-related aspects intending to characterize refactoring-inducing PRs. Method: We hypothesize that refactoring-inducing PRs have distinct characteristics than non-refactoring-inducing ones and thus deserve special attention and treatment from researchers, practitioners, and tool builders. To investigate our hypothesis, we mined a sample of 1,845 Apache's merged PRs from GitHub, mined refactoring edits in these PRs, and ran a comparative study between refactoring-inducing and non-refactoring-inducing PRs. We also manually examined 2,096 review comments and 1,891 detected refactorings from 228 refactoring-inducing PRs. Results: We found 30.2% of refactoring-inducing PRs in our sample and that they significantly differ from non-refactoring-inducing ones in terms of number of commits, code churn, number of file changes, number of review comments, length of discussion, and time to merge. However, we found no statistical evidence that the number of reviewers is related to refactoring-inducement. Our qualitative analysis revealed that at least one refactoring edit was induced by review in 133 (58.3%) of the refactoring-inducing PRs examined. Conclusions: Our findings suggest directions for researchers, practitioners, and tool builders to improve practices around pull-based code review.},
booktitle = {Proceedings of the 15th ACM / IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM)},
articleno = {9},
numpages = {12},
keywords = {refactoring-inducing pull request, empirical study, code review mining},
location = {Bari, Italy},
series = {ESEM '21}
}

@article{10.1145/3571156,
author = {L\'{o}pez Mart\'{\i}nez, Antonio and Gil P\'{e}rez, Manuel and Ruiz-Mart\'{\i}nez, Antonio},
title = {A Comprehensive Review of the State-of-the-Art on Security and Privacy Issues in Healthcare},
year = {2023},
issue_date = {December 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {55},
number = {12},
issn = {0360-0300},
url = {https://doi.org/10.1145/3571156},
doi = {10.1145/3571156},
abstract = {Currently, healthcare is critical environment in our society, which attracts attention to malicious activities and has caused an important number of damaging attacks. In parallel, the recent advancements in technologies, computing systems, and wireless communications are changing healthcare environment by adding different improvements and complexity to it. This article reviews the current state of the literature and provides a holistic view of cybersecurity in healthcare. With this purpose in mind, the article enumerates the main stakeholders and architecture implemented in the healthcare environment, as well as the main security issues (threats, attacks, etc.) produced in healthcare. In this context, this work maps the threats collected with a widely used knowledge-based framework, MITRE ATT&amp;CK, building a contribution not seen so far. This article also enumerates the security mechanisms created to protect healthcare, identifying the principal research lines addressed in the literature, and listing the available public security-focused datasets used in machine-learning to provide security in the medical domain. To conclude, the research challenges that need to be addressed for future research works in this area are presented.},
journal = {ACM Comput. Surv.},
month = {mar},
articleno = {249},
numpages = {38},
keywords = {review, framework alignment, safety, threat taxonomy, Healthcare datasets}
}

@inproceedings{10.1145/3345629.3345634,
author = {Dey, Tapajit and Ma, Yuxing and Mockus, Audris},
title = {Patterns of Effort Contribution and Demand and User Classification based on Participation Patterns in NPM Ecosystem},
year = {2019},
isbn = {9781450372336},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3345629.3345634},
doi = {10.1145/3345629.3345634},
abstract = {Background: Open source requires participation of volunteer and commercial developers (users) in order to deliver functional high-quality components. Developers both contribute effort in the form of patches and demand effort from the component maintainers to resolve issues reported against it. Open source components depend on each other directly and transitively, and evidence suggests that more effort is required for reporting and resolving the issues reported further upstream in this supply chain. Aim: Identify and characterize patterns of effort contribution and demand throughout the open source supply chain and investigate if and how these patterns vary with developer activity; identify different groups of developers; and predict developers' company affiliation based on their participation patterns. Method: 1,376,946 issues and pull-requests created for 4433 NPM packages with over 10,000 monthly downloads and full (public) commit activity data of the 272,142 issue creators is obtained and analyzed and dependencies on NPM packages are identified. Fuzzy c-means clustering algorithm is used to find the groups among the users based on their effort contribution and demand patterns, and Random Forest is used as the predictive modeling technique to identify their company affiliations. Result: Users contribute and demand effort primarily from packages that they depend on directly with only a tiny fraction of contributions and demand going to transitive dependencies. A significant portion of demand goes into packages outside the users' respective supply chains (constructed based on publicly visible version control data). Three and two different groups of users are observed based on the effort demand and effort contribution patterns respectively. The Random Forest model used for identifying the company affiliation of the users gives a AUC-ROC value of 0.68, and variables representing aggregate participation patterns proved to be the important predictors. Conclusion: Our results give new insights into effort demand and supply at different parts of the supply chain of the NPM ecosystem and its users and suggests the need to increase visibility further upstream.},
booktitle = {Proceedings of the Fifteenth International Conference on Predictive Models and Data Analytics in Software Engineering},
pages = {36–45},
numpages = {10},
keywords = {User Contribution, Software Issue Reporting, Software Dependencies, Random Forest model, NPM Packages, Clustering},
location = {Recife, Brazil},
series = {PROMISE'19}
}

@inproceedings{10.1145/3524842.3528479,
author = {Warrick, Melanie and Rosenblatt, Samuel F. and Young, Jean-Gabriel and Casari, Amanda and H\'{e}bert-Dufresne, Laurent and Bagrow, James},
title = {The OCEAN mailing list data set: network analysis spanning mailing lists and code repositories},
year = {2022},
isbn = {9781450393034},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3524842.3528479},
doi = {10.1145/3524842.3528479},
abstract = {Communication surrounding the development of an open source project largely occurs outside the software repository itself. Historically, large communities often used a collection of mailing lists to discuss the different aspects of their projects. Multimodal tool use, with software development and communication happening on different channels, complicates the study of open source projects as a sociotechnical system. Here, we combine and standardize mailing lists of the Python community, resulting in 954,287 messages from 1995 to the present. We share all scraping and cleaning code to facilitate reproduction of this work, as well as smaller datasets for the Golang (122,721 messages), Angular (20,041 messages) and Node.js (12,514 messages) communities. To showcase the usefulness of these data, we focus on the CPython repository and merge the technical layer (which GitHub account works on what file and with whom) with the social layer (messages from unique email addresses) by identifying 33% of GitHub contributors in the mailing list data. We then explore correlations between the valence of social messaging and the structure of the collaboration network. We discuss how these data provide a laboratory to test theories from standard organizational science in large open source projects.},
booktitle = {Proceedings of the 19th International Conference on Mining Software Repositories},
pages = {338–342},
numpages = {5},
keywords = {text tagging, sociotechnical systems, network analysis, datasets},
location = {Pittsburgh, Pennsylvania},
series = {MSR '22}
}

@inproceedings{10.1109/ICSE48619.2023.00212,
author = {Zhang, Lyuye and Liu, Chengwei and Xu, Zhengzi and Chen, Sen and Fan, Lingling and Zhao, Lida and Wu, Jiahui and Liu, Yang},
title = {Compatible Remediation on Vulnerabilities from Third-Party Libraries for Java Projects},
year = {2023},
isbn = {9781665457019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE48619.2023.00212},
doi = {10.1109/ICSE48619.2023.00212},
abstract = {With the increasing disclosure of vulnerabilities in open-source software, software composition analysis (SCA) has been widely applied to reveal third-party libraries and the associated vulnerabilities in software projects. Beyond the revelation, SCA tools adopt various remediation strategies to fix vulnerabilities, the quality of which varies substantially. However, ineffective remediation could induce side effects, such as compilation failures, which impede acceptance by users. According to our studies, existing SCA tools could not correctly handle the concerns of users regarding the compatibility of remediated projects. To this end, we propose Compatible Remediation of Third-party libraries (CORAL) for Maven projects to fix vulnerabilities without breaking the projects. The evaluation proved that CORAL not only fixed 87.56% of vulnerabilities which outperformed other tools (best 75.32%) and achieved a 98.67% successful compilation rate and a 92.96% successful unit test rate. Furthermore, we found that 78.45% of vulnerabilities in popular Maven projects could be fixed without breaking the compilation, and the rest of the vulnerabilities (21.55%) could either be fixed by upgrades that break the compilations or even be impossible to fix by upgrading.},
booktitle = {Proceedings of the 45th International Conference on Software Engineering},
pages = {2540–2552},
numpages = {13},
keywords = {open-source software, Java, compatibility, remediation},
location = {Melbourne, Victoria, Australia},
series = {ICSE '23}
}

@inproceedings{10.1109/ICSE-Companion58688.2023.00064,
author = {Melo, Glaucia},
title = {Designing Adaptive Developer-Chatbot Interactions: Context Integration, Experimental Studies, and Levels of Automation},
year = {2023},
isbn = {9798350322637},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-Companion58688.2023.00064},
doi = {10.1109/ICSE-Companion58688.2023.00064},
abstract = {The growing demand for software developers and the increasing development complexity have emphasized the need for support in software engineering projects. This is especially relevant in light of advancements in artificial intelligence, such as conversational systems. A significant contributor to the complexity of software development is the multitude of tools and methods used, creating various contexts in which software developers must operate. Moreover, there has been limited investigation into the interaction between context-based chatbots and software developers through experimental user studies. Assisting software developers in their work becomes essential. In particular, understanding the context surrounding software development and integrating this context into chatbots can lead to novel insight into what software developers expect concerning these human-chatbot interactions and their levels of automation. In my research, I study the design of context-based adaptive interactions between software developers and chatbots to foster solutions and knowledge to support software developers at work.},
booktitle = {Proceedings of the 45th International Conference on Software Engineering: Companion Proceedings},
pages = {235–239},
numpages = {5},
keywords = {interactions, autonomous systems, levels of automation, chatbot, context, software engineering},
location = {Melbourne, Victoria, Australia},
series = {ICSE '23}
}

@article{10.1145/1897852.1897870,
author = {Kamp, Poul-Henning},
title = {B.Y.O.C (1,342 times and counting)},
year = {2011},
issue_date = {March 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {3},
issn = {0001-0782},
url = {https://doi.org/10.1145/1897852.1897870},
doi = {10.1145/1897852.1897870},
abstract = {Why can't we all use standard libraries for commonly needed algorithms?},
journal = {Commun. ACM},
month = {mar},
pages = {56–58},
numpages = {3}
}

@article{10.1145/3429741,
author = {Botacin, Marcus and Aghakhani, Hojjat and Ortolani, Stefano and Kruegel, Christopher and Vigna, Giovanni and Oliveira, Daniela and Geus, Paulo L\'{\i}cio De and Gr\'{e}gio, Andr\'{e}},
title = {One Size Does Not Fit All: A Longitudinal Analysis of Brazilian Financial Malware},
year = {2021},
issue_date = {May 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {24},
number = {2},
issn = {2471-2566},
url = {https://doi.org/10.1145/3429741},
doi = {10.1145/3429741},
abstract = {Malware analysis is an essential task to understand infection campaigns, the behavior of malicious codes, and possible ways to mitigate threats. Malware analysis also allows better assessment of attackers’ capabilities, techniques, and processes. Although a substantial amount of previous work provided a comprehensive analysis of the international malware ecosystem, research on regionalized, country-, and population-specific malware campaigns have been scarce. Moving towards addressing this gap, we conducted a longitudinal (2012-2020) and comprehensive (encompassing an entire population of online banking users) study of MS Windows desktop malware that actually infected Brazilian banks’ users. We found that the Brazilian financial desktop malware has been evolving quickly: it started to make use of a variety of file formats instead of typical PE binaries, relied on native system resources, and abused obfuscation techniques to bypass detection mechanisms. Our study on the threats targeting a significant population on the ecosystem of the largest and most populous country in Latin America can provide invaluable insights that may be applied to other countries’ user populations, especially those in the developing world that might face cultural peculiarities similar to Brazil’s. With this evaluation, we expect to motivate the security community/industry to seriously consider a deeper level of customization during the development of next-generation anti-malware solutions, as well as to raise awareness towards regionalized and targeted Internet threats.},
journal = {ACM Trans. Priv. Secur.},
month = {jan},
articleno = {11},
numpages = {31},
keywords = {reverse engineer, banking, Malware}
}

@article{10.1145/3359224,
author = {Qiu, Huilian Sophie and Li, Yucen Lily and Padala, Susmita and Sarma, Anita and Vasilescu, Bogdan},
title = {The Signals that Potential Contributors Look for When Choosing Open-source Projects},
year = {2019},
issue_date = {November 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {CSCW},
url = {https://doi.org/10.1145/3359224},
doi = {10.1145/3359224},
abstract = {While open-source software has become ubiquitous, its sustainability is in question: without a constant supply of contributor effort, open-source projects are at risk. While prior work has extensively studied the motivations of open-source contributors in general, relatively little is known about how people choose which project to contribute to, beyond personal interest. This question is especially relevant in transparent social coding environments like GitHub, where visible cues on personal profile and repository pages, known as signals, are known to impact impression formation and decision making. In this paper, we report on a mixed-methods empirical study of the signals that influence the contributors' decision to join a GitHub project. We first interviewed 15 GitHub contributors about their project evaluation processes and identified the important signals they used, including the structure of the README and the amount of recent activity. Then, we proceeded quantitatively to test out the impact of each signal based on the data of 9,977 GitHub projects. We reveal that many important pieces of information lack easily observable signals, and that some signals may be both attractive and unattractive. Our findings have direct implications for open-source maintainers and the design of social coding environments, e.g., features to be added to facilitate better project searching experience.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = {nov},
articleno = {122},
numpages = {29},
keywords = {signaling theory, open-source software, github}
}

@proceedings{10.1145/2950290,
title = {FSE 2016: Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering},
year = {2016},
isbn = {9781450342186},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Seattle, WA, USA}
}

@inproceedings{10.1145/3611643.3613084,
author = {Sajadi, Amirali and Damevski, Kostadin and Chatterjee, Preetha},
title = {Towards Understanding Emotions in Informal Developer Interactions: A Gitter Chat Study},
year = {2023},
isbn = {9798400703270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611643.3613084},
doi = {10.1145/3611643.3613084},
abstract = {Emotions play a significant role in teamwork and collaborative activities like software development. While researchers have analyzed developer emotions in various software artifacts (e.g., issues, pull requests), few studies have focused on understanding the broad spectrum of emotions expressed in chats. As one of the most widely used means of communication, chats contain valuable information in the form of informal conversations, such as negative perspectives about adopting a tool. In this paper, we present a dataset of developer chat messages manually annotated with a wide range of emotion labels (and sub-labels), and analyze the type of information present in those messages. We also investigate the unique signals of emotions specific to chats and distinguish them from other forms of software communication. Our findings suggest that chats have fewer expressions of Approval and Fear but more expressions of Curiosity compared to GitHub comments. We also notice that Confusion is frequently observed when discussing programming-related information such as unexpected software behavior. Overall, our study highlights the potential of mining emotions in developer chats for supporting software maintenance and evolution tools.},
booktitle = {Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {2097–2101},
numpages = {5},
keywords = {emotion analysis, software developer chats},
location = {San Francisco, CA, USA},
series = {ESEC/FSE 2023}
}

@proceedings{10.1145/3649217,
title = {ITiCSE 2024: Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 29th annual conference on Innovation and Technology in Computer Science Education (ITiCSE 2024), hosted by Universit\`{a} degli Studi di Milano in Milan, Italy.ITiCSE 2024 will take place from Friday July 5 to Wednesday July 10. The conference program includes a keynote address, paper sessions, a panel, tips, techniques &amp; courseware demonstrations, posters, a doctoral consortium, and working group presentations. Working groups meet July 5-7 and will submit draft reports before the conference begins on July 8.The submissions to ITiCSE 2024 were reviewed by 446 researchers and practitioners from computing education and related fields, including 44 program committee members and 402 reviewers. Thanks to their outstanding effort and commitment, every submission received a metareview and most received at least three reviews, providing authors of all submissions with constructive feedback. Although no review process is flawless, we are confident that this effort led to a vibrant conference program, capturing multiple voices and perspectives in the field.},
location = {Milan, Italy}
}

@inproceedings{10.1145/2441776.2441891,
author = {Luther, Kurt and Fiesler, Casey and Bruckman, Amy},
title = {Redistributing leadership in online creative collaboration},
year = {2013},
isbn = {9781450313315},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2441776.2441891},
doi = {10.1145/2441776.2441891},
abstract = {In this paper, we integrate theories of distributed leadership and distributed cognition to account for the roles of people and technology in online leadership. When leadership is distributed effectively, the result can be success stories like Wikipedia and Linux. However, finding a successful distribution is challenging. In the online community Newgrounds, hundreds of collaborative animation projects called "collabs" are started each year, but less than 20% are completed. We suggest that many collabs fail because leaders are overburdened and lack adequate technological support. We introduce Pipeline, a collaboration tool designed to support and transform leadership, with the goal of easing the burden on leaders of online creative projects. Through a case study of a six-week, 30-artist collaboration called Holiday Flood, we show how Pipeline supported redistributed leadership. We conclude with implications for theory and the design of social computing systems.},
booktitle = {Proceedings of the 2013 Conference on Computer Supported Cooperative Work},
pages = {1007–1022},
numpages = {16},
keywords = {social computing, online creative collaboration, distributed leadership, distributed cognition, creativity support tools},
location = {San Antonio, Texas, USA},
series = {CSCW '13}
}

@proceedings{10.1145/3551349,
title = {ASE '22: Proceedings of the 37th IEEE/ACM International Conference on Automated Software Engineering},
year = {2022},
isbn = {9781450394758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Rochester, MI, USA}
}

@inproceedings{10.1145/2619287.2619292,
author = {Farhadi, Hamid and Du, Ping and Nakao, Akihiro},
title = {User-defined actions for SDN},
year = {2014},
isbn = {9781450329422},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2619287.2619292},
doi = {10.1145/2619287.2619292},
abstract = {In Software-Defined Networking (SDN), the control plane can program the data plane via SDN open APIs such as OpenFlow. An OpenFlow-like data plane applies &lt;match, action&gt; rules to every packet. However, it only supports a few actions that are all predefined and hardcoded to a piece of hardware in SDN switch. We argue that we should extend the programmability and flexibility of SDN to the data plane to allow network owners to add their custom network functions while keeping the programability of existing SDN. Since current OpenFlow actions are not sufficient and flexible, we posit we need user-defined actions deployed within the switch box rather than an external equipment (e.g., Fire-wall). Finally, we study the feasibility of two sample user-defined actions (i.e., Portscan detector and Botminer detector) using two different underlying mechanisms: OpenFlow and our previous work, TagFlow. Our evaluations show that user-defined actions are capable of handling traffic at line speed. Moreover, we also indicate that TagFlow user-defined actions are 33% faster than OpenFlow. We concluded that extending SDN features to include user-defined actions is lightweight and feasible.},
booktitle = {Proceedings of The Ninth International Conference on Future Internet Technologies},
articleno = {3},
numpages = {6},
keywords = {southbound application, software-defined networking, programmable networks, OpenFlow},
location = {Tokyo, Japan},
series = {CFI '14}
}

@inproceedings{10.1145/1984674.1984681,
author = {Kiniry, Joseph R. and Zimmerman, Daniel M.},
title = {Verified gaming},
year = {2011},
isbn = {9781450305785},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1984674.1984681},
doi = {10.1145/1984674.1984681},
abstract = {In recent years, several Grand Challenges (GCs) of computing have been identified and expounded upon by various professional organizations in the U.S. and England. These GCs are typically very difficult problems that will take many hundreds, or perhaps thousands, of man-years to solve. Researchers involved in identifying these problems are not going to solve them. That task will fall to our students, and our students' students. Unfortunately for GC6, the Grand Challenge focusing on Dependable Systems Evolution, interest in formal methods--both by students and within computer science faculties - falls every year and any mention of mathematics in the classroom seems to frighten students away. So the question is: How do we attract new students in computing to the area of dependable software systems?Over the past several years at three universities we have experimented with the use of computer games as a target domain for software engineering project courses that focus on reliable systems engineering. This position paper summarizes our experiences in incorporating rigorous software engineering into courses with computer game projects.},
booktitle = {Proceedings of the 1st International Workshop on Games and Software Engineering},
pages = {17–20},
numpages = {4},
keywords = {grand challenges, games in education, formal methods},
location = {Waikiki, Honolulu, HI, USA},
series = {GAS '11}
}

@inproceedings{10.1145/3589334.3645319,
author = {Huang, Junqin and Kong, Linghe and Cheng, Guanjie and Xiang, Qiao and Chen, Guihai and Huang, Gang and Liu, Xue},
title = {Advancing Web 3.0: Making Smart Contracts Smarter on Blockchain},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645319},
doi = {10.1145/3589334.3645319},
abstract = {Blockchain and smart contracts are one of the key technologies promoting Web 3.0. However, due to security considerations and consistency requirements, smart contracts currently only support simple and deterministic programs, which significantly hinders their deployment in intelligent Web 3.0 applications. To enhance smart contracts intelligence on the blockchain, we propose SMART, a plug-in smart contract framework that supports efficient AI model inference while being compatible with existing blockchains. To handle the high complexity of model inference, we propose an on-chain and off-chain joint execution model, which separates the SMART contract into two parts: the deterministic code still runs inside an on-chain virtual machine, while the complex model inference is offloaded to off-chain compute nodes. To solve the non-determinism brought by model inference, we leverage Trusted Execution Environments (TEEs) to endorse the integrity and correctness of the off-chain execution. We also design distributed attestation and secret key provisioning schemes to further enhance the system security and model privacy. We implement a SMART prototype and evaluate it on a popular Ethereum Virtual Machine (EVM)-based blockchain. Theoretical analysis and prototype evaluation show that SMART not only achieves the security goals of correctness, liveness, and model privacy, but also has approximately 5 orders of magnitude faster inference efficiency than existing on-chain solutions.},
booktitle = {Proceedings of the ACM on Web Conference 2024},
pages = {1549–1560},
numpages = {12},
keywords = {blockchain, model inference, smart contract, trusted execution environment, web 3.0},
location = {Singapore, Singapore},
series = {WWW '24}
}

@proceedings{10.1145/3627106,
title = {ACSAC '23: Proceedings of the 39th Annual Computer Security Applications Conference},
year = {2023},
isbn = {9798400708862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Austin, TX, USA}
}

@proceedings{10.1145/3644032,
title = {AST '24: Proceedings of the 5th ACM/IEEE International Conference on Automation of Software Test (AST 2024)},
year = {2024},
isbn = {9798400705885},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {AST continues to be a venue for researchers and practitioners where they can discuss high quality research contributions on methods for software test automation, and various case studies reporting practices in this field. Indeed, software test automation is a discipline that has produced noteworthy research in the last decade.The special theme of AST 2024 is "Test automation for and with Generative AI". This innovative and promising research direction deals with the application of test automation technologies to the testing of Generative AI applications, as well as the adoption of generative AI to facilitate test automation.},
location = {Lisbon, Portugal}
}

@proceedings{10.1145/3597926,
title = {ISSTA 2023: Proceedings of the 32nd ACM SIGSOFT International Symposium on Software Testing and Analysis},
year = {2023},
isbn = {9798400702211},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to ISSTA 2023, the 32nd edition of the International Symposium on Software Testing and Analysis, to be held on July 18–20, 2023 in Seattle, USA. The symposium has become a premier scientific event in the expanding area of software testing and analysis, with a strong appeal to researchers from all continents.},
location = {Seattle, WA, USA}
}

@inproceedings{10.1145/2441776.2441871,
author = {Morgan, Jonathan T. and Bouterse, Siko and Walls, Heather and Stierch, Sarah},
title = {Tea and sympathy: crafting positive new user experiences on wikipedia},
year = {2013},
isbn = {9781450313315},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2441776.2441871},
doi = {10.1145/2441776.2441871},
abstract = {We present the Teahouse, a pilot project for supporting and socializing new Wikipedia editors. Open collaboration systems like Wikipedia must continually recruit and retain new members in order to sustain themselves. Wikipedia's editor decline presents unique exigency for evaluating novel strategies to support newcomers and increase new user retention in such systems, particularly among demographics that are currently underrepresented in the user community. In this paper, we describe the design and deployment of Teahouse, and present preliminary findings. Our findings highlight the importance of intervening early in the editor lifecycle, providing user-friendly tools, creating safe spaces for newcomers, and facilitating positive interactions between newcomers and established community members.},
booktitle = {Proceedings of the 2013 Conference on Computer Supported Cooperative Work},
pages = {839–848},
numpages = {10},
keywords = {wikipedia, user experience, socialization, new users, gender, collaboration},
location = {San Antonio, Texas, USA},
series = {CSCW '13}
}

@inproceedings{10.1109/ICSE-SEET58685.2023.00017,
author = {Wyrich, Marvin and Wagner, Stefan},
title = {Teaching Computer Science Students to Communicate Scientific Findings More Effectively},
year = {2023},
isbn = {9798350322590},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-SEET58685.2023.00017},
doi = {10.1109/ICSE-SEET58685.2023.00017},
abstract = {Science communication forms the bridge between computer science researchers and their target audience. Researchers who can effectively draw attention to their research findings and communicate them comprehensibly not only help their target audience to actually learn something, but also benefit themselves from the increased visibility of their work and person. However, the necessary skills for good science communication must also be taught, and this has so far been neglected in the field of software engineering education.We therefore designed and implemented a science communication seminar for bachelor students of computer science curricula. Students take the position of a researcher who, shortly after publication, is faced with having to draw attention to the paper and effectively communicate the contents of the paper to one or more target audiences. Based on this scenario, each student develops a communication strategy for an already published software engineering research paper and tests the resulting ideas with the other seminar participants.We explain our design decisions for the seminar, and combine our experiences with responses to a participant survey into lessons learned. With this experience report, we intend to motivate and enable other lecturers to offer a similar seminar at their university. Collectively, university lecturers can prepare the next generation of computer science researchers to not only be experts in their field, but also to communicate research findings more effectively.},
booktitle = {Proceedings of the 45th International Conference on Software Engineering: Software Engineering Education and Training},
pages = {107–114},
numpages = {8},
keywords = {soft skills, education, training, presentation, science communication},
location = {Melbourne, Australia},
series = {ICSE-SEET '23}
}

@article{10.1145/3652153,
author = {Guo, Yimeng and Chen, Zhifei and Chen, Lin and Xu, Wenjie and Li, Yanhui and Zhou, Yuming and Xu, Baowen},
title = {Generating Python Type Annotations from Type Inference: How Far Are We?},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {5},
issn = {1049-331X},
url = {https://doi.org/10.1145/3652153},
doi = {10.1145/3652153},
abstract = {In recent years, dynamic languages such as Python have become popular due to their flexibility and productivity. The lack of static typing makes programs face the challenges of fixing type errors, early bug detection, and code understanding. To alleviate these issues, PEP 484 introduced optional type annotations for Python in 2014, but unfortunately, a large number of programs are still not annotated by developers. Annotation generation tools can utilize type inference techniques. However, several important aspects of type annotation generation are overlooked by existing works, such as in-depth effectiveness analysis, potential improvement exploration, and practicality evaluation. And it is unclear how far we have been and how far we can go.In this paper, we set out to comprehensively investigate the effectiveness of type inference tools for generating type annotations, applying three categories of state-of-the-art tools on a carefully-cleaned dataset. First, we use a comprehensive set of metrics and categories, finding that existing tools have different effectiveness and cannot achieve both high accuracy and high coverage. Then, we summarize six patterns to present the limitations in type annotation generation. Next, we implement a simple but effective tool to demonstrate that existing tools can be improved in practice. Finally, we conduct a controlled experiment showing that existing tools can reduce the time spent annotating types and determine more precise types, but cannot reduce subjective difficulty. Our findings point out the limitations and improvement directions in type annotation generation, which can inspire future work.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = {jun},
articleno = {123},
numpages = {38},
keywords = {Type annotations, type inference, Python, empirical study}
}

@article{10.1145/3542937,
author = {P\^{a}r\c{t}achi, Profir-Petru and White, David R. and Barr, Earl T.},
title = {Aide-m\'{e}moire: Improving a Project’s Collective Memory via Pull Request–Issue Links},
year = {2023},
issue_date = {March 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {32},
number = {2},
issn = {1049-331X},
url = {https://doi.org/10.1145/3542937},
doi = {10.1145/3542937},
abstract = {Links between pull request and the issues they address document and accelerate the development of a software project but are often omitted. We present a new tool, Aide-m\'{e}moire, to suggest such links when a developer submits a pull request or closes an issue, smoothly integrating into existing workflows. In contrast to previous state-of-the-art approaches that repair related commit histories, Aide-m\'{e}moire is designed for continuous, real-time, and long-term use, employing Mondrian forest to adapt over a project’s lifetime and continuously improve traceability. Aide-m\'{e}moire is tailored for two specific instances of the general traceability problem—namely, commit to issue and pull request to issue links, with a focus on the latter—and exploits data inherent to these two problems to outperform tools for general purpose link recovery. Our approach is online, language-agnostic, and scalable. We evaluate over a corpus of 213 projects and six programming languages, achieving a mean average precision of 0.95. Adopting Aide-m\'{e}moire is both efficient and effective: A programmer need only evaluate a single suggested link 94% of the time, and 16% of all discovered links were originally missed by developers.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = {mar},
articleno = {32},
numpages = {36},
keywords = {missing link, link inference, Traceability}
}

@proceedings{10.1145/3411763,
title = {CHI EA '21: Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
year = {2021},
isbn = {9781450380959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Yokohama, Japan}
}

@proceedings{10.1145/3639477,
title = {ICSE-SEIP '24: Proceedings of the 46th International Conference on Software Engineering: Software Engineering in Practice},
year = {2024},
isbn = {9798400705014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Lisbon, Portugal}
}

@proceedings{10.1145/3639476,
title = {ICSE-NIER'24: Proceedings of the 2024 ACM/IEEE 44th International Conference on Software Engineering: New Ideas and Emerging Results},
year = {2024},
isbn = {9798400705007},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Lisbon, Portugal}
}

@inproceedings{10.1109/MSR.2017.43,
author = {Alkadhi, Rana and La\c{t}a, Teodora and Guzman, Emitza and Bruegge, Bernd},
title = {Rationale in development chat messages: an exploratory study},
year = {2017},
isbn = {9781538615447},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MSR.2017.43},
doi = {10.1109/MSR.2017.43},
abstract = {Chat messages of development teams play an increasingly significant role in software development, having replaced emails in some cases. Chat messages contain information about discussed issues, considered alternatives and argumentation leading to the decisions made during software development. These elements, defined as rationale, are invaluable during software evolution for documenting and reusing development knowledge. Rationale is also essential for coping with changes and for effective maintenance of the software system. However, exploiting the rationale hidden in the chat messages is challenging due to the high volume of unstructured messages covering a wide range of topics. This work presents the results of an exploratory study examining the frequency of rationale in chat messages, the completeness of the available rationale and the potential of automatic techniques for rationale extraction. For this purpose, we apply content analysis and machine learning techniques on more than 8,700 chat messages from three software development projects. Our results show that chat messages are a rich source of rationale and that machine learning is a promising technique for detecting rationale and identifying different rationale elements.},
booktitle = {Proceedings of the 14th International Conference on Mining Software Repositories},
pages = {436–446},
numpages = {11},
location = {Buenos Aires, Argentina},
series = {MSR '17}
}

@proceedings{10.1145/3555228,
title = {SBES '22: Proceedings of the XXXVI Brazilian Symposium on Software Engineering},
year = {2022},
isbn = {9781450397353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Virtual Event, Brazil}
}

@proceedings{10.5555/3623293,
title = {ICSE-SEIP '23: Proceedings of the 45th International Conference on Software Engineering: Software Engineering in Practice},
year = {2023},
isbn = {9798350300376},
publisher = {IEEE Press},
location = {Melbourne, Australia}
}

@article{10.1145/3412378,
author = {Ehsan, Osama and Hassan, Safwat and Mezouar, Mariam El and Zou, Ying},
title = {An Empirical Study of Developer Discussions in the Gitter Platform},
year = {2021},
issue_date = {January 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {30},
number = {1},
issn = {1049-331X},
url = {https://doi.org/10.1145/3412378},
doi = {10.1145/3412378},
abstract = {Developer chatrooms (e.g., the Gitter platform) are gaining popularity as a communication channel among developers. In developer chatrooms, a developer (asker) posts questions and other developers (respondents) respond to the posted questions. The interaction between askers and respondents results in a discussion thread. Recent studies show that developers use chatrooms to inquire about issues, discuss development ideas, and help each other. However, prior work focuses mainly on analyzing individual messages of a chatroom without analyzing the discussion thread in a chatroom. Developer chatroom discussions are context-sensitive, entangled, and include multiple participants that make it hard to accurately identify threads. Therefore, prior work has limited capability to show the interactions among developers within a chatroom by analyzing only individual messages.In this article, we perform an in-depth analysis of the Gitter platform (i.e., developer chatrooms) by analyzing 6,605,248 messages of 709 chatrooms. To analyze the characteristics of the posted questions and the impact on the response behavior (e.g., whether the posted questions get responses), we propose an approach that identifies discussion threads in chatrooms with high precision (i.e., 0.81 F-score). Our results show that inactive members responded more often and unique questions take longer discussion time than simple questions. We also find that clear and concise questions are more likely to be responded to than poorly written questions.We further manually analyze a randomly selected sample of 384 threads to examine how respondents resolve the raised questions. We observe that more than 80% of the studied threads are resolved. Advanced-level/beginner-level questions along with the edited questions are the mostly resolved questions. Our results can help the project maintainers understand the nature of the discussion threads (e.g., the topic trends). Project maintainers can also benefit from our thread identification approach to spot the common repeated threads and use these threads as frequently asked questions (FAQs) to improve the documentation of their projects.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = {dec},
articleno = {8},
numpages = {39},
keywords = {thread identification, mixed-effect models, developer threads, developer chatrooms, Gitter, Chat disentanglement}
}

@inproceedings{10.1145/3345629.3345635,
author = {Wang, Song and Bansal, Chetan and Nagappan, Nachiappan and Philip, Adithya Abraham},
title = {Leveraging Change Intents for Characterizing and Identifying Large-Review-Effort Changes},
year = {2019},
isbn = {9781450372336},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3345629.3345635},
doi = {10.1145/3345629.3345635},
abstract = {Code changes to software occur due to various reasons such as bug fixing, new feature addition, and code refactoring. In most existing studies, the intent of the change is rarely leveraged to provide more specific, context aware analysis.In this paper, we present the first study to leverage change intent to characterize and identify Large-Review-Effort (LRE) changes regarding review effort---changes with large review effort. Specifically, we first propose a feedback-driven and heuristics-based approach to obtain change intents. We then characterize the changes regarding review effort by using various features extracted from change metadata and the change intents. We further explore the feasibility of automatically classifying LRE changes. We conduct our study on a large-scale project from Microsoft and three large-scale open source projects, i.e., Qt, Android, and OpenStack. Our results show that, (i) code changes with some intents are more likely to be LRE changes, (ii) machine learning based prediction models can efficiently help identify LRE changes, and (iii) prediction models built for code changes with some intents achieve better performance than prediction models without considering the change intent, the improvement in AUC can be up to 19 percentage points and is 7.4 percentage points on average. The tool developed in this study has already been used in Microsoft to provide the review effort and intent information of changes for reviewers to accelerate the review process.},
booktitle = {Proceedings of the Fifteenth International Conference on Predictive Models and Data Analytics in Software Engineering},
pages = {46–55},
numpages = {10},
keywords = {review effort, machine learning, change intent, Code review},
location = {Recife, Brazil},
series = {PROMISE'19}
}

@proceedings{10.1145/3629479,
title = {SBQS '23: Proceedings of the XXII Brazilian Symposium on Software Quality},
year = {2023},
isbn = {9798400707865},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Bras\'{\i}lia, Brazil}
}

@proceedings{10.1145/3644815,
title = {CAIN '24: Proceedings of the IEEE/ACM 3rd International Conference on AI Engineering - Software Engineering for AI},
year = {2024},
isbn = {9798400705915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {The goal of the CAIN Conference Series is to bring together researchers and practitioners in software engineering, data science, and artificial intelligence (AI) as part of a growing community that is targeting the challenges of Software Engineering for AI-enabled systems.},
location = {Lisbon, Portugal}
}

@proceedings{10.1145/3613905,
title = {CHI EA '24: Extended Abstracts of the 2024 CHI Conference on Human Factors in Computing Systems},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3605098,
title = {SAC '24: Proceedings of the 39th ACM/SIGAPP Symposium on Applied Computing},
year = {2024},
isbn = {9798400702433},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {On behalf of the Organizing Committee, I extend a warm welcome to you at the 39th Annual ACM Symposium on Applied Computing (SAC 2024), taking place in \'{A}vila, Spain, and hosted by the University of Salamanca. For more than three decades, this international forum has been dedicated to computer scientists, engineers, and practitioners, providing a platform for presenting their research findings and results in various areas of applied computing. The organizing committee sincerely appreciates your participation in this exciting international event, and we hope that the conference proves interesting and beneficial for all attendees.},
location = {Avila, Spain}
}

@article{10.1145/3557999,
author = {Cao, Jacky and Lam, Kit-Yung and Lee, Lik-Hang and Liu, Xiaoli and Hui, Pan and Su, Xiang},
title = {Mobile Augmented Reality: User Interfaces, Frameworks, and Intelligence},
year = {2023},
issue_date = {September 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {55},
number = {9},
issn = {0360-0300},
url = {https://doi.org/10.1145/3557999},
doi = {10.1145/3557999},
abstract = {Mobile Augmented Reality (MAR) integrates computer-generated virtual objects with physical environments for mobile devices. MAR systems enable users to interact with MAR devices, such as smartphones and head-worn wearables, and perform seamless transitions from the physical world to a mixed world with digital entities. These MAR systems support user experiences using MAR devices to provide universal access to digital content. Over the past 20 years, several MAR systems have been developed, however, the studies and design of MAR frameworks have not yet been systematically reviewed from the perspective of user-centric design. This article presents the first effort of surveying existing MAR frameworks (count: 37) and further discusses the latest studies on MAR through a top-down approach: (1) MAR applications; (2) MAR visualisation techniques adaptive to user mobility and contexts; (3) systematic evaluation of MAR frameworks, including supported platforms and corresponding features such as tracking, feature extraction, and sensing capabilities; (4) and underlying machine learning approaches supporting intelligent operations within MAR systems. Finally, we summarise the development of emerging research fields and the current state-of-the-art and discuss the important open challenges and possible theoretical and technical directions. This survey aims to benefit both researchers and MAR system developers alike.},
journal = {ACM Comput. Surv.},
month = {jan},
articleno = {189},
numpages = {36},
keywords = {metaverse, artificial intelligence, development framework, user interactions, Mobile augmented reality}
}

@inproceedings{10.1145/2736277.2741130,
author = {Kooti, Farshad and Aiello, Luca Maria and Grbovic, Mihajlo and Lerman, Kristina and Mantrach, Amin},
title = {Evolution of Conversations in the Age of Email Overload},
year = {2015},
isbn = {9781450334693},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/2736277.2741130},
doi = {10.1145/2736277.2741130},
abstract = {Email is a ubiquitous communications tool in the workplace and plays an important role in social interactions. Previous studies of email were largely based on surveys and limited to relatively small populations of email users within organizations. In this paper, we report results of a large-scale study of more than 2 million users exchanging 16 billion emails over several months. We quantitatively characterize the replying behavior in conversations within pairs of users. In particular, we study the time it takes the user to reply to a received message and the length of the reply sent. We consider a variety of factors that affect the reply time and length, such as the stage of the conversation, user demographics, and use of portable devices. In addition, we study how increasing load affects emailing behavior. We find that as users receive more email messages in a day, they reply to a smaller fraction of them, using shorter replies. However, their responsiveness remains intact, and they may even reply to emails faster. Finally, we predict the time to reply, length of reply, and whether the reply ends a conversation. We demonstrate considerable improvement over the baseline in all three prediction tasks, showing the significant role that the factors that we uncover play, in determining replying behavior. We rank these factors based on their predictive power. Our findings have important implications for understanding human behavior and designing better email management applications for tasks like ranking unread emails.},
booktitle = {Proceedings of the 24th International Conference on World Wide Web},
pages = {603–613},
numpages = {11},
keywords = {prediction, information overload, emailing behavior},
location = {Florence, Italy},
series = {WWW '15}
}

@proceedings{10.1145/3500868,
title = {CSCW'22 Companion: Companion Publication of the 2022 Conference on Computer Supported Cooperative Work and Social Computing},
year = {2022},
isbn = {9781450391900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Virtual Event, Taiwan}
}

@proceedings{10.1145/3643916,
title = {ICPC '24: Proceedings of the 32nd IEEE/ACM International Conference on Program Comprehension},
year = {2024},
isbn = {9798400705861},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {ICPC is the premier (CORE A) venue for research on program comprehension. Research on program comprehension encompasses both human activities for comprehending the software and technologies for supporting such comprehension.},
location = {Lisbon, Portugal}
}

@proceedings{10.1145/3607505,
title = {CSET '23: Proceedings of the 16th Cyber Security Experimentation and Test Workshop},
year = {2023},
isbn = {9798400707889},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Marina del Rey, CA, USA}
}

@inproceedings{10.1145/3173574.3174080,
author = {Karumur, Raghav Pavan and Yu, Bowen and Zhu, Haiyi and Konstan, Joseph A.},
title = {Content is King, Leadership Lags: Effects of Prior Experience on Newcomer Retention and Productivity in Online Production Groups},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174080},
doi = {10.1145/3173574.3174080},
abstract = {Organizers of online groups often struggle to recruit members who can most effectively carry out the group's activities and remain part of the group over time. In a study of a sample of 30,000 new editors belonging to 1,054 English WikiProjects, we empirically examine the effects of generalized prior work-productivity experience (measured by overall prior article edits), prior leadership experience (measured by overall prior project edits), and localized prior work-productivity experience (measured by pre-joining article edits on a project) on early retention and productivity. We find that (1)generalized prior work-productivity experience is positively associated with retention, but negatively associated with productivity (2) prior leadership experience is negatively associated with both retention and productivity, and (3) localized prior work-productivity experience is positively associated with both retention and productivity within that focal project. We then discuss implications to inform the designs of early interventions aimed at group success.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {withdrawal, wikiprojects, wikipedia, subgroups, retention, resocialization, productivity, prior experience, peer production, online groups, online communities, newcomers, learning transfer},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@proceedings{10.1145/3580507,
title = {EC '23: Proceedings of the 24th ACM Conference on Economics and Computation},
year = {2023},
isbn = {9798400701047},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Over the course of two decades, EC has established itself as one of the few truly successful interdisciplinary conferences, attracting papers and participants with a broad range of interests in economics and computer science, and fostering work in the intersection.},
location = {London, United Kingdom}
}

@inproceedings{10.1145/3545948.3545971,
author = {Jang, Daehee and Askar, Ammar and Yun, Insu and Tong, Stephen and Cai, Yiqin and Kim, Taesoo},
title = {Fuzzing@Home: Distributed Fuzzing on Untrusted Heterogeneous Clients},
year = {2022},
isbn = {9781450397049},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3545948.3545971},
doi = {10.1145/3545948.3545971},
abstract = {Fuzzing is a practical technique to automatically find vulnerabilities in software. It is well-suited to running at scale with distributed computing platforms thanks to its parallelizability. Therefore, individual researchers and companies typically setup fuzzing platforms on multiple servers and run fuzzers in parallel. However, as such resources are private, they suffer from financial and physical limits. In this paper, we propose Fuzzing@Home; the first public collaborative fuzzing network, based on heterogeneous machines owned by potentially untrusted users. Using our system, multiple organizations (or individuals) can easily collaborate to fuzz a software of common interest in an efficient way. One can participate and earn economic benefits if the fuzzing network is tied to a bug-bounty program, or simply donate spare computing power as a volunteer. If the network compensates collaborators, system fairness becomes an issue. In this light, we devise a system to make the fuzzing results verifiable and devise cheat detection techniques to ensure integrity and fairness in collaboration. In terms of performance, we devise a technique to effectively sync the global coverage state, hence minimizing the overhead for verifying computation results. Finally, to increase participation, Fuzzing@Home uses WebAssembly to run fuzzers inside the web browser engine, allowing anyone to instantly join a fuzzing network with a single click on their mobile phone, tablet, or any modern computing device. To evaluate our system, we bootstrapped Fuzzing@Home with 72 open-source projects and ran experimental fuzzing networks for 330 days with 826 collaborators as beta testers.},
booktitle = {Proceedings of the 25th International Symposium on Research in Attacks, Intrusions and Defenses},
pages = {1–16},
numpages = {16},
location = {Limassol, Cyprus},
series = {RAID '22}
}

@proceedings{10.1145/3600160,
title = {ARES '23: Proceedings of the 18th International Conference on Availability, Reliability and Security},
year = {2023},
isbn = {9798400707728},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Benevento, Italy}
}

@proceedings{10.5555/3590145,
title = {ASONAM '22: Proceedings of the 2022 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining},
year = {2022},
isbn = {9781665456616},
publisher = {IEEE Press},
abstract = {We were delighted to welcome each participant at ASONAM 2022 and thank you for having contributed virtually or in person in Istanbul. ASONAM 2022 was the fourteenth annual conference in the successful ASONAM conferences series and also the first hybrid version of the conference. Previous ASONAM conferences were held in Athens (2009), Odense (2010), Kaohsiung (2011), Istanbul (2012), Niagara Falls (2013), Beijing (2014), Paris (2015), San Francisco (2016), Sydney (2017), Barcelona (2018), Vancouver (2019), Virtual (2020), Virtual (2021). The pre-pandemic locations of the conferences have enabled the participants to enjoy local sights and to engage in person-to-person interactions, making new contacts and form new scientific collaborations. These possibilities were only available in a limited form during the virtual conferences. As the covid pandemic seems to be moving towards an endemic form it was decided to have the conference in the hybrid form, as a move towards normal endemic in-person conferences.For more than a century, social networks have been studied in a variety of disciplines including sociology, anthropology, psychology, and economics. The Internet, the social Web, and other large-scale, sociotechnological infrastructures have triggered a growing interest and resulted in significant methodological advancements in social network analysis and mining. Method development in graph theory, statistics, data mining, machine learning, and AI have inspired new research problems and, in turn, opens up further possibilities for application. These spiraling trends have led to a rising prominence of social network analysis and mining methods and tools in academia, politics, security, and business.},
location = {Istanbul, Turkey}
}

@inproceedings{10.1145/2858036.2858564,
author = {Bennett, Cynthia L. and Cen, Keting and Steele, Katherine M. and Rosner, Daniela K.},
title = {An Intimate Laboratory? Prostheses as a Tool for Experimenting with Identity and Normalcy},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858564},
doi = {10.1145/2858036.2858564},
abstract = {This paper is about the aspects of ability, selfhood, and normalcy embodied in people's relationships with prostheses. Drawing on interviews with 14 individuals with upper-limb loss and diverse experiences with prostheses, we find people not only choose to use and not use prosthesis throughout their lives but also form close and complex relationships with them. The design of "assistive" technology often focuses on enhancing function; however, we found that prostheses played important roles in people's development of identity and sense of normalcy. Even when a prosthesis failed functionally, such as was the case with 3D-printed prostheses created by an on-line open-source maker community (e-NABLE), we found people still praised the design and initiative because of the positive impacts on popular culture, identity, and community building. This work surfaces crucial questions about the role of design interventions in identity production, the promise of maker communities for accelerating innovation, and a broader definition of "assistive" technology.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {1745–1756},
numpages = {12},
keywords = {prostheses, normalcy, identity, design interventions, assistive technology, ability},
location = {San Jose, California, USA},
series = {CHI '16}
}

@article{10.1145/2785733,
author = {Meng, Guozhu and Liu, Yang and Zhang, Jie and Pokluda, Alexander and Boutaba, Raouf},
title = {Collaborative Security: A Survey and Taxonomy},
year = {2015},
issue_date = {September 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/2785733},
doi = {10.1145/2785733},
abstract = {Security is oftentimes centrally managed. An alternative trend of using collaboration in order to improve security has gained momentum over the past few years. Collaborative security is an abstract concept that applies to a wide variety of systems and has been used to solve security issues inherent in distributed environments. Thus far, collaboration has been used in many domains such as intrusion detection, spam filtering, botnet resistance, and vulnerability detection. In this survey, we focus on different mechanisms of collaboration and defense in collaborative security. We systematically investigate numerous use cases of collaborative security by covering six types of security systems. Aspects of these systems are thoroughly studied, including their technologies, standards, frameworks, strengths and weaknesses. We then present a comprehensive study with respect to their analysis target, timeliness of analysis, architecture, network infrastructure, initiative, shared information and interoperability. We highlight five important topics in collaborative security, and identify challenges and possible directions for future research. Our work contributes the following to the existing research on collaborative security with the goal of helping to make collaborative security systems more resilient and efficient. This study (1) clarifies the scope of collaborative security, (2) identifies the essential components of collaborative security, (3) analyzes the multiple mechanisms of collaborative security, and (4) identifies challenges in the design of collaborative security.},
journal = {ACM Comput. Surv.},
month = {jul},
articleno = {1},
numpages = {42},
keywords = {trust, taxonomy, spam, privacy, malware, intrusion detection, information sharing, Collaborative security}
}

@proceedings{10.1145/3560107,
title = {ICEGOV '22: Proceedings of the 15th International Conference on Theory and Practice of Electronic Governance},
year = {2022},
isbn = {9781450396356},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Guimar\~{a}es, Portugal}
}

@proceedings{10.1145/3308558,
title = {WWW '19: The World Wide Web Conference},
year = {2019},
isbn = {9781450366748},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to The Web Conference 2019. The Web Conference is the premier venue focused on understanding the current state and the evolution of the Web through the lens of computer science, computational social science, economics, policy, and many other disciplines. The 2019 edition of the conference is a reflection point as we celebrate the 30th anniversary of the Web.},
location = {San Francisco, CA, USA}
}

@proceedings{10.1145/3411764,
title = {CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Yokohama, Japan}
}

@proceedings{10.1145/2998181,
title = {CSCW '17: Proceedings of the 2017 ACM Conference on Computer Supported Cooperative Work and Social Computing},
year = {2017},
isbn = {9781450343350},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to CSCW 2017, the ACM 2017 Conference on Computer Supported Cooperative Work and Social Computing! We are excited to welcome the CSCW community back to Portland, Oregon, where the second CSCW conference was held in 1988. Both Portland and CSCW have matured a great deal during the intervening 29 years. We hope that you will find that Portland provides a stimulating environment for our conference.CSCW is the premier venue for presenting research in the design and use of technologies that affect groups, organizations, communities, and networks. Bringing together top researchers and practitioners from academia and industry, CSCW explores the technical, social, material, and theoretical challenges of designing technology to support collaborative work and life activities. CSCW welcomes a diverse range of topics and research methodologies. Studies often involve the development and application of novel technologies and/or ethnographic studies that inform design practice or theory. The mission of the conference is to share research that advances the state of human knowledge and improves both the design of systems and the ways they are used. The diversity of work in our conference program reflects the diversity of technology use in people's work, social, and civic lives as well as the geographic and cultural diversity of contributors.As many of you know, CSCW follows a rigorous "revise and resubmit" review process that uses peer review to improve submitted papers while maintaining a high-quality threshold for final acceptance. We also help prepare the next generation of reviewers with a mentorship program in which students review papers under the guidance of an experienced reviewer. This year we have the largest CSCW program ever. We had 530 submitted papers and 183 were accepted for presentation at the conference. The program also includes 4 papers published in ACM Transactions on Human- Computer Interaction (TOCHI). In addition, we will feature 14 workshops, 56 posters, 12 demos, and 3 panels.Lili Cheng of Microsoft Research will open the conference, speaking on "Conversational AI &amp; Lessons Learned." Our closing plenary will feature Jorge Cham, the creator of PhD Comics, who will talk about, "The Science Gap." We also welcome Paul Luff and Christian Heath from King's College as the recipients of this year's CSCW Lasting Impact award for their influential 1998 paper, "Mobility in Collaboration."},
location = {Portland, Oregon, USA}
}

@proceedings{10.1145/3626252,
title = {SIGCSE 2024: Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 55th annual SIGCSE Technical Symposium on Computer Science Education (SIGCSE TS 2024)! This year, we have returned to Portland, Oregon. We hope that, like us, you are looking forward to a highly productive and engaging symposium that provides ample opportunity to renew old relationships, build new connections, and learn about the latest advances in our field. While we are sure that there will be a few surprises along the way, we hope and expect that we won't experience anything nearly as disruptive as the opening days of the pandemic, which occurred when we last tried to gather here in 2020.Our theme for this year's symposium is "Blazing New Trails in CS Education." This broad theme captures the exceptional work being performed by this community to enhance our teaching, improve our assessments, attract diverse students, and all of the other laudable projects, initiatives, and undertakings that affect positive change. The breadth of the program is substantial - there truly should be something for everyone. In fact, your biggest challenge may be deciding which session to attend in each time slot because there is so much going on! We know that many of you want to attend as many sessions as possible while you are here in Portland, but we encourage you to also find a little bit of time for yourself so that you leave Portland refreshed, renewed and encouraged, rather than exhausted or burnt out.},
location = {Portland, OR, USA}
}

@proceedings{10.1145/2970276,
title = {ASE '16: Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering},
year = {2016},
isbn = {9781450338455},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Singapore, Singapore}
}

@proceedings{10.1145/3627050,
title = {IoT '23: Proceedings of the 13th International Conference on the Internet of Things},
year = {2023},
isbn = {9798400708541},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Nagoya, Japan}
}

@proceedings{10.1145/2785585,
title = {SIGGRAPH '15: SIGGRAPH 2015: Studio},
year = {2015},
isbn = {9781450336376},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {The world is becoming more malleable by the day, with new tools, applications, and methods to create, craft, build, and share. At SIGGRAPH 2015, the Studio focuses on disruptive practices in the world of content creation. Along with a renewed emphasis on technology, it presents projects from alternative fields that utilize and build new foundations in computer graphics - particularly those that extend beyond traditional screens and into the physical world - including themed entertainment, location-based installations, projection mapping, and advancements in augmented and virtual reality.},
location = {Los Angeles, California}
}

@proceedings{10.1145/3626562,
title = {Middleware '23: Proceedings of the 24th International Middleware Conference: Industrial Track},
year = {2023},
isbn = {9798400704277},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Bologna, Italy}
}

@proceedings{10.1145/3603163,
title = {HT '23: Proceedings of the 34th ACM Conference on Hypertext and Social Media},
year = {2023},
isbn = {9798400702327},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Rome, Italy}
}

@proceedings{10.1145/3544548,
title = {CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Hamburg, Germany}
}

@proceedings{10.1145/3613904,
title = {CHI '24: Proceedings of the CHI Conference on Human Factors in Computing Systems},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Honolulu, HI, USA}
}

@proceedings{10.1145/3559712,
title = {SBCARS '22: Proceedings of the 16th Brazilian Symposium on Software Components, Architectures, and Reuse},
year = {2022},
isbn = {9781450397452},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Uberlandia, Brazil}
}

@proceedings{10.1145/3639856,
title = {AIMLSystems '23: Proceedings of the Third International Conference on AI-ML Systems},
year = {2023},
isbn = {9798400716492},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Bangalore, India}
}

@proceedings{10.1145/3630106,
title = {FAccT '24: Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency},
year = {2024},
isbn = {9798400704505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Rio de Janeiro, Brazil}
}

@proceedings{10.1145/3643833,
title = {WiSec '24: Proceedings of the 17th ACM Conference on Security and Privacy in Wireless and Mobile Networks},
year = {2024},
isbn = {9798400705823},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 2024 ACM Conference on Security and Privacy in Wireless and Mobile Networks (ACM WiSec)!Now in its 17th year, WiSec continues to be the premier venue for research on all aspects of security and privacy in wireless and mobile networks, their systems, and their applications. We are hosted by the Korea Institute of Information Security &amp; Cryptology, located in the city center of Seoul, Korea - a city known for its dynamic mix of 600-year-old palaces and the contemporary urban landscape characterized by towering skyscrapers.We begin our exciting three-day main conference program on May 27th with single-track technical paper sessions, a poster and demo session, two excellent keynotes from telecommunication security expert Prof. Jean-Pierre Seifert (TU Berlin) and wireless security expert Mathy Vanhoef (KU Leuven), and a panel on wireless security and AI. Three invited talks named "Vision Talk" discuss the future of wireless and mobile security issues. The WiseML Workshop follows the main program on May 30th. We invite participants to attend the exciting paper presentations and keynotes, interact with the presenters during the Q&amp;A sessions after each talk, network during the coffee breaks and lunches each day, and socialize during the banquet dinner.},
location = {Seoul, Republic of Korea}
}

@proceedings{10.1145/3581754,
title = {IUI '23 Companion: Companion Proceedings of the 28th International Conference on Intelligent User Interfaces},
year = {2023},
isbn = {9798400701078},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Sydney, NSW, Australia}
}

@proceedings{10.1145/3636501,
title = {CPP 2024: Proceedings of the 13th ACM SIGPLAN International Conference on Certified Programs and Proofs},
year = {2024},
isbn = {9798400704888},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 13th ACM SIGPLAN International Conference on Certified 
Programs and Proofs (CPP 2024). CPP covers the practical and 
theoretical topics in all areas that consider formal verification and 
certification as an essential paradigm for their work. CPP spans 
topics in computer science, mathematics, logic, and education. CPP 
2024 will be held on 15-16 January 2024 in London, UK. The conference is co-located with POPL 2024, and is sponsored by ACM SIGPLAN in cooperation with ACM SIGLOG.},
location = {London, UK}
}

@article{10.1145/3491039,
author = {Calefato, Fabio and Lanubile, Filippo},
title = {Using Personality Detection Tools for Software Engineering Research: How Far Can We Go?},
year = {2022},
issue_date = {July 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {3},
issn = {1049-331X},
url = {https://doi.org/10.1145/3491039},
doi = {10.1145/3491039},
abstract = {Assessing the personality of software engineers may help to match individual traits with the characteristics of development activities such as code review and testing, as well as support managers in team composition. However, self-assessment questionnaires are not a practical solution for collecting multiple observations on a large scale. Instead, automatic personality detection, while overcoming these limitations, is based on off-the-shelf solutions trained on non-technical corpora, which might not be readily applicable to technical domains like software engineering. In this article, we first assess the performance of general-purpose personality detection tools when applied to a technical corpus of developers’ e-mails retrieved from the public archives of the Apache Software Foundation. We observe a general low accuracy of predictions and an overall disagreement among the tools. Second, we replicate two previous research studies in software engineering by replacing the personality detection tool used to infer developers’ personalities from pull-request discussions and e-mails. We observe that the original results are not confirmed, i.e., changing the tool used in the original study leads to diverging conclusions. Our results suggest a need for personality detection tools specially targeted for the software engineering domain.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = {apr},
articleno = {42},
numpages = {48},
keywords = {IBM personality insights, LIWC, negative results, replication, Five-Factor Model, Big Five, automatic personality recognition, Computational personality detection}
}

@proceedings{10.1145/3549015,
title = {EuroUSEC '22: Proceedings of the 2022 European Symposium on Usable Security},
year = {2022},
isbn = {9781450397001},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Karlsruhe, Germany}
}

@proceedings{10.1145/3617184,
title = {ICCSIE '23: Proceedings of the 8th International Conference on Cyber Security and Information Engineering},
year = {2023},
isbn = {9798400708800},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Putrajaya, Malaysia}
}

@inproceedings{10.1145/3245651,
author = {LaViola, Joseph},
title = {Session details: An introduction to sketch-based interfaces},
year = {2006},
isbn = {1595933646},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3245651},
doi = {10.1145/3245651},
booktitle = {ACM SIGGRAPH 2006 Courses},
location = {Boston, Massachusetts},
series = {SIGGRAPH '06}
}

@proceedings{10.1145/3571473,
title = {SBQS '22: Proceedings of the XXI Brazilian Symposium on Software Quality},
year = {2022},
isbn = {9781450399999},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Curitiba, Brazil}
}

@proceedings{10.1145/3578357,
title = {EUROSEC '23: Proceedings of the 16th European Workshop on System Security},
year = {2023},
isbn = {9798400700859},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Rome, Italy}
}

@proceedings{10.1145/3555776,
title = {SAC '23: Proceedings of the 38th ACM/SIGAPP Symposium on Applied Computing},
year = {2023},
isbn = {9781450395175},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Tallinn, Estonia}
}

@proceedings{10.1145/3564625,
title = {ACSAC '22: Proceedings of the 38th Annual Computer Security Applications Conference},
year = {2022},
isbn = {9781450397599},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Austin, TX, USA}
}

@proceedings{10.1145/3579856,
title = {ASIA CCS '23: Proceedings of the 2023 ACM Asia Conference on Computer and Communications Security},
year = {2023},
isbn = {9798400700989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Melbourne, VIC, Australia}
}

@proceedings{10.5555/3643142,
title = {WSC '23: Proceedings of the Winter Simulation Conference},
year = {2023},
isbn = {9798350369663},
publisher = {IEEE Press},
location = {San Antonio, Texas, USA}
}

@proceedings{10.1145/3563768,
title = {SPLASH Companion 2022: Companion Proceedings of the 2022 ACM SIGPLAN International Conference on Systems, Programming, Languages, and Applications: Software for Humanity},
year = {2022},
isbn = {9781450399012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the SPLASH 2022! After two years of virtual only (SPLASH 2020), closed borders USA only (SPLASH 2021), we finally feel the reopening and going back to the pre-Covid in person vibe of the 37th OOPSLA/SPLASH. I am especially proud of having SPLASH outside of the USA/Canada region for the 3rd time in its history and the first time it is held in the Asia Pacific. We invited the Asian Symposium on Programming Languages and Systems (APLAS) to co-locate with us for the 3rd year in a row to celebrate this occasion.},
location = {Auckland, New Zealand}
}

@proceedings{10.1145/3637543,
title = {CF '24 Companion: Proceedings of the 21st ACM International Conference on Computing Frontiers: Workshops and Special Sessions},
year = {2024},
isbn = {9798400704925},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {This is the companion proceedings of the 21st ACM International Conference on Computing Frontiers (Volume 2) collecting the papers from co-located workshops and invited papers from special sessions. For papers from the main track, as well as keynote abstract and poster abstracts, see Volume 1.},
location = {Ischia, Italy}
}

@proceedings{10.1145/3607199,
title = {RAID '23: Proceedings of the 26th International Symposium on Research in Attacks, Intrusions and Defenses},
year = {2023},
isbn = {9798400707650},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Hong Kong, China}
}

@proceedings{10.1145/3548785,
title = {IDEAS '22: Proceedings of the 26th International Database Engineered Applications Symposium},
year = {2022},
isbn = {9781450397094},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Budapest, Hungary}
}

@proceedings{10.1145/3592813,
title = {SBSI '23: Proceedings of the XIX Brazilian Symposium on Information Systems},
year = {2023},
isbn = {9798400707599},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Macei\'{o}, Brazil}
}

@proceedings{10.1145/3615366,
title = {LADC '23: Proceedings of the 12th Latin-American Symposium on Dependable and Secure Computing},
year = {2023},
isbn = {9798400708442},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {La Paz, Bolivia}
}

@proceedings{10.1145/3277644,
title = {SA '18: SIGGRAPH Asia 2018 Courses},
year = {2018},
isbn = {9781450360265},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {At SIGGRAPH Asia 2018 hundreds of visitors will attend its courses to broaden and deepen their knowledge and to learn the secrets of new directions. The Crossover can also be offered via the presenters being from different backgrounds (e.g., computer science, art, animation, medicine, science and others), with each giving their unique perspective on the topic.},
location = {Tokyo, Japan}
}

@proceedings{10.1145/3568562,
title = {SoICT '22: Proceedings of the 11th International Symposium on Information and Communication Technology},
year = {2022},
isbn = {9781450397254},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Hanoi, Vietnam}
}

@proceedings{10.1145/2619195,
title = {SIGGRAPH '14: ACM SIGGRAPH 2014 Studio},
year = {2014},
isbn = {9781450329774},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Vancouver, Canada}
}

@proceedings{10.1109/3655039,
title = {ASPDAC '24: Proceedings of the 29th Asia and South Pacific Design Automation Conference},
year = {2024},
isbn = {9798350393545},
publisher = {IEEE Press},
abstract = {ASP-DAC is a high-quality and premium conference on Electronic Design Automation (EDA) area like other sister conferences such as Design Automation Conference (DAC), Design, Automation &amp; Test in Europe (DATE), International Conference on Computer-Aided Design (ICCAD), and Embedded Systems Week (ESWEEK). ASP-DAC started in 1995 and has continuously offered opportunity to know the recent advanced technologies on LSI design and design automation areas, and to communicate each other for researchers and designers around Asia and South Pacific regions.},
location = {Incheon, Republic of Korea}
}

@proceedings{10.1145/3586183,
title = {UIST '23: Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
year = {2023},
isbn = {9798400701320},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {San Francisco, CA, USA}
}

@proceedings{10.1145/3594806,
title = {PETRA '23: Proceedings of the 16th International Conference on PErvasive Technologies Related to Assistive Environments},
year = {2023},
isbn = {9798400700699},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Corfu, Greece}
}

@proceedings{10.1145/3590837,
title = {ICIMMI '22: Proceedings of the 4th International Conference on Information Management &amp; Machine Intelligence},
year = {2022},
isbn = {9781450399937},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Jaipur, India}
}

@proceedings{10.1145/3623652,
title = {HASP '23: Proceedings of the 12th International Workshop on Hardware and Architectural Support for Security and Privacy},
year = {2023},
isbn = {9798400716232},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Toronto, Canada}
}

@proceedings{10.5555/3581644,
title = {CNSM '22: Proceedings of the 18th International Conference on Network and Service Management},
year = {2022},
isbn = {9783903176515},
publisher = {International Federation for Information Processing},
address = {Laxenburg, AUT},
abstract = {CNSM 2022 focuses on the theme "Intelligent Management of Disruptive Network Technologies and Services", that aims at capturing emerging approaches and intelligent solutions for dealing with disruptive network technologies, as well as associated services and applications.},
location = {Thessaloniki, Greece}
}

@proceedings{10.1145/3558535,
title = {AFT '22: Proceedings of the 4th ACM Conference on Advances in Financial Technologies},
year = {2022},
isbn = {9781450398619},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Cambridge, MA, USA}
}

@proceedings{10.1145/3582437,
title = {FDG '23: Proceedings of the 18th International Conference on the Foundations of Digital Games},
year = {2023},
isbn = {9781450398558},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Lisbon, Portugal}
}

@proceedings{10.1145/3620666,
title = {ASPLOS '24: Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 3},
year = {2024},
isbn = {9798400703867},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
abstract = {Welcome to the third volume of ASPLOS'24: the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems. This document is mostly dedicated to the 2024 fall cycle but also provides some statistics summarizing all three cycles.We introduced several notable changes to ASPLOS this year, most of which were discussed in our previous messages from program chairs in Volume 1 and 2, including: (1) significantly increasing the program committee size to over 220 members (more than twice the size of last year); (2) foregoing synchronous program committee (PC) meetings and instead making all decisions online; (3) overhauling the review assignment process; (4) developing an automated submission format violation identifier script that uncovers, e.g., disallowed vertical space manipulations that "squeeze" space; (5) introducing the new ASPLOS role of Program Vice Chairs to cope with the increased number of submissions and the added load caused by foregoing synchronous program committee; and (6) characterizing a systematic problem that ASPLOS is facing in reviewing quantum computing submissions, describing how we addressed it and highlighting how we believe that it should be handled in the future.Assuming readers have read our previous messages, here, we will only describe differences between the current cycle and the previous ones. These include: (1) Finally unifying submission and acceptance paper formatting instructions (forgoing the `jpaper' class) to rid authors of accepted papers from the need to reformat; (2) Describing the methodology we employed to select best papers, which we believe ensures quality and hope will persist; and (3) Reporting the ethical incidents we encountered and how we handled them. In the final, fourth volume, when the outcome of the ASPLOS'24 fall major revisions will become known, we plan to conduct a broader analysis of all the data we have gathered throughout the year.Following are some key statistics of the fall cycle: 340 submissions were finalized (43% more than last year's fall count and 17% less than our summer cycle) of which 111 are related to accelerators/FPGAs/GPUs, 105 to machine learning, 54 to security, 50 to datacenter/cloud and 50 to storage/memory; 183 (54%) submissions were promoted to the second review round; 39 (11.5%) papers were accepted (of which 19 were awarded artifact evaluation badges); 33 (9.7%) submissions were allowed to submit major revisions and are currently under review (these will be addressed in the fourth volume of ASPLOS'24 and will be presented in ASPLOS'25 if accepted); 1,368 reviews were uploaded; and 4,949 comments were generated during online discussions, of which 4,070 were dedicated to the submissions that made it to the second review round.This year, in the submission form, we asked authors to specify which of the three ASPLOS research areas are related to their submitted work. Analyzing this data revealed that 80%, 39%, and 29% of the submissions are categorized by their authors as related to architecture, operating systems, and programming languages, respectively, generating the highest difference we have observed across the cycles between architecture and the other two. About 46% of the fall submissions are "interdisciplinary," namely, were associated with two or more of the three areas.Overall, throughout all the ASPLOS'24 cycles, we received 922 submissions, constituting a 1.54x increase compared to last year. Our reviewers submitted a total of 3,634 reviews containing more than 2.6 million words, and we also generated 12,655 online comments consisting of nearly 1.2 million words. As planned, PC members submitted an average of 15.7 reviews and a median of 15, and external review committee (ERC) members submitted an average of 4.7 and a median of 5.We accepted 170 papers thus far, written by 1100 authors, leading to an 18.4% acceptance rate, with the aforementioned 33 major revisions still under review. Assuming that the revision acceptance rate will be similar to that of previous cycles, we estimate that ASPLOS'24 will accept nearly 200 (!) papers, namely, 21%–22% of the submissions.The ASPLOS'24 program consists of 193 papers: the 170 papers we accepted thus far and, in addition, 23 major revisions from the fall cycle of ASPLOS'23, which were re-reviewed and accepted. The full details are available in the PDF of the front matter.},
location = {La Jolla, CA, USA}
}

@proceedings{10.1145/3528535,
title = {Middleware '22: Proceedings of the 23rd ACM/IFIP International Middleware Conference},
year = {2022},
isbn = {9781450393409},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Quebec, QC, Canada}
}

@proceedings{10.1145/3600006,
title = {SOSP '23: Proceedings of the 29th Symposium on Operating Systems Principles},
year = {2023},
isbn = {9798400702297},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the Proceedings of the 29th ACM Symposium on Operating Systems Principles (SOSP 2023). This year's program includes 43 papers that reflect today's broad range of topics that comprise modern computer systems research. The program committee carefully reviewed submitted papers and worked closely with the authors of selected papers to produce the collection of high-quality, readable papers presented here. We hope that you enjoy the program!},
location = {Koblenz, Germany}
}

@proceedings{10.1145/3620665,
title = {ASPLOS '24: Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2},
year = {2024},
isbn = {9798400703850},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
abstract = {Welcome to the second volume of ASPLOS'24: the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems. This document is dedicated to the 2024 summer review cycle.We introduced several notable changes to ASPLOS this year, many of which were discussed in the previous message from program chairs in Volume 1. Here, to avoid repetition, we assume that readers have already read the latter message and will only describe differences between the current cycle and the previous one. These include: (1) developing and utilizing an automated format violation identifier script focused on uncovering disallowed vertical space manipulations that "squeeze" space; (2) incorporating authors-declared best-matching topics into our review assignment process; (3) introducing the new ASPLOS role of Program Vice Chairs to cope with the increased number of submissions and the added load caused by foregoing synchronous program committee (PC) meetings, which necessitated additional managerial involvement in online dissensions; and (4) characterizing a systematic problem that ASPLOS is facing in reviewing quantum computing submissions, describing how we addressed it, and highlighting how we believe that it should be handled in the future.Key statistics of the ASPLOS'24 summer cycle include: 409 submissions were finalized (about 1.5x more than last year's summer count and nearly 2.4x more than our spring cycle), with 107 related to accelerators/FPGAs/GPUs, 97 to machine learning, 88 to storage/memory, 80 to security, and 69 to datacenter/cloud; 179 (44%) submissions were promoted to the second review round; 54 (13.2%) papers were accepted (with 20 awarded one or more artifact evaluation badges); 33 (8.1%) submissions were allowed to submit major revisions, of which 27 were subsequently accepted during the fall cycle (with 13 awarded one or more artifact evaluation badges); 1,499 reviews were uploaded; and 5,557 comments were generated during online discussions.Analyzing the per-submission most-related broader areas of research, which we asked authors to associate with their work in the submission form, revealed that 71%, 47%, and 28% of the submissions are categorized by their authors as related to architecture, operating systems, and programming languages, respectively, with about 45% being "interdisciplinary" submissions (associated with more than one area). The full details are available in the PDF of the front matter.},
location = {La Jolla, CA, USA}
}

@proceedings{10.1145/3624062,
title = {SC-W '23: Proceedings of the SC '23 Workshops of The International Conference on High Performance Computing, Network, Storage, and Analysis},
year = {2023},
isbn = {9798400707858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Denver, CO, USA}
}

@proceedings{10.1145/3579371,
title = {ISCA '23: Proceedings of the 50th Annual International Symposium on Computer Architecture},
year = {2023},
isbn = {9798400700958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Orlando, FL, USA}
}

@proceedings{10.1145/3656156,
title = {DIS '24 Companion: Companion Publication of the 2024 ACM Designing Interactive Systems Conference},
year = {2024},
isbn = {9798400706325},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {IT University of Copenhagen, Denmark}
}

@proceedings{10.1145/3647722,
title = {ICSIM '24: Proceedings of the 2024 7th International Conference on Software Engineering and Information Management},
year = {2024},
isbn = {9798400709197},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Suva, Fiji}
}

@proceedings{10.1145/3650105,
title = {FORGE '24: Proceedings of the 2024 IEEE/ACM First International Conference on AI Foundation Models and Software Engineering},
year = {2024},
isbn = {9798400706097},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {FORGE aims to bring researchers, practitioners, and educators from the AI and Software Engineering community to solve the new challenges we meet in the era of foundation models.},
location = {Lisbon, Portugal}
}

@proceedings{10.1145/3573428,
title = {EITCE '22: Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering},
year = {2022},
isbn = {9781450397148},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Xiamen, China}
}

@proceedings{10.1145/3545948,
title = {RAID '22: Proceedings of the 25th International Symposium on Research in Attacks, Intrusions and Defenses},
year = {2022},
isbn = {9781450397049},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Limassol, Cyprus}
}

@proceedings{10.1145/3626232,
title = {CODASPY '24: Proceedings of the Fourteenth ACM Conference on Data and Application Security and Privacy},
year = {2024},
isbn = {9798400704215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to the fourteenth edition of the ACM Conference on Data and Application Security and Privacy (CODASPY 2024), for the first time held outside United States of America. This conference series has been founded to foster novel and exciting research in the data and application security and privacy arena and to help generate new directions for further research and development. The initial concept was established by the two co-founders, Elisa Bertino and Ravi Sandhu, and sharpened by subsequent discussions with several fellow data security and privacy researchers. Their enthusiastic encouragement persuaded the co-founders to move ahead with the always daunting task of creating a high-quality conference. CODASPY has become a leading forum for presentation of research results and experience reports on hardware and software security. The conference gives researchers and practitioners a unique opportunity to share their perspectives with others interested in the various aspects of data and applications security and privacy.},
location = {Porto, Portugal}
}

@proceedings{10.1145/3661167,
title = {EASE '24: Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering},
year = {2024},
isbn = {9798400717017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Salerno, Italy}
}

@proceedings{10.1145/3542929,
title = {SoCC '22: Proceedings of the 13th Symposium on Cloud Computing},
year = {2022},
isbn = {9781450394147},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {SoCC 2022 is the thirteenth annual ACMSymposium on Cloud Computing, the premier conference on cloud computing. It brings together researchers, software developers, end-users, and practitioners interested in wide-ranging aspects of cloud computing, and it is the only conference co-sponsored by the ACM Special Interest Groups on Management of Data (SIGMOD) and on Operating Systems (SIGOPS).},
location = {San Francisco, California}
}

@proceedings{10.1145/3588015,
title = {ETRA '23: Proceedings of the 2023 Symposium on Eye Tracking Research and Applications},
year = {2023},
isbn = {9798400701504},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Tubingen, Germany}
}

@proceedings{10.1145/3593663,
title = {ECSEE '23: Proceedings of the 5th European Conference on Software Engineering Education},
year = {2023},
isbn = {9781450399562},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Seeon/Bavaria, Germany}
}

@book{10.1145/280811,
editor = {Wolfe, Rosalee},
title = {Seminal graphics: pioneering efforts that shaped the field, Volume 1},
year = {1998},
isbn = {158113052X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {Volume 1}
}

@proceedings{10.1145/2988458,
title = {SA '16: SIGGRAPH ASIA 2016 Courses},
year = {2016},
isbn = {9781450345385},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {The SIGGRAPH Asia Courses program will feature a variety of instructional sessions catered to the different levels of expertise of our attendees. Sessions from introductory to advanced topics in computer graphics and interactive techniques will be conducted by speakers from renowned organizations and academic research institutions from over the world.The program has been the premier source for practitioners, developers, researchers, artists, and students who want to learn about the state-of-the-art technologies in computer graphics and their related topics.},
location = {Macau}
}

@proceedings{10.1145/3543174,
title = {AutomotiveUI '22: Proceedings of the 14th International Conference on Automotive User Interfaces and Interactive Vehicular Applications},
year = {2022},
isbn = {9781450394154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Seoul, Republic of Korea}
}

@proceedings{10.1145/3606094,
title = {ICDEL '23: Proceedings of the 2023 8th International Conference on Distance Education and Learning},
year = {2023},
isbn = {9798400700422},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Beijing, China}
}

@proceedings{10.1145/3603781,
title = {CNIOT '23: Proceedings of the 2023 4th International Conference on Computing, Networks and Internet of Things},
year = {2023},
isbn = {9798400700705},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Xiamen, China}
}

@proceedings{10.1145/3579990,
title = {CGO 2023: Proceedings of the 21st ACM/IEEE International Symposium on Code Generation and Optimization},
year = {2023},
isbn = {9798400701016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 21st ACM/IEEE International Symposium on Code Generation and Optimization (CGO ’23), and to Montreal. After two years of virtual CGO, we are finally back in person! 

CGO provides a premier venue to bring together researchers and practitioners working at the interface of hardware and software on a wide range of optimization and code generation techniques and related issues. The conference spans the spectrum from purely static to fully dynamic approaches, and from pure software-based methods to specific architectural features and support for code generation and optimization.},
location = {Montr\'{e}al, QC, Canada}
}

@proceedings{10.1145/3590140,
title = {Middleware '23: Proceedings of the 24th International Middleware Conference},
year = {2023},
isbn = {9798400701771},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Bologna, Italy}
}

@proceedings{10.1145/3569009,
title = {TEI '23: Proceedings of the Seventeenth International Conference on Tangible, Embedded, and Embodied Interaction},
year = {2023},
isbn = {9781450399777},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Warsaw, Poland}
}

@proceedings{10.1145/3613424,
title = {MICRO '23: Proceedings of the 56th Annual IEEE/ACM International Symposium on Microarchitecture},
year = {2023},
isbn = {9798400703294},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Toronto, ON, Canada}
}

@proceedings{10.1145/3544793,
title = {UbiComp/ISWC '22 Adjunct: Adjunct Proceedings of the 2022 ACM International Joint Conference on Pervasive and Ubiquitous Computing and the 2022 ACM International Symposium on Wearable Computers},
year = {2022},
isbn = {9781450394239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Cambridge, United Kingdom}
}

@proceedings{10.1145/3653081,
title = {IoTAAI '23: Proceedings of the 2023 5th International Conference on Internet of Things, Automation and Artificial Intelligence},
year = {2023},
isbn = {9798400716485},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Nanchang, China}
}

@proceedings{10.1145/3643832,
title = {MOBISYS '24: Proceedings of the 22nd Annual International Conference on Mobile Systems, Applications and Services},
year = {2024},
isbn = {9798400705816},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Minato-ku, Tokyo, Japan}
}

@proceedings{10.1145/3650215,
title = {ICMLCA '23: Proceedings of the 2023 4th International Conference on Machine Learning and Computer Application},
year = {2023},
isbn = {9798400709449},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Hangzhou, China}
}

@proceedings{10.1145/3650400,
title = {EITCE '23: Proceedings of the 2023 7th International Conference on Electronic Information Technology and Computer Engineering},
year = {2023},
isbn = {9798400708305},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Xiamen, China}
}

