series,keywords,pages,booktitle,abstract,doi,url,address,publisher,isbn,year,title,author,ENTRYTYPE,ID,journal,number,volume,issn,note,editor,edition
International Review of Cytology,,243-372,Mechanical Engineering of the Cytoskeleton in Developmental Biology,"An examination of the artificial diatoms shows that purely chemical and physical considerations will account for the varieties of pattern we notice in natural diatoms, and their living structure appears only to provide the conditions under which the silicious precipitation takes place, according to the ordinary laws of chemical action and molecular coalescence [I have tried] to make the subject more intelligible to that, I fear, very numerous class of microscopists who have not paid to Schultze's (1863a,b) artificial diatoms the attention they deserve. (Slack, 1870) The external form of crystals is prismatic, and bounded by straight surfaces which cut each other at certain angles. But the same form is seen in the skeletons of many of the protists, especially the flinty shells of the diatomes and radiolaria; their silicious coverings lend themselves to mathematical determination just as well as the inorganic crystals. (Haeckel, 1905)",https://doi.org/10.1016/S0074-7696(08)61544-2,https://www.sciencedirect.com/science/article/pii/S0074769608615442,,Academic Press,,1994,"The Chemical Basis of Diatom Morphogenesis††Dedicated to the memory of Judith Georgia Colburn, botanist, and her love for plants.",Richard Gordon and Ryan W. Drum,incollection,GORDON1994243,,,150,0074-7696,,Richard Gordon,
,"photosynthesis, plant metabolism, phosphoglucomutase, starch, sucrose",47-56,,"Photosynthetic intermediate levels were measured in barley leaves (Hordeum vulgare L.) as a function of light, carbon dioxide concentration and leaf excision. The results were related to changes in starch, and hexose metabolism. Glucose 6-phosphate (Glc 6-P) and fructose 6-phosphate (Fru6-P) pools in barley primary leaves decreased when net photosynthesis was eliminated after a light-to-dark transition or when leaves were exposed to CO2-free air. However, the glucose 1-phosphate (Glc1-P) concentration remained constant during transitions in leaf metabolism. Glucose 1,6-biphosphate (Glc1,6-P2) levels were about 1 and 3 nmol (mg chlorophyll)−1 in dark and light barley leaves, respectively. This finding suggests that Glc1,6-P2 in plants functions primarily in gluconeogenic metabolic pathways. Changes of Glc1,6-P2 level were slower than the rapid adjustments observed in fructose 2,6-bisphosphate (Fru2,6-P2) during shifts in metabolism, indicating that the former compound is unlikely to be a signal metabolite in plants. Hexose-bisphosphate and hexose-phosphate levels, other than Glc1-P, decreased in 72-h old barley roots after seedlings were exposed to anoxia for 24-h. Changes in Glc1,6-P2 levels in barley leaves and roots were proportional to alterations in the hexose-phosphate pool, except during the 60–90-min transition period following an abrupt shift in metabolism. Metabolite ratios indicated that phosphoglucose isomerase was slightly displaced from equilibrium in illuminated barley leaves but was near equilibrium in darkened leaves and roots. Glc1-P to Glc1-P ratios were about 6 and 2 in light and dark barley primary leaves, respectively, indicating that phosphoglucomutase was closer to equilibrium in the light than in the dark.",https://doi.org/10.1016/0168-9452(90)90049-T,https://www.sciencedirect.com/science/article/pii/016894529090049T,,,,1990,"Hexose and hexose-phosphate metabolism in barley leaves and roots. Role of glucose 1,6-biphosphate",R.C. Sicher and D.F. Kremer,article,SICHER199047,Plant Science,1,67,0168-9452,,,
,,136-142,,Primary cell cultures from mammary glands of virgin mice that were not pretreated with hormones were subjected to: (1) procaine; (2) insulin+ prolactin +hydrocortisone; (3) a combination of (1) and (2). Procaine caused a ‘ridge’ effect similar to that of the hormones. The combination of procaine with the hormones caused a still stronger ‘ridge’ effect as well as the formation of ‘domes’. The formation of ‘domes’ is suggested to be dependent on cell density.,https://doi.org/10.1016/0014-4827(76)90472-9,https://www.sciencedirect.com/science/article/pii/0014482776904729,,,,1976,Effect of procaine on development of ‘ridges’ and ‘domes’ in primary cell cultures from mammary glands of untreated virgin mice: The role of cell density in the occurrence of ‘domes’,G.J. Wiepjes and A.S. Visser and F.J.A. Prop,article,WIEPJES1976136,Experimental Cell Research,1,98,0014-4827,,,
,"Multi-level analysis, Correlated data, Infectious diseases, Generalized linear mixed model",161-177,,"The patterns of sero-prevalence of antibodies to four infectious diseases, representing a broad range of pathogens (bacteria: brucellosis; mycoplasma: contagious bovine pleuropneumonia; viruses: infectious bovine rhinotracheitis; protozoa: trypanosomosis) were investigated at three levels of organization (farm, area and district). Three contrasting districts in Kenya were compared: an arid and pastoral area (Samburu); a tropical highland area (Kiambu), and a tropical coastal area (Kilifi). Cattle in three districts were selected by two-stage cluster sampling between August 1991 and 1992. Schall's algorithm, a generalized linear mixed model suitable for multi-level analysis, was compared to ordinary logistic regression (OLR), which ignores clustering of responses; generalized estimating equations (GEE) or Jacknife, to account for clustering at the farm level; SAS VARCOMP, which provides normal-theory random-effects models. Schall's algorithm provided similar estimates to GEE (regression effects) and Jackknife (standard errors) for farm-level clustered data. Extending Schall's procedure for additional district and area-withindistrict random effects usually provided additional information. In general, models that included only a farm-level random effect consistently provided larger estimates of farms' variance components than did models with additional district and area random effects. The four type diseases exhibited various amounts of clustering. Brucellosis had moderate farm clustering plus some area and district clustering. Contagious bovine pleuropneumonia had only a small amount of clustering, mostly by area. Infectious bovine rhinotracheitis exhibited a large amount of clustering, primarily at the farm level. Trypanosomiasis antibody prevalence varied by district, area and farm. We believe that patterns of disease clustering identified by multi-level analysis can be used to better target high-risk units for disease control and guide research to understand disease transmission factors.",https://doi.org/10.1016/S0167-5877(96)01084-7,https://www.sciencedirect.com/science/article/pii/S0167587796010847,,,,1997,Assessing infections at multiple levels of aggregation,M. Kadohira and J.J. McDermott and M.M. Shoukri and M.A. Thorburn,article,KADOHIRA1997161,Preventive Veterinary Medicine,3,29,0167-5877,,,
,,41-83,,,https://doi.org/10.1016/S0010-8545(00)80459-2,https://www.sciencedirect.com/science/article/pii/S0010854500804592,,,,1981,Ruthenium and osmium,K.R. Seddon,article,SEDDON198141,Coordination Chemistry Reviews,,35,0010-8545,,,
,,555-561,,,https://doi.org/10.1016/0375-9474(80)90206-7,https://www.sciencedirect.com/science/article/pii/0375947480902067,,,,1980,Physics with a GeV-electron accelerator,Ingo Sick,article,SICK1980555,Nuclear Physics A,1,335,0375-9474,,,
,"Extreme Programming, Object, Object-Oriented Programming, Procedural languages, Spiral Model, Systems Development Life Cycle, Waterfall Model",429-477,CISSP Study Guide (Third Edition),"Chapter 9 introduces Domain 8 of the CISSP, Software Development Security. The most important aspects of this domain are related to managing the development of software and applications. Approaches to software development that attempt to reduce the likelihood of defects or flaws are a key topic in this domain. In particular, the Waterfall, Spiral, and Rapid Application Development (RAD) models of the software development are considered. Another significant portion of this chapter is dedicated to understanding the principles of Object Oriented programming and design. A basic discussion of several types of software vulnerabilities and the issues surrounding disclosure of the vulnerabilities are also a topic for this domain. Finally, databases, being a key component of many applications, are considered.",https://doi.org/10.1016/B978-0-12-802437-9.00009-6,https://www.sciencedirect.com/science/article/pii/B9780128024379000096,Boston,Syngress,978-0-12-802437-9,2016,"Chapter 9 - Domain 8: Software Development Security (Understanding, Applying, and Enforcing Software Security)",Eric Conrad and Seth Misenar and Joshua Feldman,incollection,CONRAD2016429,,,,,,Eric Conrad and Seth Misenar and Joshua Feldman,Third Edition
,,21310-21317,,"Human interleukin-3 (hIL-3) is a regulator of proliferation and differentiation of multipotent hemopoietic progenitor cells. Mutants of hIL-3 have been constructed by oligonucleotide-directed mutagenesis and expressed in Escherichia coli and Bacillus licheniformis. Purified muteins were assayed for induction of DNA synthesis in IL-3-dependent human cells and for binding to the IL-3 receptor. Residues at the NH2 and COOH termini together comprising one-quarter of the molecule could be removed without loss of biological function. Deletions of 6-15 residues within the central part of the molecule caused a large reduction (up to 5 logs) but no complete loss of activity. Substitution of evolutionary conserved residues resulted in a strong decrease of biological activity and demonstrated that the S-S bridge is an essential structural element in hIL-3. Interestingly, four muteins displayed a significantly higher potency of binding to the IL-3 receptor than in stimulating DNA synthesis. These results demonstrate that receptor binding may be (partly) disconnected from activation of DNA synthesis. Analysis of hIL-3 muteins demonstrated that the majority of monoclonal antibodies are directed against a small portion of the IL-3 molecule. The neutralizing potential of individual monoclonal antibodies could be increased by a combination of antibodies directed against nonoverlapping epitopes.",https://doi.org/10.1016/S0021-9258(18)54857-2,https://www.sciencedirect.com/science/article/pii/S0021925818548572,,,,1991,Receptor and antibody interactions of human interleukin-3 characterized by mutational analysis.,L.C. Dorssers and M.C. Mostert and H. Burger and C. Janssen and P.J. Lemson and R. {van Lambalgen} and G. Wagemaker and R.W. {van Leen},article,DORSSERS199121310,Journal of Biological Chemistry,31,266,0021-9258,,,
,,169-208,,"The broad trends of climatic evolution in the Southeast Indian Ocean region during the Tertiary have become clearer with the accumulation of data from Legs 28 and 29 of the Deep Sea Drilling Project. The same events which are reflected in the deep-sea sediments clearly influenced the major continental areas of Australia and Antarctica and the vegetation which covered those regions. In this review, data relating to sea-surface temperatures, to land and sea positions, and to the extent of the Antarctic ice-cap, are used to derive climatic models for the Palaeocene to latest Miocene interval: the models are correlated with vegetation history deciphered from palynological data. For most of the Palaeocene, Australia and Antarctica were joined, and lay in high southern latitudes. Sea-surface temperatures were relatively high, and there is no evidence for Antarctic ice. The postulated atmospheric circulation patterns suggest a zone of westerly winds confined to 60–80°S, and, north of that, a wide zone of erratic circulation, with deep inland penetration of rain-bearing winds. Palynological evidence from Australia indicates rainforest in the southeast, with an extension to presently arid inland South Australia. In the Eocene, Australia and Antarctica were separated by a wide gulf; water temperatures were high — in the vicinity of 20°C on the Campbell Plateau — and evidence for Antarctic ice development is meagre. Atmospheric circulation was probably sluggish, with patterns similar to those of the Palaeocene. Vegetational data show the spread of rainforest communities across Australia from the east to the southwest, and locally, inland to central Australia. Vegetation zonation appears to have been minimal on that continent. In Antarctica, late Eocene vegetation was poorly diversified. For the Oligocene, evidence for a pronounced temperature drop is both isotopic and sedimentological, and includes the first record of ice-rafting near Antarctica. Intensification of atmospheric circulation seems likely. The vegetation records suggest lowered floristic diversity in Australia, and the persistence of vegetation, again of low diversity, in Antarctica into the late Oligocene. For the Miocene, the marine record suggests the development of a major Antarctic ice-cap; in consequence, atmospheric circulations continued to intensify. Continued northward drift of Australia meant increasing aridity in regions to the north and northwest; the south and east were watered by rain-bearing westerly systems and by embryonic Trade Winds. Vegetation data in Australia suggest rainforest cover in the southeast and on the east coast, and, in the middle Miocene, the development of grasslands in interfluvial areas in the central part of the continent. The latest Miocene was marked by an intense and sudden chilling which is clearly documented in Southern Ocean sediments. This event must have caused marked precipitation decrease in much of Australia, and may coincide with the disappearance of pollen of the Nothofagus brassi type from regions west of the Great Dividing Range, although age control of this event is poor.",https://doi.org/10.1016/0031-0182(78)90042-1,https://www.sciencedirect.com/science/article/pii/0031018278900421,,,,1978,Tertiary climatic evolution and vegetation history in the Southeast Indian Ocean region,Elizabeth M. Kemp,article,KEMP1978169,"Palaeogeography, Palaeoclimatology, Palaeoecology",3,24,0031-0182,,,
,"adrenal cells, 25-hydroxycholesterol, ACTH, aminoglutethimide, congenital lipoid adrenal hyperplasia",107-114,,"The production of corticosterone from 25-hydroxycholesterol by isolated rat adrenal cells is inhibited by aminoglutethimide phosphate (AGI); half-maximal inhibition is obtained at ca. 10 μM. AGI also inhibits ACTH-stimulated steroid production from endogeneous substrates; here half-maximal inhibition is obtained with ca. 40 μM AGI. In the presence of ACTH + AGI, 25-hydroxycholesterol causes additive inhibition. This effect of 25-hydroxycholesterol is dose-dependent. ACTH-stimulated steroid production from endogeneous substrates is partially inhibited by 5-cholene-3β, 24-diol. These results may just reflect substrate competition for the side-chain cleaving system or may be due to some secondary toxic effect on the cells.",https://doi.org/10.1016/0303-7207(76)90030-7,https://www.sciencedirect.com/science/article/pii/0303720776900307,,,,1976,Effects of 25-hydroxycholesterol and aminoglutethimide in isolated rat adrenal cells. A model for congenital lipoid adrenal hyperplasia?,H.E. Falke and H.J. Degenhart and G.J.A. Abeln and H.K.A. Visser,article,FALKE1976107,Molecular and Cellular Endocrinology,2,4,0303-7207,,,
,,397-421,Homeland Security (Second Edition),,https://doi.org/10.1016/B978-0-12-804465-0.00027-3,https://www.sciencedirect.com/science/article/pii/B9780128044650000273,,Butterworth-Heinemann,978-0-12-804465-0,2018,Index,,incollection,2018397,,,,,,Jane A. Bullock and George D. Haddow and Damon P. Coppola,Second Edition
,,601-612,,"Aggregates of barley stripe mosaic virus protein (BSMVp) beginning at the level of 10 S aggregate (i.e., 10 S, 20 S, 30 S, 40 S, etc.) are antigenically identical to each other and to BSMV. The monomeric BSMVp unit is serologically related to, but not identical with, the intact BSMV. The influence of quaternary structure of BSMVp on the conformation of polypeptide chain is discussed. The multiple line formation, with antibody in excess, by the mixtures of antigenically identical BSMVp and BSMV was demonstrated in double-diffusion tests.",https://doi.org/10.1016/0042-6822(68)90191-8,https://www.sciencedirect.com/science/article/pii/0042682268901918,,,,1968,Serological study on barley stripe mosaic virus protein polymerization: II. Comparative antigenic analysis of intact virus and some stable protein intermediates,J.G. Atabekov and S.P. Dementyeva and N.D. Schaskolskaya and G.N. Sacharovskaya,article,ATABEKOV1968601,Virology,4,36,0042-6822,,,
,,71-80,,"The experiments have been carried out with lettuce shoots on board the Salyut-7 orbital station, the Kosmos-1667 biological satellite and under ground conditions at 180° plant inversion. By means of the centrifuge Biogravistat-1M the threshold value of gravitational sensitivity of lettuce shoots has been determined on board the Salyut-7 station. It was found to be equal to 2.9 × 10−3g for hypocotyls and 1.5 × 10−4g for roots. The following results have been received in the experiment performed on board the Kosmos-1667 satellite: a) under microgravity the proliferation of the meristem cells and the growth of roots did not differ from the control; b) the growth of hypocotyls in length was significantly enhanced in microgravity; c) under microgravity transverse growth of hypocotyls (increase in cross sectional area) was significantly increased due to enhancement of cortical parenchyma cell growth. At 180° inversion in Earth's gravity root extension growth and rate of cell division in the root apical meristem were decreased. The determination of DNA-fuchsin value in the nuclei of the cell root apexes showed that inversion affected processess of the cell cycle preceeding cytokinesis.",https://doi.org/10.1016/0273-1177(86)90069-4,https://www.sciencedirect.com/science/article/pii/0273117786900694,,,,1986,Interaction of growth-determining systems with gravity,A. Merkys and R. Laurinavičius and D. Bendoraityté and D. Švegždiené and O. Rupainiené,article,MERKYS198671,Advances in Space Research,12,6,0273-1177,,,
,,205-219,,"Countercurrent two-phase flow associated with filling of sealed vessels via gravity-driven liquid injection through inclined channels was experimentally studied and analytically modeled. Experiments were performed using transparent tubular test sections connected at one end to the bottom of a large, open water tank, and at the other end to an unvented tank. The test section parameters (including the channel diameter (1.27–2.54cm), length (30.5–122 cm), angle of inclination with respect to horizontal plane (0–30°), and the empty volume in the sealed vessel) were systematically varied. Flow regimes in the test section were recorded and transient flow rates were measured during the experiments. Oscillatory, and intermittent stratified slug, were dominant flow regimes in most tests. The quasi-steady liquid superficial velocity in the test section was sensitive to the test section dimensions, and varied in the range 0.04–0.95 m s−1. These flow regimes were mechanisally modeled. The models are shown to satisfactory predict the measured hydrodynamic parameters.",https://doi.org/10.1016/0029-5493(95)00995-O,https://www.sciencedirect.com/science/article/pii/002954939500995O,,,,1995,Gravity-driven countercurrent two-phase flow during filling of an unvented vessel,B. Kamboj and E.M. Ritenour and S.M. Ghiaasiaan and S.I. Abdel-Khalik,article,KAMBOJ1995205,Nuclear Engineering and Design,1,157,0029-5493,,,
,"Monocyte mediated cytotoxicity, MTT assay",311-320,,"The MTT-colorimetric monocyte mediated cytotoxicity assay, based upon the ability of living cells to reduce 3-[4,5-dimethylthiazol-2-yl]-2,5 diphenyltetrazolium bromide (MTT) into formazan, was evaluated using leukemic cells from five representative human leukemic cell lines and from 28 patients with acute myeloid leukemia (AML). An excellent linearity between absorbance and leukemic cell number was observed up to 5 × 104 cells/well and 50 × 104 cells/well for all cell lines and patients samples tested, respectively, in a 96-wells microtiter culture system. A huge variability in the susceptibility of leukemic cells to purified and IFN-γ-activated human monocytes could be observed at effector-to-target cell (E:T) ratios of 1. The mean signal-to-noise ratio of the MTT assay for monocyte-leukemic cell mixtures from patients was 2.69 ± 0.39 at E:T 1. In conclusion, the MIT based monocyte mediated cytotoxicity assay should be useful for studying the susceptibility of a variety of leukemic cells from cell lines and from patients with AML to monocytes in a rapid, sensitive and semi-automated manner.",https://doi.org/10.1016/0022-1759(94)90034-5,https://www.sciencedirect.com/science/article/pii/0022175994900345,,,,1994,A tetrazolium-based colorimetric MTT assay to quantitate human monocyte mediated cytotoxicity against leukemic cells from cell lines and patients with acute myeloid leukemia,A.A. {van de Loosdrecht} and R.H.J. Beelen and G.J. Ossenkoppele and M.G. Broekhoven and M.M.A.C. Langenhuijsen,article,VANDELOOSDRECHT1994311,Journal of Immunological Methods,1,174,0022-1759,,,
,"Legumin (immunolocalization, mRNA localization), Legumin gene (biphasic expression), Seed development, Tobacco 12S globulins, Transgenic plants, Nicotiana tabacum",115-126,,"Summary
We analysed the spatial and temporal expression of the Vicia faba legumin gene LeB4 in developing seeds of transgenic tobacco plants by means of in situ hybridization and immunohistostaining. The results indicate that the expression of the LeB4 gene is regulated in embryo and endosperm in a biphasic manner. Legumin accumulation starts during early seed development at low amounts in single cells of the integument. Accumulation proceeds successively in the proembryo, suspensor and endosperm reaching maximum levels in all cells of these organs around 10 to 12 DAP. With the beginning of the heart stage (around 13 DAP) legumin reserves disappear completely from all parts of the seed. The described early phase of legumin accumulation occurs in embryo and endosperm still before the onset of the cell expansion phase in a period of continuous mitotic activity. A second expression phase starts in embryo and endosperm around 18 DAP, as the embryo enters late torpedo stage. Within the embryo the accumulation is restricted to the parenchyma cells of cotyledons and hypocotyl, while the embryonic root and provascular tissue do not accumulate LeB4 protein. In addition, a low percentage (<10%) of cells from protoderm and calyptra was found to be involved in legumin accumulation. A comparison of LeB4 mRNA and protein distribution in embryo and endosperm revealed corresponding patterns for both expression phases. The biphasic expression of the LeB4 gene in transgenic tobacco seeds is identical to that found in V. faba for the legumin and vicilin genes during early embryogenesis (Panitz et al., 1995), but differs from that of tobacco 12S globulin genes, which are expressed in the embryo not before the late heart stage.",https://doi.org/10.1016/S0176-1617(97)80190-3,https://www.sciencedirect.com/science/article/pii/S0176161797801903,,,,1997,Biphasic expression of a Vicia faba legumin B gene in developing seeds of transgenic tobacco,Reinhard Panitz and Renate Manteuffel and Helmut Bäumlein and Ulrich Wobus,article,PANITZ1997115,Journal of Plant Physiology,1,150,0176-1617,,,
,", Rutaceae, benzophenanthridine alkaloids, limonoids, biochemical systematics, Rutales",45-51,,"From the stem bark of Fagaropsis angolensis (Rutaceae) three alkaloids and two limonoids were isolated. The alkaloids were identified as the 6-acetonyl derivatives of the benzophenantridines, dihydrochelerythrine, dihydrosanguinarine and dihydronitidine, the last of these being reported for the first time. The alkaloids did not appear to be artefacts of the corresponding benzophenanthridines. The limonoids were identified as rutaevin and limonin diosphenol. The significance of these compounds in resolving the confused taxonomic position of F. angolensis is discussed. Attention is drawn to the presence of a small group of taxa within the Rutaceae capable of synthesizing 1-benzyltetrahydroisoquinoline-derived alkaloids and the potential of these taxa as a starting point for visualizing biochemical evolution within the order Rutales, and putative relationships between the Rutales and Ranales are examined.",https://doi.org/10.1016/0305-1978(81)90058-2,https://www.sciencedirect.com/science/article/pii/0305197881900582,,,,1981,The biochemical systematics of Fagaropsis angolensis and its significance in the Rutales,Peter G. Waterman and Sami A. Khalid,article,WATERMAN198145,Biochemical Systematics and Ecology,1,9,0305-1978,,,
,,I-CXXIII,,,https://doi.org/10.1016/S1936-8798(23)00889-0,https://www.sciencedirect.com/science/article/pii/S1936879823008890,,,,2023,Full Issue PDF,,article,2023I,JACC: Cardiovascular Interventions,11,16,1936-8798,,,
,,65-74,,,https://doi.org/10.1016/S0144-8617(96)90007-7,https://www.sciencedirect.com/science/article/pii/S0144861796900077,,,,1996,Bibliography of carbohydrate polymers,,article,199665,Carbohydrate Polymers,1,30,0144-8617,,,
,,243-247,,,https://doi.org/10.1016/0014-5793(74)81221-4,https://www.sciencedirect.com/science/article/pii/0014579374812214,,,,1974,13C-Nuclear magnetic resonance and X-ray photoelectron spectroscopy of Cu-AMP,Ulrich Weser and Gert-Joachim Strobel and Wolfgang Voelter,article,WESER1974243,FEBS Letters,2,41,0014-5793,,,
,"Aggregation, Allometry, Biomechanics, Intertidal ecology, Macroalga, ",39-67,,"Sea-palms Postelsia palmaeformis Ruprecht are annual brown algae that grow on wave-swept rocky shores, often forming dense stands. Unlike most macroalgae, Postelsia stands upright in air-like trees. The stipe flexibility that permits Postelsia to withstand waves is provided by the low elastic modulus (5–10 MPa) of stipe tissue; in spite of the weakness (low breaking stress, ≈ 1 MPa) of this tissue, a large amount of energy (≈ 100 kJ/m3) is required to break a stipe because they can be extended by 20–25% before breaking. Although made of such easily deformed tissue, Postelsia can stand upright in air due to the width (high second moment of area) and resilience of their stipes, but the brittleness (low work of fracture, 400–900 J/m2) that accompanies this resilience renders them susceptible to breakage if they sustain deep scratches. Although wave-induced stresses experienced by individuals in aggregations are not lower than those experienced by isolated sea-palms, photon flux densities of photosynthetically active radiation within these dense groves are less than 10% of those above Postelsia canopies. A number of morphological features differ between canopy, understory, and isolated individuals. Canopy plants in dense aggregations are taller than isolated individuals and may exceed limiting proportions for elastic stability. Postelsia shows photosynthetic characteristics of “shade-adapted” plants, understory individuals being especially effective at using low light. Despite this, blade growth rates of understory plants are lower than those of either canopy or isolated individuals.",https://doi.org/10.1016/0022-0981(91)90254-T,https://www.sciencedirect.com/science/article/pii/002209819190254T,,,,1991,Intertidal “trees”: consequences of aggregation on the mechanical and photosynthetic properties of sea-palms Postelsia palmaeformis Ruprecht,N. {Michele Holbrook} and Mark W. Denny and M.A.R. Koehl,article,MICHELEHOLBROOK199139,Journal of Experimental Marine Biology and Ecology,1,146,0022-0981,,,
,,352-354,,"Summary
A method novel to the quantitation of leptospiral viability was used which permitted new observations on the effect of freezing leptospires. Use of this method showed that some loss of viability occurred during freezing and/or thawing of three serotypes of leptospires with no significant additional loss during 22 months of storage in liquid nitrogen. These studies also indicated that a controlled rate of freezing was significantly better than quick freezing by immersion in liquid nitrogen. In an additional study, a hamster-virulent strain of L. canicola was frozen and gave reproducible viability and virulence titers at intervals over a 2-year period.",https://doi.org/10.1016/S0011-2240(69)80466-9,https://www.sciencedirect.com/science/article/pii/S0011224069804669,,,,1969,Viability quantitation of leptospires after rapid and controlled rate freezing,Harry L. Torney and Dale E. Bordt,article,TORNEY1969352,Cryobiology,5,5,0011-2240,,,
,,317-335,,"Palaeobotanical data show that during the last, or Eemian, interglacial, the climate in northern Europe was warmer than during the postglacial climatic optimum. The main warm period of the Eemian is identifiable in pollen and plant macrofossil analyses from the abundance of thermophilous species, many of which grew in Eemian time far beyond their Flandrian northern limits. These features, typical of the Eemian occurrences, were found in the Ollala interglacial site in Haapavesi, western Finland. The diatom flora, together with the plant macrofossils, showed a sequence from a marine to fresh-water environment, and thus the isolation of the sedimentary basin from the Eemian sea as a consequence of glacio-isostatic rebound. The marine diatom flora was rich, with many exotic species, indicating a higher salinity than ever found in the postglacial marine deposits in this region. Together with some other finds, the Ollala interglacial deposits (at about 116–117 m above the present sea level), suggest that the general patterns of Eemian and Flandrian uplift were largely similar, but that there were also differences in crustal deformations during these two interglacials. The ice load during the maximum phase of each glaciation determines the amount of crustal downwarping, but the deglaciation history and changes in the geographical distribution of the ice load during the melting phase are other important factors, responsible for the shape of the land uplift regions.",https://doi.org/10.1016/0031-0182(88)90049-1,https://www.sciencedirect.com/science/article/pii/0031018288900491,,,,1988,Stratigraphic evidence for eemian crustal movements and relative sea-level changes in eastern fennoscandia,Lars Forsström and Marjatta Aalto and Matti Eronen and Tuulikki Grönlund,article,FORSSTROM1988317,"Palaeogeography, Palaeoclimatology, Palaeoecology",2,68,0031-0182,Quaternary Coastal Changes,,
,",  Promoter,  Promoter, Recombinant cocoa protein, , ",43-54,,"The production in two yeast expression systems of recombinant forms of the major proteins from the cocoa bean is described. Three major protein species are found in the cocoa bean: an albumin of molecular mass 21 kDa (p21) and two insoluble vicilin-like proteins of molecular mass 31 kDa and 47 kDa (p31 and p47, respectively). The p31 and p47 species are known to be derived from a common 67-kDa precursor (p67) by post-translational processing that includes the deletion of a hydrophilic domain located immediately after an N-terminal signal sequence. All three proteins appear to be targeted to membrane-bound storage organelles by N-terminal signal sequences. The p21 and p67 coding sequences were expressed in Hansenula polymorpha using the powerful methanol oxidase (MOX) promoter and in Saccharomyces cerevisiae using the promoter of the pyruvate kinase (PYK) gene. The expression constructs contained the native plant signal sequence, or various yeast signals. The p21 protein was successfully expressed and secreted from both yeasts. The insoluble p67 protein proved more difficult. Species of the correct molecular mass were recovered internally and small amounts of a p47 species were secreted using a yeast leader sequence. However, proteolytic cleavage, probably due to Kex2p-like processing, led to the appearance of other protein species.",https://doi.org/10.1016/0168-1656(95)00181-6,https://www.sciencedirect.com/science/article/pii/0168165695001816,,,,1996,Expression of the major bean proteins from Theobroma cacao (cocoa) in the yeasts Hansenula polymorpha and Saccharomyces cerevisiae,M.Ö. Yavuz and S.M.V. Ashton and E.D. Deakin and M.E. Spencer and P.E. Sudbery,article,YAVUZ199643,Journal of Biotechnology,1,46,0168-1656,,,
,"Alzheimer's disease, Paired helical filaments, Beta-amyloid, Amyloid precursor protein, Neurofibrillary tangles",387-392,,Paired helical filaments (PHF) were electro-phoretically purified and solubilized from Alzheimer's neurofibrillary tangles and consisted of a primary 66 kDa protein on SDS-PAGE analysis. A panel of antibodies raised against restricted regions of the beta-amyloid precursor protein (APP) were employed for epitope mapping studies of this 66 kDa PHF protein. Western blot studies revealed that C-terminal APP antibodies were immunoreactive with the 66 kDa PHF protein. Further analysis revealed that only antisera raised against peptides that include the beta/A4-amyloid region within the C-terminal portion of APP were immunoreactive with PHF proteins. These data complement previous immunocytochemical studies which indicated that C-terminal APP antibodies preferentially label PHF-containing neurofibrillary tangles in Alzheimer's brain. The present data suggest a similarity of secondary or tertiary structure between beta/A4-amyloid and PHF which accounts for the cross-reactivity of beta/A4-amyloid antibodies with PHF proteins.,https://doi.org/10.1016/0361-9230(94)90281-X,https://www.sciencedirect.com/science/article/pii/036192309490281X,,,,1994,Alzheimer's paired helical filaments: Amyloid precursor protein epitope mapping,Frank P. Zemlan and Glenn D. Vogelsang and Lea McLaughlin and Gary E. Dean,article,ZEMLAN1994387,Brain Research Bulletin,4,33,0361-9230,,,
,,1-19,,,https://doi.org/10.1016/0304-3479(87)90046-9,https://www.sciencedirect.com/science/article/pii/0304347987900469,,,,1987,Давид Бурлюк — Лирика,Živa Benčić,article,BENCIC19871,Russian Literature,1,22,0304-3479,The Russian Avant-Garde XXVIII The Zagreb Symposia VI,,
,"Verification, Validation, Automated systems, Security, Privacy",104349,,"Manufacturers of automated systems and their components have been allocating an enormous amount of time and effort in R&D activities, which led to the availability of prototypes demonstrating new capabilities as well as the introduction of such systems to the market within different domains. Manufacturers need to make sure that the systems function in the intended way and according to specifications. This is not a trivial task as system complexity rises dramatically the more integrated and interconnected these systems become with the addition of automated functionality and features to them. This effort translates into an overhead on the V&V (verification and validation) process making it time-consuming and costly. In this paper, we present VALU3S, an ECSEL JU (joint undertaking) project that aims to evaluate the state-of-the-art V&V methods and tools, and design a multi-domain framework to create a clear structure around the components and elements needed to conduct the V&V process. The main expected benefit of the framework is to reduce time and cost needed to verify and validate automated systems with respect to safety, cyber-security, and privacy requirements. This is done through identification and classification of evaluation methods, tools, environments and concepts for V&V of automated systems with respect to the mentioned requirements. VALU3S will provide guidelines to the V&V community including engineers and researchers on how the V&V of automated systems could be improved considering the cost, time and effort of conducting V&V processes. To this end, VALU3S brings together a consortium with partners from 10 different countries, amounting to a mix of 25 industrial partners, 6 leading research institutes, and 10 universities to reach the project goal.",https://doi.org/10.1016/j.micpro.2021.104349,https://www.sciencedirect.com/science/article/pii/S0141933121005068,,,,2021,The VALU3S ECSEL project: Verification and validation of automated systems safety and security,J.A. Agirre and L. Etxeberria and R. Barbosa and S. Basagiannis and G. Giantamidis and T. Bauer and E. Ferrari and M. {Labayen Esnaola} and V. Orani and J. Öberg and D. Pereira and J. Proença and R. Schlick and A. Smrčka and W. Tiberti and S. Tonetta and M. Bozzano and A. Yazici and B. Sangchoolie,article,AGIRRE2021104349,Microprocessors and Microsystems,,87,0141-9331,,,
,,111-119,,"The scanning electron microscope provides good three-dimensional pictures of dog thyroid slices. Our observations have shown at the apical surface of thyroid cells, beside numerous microvilli, large pseudopods appearing after acute TSH stimulation in vivo and in vitro. Their formation was completely inhibited by cytochalasin B. In chronic stimulation in vivo, these pseudopods are not observed. Their morphogenesis is discussed.",https://doi.org/10.1016/0014-4827(73)90495-3,https://www.sciencedirect.com/science/article/pii/0014482773904953,,,,1973,Scanning electron microscope observations of apical surfaces of dog thyroid cells,P. Ketelbant-Balasse and F. Rodesch and P. Neve and J.M. Pasteels,article,KETELBANTBALASSE1973111,Experimental Cell Research,1,79,0014-4827,,,
,,75-85,,,https://doi.org/10.1016/0144-8617(92)90027-N,https://www.sciencedirect.com/science/article/pii/014486179290027N,,,,1992,Bibliography on carbohydrate polymers,,article,199275,Carbohydrate Polymers,1,17,0144-8617,,,
,"Cloud scheduling, Pilot jobs, Cloud middleware, Resource management, Application compatibility",90-103,,"In the pool of cloud providers that are currently available there is a lack of standardised APIs and brokering tools to effectively distribute high throughput calculations among them. Moreover, the current middleware tools are not able to straightforwardly provision the ephemeral and specific environments that certain codes and simulations require. These facts prevent the massive portability of legacy applications to cloud environments. Such an issue can be overcome by effectively scheduling the distributed calculations using the basic capacities offered by cloud federations. In this work, a framework achieving such a goal is presented: a pilot system (GWpilot) that has been improved with cloud computing capabilities (GWcloud). This framework profits from the expertise acquired in grid federations and provides interesting features that make it more efficient, flexible and useable than other approaches. Thus, decentralisation, middleware independence, dynamic brokering, on-demand provisioning of specific virtual images, compatibility with legacy applications, and the efficient accomplishment of short tasks, among other features, are achieved. Not only this, the new framework is multi-user and multi-application, dynamically instantiating virtual machines depending on the available and demanded resources, i.e. allowing users to consolidate their own resource provisioning. Results presented in this work demonstrate these features by efficiently executing several legacy applications with very different requirements on the FedCloud infrastructure at the same time.",https://doi.org/10.1016/j.future.2016.03.021,https://www.sciencedirect.com/science/article/pii/S0167739X16300656,,,,2017,Scheduling multiple virtual environments in cloud federations for distributed calculations,A.J. Rubio-Montero and E. Huedo and R. Mayo-García,article,RUBIOMONTERO201790,Future Generation Computer Systems,,74,0167-739X,,,
,"Cloud computing security, Cloud attacks, Anomaly detection, Intrusion detection system, Machine learning, Deep learning",9102-9131,,"Nowadays, machine learning and deep learning algorithms are used in recent studies as active security techniques instead of traditional ones to secure the cloud environment based on pre-trained data. In this paper, a literature review on machine and deep learning based defences against attacks and security issues in cloud computing is provided. A taxonomy of all different types of attacks and threats as per cloud security alliance (CSA) layers; and the general defences against cloud attacks is shown in this review as well as the reasons which let the traditional security techniques fail to satisfy the desired security level are discussed. Forty-two case studies are selected based on seven quality assessment standards and then, analyzed to answer seven research questions which help to protect cloud environments from various attacks, issues, and challenges. The analysis of case studies shows a description of the most common security issues in cloud; machine learning and deep learning models that are applied, datasets models, performance metrics, machine learning and deep learning based countermeasures and defences that are developed to prevent security issues. Finally, the future scope and open challenges in cloud computing security based on machine and deep learning are discussed as well.",https://doi.org/10.1016/j.jksuci.2022.08.035,https://www.sciencedirect.com/science/article/pii/S1319157822003184,,,,2022,"Comprehensive review on intelligent security defences in cloud: Taxonomy, security issues, ML/DL techniques, challenges and future trends",Mohamad Mulham Belal and Divya Meena Sundaram,article,BELAL20229102,Journal of King Saud University - Computer and Information Sciences,"10, Part B",34,1319-1578,,,
,,25-31,,,https://doi.org/10.1016/0045-8732(80)90117-5,https://www.sciencedirect.com/science/article/pii/0045873280901175,,,,1980,Forthcoming meetings of interest to COSPAR,,article,198025,COSPAR Information Bulletin,87,1980,0045-8732,,,
,"Space perception, Spatial vision, Spatial localization, Spatial orientation, Egocentric localization, Multisensory integration, Intersensory integration, Extraretinal eye position information, Visual constancy",315-324,,"Observing a pitched visual field (i.e. tilted around a horizontal axis in the observer's frontal plane) results in large changes in the elevation visually perceived to correspond to eye level (VPEL) and in the perceived elevation and size of stationary objects viewed against the field. With topforward pitch (top toward observer) VPEL lies above true eye level and objects appear smaller and lower; with topbackward pitch VPEL lies below true eye level and objects appear larger and higher. Oscillation of the pitched field induces synchronous perceived oscillation of elevation of a stationary target viewed against the field. Typical VPEL settings deviated from true eye level by 20° with the field pitched at 40°, although some individuals mislocalized by as much as 40°. VPEL varied linearly with visual field pitch with individual slopes for the relation between VPEL and visual field pitch ranging from +0.42 to +0.78 (avg = +0.56). The linear correlation (r) between VPEL in darkness and against an erect visual field was +0.91. The two relations—VPEL vs visual field pitch, VPEL in darkness vs VPEL in the erect illuminated visual field (slope ≈ 0.5)—are both accurately predicted by the linear model: VPEL = kvV + kbB; in which V is the influence of visual field structure and B is the influence of the body-referenced mechanism which combines information regarding the orientation of the head relative to gravity, the position of the eye in the orbit, and the vertical location of the image on the retina; kv and kb are the relative weights of V and B with kv + kb = 1. In an illuminated field kv = kb ≈ 0.5; in the dark kv = 0, kb = 1.",https://doi.org/10.1016/0042-6989(89)90080-1,https://www.sciencedirect.com/science/article/pii/0042698989900801,,,,1989,Visually perceived eye level and perceived elevation of objects: Linearly additive influences from visual field pitch and from gravity,Lonard Matin and Charles R. Fox,article,MATIN1989315,Vision Research,3,29,0042-6989,,,
,,149-156,,,https://doi.org/10.1016/0144-8617(94)90025-6,https://www.sciencedirect.com/science/article/pii/0144861794900256,,,,1994,Bibliography of carbohydrate polymers,,article,1994149,Carbohydrate Polymers,2,24,0144-8617,,,
,,249-255,,"Monomeric cyanoboranes are obtained by reaction of bis(amino)haloboranes and amino(halo)organylboranes with AgCN. 1H, 11B NMR, IR and mass spectra are reported together with analytical data.
Zusammenfassung
Monomere Cyanoborane werden bei der Reaktion von Bis(amino)halogenboranen und Amino(halogen)organylboranen mit AgCNerhalten. 1H- 11B-NMR, IR und Massenspektren werden zusammen mit analytischen Daten berichtet.",https://doi.org/10.1016/S0022-328X(00)90847-7,https://www.sciencedirect.com/science/article/pii/S0022328X00908477,,,,1977,Umsetzung von metall- und metalloidverbindungen mit mehrfunktionellen molekülen: XIV. Darstellung monomerer cyanoborane,Anton Meller and Walter Maringgele and Ulrich Sicker,article,MELLER1977249,Journal of Organometallic Chemistry,3,141,0022-328X,,,
,,30-39,,"Rapid industrialization and urbanization spurred on by a surge in foreign investment is often considered typical of newly industrializing countries (NICs). But in Indonesia, the combination of late development and an authoritarian state has created a particularly potent mix, one that has raised more questions than usual about the effects of growth, trade, and investment on labor conditions and local standards of living. The basic motives of foreign direct investment (FDI) are said to create a pattern that is inherently ripe for exploitation, since the capital, technology and market access all rest with the foreign investor. The author uses the Indonesian case to explore factors that might reduce exploitation. While conceding that foreign investment is likely to affect labor conditions in the host economy, especially in times of rapid growth, she cautions against presuming that the consequences will be mainly negative with respect to the living standards and basic human rights of the local population.",https://doi.org/10.1016/S0022-5428(96)90030-7,https://www.sciencedirect.com/science/article/pii/S0022542896900307,,,,1996,"Trade, investment, and labor: The case of Indonesia",Debora Spar,article,SPAR199630,The Columbia Journal of World Business,4,31,0022-5428,,,
,"adrenal cells, 25-hydroxycholesterol, ACTH, Cycloheximide, chloramphenicol",331-339,,"Cycloheximide and chloramphenicol both inhibit the stimulating effect of adenocorticotropic hormone (ACTH) on adrenal steroid production. To test whether these inhibitors had any effect on adrenal steroid production, independent from the mechanism of action of ACTH, we investigated their effect on the conversion of 25-hydroxycholesterol into corticosterone in isolated rat adrenal cells. Cycloheximide, both in the absence and in the presence of ACTH, had no effect on this conversion. Chloramphenicol inhibited the conversion of 25-hydroxycholesterol into corticosterone whether ACTH was present or not. The results with Cycloheximide indicate that ACTH has no direct effect on the cholesterol side-chain cleaving system. The inhibition by chloramphenicol of the ACTH-stimulated steroid production is at least partly due to inhibition of one or more of the processes involved in the conversion of 25-hydroxycholesterol into corticosterone.",https://doi.org/10.1016/0303-7207(76)90049-6,https://www.sciencedirect.com/science/article/pii/0303720776900496,,,,1976,Different effects of cycloheximide and chloramphenicol on corticosterone production by isolated rat adrenal cells,H.E. Falke and J.G.M. Huijmans and H.J. Degenhart,article,FALKE1976331,Molecular and Cellular Endocrinology,5,4,0303-7207,,,
,,140-147,,"Most modern protein sequence analysis is carried out using classical, wet-chemical Edman degradation technology. However, an increasing number of studies on both natural and recombinant genetically engineered proteins demands the use of new technologies capable of assigning structural features such as glycosylation, which cannot be assigned by Edman sequence analysis. The most important alternative and complementary procedure at present is the use of high-mass mass spectrometry. This brief article introduces some of the principles and applications of the technique. Protein research laboratories, both academic and industrial will make increasing use of these techniques to complement classical gas phase sequencing, and to identify post-translational modifications including glycosylation, phosphorylation, SS bridge assignment and processing events, including the formation of ‘ragged ends’.",https://doi.org/10.1016/0167-7799(88)90083-2,https://www.sciencedirect.com/science/article/pii/0167779988900832,,,,1988,Mass spectrometry of natural and recombinant proteins and glycoproteins,Howard R. Morris and Fiona M. Greer,article,MORRIS1988140,Trends in Biotechnology,7,6,0167-7799,,,
,,155-161,,,https://doi.org/10.1016/0144-8617(95)90062-4,https://www.sciencedirect.com/science/article/pii/0144861795900624,,,,1995,Bibliography of carbohydrate polymers,,article,1995155,Carbohydrate Polymers,2,27,0144-8617,,,
,,1653-1657,,,https://doi.org/10.1016/S0041-0101(97)90025-8,https://www.sciencedirect.com/science/article/pii/S0041010197900258,,,,1997,Bibliography of toxinology,,article,19971653,Toxicon,11,35,0041-0101,,,
,,497-509,,"The type species of Cyphellopycnis Tehon & Stout and Alveophoma Alcalde, genera described as characterized by multi-ostiolate pycnidia, are compared with Phoma herbarum Westend, var. lactaria var. nov., a multi-ostiolate variety isolated from the rubber tubing of an automatic milking machine. Cyphellopycnis is shown to be congeneric with Phomopsis (Sacc.) Sacc, the type species C. pastinacae Tehon & Stout being antedated by P. diachenii Sacc. Alveophoma is distinct from Phomopsis and Phoma Sacc. on account of the sympodial development of the conidiophores. As a result of comparative studies on several hyaline-spored pycnidial fungi related to Phoma, it is suggested that separation of genera on the basis of conidium and conidiophore development will provide a more satisfactory approach to the classification of pycnidial fungi.",https://doi.org/10.1016/S0007-1536(64)80028-0,https://www.sciencedirect.com/science/article/pii/S0007153664800280,,,,1964,Phoma and related genera,B.C. Sutton,article,SUTTON1964497,Transactions of the British Mycological Society,4,47,0007-1536,,,
,"(+)-WAY-100135, Social behavior, Agonistic behavior 5-HT antagonist, Ethological analysis",159-167,,"Compounds previously identified as 5-HT1A antagonists have subsequently been demonstrated to possess partial agonistic properties in models assessing somatodendritic autoreceptor function. This study examined the influences of (+)-WAY-100135, claimed to be the first selective 5-HT1A antagonist, on offensive behaviour in male mice. Employing a resident-intruder paradigm, administration of (+)WAY-100135 (1.0–10.0 mg/kg sc) enhanced elements of resident offensive behaviour at 2.5 and 5.0 mg/kg but reduced such behaviour at 10.0 mg/kg. In comparison, resident defensive postures remained unchanged except for a significant increase in defensive sideways behaviour at 10.0 mg/kg. These effects were accompanied by reduced rearing behaviour across the dose range tested. Attend/approach behaviour was significantly reduced at the lowest, but increased at the highest, doses tested. Such results may reflect response competition rather than concomitant motor impairment. Given the dynamic behavioural interactions occurring in this paradigm, the increased offensive behaviour of the resident mice leads to enhanced defence and counter-attack by the intruder conspecifics. The results are discussed with reference to the current literature concerning the behavioural effects of other 5-HT1A antagonists.",https://doi.org/10.1016/0091-3057(95)02168-X,https://www.sciencedirect.com/science/article/pii/009130579502168X,,,,1996,Effects of the 5-HT1A antagonist (+)-way-100135 on murine social and agonistic behavior,Robert Bell and Paul J. Mitchell and Helen Hobson,article,BELL1996159,Pharmacology Biochemistry and Behavior,1,54,0091-3057,"Anxiety, Stress and Depression",,
,,379-391,,"On treating the blue-green alga Anacystis nidulans with dimethylsuberimidate up to 70% of the free NH2 of the photosynthetic membrane is amidinated, and presumably inter- and intramolecular cross-links are established in the membrane proteins. Amidination destroys the ability of A. nidulans to photoreduce HCO3− but leaves the photochemical activities of Photosystems II and I nearly intact. With added electron acceptors, photosynthetic O2 evolution can be demonstrated both with permeable cells (permeaplasts) prepared by digestion of the cell wall of dimethylsuberimidate-reacted A. nidulans with lysozyme, as well as with heavy membrane particles (36 000 × g) prepared from dimethylsuberimidate-reacted cells. Permeaplasts prepared from dimethylsuberimidate-reacted cells resist damage in hypoosmotic medium, whereas those prepared from unreacted cells are induced to release C-phycocyanin. On the other hand, the former are inactivated more easily by heat stress than the latter. On this basis, it is concluded that cross-linking with dimethylsuberimidate confers functional instability to photosynthetic membranes.",https://doi.org/10.1016/0005-2728(77)90227-4,https://www.sciencedirect.com/science/article/pii/0005272877902274,,,,1977,"Photosynthetic activity of diimidoester-modified cells, permeaplasts, and cell-free membrane fragments of the blue-green alga Anacystis nidulans",George C. Papageorgiou,article,PAPAGEORGIOU1977379,Biochimica et Biophysica Acta (BBA) - Bioenergetics,3,461,0005-2728,,,
,"Cluster chemistry, Organometallic chemistry",91-138,,,https://doi.org/10.1016/0010-8545(95)01223-0,https://www.sciencedirect.com/science/article/pii/0010854595012230,,,,1996,Annual survey of organometallic metal cluster chemistry for the year 1994,Michael G. Richmond,article,RICHMOND199691,Coordination Chemistry Reviews,,156,0010-8545,,,
,"Gas chromatography, Mercury speciation, Derivatization, Microwave-induced plasma emission detector",545-554,,"The determination of methyl- and ethylmercury halides in environmental and biological samples typically involves gas chromatography with electron-capture detection. However, these organomercury halides are notorious for their poor chromatographic characteristics (severe tailing, decomposition, low column efficiencies) on packed columns. The problems can be temporarily alleviated by column passivation using a concentrated organic solution of mercury(II) chloride. Attempts to use capillary columns instead, to improve the chromatographic behaviour of organomercury halides, have met with mixed success, and the results presented generally show poorer performance than that obtained using packed columns, even after passivation. To eliminate the problem at its source (the polar mercury-halide bond), it is proposed to butylate the mercury species with a Grignard reagent to yield the non-polar dialkyl derivatives. As the electron-capturing halide moiety is absent from these derivatives, mercury-specific detection is necessary, and a microwave-induced plasma emission detector is utilized. In combination with capillary gas chromatography, unprecedented column and separation efficiencies for methyl- and ethylmercury are achieved. The practical utility of the method is illustrated in a preliminary application to the determination of mercury species in a fish tissue reference material after extraction and butylation.",https://doi.org/10.1016/S0003-2670(00)83032-9,https://www.sciencedirect.com/science/article/pii/S0003267000830329,,,,1991,Capillary column gas chromatography for mercury speciation,E. Bulska and D.C. Baxter and W. Frech,article,BULSKA1991545,Analytica Chimica Acta,2,249,0003-2670,,,
,,691-694,,Electrocapillary curves were measured for L-α-dipalmitoylphosphatidylcholine in 97% (υ/υ) methanol-water solutions containing 0·01 M NH4NO3. The electrosorption isotherms are similar to those of simpler aliphatic compounds. Saturated coverage of the electrode surface with this lipid in 97% (υ/υ) methanol-water was not possible owing to the formation of micelles in the bulk solution. It is shown that it is possible from the electrocapillary curves to estimate the critical micelle concentration of lipids in non-aqueous electrolyte solutions.,https://doi.org/10.1016/0013-4686(75)85001-8,https://www.sciencedirect.com/science/article/pii/0013468675850018,,,,1975,Electrosorption of L-α-dipalmitoylphosphatidylcholine at the mercury solution interface,G.T. Runbeck and D.M. Mohilner and T.N. Solie,article,RUNBECK1975691,Electrochimica Acta,10,20,0013-4686,,,
,", Trematoda, Blood Fluke, Percoll, Density gradient centrifugation, Mouse, skin, lung, Differentiation, Purification",39-44,,"Step gradients of polyvinylpyrolidone-coated colloidal silica particles (Percoll) were used to isolate and purify early development stages of Schistosoma mansoni (cercariae, skin stage, and 5-day-old schistosomula). With this method, mechanically transformed schistosomula can be isolated in higher purity and yield than that obtained with conventional procedures. In addition, use of the method revealed that schistosomula undergo a dramatic change in density during the first hours after transformation from cercariae. In other experiments, 5-day-old schistosomula were effectively purified from contaminating lung tissue by means of the Percoll gradient procedure. After purification on Percoll, schistosomula display no evidence of damage when examined by light microscopy and no loss in viability as judged by recovery of adult worms from mice.",https://doi.org/10.1016/0014-4894(82)90090-X,https://www.sciencedirect.com/science/article/pii/001448948290090X,,,,1982,Schistosoma mansoni: Rapid isolation and purification of schistosomula of different developmental stages by centrifugation on discontinuous density gradients of Percoll,Janis K. Lazdins and Marsha J. Stein and John R. David and Alan Sher,article,LAZDINS198239,Experimental Parasitology,1,53,0014-4894,,,
,"Traffic classification, Mobile apps, Android apps, IOS apps, Encrypted traffic, Information fusion, Classification combining, Multi-classification",131-145,,"The growing usage of smartphones in everyday life is deeply (and rapidly) changing the nature of traffic traversing home and enterprise networks, and the Internet. Different tools and middleboxes, such as performance enhancement proxies, network monitors and policy enforcement devices, base their functions on the knowledge of the applications generating the traffic. This requirement is tightly coupled to an accurate traffic classification, being exacerbated by the (daily) expanding set of apps and the moving-target nature of mobile traffic. On the top of that, the increasing adoption of encrypted protocols (such as TLS) makes classification even more challenging, defeating established approaches (e.g., Deep Packet Inspection). To this end, in this paper we aim to improve the performance of classification of mobile apps traffic by proposing a multi-classification (viz. fusion) approach, intelligently-combining outputs from state-of-the-art classifiers proposed for mobile and encrypted traffic classification. Under this framework, four classes of different combiners (differing in whether they accept soft or hard classifiers' outputs, the training requirements, and the learning philosophy) are taken into account and compared. The present approach enjoys modularity, as any classifier may be readily plugged-in/out to improve performance further. Finally, based on a dataset of (true) users' activity collected by a mobile solutions provider, our results demonstrate that classification performance can be improved according to all considered metrics, up to +9.5% (recall score) with respect to the best state-of-the-art classifier. The proposed system is also capitalized to validate a novel pre-processing of traffic traces, here developed, and assess performance sensitivity to traffic object (temporal) segmentation, before actual classification.",https://doi.org/10.1016/j.jnca.2017.11.007,https://www.sciencedirect.com/science/article/pii/S1084804517303740,,,,2018,Multi-classification approaches for classifying mobile app traffic,Giuseppe Aceto and Domenico Ciuonzo and Antonio Montieri and Antonio Pescapé,article,ACETO2018131,Journal of Network and Computer Applications,,103,1084-8045,,,
,"melatonin, nucleus accumbens, locomotor activity, grooming, sniffing, serotonin, antidepressant drugs, apomorphine",237-244,,"Small doses of melatonin (0.1–100 ng), injected into the nucleus accumbens of rats, decreased locomotor activity and rearing, and increased grooming and sniffing behaviour when the animals were tested in small test-cages. Larger doses ofmelatonin appeared to be less effective. The action ofmelatonin is apparently not mediated by dopaminergic systems, because the behavioural changes were not antagonized by local pretreatment with haloperidol or sulpiride. Injection of serotonin antagonists (methysergide and cyproheptadine) into the nucleus accumbens resulted in similar behavioural changes as was found after treatment with melatonin. Treatment with serotonin and various antidepressant drugs (zimelidine, mianserin, nortriptyline, clomipramine, desipramine) injected into the nucleus accumbens, completely inhibited the melatonin-induced behavioural responses. The antidepressants did not significantly interfere with the decrease of locomotor activity and rearing induced by injection of small doses of the dopamine agonist, apomorphine, into the nucleus accumbens. p ]These results suggest that there is an interrelationship between melatonin and serotonin systems in the nucleus accumbens and showed that various antidepressant drugs, similar to serotonin, antagonized the behavioural effects of melatonin after injection into the nucleus accumbens.",https://doi.org/10.1016/0028-3908(85)90080-2,https://www.sciencedirect.com/science/article/pii/0028390885900802,,,,1985,Serotonin and antidepressant drugs antagonize melatonin-induced behavioural changes after injection into the nucleus accumbens of rats,Odile Gaffori and J.M. {Van Ree},article,GAFFORI1985237,Neuropharmacology,3,24,0028-3908,,,
,,I-CXXI,,,https://doi.org/10.1016/S2213-1779(23)00123-3,https://www.sciencedirect.com/science/article/pii/S2213177923001233,,,,2023,Full issue PDF,,article,2023I,JACC: Heart Failure,4,11,2213-1779,,,
,"North Cascades, trampling, ordination, dendrochronology, succession",279-287,,"The purpose of this study was to establish what effects soil trampling impacts may have had on tree growth and plant community succession at subalpine elevations in the North Cascade Mountains of Washington. While soil penetrability of an impacted site was not different from that of control sites, other soil characteristics were significantly different. Species diversity was greater at the impacted site, which was characterized by associations between soil characteristics and vegetation that were unlike those found at control sites. Mixed ordination analyses of the floristic and soil data indicated that past trampling impacts on soils may have had long-term effects on the successional development of the plant community. The impact of turn of the century mining operations on tree growth was significant at the time of impact but had no long-term effect after mining activities ceased. Recommendations for the management and reclamation of disturbed sties at subalpine elevations are given.",https://doi.org/10.1016/0006-3207(95)00036-4,https://www.sciencedirect.com/science/article/pii/0006320795000364,,,,1996,Indirect impacts of soil trampling on tree growth and plant succession in the North Cascade Mountains of Washington,Roland C. {de Gouvenain},article,DEGOUVENAIN1996279,Biological Conservation,3,75,0006-3207,,,
Progress in Brain Research,,159-172,Biochemical Basis of Functional Neuroteratology,"Publisher Summary
The purpose of this chapter is to provide foundations for a working hypothesis on drug-induced functional neuroteratology. A class of centrally acting antihypertensive drugs, including clonidine, which are still being prescribed during pregnancy in humans, is used as the model. A hypothesis is put forward in this chapter which proposes that behavioral state-dependent changes in monoaminergic neuronal firing levels and patterns play a key role during early ontogeny in regulating neuron membrane potential, neurotransmitter release and neurotransmitter receptor sensitivity patterns in adulthood. Neurons show spontaneous activity that varies as a function of the behavioral state of the organism. This has been demonstrated for noradrenergic neurons of the locus coeruleus (LC), serotonergic neurons of the dorsal raphe (DR), dopaminergic neurons of the substantia nigra (SN) and cholinergic neurons of the dorsolateral part of the pons and basal forebrain. Because centrally acting antihypertensives predominantly affect the noradrenaline (NA) system in the brain, the induced modifications of central NA neurotransmission is also emphasized in this chapter.",https://doi.org/10.1016/S0079-6123(08)60503-8,https://www.sciencedirect.com/science/article/pii/S0079612308605038,,Elsevier,,1988,Functional deprivation of noradrenaline neurotransmission: effects of clonidine on brain development,Majid Mirmiran and Matthijs G.P. Feenstra and Fred A. Dijcks and Nico P.A. Bos and Frans {Van Haaren},incollection,MIRMIRAN1988159,,,73,0079-6123,,G.J. Boer and M.G.P. Feenstra and M. Mirmiran and D.F. Swaab and F. {Van Haaren},
,,245-255,,"The density and configuration of the basal ganglia were analyzed on 1000 consecutive cranial computed tomography (CCT) scans performed both with and without contrast enhancement. At our standard window width (150 H) and window level (30 H), visibly increased attenuation in the arus of the basal ganglia was apparent in 5.2% of all scans examined. A statistically significant difference in attenuation between these subcortical gray nuclei and adjacent white matter was detected by computer analysis of numerical printouts even though this difference was often not visually perceptible on our first generation-type CCT scanner. Slight, but statistically significant increased attenuation occurs with contrast enhancement and affects both the basal ganglia and surrounding white matter. Three thousand consecutive CCT scans were reviewed; of these, 61 cases had lesions primarily involving the basal ganglia. Cases representative of typical abnormalities are described and discussed.",https://doi.org/10.1016/0149-936X(77)90033-9,https://www.sciencedirect.com/science/article/pii/0149936X77900339,,,,1977,The basal ganglia on cranial computed tomography: Normal anatomy and pathology,Anne G. Osborn and Terrence Saville,article,OSBORN1977245,Journal of Computed Tomography,4,1,0149-936X,,,
,,136-137,,,https://doi.org/10.1016/S0016-0032(32)91838-9,https://www.sciencedirect.com/science/article/pii/S0016003232918389,,,,1832,Manufacture of salt,,article,1832136,Journal of the Franklin Institute,2,14,0016-0032,,,
The Morgan Kaufmann Series in Networking,,503-516,Telecommunications Law in the Internet Age,,https://doi.org/10.1016/B978-155860546-6/50043-0,https://www.sciencedirect.com/science/article/pii/B9781558605466500430,San Francisco,Morgan Kaufmann,,2002,Index,,incollection,2002503,,,,18759351,,Sharon K. Black,
,"corneal epithelium, trigeminal ganglion, corneal nerve, nerve regeneration, trophic factor, corneal wound healing, organ culture",633-646,,"Epithelial neuronotropic factor (ENF) is secreted by cultured epithelial cells of rabbit cornea and conjunctiva, and is active in promoting survival and inducing neurite outgrowth of cultured trigeminal neurons. This study evaluated the relation of ENF to corneal nerve regeneration utilizing a model of heptanol-induced epithelial wounding. The organ culture technique was used to collect ENF from the intact corneal epithelium, and a neuronal bioassay was utilized to quantify ENF. The results revealed no change in ENF secretion either during initial wound closure or after 1 week, when the epithelium had regenerated. However, ENF secretion was elevated 2·4 times in 2 weeks after wounding. Morphometric analysis of corneal nerves stained by gold chloride impregnation showed that the first sign of regeneration of intraepithelial nerves was observed after 2 weeks, and the normal pattern of epithelial neural density was re-established after 3 weeks. However, the neural density was still subnormal (35–47% less than the control) in the wounded epithelium up to 4 weeks after wounding. Thus it appears that a surge in ENF secretion occurred after epithelial regeneration but before nerve regeneration. The results suggest that ENF may mediate corneal nerve regeneration.",https://doi.org/10.1016/S0014-4835(87)80112-4,https://www.sciencedirect.com/science/article/pii/S0014483587801124,,,,1987,Release of neuronotrophic factor from rabbit corneal epithelium during wound healing and nerve regeneration,Kwan Y. Chan and Robert R. Jones and Don H. Bark and Jay Swift and James A. Parker and Richard H. Haschke,article,CHAN1987633,Experimental Eye Research,5,45,0014-4835,,,
,"emic developmental issues, immigration, mestizaje, generation., componentes émicos del desarrollo, generación, inmigración, mestizaje.",291-303,,"In order for the field of psychology in the United States to maintain its relevance and validity, it must become more inclusive in its theory and research of Latinos, who are now the largest “minority” group in the nation. In particular, due to immigration and birth rates, Mexican Americans are the largest and fastest growing segment of the Latino population. This paper addresses some of the most significant historical and socio-cultural factors contributing to the psychological nature and wellbeing of Mexican Americans. These factors should be understood and used to guide research and theory in order to make the discipline of psychology relevant for Mexican Americans. The concept of mestizaje is used to explain the biological and cultural mixing constituting the diverse origins of the Mexican people. Immigration to the U.S. is described in terms of selective socio-cultural variables giving rise to a diverse Mexican American culture that is resistant to complete assimilation. Within a U.S. context, the constructs of generational status, acculturation, and biculturalism are used to explain the socio-cultural adaptation of Mexican Americans. The special role of children in immigrant families as language and cultural brokers are also discussed, and used to explain the adjustment of Mexican American families.
Resumen
Para que el campo de la Psicología en los Estados Unidos siga manteniendo su relevancia y validez, debe incluir en mayor medida, tanto en su teoría como en la investigación práctica, a las poblaciones hispanas, grupo que en la actualidad compone la “minoría” más numerosa de la nación. En concreto, debido a la inmigración y las tasas de natalidad, los mexicano-estadounidenses son el segmento más amplio y de mayor crecimiento dentro de la población hispana. El presente artículo aborda algunos de los factores históricos y socio-culturales más significativos en la naturaleza y bienestar psicológico de los mexicanoestadounidenses. Estos factores deben ser comprendidos y utilizados como guía en la investigación y el desarrollo teórico para que la disciplina de psicología incluya a la población mexicano-estadounidense. Se emplea el concepto de mestizaje para explicar la mezcolanza biológica y cultural que da pie a la diversidad de orígenes de la población mejicana. Se describe la inmigración a los EEUU en base a variables socioculturales selectivas que conforman una cultura mexicano-estadounidense diversa que se resiste a una total asimilación. Dentro del contexto norteamericano, los constructos de estatus generacional, aculturación y bi-culturalismo son utilizados para explicar la adaptación socio-cultural de los mexicano-estadounidenses. También se aborda el papel especial que desempeñan los niños de familias inmigrantes en cuanto al idioma y la cultura y su importancia en el proceso de adaptación de las familias mexicano-estadounidenses.",https://doi.org/10.5093/in2012a26,https://www.sciencedirect.com/science/article/pii/S1132055912700844,,,,2012,"Historical, Socio-Cultural, and Conceptual Issues to Consider When Researching Mexican American Children and Families, and other Latino Subgroups*",Raymond Buriel,article,BURIEL2012291,Psychosocial Intervention,3,21,1132-0559,,,
,"Software engineering process, Traceability, Developer support, Quality assurance, Process deviation, Constraint checking",111727,,"When dealing with safety–critical systems, various regulations, standards, and guidelines stipulate stringent requirements for certification and traceability of artifacts, but typically lack details with regards to the corresponding software engineering process. Given the industrial practice of only using semi-formal notations for describing engineering processes – with the lack of proper tool mapping – engineers and developers need to invest a significant amount of time and effort to ensure that all steps mandated by quality assurance are followed. The sheer size and complexity of systems and regulations make manual, timely feedback from Quality Assurance (QA) engineers infeasible. In order to address these issues, in this paper, we propose a novel framework for tracking, and “passively” executing processes in the background, automatically checking QA constraints depending on process progress, and informing the developer of unfulfilled QA constraints. We evaluate our approach by applying it to three case studies: a safety–critical open-source community system, a safety–critical system in the air-traffic control domain, and a non-safety–critical, web-based system. Results from our analysis confirm that trace links are often corrected or completed after the work step has been considered finished, and the engineer has already moved on to another step. Thus, support for timely and automated constraint checking has significant potential to reduce rework as the engineer receives continuous feedback already during their work step.",https://doi.org/10.1016/j.jss.2023.111727,https://www.sciencedirect.com/science/article/pii/S016412122300122X,,,,2023,ProCon: An automated process-centric quality constraints checking framework,Christoph Mayr-Dorn and Michael Vierhauser and Stefan Bichler and Felix Keplinger and Jane Cleland-Huang and Alexander Egyed and Thomas Mehofer,article,MAYRDORN2023111727,Journal of Systems and Software,,202,0164-1212,,,
,,205-217,,,https://doi.org/10.1016/0144-8617(90)90031-M,https://www.sciencedirect.com/science/article/pii/014486179090031M,,,,1990,Bibliography on carbohydrate polymers,,article,1990205,Carbohydrate Polymers,2,14,0144-8617,,,
,", measured, deduced, Inverse kinematics scattering method with secondary radioactive beam and FRS fragment separator",8-28,,"In the present work, the differential cross sections for small-angle proton elastic scattering on the 12,14Be nuclei were measured in inverse kinematics, using secondary radioactive beams with energies near 700 MeV/u produced with the fragment separator FRS at GSI. The main part of the experimental setup was the active target IKAR, which was used simultaneously as a target and a detector for the recoil protons. Auxiliary detectors for projectile tracking and isotope identification completed the setup. The measured differential cross sections were analyzed using the Glauber multiple-scattering theory. For the evaluation of the data several phenomenological nuclear-matter density parametrizations and a sum of Gaussian parametrization were used. The nuclear-matter radii and radial density distributions of the isotopes 12,14Be were deduced. Extended nuclear-matter density distributions were observed in both isotopes, and the halo structure of 14Be was confirmed. The results were also compared with microscopic few-body and fermionic molecular dynamics model calculations concerning the structure of these neutron-rich nuclei.",https://doi.org/10.1016/j.nuclphysa.2011.11.010,https://www.sciencedirect.com/science/article/pii/S037594741100666X,,,,2012,"Nuclear-matter density distribution in the neutron-rich nuclei 12,14Be from proton elastic scattering in inverse kinematics",S. Ilieva and F. Aksouh and G.D. Alkhazov and L. Chulkov and A.V. Dobrovolsky and P. Egelhof and H. Geissel and M. Gorska and A. Inglessi and R. Kanungo and A.V. Khanzadeev and O.A. Kiselev and G.A. Korolev and X.C. Le and Yu.A. Litvinov and C. Nociforo and D.M. Seliverstov and L.O. Sergeev and H. Simon and V.A. Volkov and A.A. Vorobyov and H. Weick and V.I. Yatsoura and A.A. Zhdanov,article,ILIEVA20128,Nuclear Physics A,,875,0375-9474,,,
,"Android apps, Android antimalware apps, Malicious app detection, Mobile malware apps, Mobile threats",167-203,Mobile Security and Privacy,"With the increasing popularity of Android devices and the number of malware apps targeting them, ensuring the security and privacy of user data and preventing the device from being compromised are of paramount importance. In this chapter, we survey Android-related security risks and vulnerabilities, as well as conduct a systematic evaluation of 15 popular free antimalware apps using 11 known malware samples collected between Feb. 27, 2014 and Aug. 3, 2014 from the Contagio Mobile Malware Mini Dump database. By conducting a manual experiment to replicate potential day-to-day threats to users unknowingly installing malicious apps (i.e., malware samples), the evaluation produced results that varied significantly across all three Android operating systems and hardware test devices. We hope the findings will contribute to a better understanding of the effectiveness and reliability of such apps for Android devices, as well as improved antimalware apps and detection rates.",https://doi.org/10.1016/B978-0-12-804629-6.00008-0,https://www.sciencedirect.com/science/article/pii/B9780128046296000080,Boston,Syngress,978-0-12-804629-6,2017,Chapter 8 - A Study of the Effectiveness Abs Reliability of Android Free Anti-Mobile Malware Apps,J. Walls and K.-K.R. Choo,incollection,WALLS2017167,,,,,,Man Ho Au and Kim-Kwang Raymond Choo,
,"Stratigraphy, Data system, Subsurface geology",395-427,,"Stratigraphic Analysis System (SAS) is an on-line, interactive data-base analysis system designed for use in a subsurface laboratory. The program is written in FORTRAN and ALGOL W and presently runs under the Michigan Terminal System at the University of Michigan. The SAS system was designed to overcome several problems in geological data-base systems. Both data discontinuities and substring indexing have been considered as well as three-dimensional location of information. The system consists of four procedures; the command processor, the user aid package, the data-set loader and general data processors. The data set is composed of hierarchical records in a one-dimensional array which consists of logical flags to index an internal dictionary. Presently output contains well listings, well displays, data editing and data search capabilities.",https://doi.org/10.1016/0098-3004(77)90017-6,https://www.sciencedirect.com/science/article/pii/0098300477900176,,,,1977,Stratigraphic analysis system: SAS,Brian R. Shaw and Richard Simms,article,SHAW1977395,Computers & Geosciences,3,3,0098-3004,,,
,,603-625,Microsoft Vista for IT Security Professionals,,https://doi.org/10.1016/B978-159749139-6/50017-0,https://www.sciencedirect.com/science/article/pii/B9781597491396500170,Burlington,Syngress,978-1-59749-139-6,2007,Index,,incollection,2007603,,,,,,Anthony Piltzecker,
,,395-409,Software Defined Networks (Second Edition),,https://doi.org/10.1016/B978-0-12-804555-8.09984-1,https://www.sciencedirect.com/science/article/pii/B9780128045558099841,Boston,Morgan Kaufmann,978-0-12-804555-8,2017,Index,,incollection,2017395,,,,,,Paul Göransson and Chuck Black and Timothy Culver,Second Edition
,,249-267,,,https://doi.org/10.1016/S0733-8627(20)30712-4,https://www.sciencedirect.com/science/article/pii/S0733862720307124,,,,1992,"Venomous Snakebites: Current Concepts in Diagnosis, Treatment, and Management",Barry S. Gold and Robert A. Barish,article,GOLD1992249,Emergency Medicine Clinics of North America,2,10,0733-8627,,,
,"Cell-surface adhesion, plant cells, ionic strength",318-324,,"The correlation between the effects of pH, ionic strength and cation valency on the electrophoretic mobility and the extent of adhesion of suspension-cultured Catharanthus roseus cells to various polymer substrates is presented. The electrophoretic mobility of cells was unaltered in the pH range of 6–8, but decreased from approximately −2.2 × 10−8 m V−1 s−1 and approached zero as the pH of the suspending liquid was decreased from 6 to 2. Similarly, the value of electrophoretic mobility decreased continuously as the ionic strength was increased from 0 to 1.0 M when cells were suspended in salt solutions of sodium chloride, calcium chloride, and aluminium chloride. However, using equimolar concentrations, the slope of the decrease in electrophoretic mobility increased following the sequence sodium chloride < calcium chloride < aluminium chloride. The electrophoretic mobility was near zero for suspensions containing 1.0 M calcium chloride or 0.1 M aluminium chloride. The extent of adhesion of the cells to the polymers sulphonated polystyrene < polyethylene terephthalate < polystyrene < fluorinated ethylene-propylene followed this sequence. These results agree with a thermodynamic model of plant cell adhesion that implicates the importance of interfacial tensions in the adhesion process. However, higher levels of adhesion were generally observed when the electrophoretic mobility for the cells in the corresponding test liquid was at a minimum absolute value. These results can be explained by considering the effects of the electrolytic properties of the suspending liquid on the electrostatic repulsive interactions between the cells and the polymer surface in terms of a double-layer phenomenon and the DLVO theory. Consideration of results presented here along with kinetic studies of plant cell adhesion indicates that cell-cell, rather than cell-substrate repulsion, may play the more important role in modifying the extent of adhesion.",https://doi.org/10.1016/0142-9612(89)90072-0,https://www.sciencedirect.com/science/article/pii/0142961289900720,,,,1989,"Adhesion of suspension-cultured Catharanthus roseus cells to surfaces: effect of pH, ionic strength, and cation valency",Peter J. Facchini and A. {Wilhelm Neumann} and Frank DiCosmo,article,FACCHINI1989318,Biomaterials,5,10,0142-9612,,,
,,615-627,,"Megestrol acetate (MA), d-norgestrel (d-Ng), and norethindrone (NET) contained in Silastic capsules were implanted under the skin for clinical evaluation as a longterm contraceptive in women. 1509 woman-months of exposure and 4 pregnancies were recorded within the first twelve months of use in 135 women who received 6 MA implants. 1049 woman-months and 19 pregnancies were recorded within the first twelve months of use in 131 women who received 4 d-Ng implants. After twelve months use, the implants were replaced with a new set of capsules. The contraceptive effectiveness of the second and subsequent set of implants was similar to that of the first. Five NET implants failed completely to prevent pregnancy and 4 MA implants combined with 2 d-Ng implants were as effective as 6 MA implants. Other doses tested were: 5 MA, 3 d-Ng, and 4 MA plus 1 d-Ng. They were significantly less effective than the higher doses. No adverse effect upon the outcome of unplanned pregnancies was noted and prompt recovery of fertility was observed after termination of treatment. Ovulation took place in most cycles of women treated with 5 or 6 MA implants, as judged from the occurrence of LH peak in urine, pregnanediol excretion, changes of cervical mucus, BBT, and endometrial biopsy. Intermenstrual bleeding was by far the most common side effect recorded. Initially, it occurred in about 30 % of the cycles, but the incidence decreased gradually and by the end of the second year, it was below 10 %. Adnexal complications were observed in some of the treatment groups.",https://doi.org/10.1016/S0010-7824(75)80045-X,https://www.sciencedirect.com/science/article/pii/S001078247580045X,,,,1975,"Clinical assessment of subdermal implants of megestrol acetate, d-norgestrel, and norethindrone as a longterm contraceptive in women",H.B. Croxatto and S. Díaz and E. Quinteros and L. Simoneti and E. Kaplan and R. Rencoret and P. Leixelard and C. Mártinez,article,CROXATTO1975615,Contraception,6,12,0010-7824,,,
,,2012-2022,,"Tissue levels of n-3 fatty acids reflect dietary intake, but quantitative data about rate of incorporation and levels as a function of intake are scarce. We fed 58 men 0, 3, 6, or 9 g/d of fish oil for 12 months and monitored fatty acids in serum cholesteryl esters, erythrocytes, and subcutaneous fat during and after supplementation. Eicosapentaenoic acid (EPA) in cholesteryl esters plateaued after 4-8 weeks; the incorporation half-life was 4.8 days. Steady-state levels increased by 3.9 +/- 0.3 mass ﹪ points (+/- SE) for each extra gram of EPA eaten per day. Incorporation of docosahexaenoic acid (DHA) was erratic; plateau values were 1.1 +/- 0.1 mass ﹪ higher for every g/d ingested. Incorporation of EPA into erythrocyte membranes showed a half-life of 28 days; a steady state was reached after 180 days. Each g/d increased levels by 2.1 +/- 0.1 mass ﹪. C22:5n-3 levels increased markedly. Changes in DHA were erratic and smaller. EPA levels in adipose tissue rose also; the change after 6 months was 67﹪ of that after 12 months in gluteal and 75﹪ in abdominal fat. After 12 months each gram per day caused an 0.11 +/- 0.01 mass ﹪ rise in gluteal fat for EPA, 0.53 +/- 0.07 for C22:5n-3, and 0.14 +/- 0.03 for DHA. Thus, different (n-3) fatty acids were incorporated with different efficiencies, possibly because of interconversions or different affinities of the enzymatic pathways involved. EPA levels in cholesteryl esters reflect intake over the past week or two, erythrocytes over the past month or two, and adipose tissue over a period of years. These findings may help in assessing the intake of (n-3) fatty acids in epidemiological studies.",https://doi.org/10.1016/S0022-2275(20)37132-7,https://www.sciencedirect.com/science/article/pii/S0022227520371327,,,,1997,"Kinetics of the incorporation of dietary fatty acids into serum cholesteryl esters, erythrocyte membranes, and adipose tissue: an 18-month controlled study",M B Katan and J P Deslypere and A P {van Birgelen} and M Penders and M Zegwaard,article,KATAN19972012,Journal of Lipid Research,10,38,0022-2275,,,
,,I-CLXXIX,,,https://doi.org/10.1016/S2452-302X(24)00173-6,https://www.sciencedirect.com/science/article/pii/S2452302X24001736,,,,2024,Full Issue PDF,,article,2024I,JACC: Basic to Translational Science,5,9,2452-302X,,,
,,171-178,,"African catfish (Mystus vittatus) were exposed to three sub-lethal concentrations of Swascofix E45 (13.8, 9.2 and 4.6 mg/l) and Swascol 3L (69.3, 46.2 and 23.1 mgl) for 15 and 30 days, and their effects on alkaline and acid phosphatase,, and succinic dehydrogenase in liver, kidney and intestine were measured. The enzymes were found to be inhibited in all the tissues. Maximum inhibition (38.44%) was observed in liver alkaline phosphatase activity after 30 days with the highest concentration of Swascofix E45 and the lowest inhibition (0.118%) was found in kidney acid phosphatase activity with the lowest concentration of Swascol 3L after 15 days. Insignificant enzyme stimulation in some cases was also observed.",https://doi.org/10.1016/0378-4274(81)90046-1,https://www.sciencedirect.com/science/article/pii/0378427481900461,,,,1981,Effects of synthetic detergents on in vivo activity of tissue phosphatases and succinic dehydrogenase from Mystus vittatus,D. Mohan and S.R. Verma,article,MOHAN1981171,Toxicology Letters,3,8,0378-4274,,,
,,2887-2900,,"The ReOs system for samples of FeNi, sulphide, and phosphide from iron meteorites was investigated. Techniques were developed which yield reproducible analyses for Re/Os at the 2%‰ level and which permit complete isotopic exchange between sample and tracer, as is necessary for concentration measurements of Re and Os by isotope dilution. High precision osmium and rhenium isotope data have been obtained using negative ion thermal ionization, with ionization efficiencies of up to 10% for Os and 20% for Re, both for normals and for Re and Os extracted from the samples. Replicate analyses of Re/Os are in good agreement, within ±2.5%o. The results show a well defined correlation line on a 187Re-187Os evolution diagram for iron meteorites from groups IAB, IIAB, IIIAB, IVA, and IVB, all taken together. This correlation line yields a slope of 0.07863 ± 0.00031 (2σ) and initial 187Os/188Os = 0.09560 ± 0.00018 (2σ). If the individual groups of iron meteorites for which there is sufficient dispersion in Re/Os are considered, data on the IIAB and on the IVA irons appear to indicate a difference in age of 60 ± 45 Ma, with the IVA group being older. This age difference is qualitatively the same as obtained for PdAg data but is larger. Sulphides from two IAB iron meteorites show extremely low concentrations of Re and Os and indicate that Re and Os are not partitioned into this phase during planetary differentiation. There is evidence for recent element remobilization or contamination, corresponding to relative enrichment of Re or loss of Os in the sulphides. Schreibersites contain small but significant amounts of Re and Os, with high Re/Os relative to the metal phases and with 187Os/188Os much more radiogenic than in the metal. Model ages for the Schreibersites are relatively young (4.3–3.5 AE) and indicate that the Schreibersites were open-systems for ReOs at least 0.5–1 AE after the original formation of the iron meteorites. It now appears possible to use metal- schreibersite pairs to determine internal isochrons. Based on the schreibersite model ages, the cooling rates for the two IAB meteorites are estimated to be ∼ 1°C/Ma, more than an order of magnitude lower than the most recently determined metallographic cooling rates for IAB irons (Herpfer et al., 1994).",https://doi.org/10.1016/0016-7037(96)00120-2,https://www.sciencedirect.com/science/article/pii/0016703796001202,,,,1996,Precise ReOs determinations and systematics of iron meteorites,J.J. Shen and D.A. Papanastassiou and G.J. Wasserburg,article,SHEN19962887,Geochimica et Cosmochimica Acta,15,60,0016-7037,,,
,,387-400,,"Summary
Within the regions studied deposits are to be found in the whole area between the Pleistocene marine terraces — situated only a few meters above sea-level — and the limit of the Pleistocene glaciations. These deposits can be interpreted as glacial frost-climate formations. Whilst in higher altitudes indications of great mass-movements were found, above all solifluction mantles, in middle altitudes formations of increased wash-off become prominent. In basin-areas, which are situated in the proximity of the sea, the accumulation of loess prevailed. On the basis of the data available at present, the greatest part of these formations appears to belong to the last glaciation (Wuerm). In some localities, however, deposits were found, which are likely to originate from older glaciations.
Zusammenfassung
In den untersuchten Gebieten kommen im gesamten Bereich zwischen den nur wenige Meter über dem Meeresspiegel liegenden pleistozänen marinen Terrassen und der Grenze der pleistozänen Vergletscherungen Ablagerungen vor, die als kaltzeitliche frostklimatische Bildungen gedeutet werden können. Während in den höheren Lagen Anzeichen starker Massenbewegungen, vor allem Solifluktionsdecken gefunden wurden, treten in einem mittleren Höhengürtel Bildungen verstärkter Abspülung in den Vordergrund. In den meernahen Beckenlagen dominierte die Löß-Akkumulation. Aufgrund der gegenwärtig verfügbaren Daten scheint der größte Teil dieser Bildungen in die letzte Kaltzeit (Würm) zu gehören. An einigen Stellen sind jedoch auch Ablagerungen gefunden worden, die wohl in älteren Kaltzeiten entstanden sind.",https://doi.org/10.1016/S0341-8162(73)80020-7,https://www.sciencedirect.com/science/article/pii/S0341816273800207,,,,1973,Pleistozäne Kaltzeitliche Ablagerungen In Der Sila Und Basilicata (Süd-Italien),Friderun Fuchs and Arno Semmel,article,FUCHS1973387,CATENA,,1,0341-8162,,,
,,100313,,,https://doi.org/10.1016/j.fsisyn.2022.100313,https://www.sciencedirect.com/science/article/pii/S2589871X22000985,,,,2023,Interpol review of digital evidence for 2019–2022,Paul Reedy,article,REEDY2023100313,Forensic Science International: Synergy,,6,2589-871X,,,
,"Functional teratology, Neurobehavioral development, Open-field behavior, Motor coordination, Learning, Styrene, Prenatal exposure",121-130,,"Maternal Wistar rats were exposed via inhalation to 0, 50, or 300 ppm styrene for 6 h/day during gestation days 7 to 21, and offspring were subsequently evaluated in several neurobehavioral tests. Preliminary results with a small number of litters revealed significant dose-dependent effects in tests performed prior to weaning (surface righting, pivoting locomotion, and bar holding), as well as in tests performed after weaning (motor coordination, open-field behavior, and motor activity). Exposure to low concentrations of styrene (50 ppm) caused disturbances in motor coordination in addition to delaying some motor and reflex developments. Large doses (300 ppm) led to changes in open-field behavior and increases in spontaneous activity in addition to the delay in neurobehavioral developments. Exposure of dams to styrene did not clearly affect the learning behavior of the offspring. It was also observed that age played a role in the differences in styrene's effects on neurobehavioral function. Only subtle effects were found in both open-field behavior and motorcoordination function when compared with control rats at 120 days of age. These results suggest that the functional neurobehavioral development of progeny of dams exposed to styrene (or other solvents) should be further investigated.",https://doi.org/10.1016/0892-0362(94)00060-Q,https://www.sciencedirect.com/science/article/pii/089203629400060Q,,,,1995,"Effect of prenatal exposure to styrene on the neurobehavioral development, activity, motor coordination, and learning behavior of rats",Reiko Kishi and Bing Qing Chen and Yohko Katakura and Toshiko Ikeda and Hirotsugu Miyake,article,KISHI1995121,Neurotoxicology and Teratology,2,17,0892-0362,,,
,"Lipoprotein lipase, Tumor necrosis factor, Lipopolysaccharide, Macrophage, (Rat heart cell culture)",220-228,,"Exposure of rat heart cell cultures, consisting mainly of nonbeating mesenchymal cells, to 50 ng/ml of bacterial lipopolysaccharide (LPS) for 24 h resulted in a more than 80% reduction in lipoprotein lipase activity. The loss of enzymic activity was accompanied by a concomitant reduction in enzyme protein, as shown by inununoblotting. Addition of LPS to the culture medium resulted also in the production of tumor necrosis factor (TNT), and the fall in lipoprotein lipase in LPS-treated cultures could be prevented by an antibody to TNF. Addition of recombinant human TNF to the heart cell cultures also depressed lipoprotein lipase activity. LPS treatment of preadipocytes in culture resulted in a fall in lipoprotein lipase activity and TNF production. Since TNF is known as a macrophage product, the cultures were tested for phagocytic capacity, and only 0.2–1.3% of the cells were shown to engulf Staphylococcus albus. Immunofluorescent staining with monoclonal antibodies OX-1, which identify leukocyte common antigen, was negative, and only 0.1 ± 0.07% of the cells were positive after staining with OX-42 antibody to iC3 receptor. Both antibodies stained more than 98% of rat peritoneal macrophages used as controls. Since LPS treatment of macrophages at numbers comparable to or exceeding the number of phagocytic cells present in the heart cell cultures did not induce measurable amounts of TNF, it is suggested that in the heart cell cultures, TNF may be produced by cells other than macrophages.",https://doi.org/10.1016/0005-2760(88)90067-7,https://www.sciencedirect.com/science/article/pii/0005276088900677,,,,1988,Lipoprotein lipase in heart cell cultures is suppressed by bacterial lipopolysaccharide: an effect mediated by production of tumor necrosis factor,G. Friedman and R. Gallily and T. Chajek-Shaul and O. Stein and E. Shiloni and J. Etienne and Y. Stein,article,FRIEDMAN1988220,Biochimica et Biophysica Acta (BBA) - Lipids and Lipid Metabolism,2,960,0005-2760,,,
,,513-519,,"Basic equations of the theory of elasticity are given in a semi-orthogonal curvilinear coordinate system in which one of the families of the coordinate surfaces is parallel to the middle surface of the shell. Symbolic notation of Lur'e /1/ is used to obtain a solution of the problem of the theory of elasticity for a shell, in terms of a series in powers of the normal coordinate. The solution is then used to reduce the three-dimensional problem to two dimensions and to express all characteristic features of the stress and deformation states of the shell in terms of six functions, namely the coordinates of the displacement and stress vectors defined on the middle surface. Use of the first two terms of the series obtained yields an applied theory free of any hypotheses and intended for removing the external load from the front surface of the shell. A similar approach to the problem of constructing applied theories was first used in /2–4/ which made wide use of the resources of tensor analysis.",https://doi.org/10.1016/0021-8928(80)90043-X,https://www.sciencedirect.com/science/article/pii/002189288090043X,,,,1980,Construction of refined applied theories for a shell of arbitrary shape,N.A. Bazarenko,article,BAZARENKO1980513,Journal of Applied Mathematics and Mechanics,4,44,0021-8928,,,
,,1873-1880,,"A block synthesis of the model compound for the phytoalexin elicitor-active glycoprotein is described. Combination of the C-terminus free compounds, N-(9-fluorenylmethoxycarbonyl)-O-(tert-butyl)-l-seryl-l-proline (1) or N-(9-fluorenylmethoxycar bonyl)-(2,3,4,6-tetra-O-acetyl-β-d-glucopyranosyl)-(1→ 6)-(2,3,4-tri-O-acetyl-α-d-mannopyranosyl)-(1→ 6)-(2,3,4-tri-O-acetyl-α-d-mannopyranosyl)-l-seryl-l-proline (2) with the N-terminus free compounds, 2,3,4,6-tetra-O-acetyl-β-d-glucopyranosyl(1→6)-(2,3,4-tri-O-acetyl-α-d- mannopyranosyl)-(1→6)-(2,3,4-tri-O-acetyl-α-d-mannopyranosyl)-l-seryl-l- prolyl-l-seryl-l-proline methyl ester (4), O-(tert-butyl)-l-seryl-l-prolyl-(2,3,4,6-tetra-O-acetyl- β-d-glucopyranosyl)- (1→6)-(2,3,4-tri-O-acetyl-α-d-mannopyranosyl)-(1→6)-(2,3,4-tri-O- acetyl-α-d-mannopyranosyl)-l-seryl-l-proline methyl ester (6) or 2,3,4,6-tetra-O-acetyl-β-d-glucopyranosyl-(1→6)-(2,3,4-tri-O-acetyl-α-d- mannopyranosyl)-(1→6)-(2,3,4-tri-O-acetyl-α-d- mannopyranosyl)-l-seryl-l-prolyl-(2,3,4,6-tetra-O-acetyl-β-d-glucopyranosyl)-(1→6)-(2,3,4-tri-O- acetyl-α-d-mannopyranosyl)-(1→6)-(2,3,4-tri- O-acetyl-α-d-mannopyranosyl)-l-seryl-l-proline methyl ester (8), by use of N-ethoxycarbonyl-2-ethoxy-1,2-dihydroquinoline (EEDQ) gave three hexaglycosyl hexapeptides and a nonaglycosyl hexapeptide derivatives (9, 11, 14, and 17). These N-terminus free compounds were derived from triglycosyl tetrapeptides (3, and 5) or a hexaglycosyl tetrapeptide (7) on selective deblock reaction by morpholine. The hexaglycosyl hexapeptides (10, 13, and 16) and the nonaglycosyl hexapeptide (18) have been prepared by the convergent block synthesis.",https://doi.org/10.1016/S0968-0896(96)00170-8,https://www.sciencedirect.com/science/article/pii/S0968089696001708,,,,1996,Synthesis of glycopeptides with phytoalexin elicitor activity — III. Syntheses of hexaglycosyl hexapeptides and a nonaglycosyl hexapeptide,Tadahiro Takeda and Takuya Kanemitsu and Yukio Ogihara,article,TAKEDA19961873,Bioorganic & Medicinal Chemistry,11,4,0968-0896,,,
,,A109-A182,Designing and Building Enterprise DMZs,,https://doi.org/10.1016/B978-159749100-6.50018-4,https://www.sciencedirect.com/science/article/pii/B9781597491006500184,Burlington,Syngress,978-1-59749-100-6,2006,Appendix B - Testing the DMZ,,incollection,2006A109,,,,,,Ido Dubrawsky and C. {Tate Baumrucker} and James Caesar and Mohan Krishnamurthy and Thomas W. Shinder and Becky Pinkard and Eric Seagren and Laura Hunter,
,,58-61,,,https://doi.org/10.1016/0031-9163(65)91128-5,https://www.sciencedirect.com/science/article/pii/0031916365911285,,,,1965,Two-pion decay of K20 at 10 GeV/c,X. {De Bouard} and D. Dekkers and B. Jordan and R. Mermod and T.R. Willitts and K. Winter and P. Scharff and L. Valentin and M. Vivargent and M. Bott-Bodenhausen,article,DEBOUARD196558,Physics Letters,1,15,0031-9163,,,
,,321-337,,,https://doi.org/10.1016/0144-8617(89)90071-4,https://www.sciencedirect.com/science/article/pii/0144861789900714,,,,1989,Bibliography on carbohydrate polymers,,article,1989321,Carbohydrate Polymers,4,10,0144-8617,,,
,,267-274,,"An empirical model of Skeletonema costatum photosynthetic rate is developed and fit to measurements of photosynthesis selected from the literature. Because the model acknowledges existence of: 1) a light-temperature interaction (by allowing optimum irradiance to vary with temperature), 2) light inhibition, 3) temperature inhibition, and 4) a salinity effect, it accurately estimates photosynthetic rates measured over a wide range of temperature, light intensity, and salinity. Integration of predicted instantaneous rate of photosynthesis with time and depth yields daily net carbon assimilation (pg C cell−1 day−1) in a mixed layer of specified depth, when salinity, temperature, daily irradiance and extinction coefficient are known. The assumption of constant carbon quota (pg C cell−1) allows for prediction of mean specific growth rate (day−1), which can be used in numerical models of Skeletonema costatum population dynamics. Application of the model to northern San Francisco Bay clearly demonstrates the limitation of growth by low light availability, and suggests that large population densities of S. costatum observed during summer months are not the result of active growth in the central deep channels (where growth rates are consistently predicted to be negative). But predicted growth rates in the lateral shallows are positive during summer and fall, thus offering a testable hypothesis that shoals are the only sites of active population growth by S. costatum (and perhaps other neritic diatoms) in the northern reach of San Francisco Bay.",https://doi.org/10.1016/0309-1708(78)90040-4,https://www.sciencedirect.com/science/article/pii/0309170878900404,,,,1978,"Empirical model of Skeletonema costatum photosynthetic rate, with applications in the San Francisco Bay estuary",James E. Cloern,article,CLOERN1978267,Advances in Water Resources,5,1,0309-1708,,,
,,163-176,,"The first part of this presentation considers some of the complexities of parasitic infections and parasite-specific effector mechanisms which have hampered the development of practical methods of immunisation against parasitic diseases. In the second part, an outline is given of the effector mechanisms involved in immunity of cattle to the protozoan parasite Theileria parva. Parasites are antigenically complex organisms which often have distinct developmental stages, sometimes with different predilection sites within the host. Antigenic polymorphism between strains is a common feature of parasites and sometimes results in strain-specific immunity. Certain parasites have also evolved mechanisms of modulating surface antigens which allow them to escape host effector mechanism. Effector mechanisms which control parasitic infections may operate by preventing establishment of the parasites, by eliminating the parasites once they have established or by affecting growth or fecundity of the parasites. In addition to specific antibody and cell-mediated immune responses, inflammatory or physiological responses play an important role in the control of some parasites. Current evidence suggests that effector mechanisms against T. parva parasites operate at two levels. First, antibodies produced against the infective stage of the parasite, the sporozoite, can, by neutralising infectivity, reduce the numbers of organisms which establish in the host. Second, cytotoxic T cells directed against parasitised lymphoblasts cause destruction of parasites following their establishment in the host. Moreover, in situations where immunity is parasite strain-specific, the cytotoxic T cell responses have also been found to be strain-specific. The elucidation of these effector mechanisms has indicated potential new strategies of immunisation against T.parva.",https://doi.org/10.1016/0304-4017(87)90102-6,https://www.sciencedirect.com/science/article/pii/0304401787901026,,,,1987,Host effector mechanisms against parasites,W.I. Morrison,article,MORRISON1987163,Veterinary Parasitology,2,25,0304-4017,,,
,"urinary calculi, ureteral calculi, lithotripsy",715-718,,"The clinical history of 30 patients with a total of 46 proved brushite urinary calculi was reviewed. The patients were active metabolically with 87% having a history of multiple calculi. Of the brushite stones 61% appeared hyperdense on x-ray but they had no consistent shape. Of the patients who were metabolically evaluated 82% had treatable abnormalities. Treatment with percutaneous nephrostolithotomy or ureteroscopy and ureteral lithotripsy was 92% successful in rendering the patient stone-free, whereas, extracorporeal shock wave lithotripsy monotherapy resulted in a stonefree rate of only 11%. Brushite stone patients require aggressive treatment, full metabolic evaluation and close clinical followup.",https://doi.org/10.1016/S0022-5347(17)38432-X,https://www.sciencedirect.com/science/article/pii/S002253471738432X,,,,1991,Clinical Implications of Brushite Calculi,Lawrence W. Klee and C. Gilberto Brito and James E. Lingeman,article,KLEE1991715,The Journal of Urology,4,145,0022-5347,,,
,,228-238,Plant Cell Organelles,,https://doi.org/10.1016/B978-0-12-395676-7.50017-3,https://www.sciencedirect.com/science/article/pii/B9780123956767500173,,Academic Press,978-0-12-395676-7,1968,CHAPTER 13 - Lysosomes,P.B. GAHAN,incollection,GAHAN1968228,,,,,,J.B. PRIDHAM,
,,655-669,,"Upon transfer into a liquid medium devoid of a nitrogen source, vegetative cells of Chlamydomonas reinhardtii undergo a gametogenic differenciation process to give rise to sexually active gametes that are capable of mating with opposite mating type gametes. Striking differences have been demonstrated in the mating efficiency (0 to 100%) of gametes induced at different vegetative growth stages in the light-dark synchronized culture. This difference in mating efficiency of gametes is independent of mating-type but directly related to the growth stage of the synchronized vegetative cultures at the time of gametogenic induction. In contrast to the synchronized culture, the mating efficiency of gametes in the continuous light, nonsynchronized vegetative culture is independent of the growth stage at the time of gametogenic induction. The mating behavior of gametes appears to be rather unstable since the mating efficiency of a given clone can be altered considerably during routine maintenance of the culture. Not all the progeny of a particular strain inherit the identical mating efficiency of their parents. The stability of the mating behavior and the transmittance of the mating behavior to the vegetative progeny have been found to vary among different clones. The high frequency at which the mating behavior alters suggests that the mating behavior is a rather complex expression of a number of different factors.",https://doi.org/10.1016/0012-1606(70)90174-0,https://www.sciencedirect.com/science/article/pii/0012160670901740,,,,1970,On the formation of a homogeneous zygotic population in Chlamydomonas reinhardtii,Kwen-Sheng Chiang and Joseph R. Kates and Raymond F. Jones and Noboru Sueoka,article,CHIANG1970655,Developmental Biology,4,22,0012-1606,,,
,,393-IN14,,"A fairly common mould on decaying branches and trunks of forest trees, formerly incorrectly known as Haplaria grisea Link, is described and Geniculosporium gen. nov. is proposed to accommodate it, with G. serpens sp.nov. as type species. Its relationship with Hypoxylon serpens (Pers. ex Fr.) Kickx. is discussed and it is briefly compared with the imperfect states of other Xylariaceae.",https://doi.org/10.1016/S0007-1536(64)80012-7,https://www.sciencedirect.com/science/article/pii/S0007153664800127,,,,1964,"Geniculosporium serpens gen. et sp.nov., the imperfect state of Hypoxylon serpens",C.G.C. Chesters and G.N. Greenhalgh,article,CHESTERS1964393,Transactions of the British Mycological Society,3,47,0007-1536,,,
,"Crop establishment, Carrot, Hypocotyl, Emergence force, Crust, Cotyledon",25-38,,"This study describes and analyses how seed placement and seed weight influence the response of emergence and early growth of carrot seedlings to changes in seedbed conditions (temperature and surface structure). The first experiment was carried out in a glasshouse with different sowing conditions (1, 3 and 5 cm sowing depths, 2 and 5 mm wet or dry crusts) and two seed weight ranges. The final emergence percentages (40–94%) and times from 50% germination to 50% emergence (55–105°Cd) varied widely. Seed weights had a marked influence only in the most extreme conditions. Seedling growth was then analysed in growth chambers at two temperatures (10 and 20°C), for the same two seed weight ranges and different times of growth in the dark. Hypocotyl elongation rates and growth forces decreased when this time increased. Heavy seeds had longer final hypocotyl lengths and greater growth forces, which explained their better emergence from deep sowing and with surface obstacles. Growth after emergence both in the glasshouse and growth chamber was influenced by seed weight and time from germination to emergence: the seedling weight at emergence depended only on initial seed weight; the seedling relative growth rate was not influenced by the initial seed weight, but decreased with increase in time before emergence. This was due to a decrease in cotyledon photosynthetic efficiency. Poor seedbed structure and seed placement control affect not only emergence but also early growth. These results provide basic information for modelling the emergence and early growth of dicotyledon epigeal seedlings.",https://doi.org/10.1016/S0167-1987(96)80004-3,https://www.sciencedirect.com/science/article/pii/S0167198796800043,,,,1996,"Emergence and early growth of an epigeal seedling (Daucus carota L.): influence of soil temperature, sowing depth, soil crusting and seed weight",V. Tamet and J. Boiffin and C. Dürr and N. Souty,article,TAMET199625,Soil and Tillage Research,1,40,0167-1987,,,
,,363-372,,"The noctiiucent cloud display of 10/11th July 1979 was observed from two sites in Scotland: Clinterty near Aberdeen, using a low light level TV camera, and Milngavie near Glasgow, using a photographic camera. Coincident observations of the display were made from 23.55 UT until 00.50 UT. By projecting the image of the noctilucent cloud structure as seen by one camera into the field of view of the other camera, the height of the clouds was found to be 82 ± 1 km. Using this result, the effect of atmospheric screening on the visible border of the noctilucent clouds was determined. Taking account of the refraction on the solar grazing rays illuminating the clouds at the visible border and the finite angular diameter of the sun's disc, the altitude of the screening layer was determined to be 7 ± 1 km. Thus, on this occasion, the screening effect of the atmosphere was confined to the troposphere and was probably caused by atmospheric haze and/or tropospheric cloud. This result contrasts markedly with the high values of screening height, ~ 30 km, deduced from measurements made earlier this century, also using the visible boundary of the clouds. The analysis presented herein indicates that these large values were probably in error, due to the poor dynamic range of the photographic films employed.",https://doi.org/10.1016/0021-9169(84)90121-1,https://www.sciencedirect.com/science/article/pii/0021916984901211,,,,1984,The effect of atmospheric screening on the visible border of noctilucent clouds,M.J Taylor and M.A Hapgood and D.A.R Simmons,article,TAYLOR1984363,Journal of Atmospheric and Terrestrial Physics,4,46,0021-9169,,,
,,270-281,,"Summary
Outbreaks of Take All in oats have often been reported in recent years from Wales, and occasionally from Australia, Denmark and Holland, although in most parts of the world it is commonly held that oats resist the disease. Isolates of Ophiobolus from oats grown in Wales were indistinguishable in cultural behaviour from O. graminis, but they were very pathogenic to oats, which were found to be highly resistant to ordinary O. graminis. This histology of the infection of oat plants by the fungus from Wales and by O. graminis was studied in detail. It was found that there were significant differences between the two groups of isolates in the length and septation of the ascospores, the Welsh material giving a length of 101–117µ, the English material 79–86µ The fungus from Welsh oats is therefore regarded as a new variety, Ophiobolus graminis Sacc. var. Avenae E.M. Turner. I have much pleasure in recording my grateful thanks to Mr S.D. Garrett, who suggested this problem and supervised the work, and to Miss E.M. Wakefield for her advice on the systematic status of the isolates of Ophiobolus from oats.",https://doi.org/10.1016/S0007-1536(40)80027-2,https://www.sciencedirect.com/science/article/pii/S0007153640800272,,,,1940,"Ophiobolus graminis Sacc. Var. Avenae var.n., as the cause of take all or whiteheads of oats in Wales",Elizabeth M. Turner,article,TURNER1940270,Transactions of the British Mycological Society,3,24,0007-1536,,,
,"attack vector, attack surface, vulnerabilities, security threats and attacks, security controls, device-level security",100162,,"For this research, our primary goal is to define an attack surface for networks utilizing the IoT (Internet of Things) devices. The IoT consists of systems of integrated objects, computing devices, digital, or mechanical machines that are given the ability to transmit and receive the data over a network without the need for human interaction. Each of these devices can operate independently within the existing Internet infrastructure. Issues will continue to increase as devices become more prevalent and continuously evolve to counter newer threats and schemes. The attack surface of a network sums up all penetration points, otherwise known as attack vectors. An attacker or an unauthorized user can take advantage of these attack vectors to penetrate and change or extract data from the threat environment. For this research, we define a threat model that allows us to systematically analyze the security solutions to mitigate potential risks from the beginning of the design phase. By designing an IoT architecture and breaking it down into several zones, we focus on each zone to identify any vulnerability or weaknesses within a system that allows unauthorized privileges, as well as any attacks that can target that area. We also investigate the available IoT devices across several domains (e.g., wellness, industrial, home, etc.) to provide a 1:1 and 1:n mapping across devices, vulnerabilities, and potential security threats based on the subjective assessment.",https://doi.org/10.1016/j.iot.2020.100162,https://www.sciencedirect.com/science/article/pii/S2542660520300056,,,,2020,Identifying the attack surface for IoT network,Syed Rizvi and RJ Orr and Austin Cox and Prithvee Ashokkumar and Mohammad R. Rizvi,article,RIZVI2020100162,Internet of Things,,9,2542-6605,,,
,,629-634,,,https://doi.org/10.1016/S0096-5588(20)32662-3,https://www.sciencedirect.com/science/article/pii/S0096558820326623,,,,1933,"THE REMOVAL OF A NEEDLE FROM THE HEART WITH ELECTROCARDIOGRAPH RECORDS BEFORE, DURING, AND AFTER OPERATION",Francis A.C. Scrimger,article,SCRIMGER1933629,Journal of Thoracic Surgery,6,2,0096-5588,,,
,,1-8,,"Traditional methods used to develop models for system identification and control studies invariably yield models which give little understanding of the physical structure of the process, and are therefore of limited value to the process design engineer. This paper demonstrates how noise analysis methods together with a comprehensive theoretical model of a boiling channel may be used to give a more detailed understanding of the channel dynamics and its coolant flow stability. Results are presented from an experimental and theoretical study carried out on a boiling channel situated in a small scale test rig.",https://doi.org/10.1016/S1474-6670(17)67622-5,https://www.sciencedirect.com/science/article/pii/S1474667017676225,,,,1975,Identification of a Boiling Channel and Comparisons with a Theoretical Model for Coolant Flow Stability Analysis,T.M. Romberg and N.W. Rees,article,ROMBERG19751,IFAC Proceedings Volumes,"1, Part 2",8,1474-6670,"6th IFAC World Congress (IFAC 1975) - Part 2: Applications, Boston/Cambridge, MA, USA, August 24-30, 1975",,
,,42-49,,,https://doi.org/10.1016/j.jviscsurg.2010.12.011,https://www.sciencedirect.com/science/article/pii/S1878788610001852,,,,2011,Press review,,article,201142,Journal of Visceral Surgery,1,148,1878-7886,,,
,Seismic-ray tracing,207-219,,"A simple, seismic-ray tracing computer program tailored to velocity models representing a Benioff zone is presented. The 2D model represents the overriding crust by flat, horizontal layers, and the subducted crust by flat, parallel, dipping layers. The propagation velocity within each layer may be constant or depend linearly on the distance perpendicular to the top of the layer. A seismic source, generating rays travelling in either P or S mode, may be located anywhere within the model. Whenever a ray intersects an interface, reflection or transmission and, if desired, change in mode of propagation can be specified. Travel time is computed for each ray, and propagation is terminated on encountering the free surface or a model boundary. Model and rays can be plotted. The advantages of this specialized program over well-known more general programs for ray tracing in laterally heterogeneous media are shortness, simplicity, and fast interactive operation.",https://doi.org/10.1016/0098-3004(86)90007-5,https://www.sciencedirect.com/science/article/pii/0098300486900075,,,,1986,A program for 2D seismic-ray tracing in Benioff zones,F {Alejandro Nava},article,ALEJANDRONAVA1986207,Computers & Geosciences,2,12,0098-3004,,,
,,103-116,,,https://doi.org/10.1016/S0030-5898(20)30508-3,https://www.sciencedirect.com/science/article/pii/S0030589820305083,,,,1973,Treatment of the Uncorrected Clubfoot by Triple Arthrodesis,Alexander Hersh and Louis A. Fuchs,article,HERSH1973103,Orthopedic Clinics of North America,1,4,0030-5898,,,
,,157-161,,Genetic and mutational analysis indicates that genes specifying resistance against obligate biotrophic fungi have a complex organization. It seems likely that new specificities are generated by rearrangement or recombinational events within the complex locus.,https://doi.org/10.1016/0168-9525(87)90217-4,https://www.sciencedirect.com/science/article/pii/0168952587902174,,,,1987,The origin and structure of fungal disease resistance genes in plants,Tony Pryor,article,PRYOR1987157,Trends in Genetics,,3,0168-9525,,,
,"DIDS, SITS, Chloride carrier, Charge pulse, Turgor pressure regulation, ()",93-101,,"The effect of the anion transport inhibitor 4,4′-diisothiocyanatostilbene-2,2′-disulfonic acid (DIDS) on the Cl−-transport system located in the plasmalemma of cells of the giant marine alga Valonia utricularis was studied by using the charge pulse relaxation technique. Analysis of the biphasic relaxation patterns in terms of the kinetic model published previously (Wang, J., Wehner, G., Benz, R. and Zimmermann, U. (1991) Biophys. J. 59, 235–248) demonstrated that extracellular DIDS dramatically reduced the translocation rate, KAS, of the Cl−-carrier complex (maximal inhibition 79%). The translocation rate of the free carrier molecules, KS, as well as the total surface concentration of the carrier, No, were not affected. A Hill-plot of DIDS inhibition on KAS yielded an half-maximal inhibition concentration (IC50) of 3.9 · 10−5 M and a Hill-coefficient of 1.61, suggesting a co-operative binding of the inhibitors to the Cl−-carrier. The maximal inhibition of DIDS was dependent on the extracellular Cl−-concentration. This inhibition was not competitive to chloride, since it increased and did not decrease with increasing chloride concentration. The DIDS effect decreased with increasing pH-value (investigated pH range between 6.5 and 10). Intravacuolar DIDS or SITS (4-acetamido-4′-isothiocyanatostilbene-2,2′-disulfonic acid) had no effect on the biphasic voltage relaxation pattern. These results showed that the binding sites of DIDS must be located on the outer surface of the plasmalemma of V. utricularis and, in turn, supported previous conclusions that the Cl−-carrier (which is assumed to be part of the turgor-pressure-sensing mechanism) is only located in the outer membrane.",https://doi.org/10.1016/0005-2736(93)90029-Y,https://www.sciencedirect.com/science/article/pii/000527369390029Y,,,,1993,"Characterization of the chloride carrier in the plasmalemma of the alga Valonia utricularis: the inhibition by 4,4′-diisothiocyanatostilbene-2,2′-disulfonic acid",Ingo Spieβ and Jianning Wang and Roland Benz and Ulrich Zimmerman,article,SPIE199393,Biochimica et Biophysica Acta (BBA) - Biomembranes,1,1149,0005-2736,,,
,,79-88,,,https://doi.org/10.1016/j.jchirv.2020.12.001,https://www.sciencedirect.com/science/article/pii/S1878786X20304551,,,,2021,Revue de presse,,article,202179,Journal de Chirurgie Viscérale,1,158,1878-786X,,,
,,230-253,,,https://doi.org/10.1016/0144-8617(89)90015-5,https://www.sciencedirect.com/science/article/pii/0144861789900155,,,,1989,Bibliography on carbohydrate polymers,,article,1989230,Carbohydrate Polymers,3,10,0144-8617,,,
,,769-825,,"Modern macroeconomists prefer the Q approach for modelling aggregate investment despite the empirical superiority of Jorgenson's ‘neo classical’ approach. This paper revisits this conflict. Its theoretical and empirical results make the case that, in contrast to the original static Q investment equation, a new dynamic Q equation is as satisfactory as Jorgenson's equation from an empirical standpoint while being more satisfactory from a theoretical standpoint. The paper identifies a theoretical and an empirical line of research in resolving the conflict between theorists and empiricists. On the theory side, the possibility of generating lags in a Q investment equation via the structural Q model is explored: This period's investment cost depends on the investment level achieved last period. The interpretation of this intertemporality combines adjustment costs and gestation lags. The closed-form Q equation is an ARMAX. The explicit generation of lagged investment therefore accounts for the key stylized fact characterizing the investment data process. The empirical line of research turns to data puzzles in the specification of a viable Q equation. It reconciles inter alia the ‘non-Q evidence’ which claims a paramount link between stock prices and investment with the ‘Q non-evidence’ which denies such a link exists. More importantly, the ARMAX Q equations is systematically gauged against the Jorgenson and accelerator specifications across six OECD countries. This comparative analysis established that the superiority of the new Q equations over Jorgenson's is robust.",https://doi.org/10.1016/0014-2921(91)90036-I,https://www.sciencedirect.com/science/article/pii/001429219190036I,,,,1991,"Aggregate investment, the stock market, and the Q model: Robust results for six OECD countries",Gabriel Sensenbrenner,article,SENSENBRENNER1991769,European Economic Review,4,35,0014-2921,,,
,,673-744,,,https://doi.org/10.1016/S0959-4388(05)80048-0,https://www.sciencedirect.com/science/article/pii/S0959438805800480,,,,1991,Neural control,,article,1991673,Current Opinion in Neurobiology,4,1,0959-4388,,,
,,39-296,,,https://doi.org/10.1016/0166-1280(87)80086-6,https://www.sciencedirect.com/science/article/pii/0166128087800866,,,,1987,Master listing,,article,198739,Journal of Molecular Structure: THEOCHEM,,154,0166-1280,,,
,,B229-B366,,,https://doi.org/10.1016/S0021-9673(01)96037-6,https://www.sciencedirect.com/science/article/pii/S0021967301960376,,,,1984,Bibliography Section: Liquid column chromatography,,article,1984B229,Journal of Chromatography A,,304,0021-9673,,,
Thin Films,,1-133,Non-Crystalline Films for Device Structures,"Publisher Summary
This chapter discusses the application of ultrathin gate dielectric films for Si-based microelectronic devices. Emphasis is placed on the correlation of dielectric quality, physicochemical issues, and processing parameters. Basic requirements of ultrathin dielectric films to be used in microelectronic devices are given. The chapter discusses the film preparation methods followed by electrical and physicochemical methods of characterization of dielectric films. The significance and effects of the hydrogen presence in gate dielectrics are also presented in the chapter. Further, silicon oxide films thermally grown on single-crystalline silicon in dry oxygen are discussed in the chapter. Understanding and simulating modem-processing routes to the formation of gate dielectric films require an understanding of the atomic transport processes responsible for their growth. Atomic transport is the natural way to approach the growth of ultrathin films and is explored in the chapter.",https://doi.org/10.1016/S1079-4050(02)80010-2,https://www.sciencedirect.com/science/article/pii/S1079405002800102,,Elsevier,,2002,Ultrathin gate dielectric films for Si-based microelectronic devices,C. Krug and I.J.R. Baumvol,incollection,KRUG20021,,,29,1079-4050,,Maurice H. Francombe,
,,629-685,,"Summary
Of all the factors concerned in bringing about oxidative changes in dairy products metallic contamination, particularly by copper, is at present the most important. The control of copper contamination in processing becomes increasingly more important as the sanitary quality of the products is improved. However, not all milk must have copper contamination to develop an oxidized flavor. Fortunately, the percentage of milk which develops oxidized flavor spontaneously is relatively small and when this milk is mixed with normal milk it remains normal in flavor. For this reason it is not of as great commercial importance as is milk susceptible to metal-induced oxidized flavor. Oxidized flavor in milk has been shown to be associated with milk of low bacterial count. The growth of bacteria in the milk, either by using up the oxygen or by reduction of the potential, render milk non-susceptible even in the presence of copper. Oxidized flavor in milk was originally believed to be the result of oxidation of the fat catalyzed by copper and brought about through the action of an enzyme. The recent trend in literature points to the phospholipid fraction as the source of the flavor and recent work on cooked flavor questions seriously the action of an enzyme in bringing about the defect. Grass feeding has been shown to reduce the susceptibility of milk to oxidized flavor even though the milk fat is made more susceptible to ordinary chemical oxidation. This is explained on the basis of reducing substances in the feed or in the milk, or in both. Various investigations have shown that ascorbic acid and carotene in the feed tend to reduce the susceptibility of the milk. Also a number of antioxidants have been demonstrated to have protective qualities. The mechanism whereby an oxidized flavor develops has not been completely demonstrated nor has the mechanism whereby the various factors exert their effects. Tallowy flavor in butter appears to be the result of metal-induced oxidation of the fat, the point of attack probably being the double bonds in the oleic and linoleic acid radicles. Light and oxygen have been demonstrated to be important factors favoring oxidative changes. Oxidation will take place in the absence of light but the rate of reaction is slow. The source of oxygen may be either the free or the combined form. Both strong acid and alkaline reactions have been shown to favor oxidative changes. Over-neutralization is known to favor oxidative changes while butter made from high acid cream in the presence of copper contamination and salt is prone to become fishy upon storage. Both salt and moisture appear to play a role in the development of oxidative changes but they are of minor importance when compared to metallic contamination. Temperature is important only as a regulator of the rate of oxidative change. As the temperature increases the rate of oxidative change increases, all other factors being constant. Low temperature storage favors a slow rate of oxidative change. Development of tallowy or oxidized flavor in ice cream is undoubtedly an oxidative change. In this product, however, we have the possibility that the oxidative changes may affect either the phospholipid fraction or the butter-fat or both. The present work points toward fat as the substance oxidized. If the present trend of research on oxidized flavor of milk continues, a reex-amination of tallowy flavor in ice cream would seem desirable. The elimination of copper contamination is one of the major problems confronting the dairy industry today as the flavor problems resulting from chemical reactions have a copper history in the vast majority of cases. If these problems are to be eliminated by removal of the cause, it will be necessary for copper to be eliminated from all surfaces with which milk comes in contact because of the extremely small amount of copper required to develop the flavor in many cases. The authors wish to express their appreciation to Dr. R. B. Dustman, Department of Agricultural Chemistry, West Virginia Agricultural Experiment Station, for advice and criticism in the preparation of this paper.",https://doi.org/10.3168/jds.S0022-0302(40)95555-2,https://www.sciencedirect.com/science/article/pii/S0022030240955552,,,,1940,A Review of Oxidation in Milk and Milk Products as Related to Flavor1,W. Carson Brown and L.M. Thurston,article,BROWN1940629,Journal of Dairy Science,7,23,0022-0302,,,
,,B641-B702,,,https://doi.org/10.1016/S0021-9673(01)93440-5,https://www.sciencedirect.com/science/article/pii/S0021967301934405,,,,1987,Liquid column chromatography,,article,1987B641,Journal of Chromatography A,,412,0021-9673,,,
,,285-288,,,https://doi.org/10.1016/0002-9610(67)90385-6,https://www.sciencedirect.com/science/article/pii/0002961067903856,,,,1967,Complications associated with Meckel's diverticulum,Grosvenor T. Root and Charles P. Baker,article,ROOT1967285,The American Journal of Surgery,2,114,0002-9610,,,
Journal of Chromatography Library,,508-565,Polymer Characterization by Liquid Chromatography,,https://doi.org/10.1016/S0301-4770(08)61426-8,https://www.sciencedirect.com/science/article/pii/S0301477008614268,,Elsevier,,1987,Bibliography,,incollection,1987508,,,34,0301-4770,,Gottfried Glöckner,
,,190-202,,,https://doi.org/10.1016/0002-9610(67)90372-8,https://www.sciencedirect.com/science/article/pii/0002961067903728,,,,1967,Anatomy and embryology of congenital intrinsic obstruction of the duodenum,Edward A. Boyden and John G. Cope and Alexander H. Bill,article,BOYDEN1967190,The American Journal of Surgery,2,114,0002-9610,,,
,,1-43,,,https://doi.org/10.1016/S0021-9673(01)86254-3,https://www.sciencedirect.com/science/article/pii/S0021967301862543,,,,1959,Review of gas-liquid chromatography,C.J. Hardy and F.H. Pollard,article,HARDY19591,Journal of Chromatography A,,2,0021-9673,,,
,,3-78,,,https://doi.org/10.1016/S0014-5793(98)80002-1,https://www.sciencedirect.com/science/article/pii/S0014579398800021,,,,1997,Author index to volumes 400–420,,article,19973,FEBS Letters,,400-420,0014-5793,,,
,,S130-S229,,,https://doi.org/10.1016/j.rcot.2010.08.001,https://www.sciencedirect.com/science/article/pii/S1877051710002431,,,,2010,Résumés des communications,,article,2010S130,Revue de Chirurgie Orthopédique et Traumatologique,"7, Supplement ",96,1877-0517,85e Réunion annuelle de la Société française de chirurgie orthopédique et traumatologique,,
,,e335-e478,,,https://doi.org/10.1016/j.ijid.2010.02.002,https://www.sciencedirect.com/science/article/pii/S1201971210000342,,,,2010,Abstracts for Supplement,,article,2010e335,International Journal of Infectious Diseases,,14,1201-9712,14th International Congress on Infectious Diseases (ICID) Abstracts,,
,,19-510,,,https://doi.org/10.1016/S0166-1280(97)83255-1,https://www.sciencedirect.com/science/article/pii/S0166128097832551,,,,1997,Master listing,,article,199719,Journal of Molecular Structure: THEOCHEM,,420-421,0166-1280,,,
,,A33-A74,,,https://doi.org/10.1016/j.aforl.2011.07.002,https://www.sciencedirect.com/science/article/pii/S1879726111001331,,,,2011,Communications orales du dimanche 16 octobre,,article,2011A33,Annales françaises d'Oto-rhino-laryngologie et de Pathologie Cervico-faciale,"4, Supplement ",128,1879-7261,"118e Congrès 2011, 15-17 octobre, Paris - Palais des Congrès",,
,,1219-1248,,,https://doi.org/10.1016/S0955-0674(89)80073-0,https://www.sciencedirect.com/science/article/pii/S0955067489800730,,,,1989,Cell differentiation,,article,19891219,Current Opinion in Cell Biology,6,1,0955-0674,,,
,,495-549,,"Weighted oscillator strengths, energy levels, and wavelengths are calculated for the 2s22p5-2s2p6, 2s22p5-222p43s, and 2s22p5-2s22p43d transition arrays for F-like ions in the isoelectronic sequence from Mg IV to Ni XX and in addition for n = 3−3 and other transitions in Mg IV, Al V, and Si VI. The calculation involves the computation of ab initio values of Slater radial energy integrals using a Hartree-Fock-Relativistic computer program package, which includes configuration-interaction and applies the Blume-Watson method for spin-orbit integrals. Some of the parameters are subsequently optimized on the basis of empirical data. Adopted values are tabulated along with atomic energy level compositions.",https://doi.org/10.1016/0092-640X(84)90012-3,https://www.sciencedirect.com/science/article/pii/0092640X84900123,,,,1984,"Calculated wavelengths, oscillator strengths, and energy levels for n = 2−2 and 2–3 transitions in F-like ions Mg IV to Ni XX and for 3−3 and other transitions in Mg IV, Al V, and Si VI",B.C. Fawcett,article,FAWCETT1984495,Atomic Data and Nuclear Data Tables,3,31,0092-640X,,,
,,338-419,,,https://doi.org/10.1016/j.tracli.2011.02.013,https://www.sciencedirect.com/science/article/pii/S1246782011000395,,,,2011,Posters,,article,2011338,Transfusion Clinique et Biologique,3,18,1246-7820,XXVe congres de la SFTS Lyon 4-6 mai 2011,,
,,I-CXXX,,,https://doi.org/10.1016/S2772-3747(21)00062-4,https://www.sciencedirect.com/science/article/pii/S2772374721000624,,,,2021,Full Issue PDF,,article,2021I,JACC: Asia,1,1,2772-3747,,,
,,209-212,,,https://doi.org/10.1016/0002-9610(67)90374-1,https://www.sciencedirect.com/science/article/pii/0002961067903741,,,,1967,Electrical control of facial pain,C.Hunter Shelden and Robert H. Pudenz and James Doyle,article,SHELDEN1967209,The American Journal of Surgery,2,114,0002-9610,,,
,,289-296,,"A review of thoracic trauma as treated at Highland General Hospital is presented. Five hundred sixty-two cases with twenty-five deaths were analyzed. The survey encompasses an eight year span and changes in technics over this period are stressed. All phases of thoracic trauma, including blunt trauma, pneumothorax and hemopneumothorax, flail chest and cardiac and great vessel injury, esophageal injury, and diaphragmatic injury, are discussed as to emergency and definitive care. Morbidity and mortality are presented with discussion relevant to decreasing both, in the emergency care of thoracic injury.",https://doi.org/10.1016/0002-9610(67)90386-8,https://www.sciencedirect.com/science/article/pii/0002961067903868,,,,1967,Current management of civilian thoracic trauma,Reinold J. Jones and Paul C. Samson and David J. Dugan,article,JONES1967289,The American Journal of Surgery,2,114,0002-9610,,,
,,669-783,,,https://doi.org/10.1016/S0198-0254(06)80059-2,https://www.sciencedirect.com/science/article/pii/S0198025406800592,,,,1990,Oceanographic Literature Review,,article,1990669,Deep Sea Research Part B. Oceanographic Literature Review,8,37,0198-0254,,,
,,367-427,,,https://doi.org/10.1016/0955-0674(90)90025-A,https://www.sciencedirect.com/science/article/pii/095506749090025A,,,,1990,Cell multiplication,,article,1990367,Current Opinion in Cell Biology,2,2,0955-0674,,,
,,203-208,,,https://doi.org/10.1016/0002-9610(67)90373-X,https://www.sciencedirect.com/science/article/pii/000296106790373X,,,,1967,Transmesenteric plication for small intestinal obstruction,A.Thomas Ferguson and Vernoy A. Reihmer and Max R. Gaspar,article,FERGUSON1967203,The American Journal of Surgery,2,114,0002-9610,,,
,,71-179,,"Summary
According to the findings of several studies the older concept of paleoclimates, which postulates the regular alternation of humid “Pluvials” and arid “Interpluvials” in the subtropics of the northern hemisphere, and which are supposed to correspond to Glacials and Interglacials in Central Europe, can no longer be supported.1.Palynological studies performed in Spain, Italy, and Greece unanimously prove the existence of types of vegetation with sparce trees or even free of tree growth, whereas from the older point of view Glacials were marked by dense forests (increase of rainfall is taken for granted).2.From loess covers that are to be found in several parts of the Mediterranean (corresponding to the above mentioned facts) Glacial aridity can be concluded, as confirmed by the loess snail fauna.3.Lime — crusts, which are the predominant evidence for very arid conditions, are not surface formations, but CCa-horizons of soils. Their formation is based on conditions of lime removal from close-to-surface soils horizons; this presupposes a humid season, while on the other hand the considerable lime precipitation in the subsoil presupposes an arid season as well.4.Paleosols and debris covers on slopes, being analogously considered indications for increased rainfall (“Pluvial” climate), are not the product of one type of climate only. As they occur in multiple alternations they cannot be simultaneous formations, but were formed at various times under different ecological conditions. Substantial seepage and relative stagnation of erosion are requisites for the formation of soils, whereas displacement of debris is conditional on the predominance of surface runoff. The most important indications — soils (having partly lime-crust CCa-horizons) an slope debris covers — do not allow any conclusions as to the absolute amount of rainfall and its variations, but to different ecological types of effects of rainfall, which are due to a different ratio of see page to surface runoff because of variable rainfall distribution. The abandonment of the misleading terms “Pluvial” — “Interpluvial” is suggested in favour of terms not based on hypothesis, but which describe directly observable basic geoecological conditions: periods of morphodynamic activity (with predominance of slope erosion and without formation of soils) are put in contrast to the periods of morphodynamic stability (with formation of soils and a lack of or only insignificant displacement of suspended material on slopes). Transitional states are characterized by the term “partial activity”. During several excursions accumulation sequences interrupted by as few erosion phases as possible have been searched for, in order to obtain a new paleoclimatic concept. Out of these, one large scale profile (Ses Penyes Rotjes/Mallorca), which includes early and middle pleistocene series composed of alternating soils and sediments (> 30 fossil soils), as well as several low cliff profiles on the Balearic Islands and at the Moroccan Atlantic Coast with late pleistocene soil and sediment series, have been subjected to a detailed analysis up to now. We think it worthwhile to repeat the following partia results obtained: As in Central Europe, an alternation of soil formation periods (periods of morphodynamic stability) and of periods characterized by an intense morphodynamic activity on slopes, valley floors, and alluvial fans (periods of morphodynamic activity) can be observed. As in Central Europe the paleosols do not occur in isolation but as soil complexes in profiles of a more complex nature. They correspond to the interglacial and early glacial periods according to a correlation (partially even in alternating layers) with marine sediments of the interglacial high sea levels. In contrast to what is known about Central European soil complexes, the individual soils of the Mediterranean usually cannot be distinguished from each other in terms of soil typology. As the basal soil of a complex is often marked by karst formations of the lime-crust CCa-horizon, indicating a more substantial humidity and/or longer duration of formation processes, so it can be considered the correlate formation of the Central European Interglacial (or parts of it). In accordance with KUKLA's findings obtained at loess profiles in the ČSSR, the soil complexes can be subdivided into several subcycles on the basis of different types of sediments and variable intensities of individual soil formation. Depending on varying site conditions the pleniglacial sections tend to consist mainly of fine to coarse clastic alluvial sediments or dune series resulting from periods of regression and/or alternating layers of these two formations. Unlike early and interglacial series, soil sediments, even autochthonous soils diminish in the pleniglacial series. Though soil formations are not completely lacking, they are, however, of weak intensity. Soils both well- and badly-developed, in all profile sections, may have CCa-horizons, either of the cementation or the lamellar lime-crust type. This means that during all soil formation periods — during both the warm and cold periods of the quarternary Glacial-Interglacial-cycles — mediterraneanlike climate, marked by intense soil exsiccation in summer time, was prevalent. The latest sediment sequence is covered by several soils probably of holocene or late glacial origin. In the Mediterranean the profiles which are composed of alternating soils and sediments exhibit a sequence as rich as, and strikingly similar to some of the most richly differentiated Central European profiles. According to KUKLA they can be subdivided into Lower and Upper Series. The Lower Series are mainly characterized by periods of morphodynamic stability, interrupted by comparatively short periods of morphodynamic activity during which, moreover, only the state of partial activity (moderately reduced vegetal cover) was reached. The Upper Series consist of longer periods of activity during which the state of total activity (considerably reduced vegetal cover), besides states of partial activity, gained more importance. Intercalated periods of morphodynamic stability were of short duration only. The Holocene is a stratigraphic period that, under natural conditions, was predominantly marked by morphodynamic stability and intense formation of soils since rainfall distribution — though being more accentuated than in Central Europe — favoured types of vegetation rich in ligneous plants which gave sufficient soil protection. In deforested areas intact soil covers can be found only in areas with low slope gradients; in areas with steep slope gradients only in some large forested zones (e. g. cork oak forests in Catalonia). In vast areas the solum of the holocene soil is largely or fully eroded so that the solid rock or the Cca-horizon either constitute the surface or are close to it. Potent cutting or complete removal of a bulk of the holocene soil cover is to a great extent due to direct and indirect destruction of the vegetal cover by man (e.g. by grazing). This erosion caused by man — a quasi-natural erosion — is by no means as intense as erosion of the stronger pleistocene phases of activity. Partial activity is predominant, i.e. slow slope erosion due to unconcentrated surface runoff not proceeding on the piedmont plain but being changed into accumulation. Concentration of surface runoff accompanied by a revival of dry valleys or even new formation of runoff-concentration-forms — i.e. slope gullying — is frequent on very argillaceous rocks. Even then accumulation or gullying are predominant in the piedmont area. Examples of recent areal erosion in the piedmont plain and at the same time expansion of the erosional piedmont plain (= pediment), i.e. existence of recent pedimentation, are rare, and always confined to rocks highly susceptible to erosion. This is borne out by the fact that newly formed pediments have only an extremely small extent. It was observed at several locations that pedimentation was more important in subrecent periods than now. This is in conformity with the fact that post-pleistocene slope gullying forms can be observed comparatively often which, due to their slope debris and vegetal cover, prove to be inactive. Occasional observations show that to some (or even to a considerable) extent cutting or removal of the post-pleistocene soil cover is due to this (or these) subrecent period(s) of more substantial erosion caused by climatic conditions only, or by a super-imposition of climatic and anthropogenic influences. This is to say that the holocene period of predominant morphodynamic stability may be assumed — mainly in the arid areas — to have been interrupted by short phases of morphodynamic activity of climatic origin, as was proved in West Africa and North America. From a comparison of results obtained in the Central Sahara desert with those obtained in the Mediterranean area, numerous parallels are followed and also a marked difference: the morphodynamics of humid areas are characterized by alternating states of stability and activity (often states of partial activity only); whereas in deserts the state of stability is largely substituted by the state of partial activity. Well developed soils are not completely lacking, but here they are confined to the less frequent periods of highest soil-climatic humidity. Though direct comparison between the climatic sequence, as ascertained in the Mediterranean and the hitherto existing best profiles of the Sahara (Saoura Valley), is not yet practicable, it must be assumed that in the Sahara geomorphodynamically relevant climatic variations were not less frequent than in the more humid subtropics and Central Europe. The question as to whether climatic variations in the Sahara (and West Africa) ran parallel with or in opposition to those of the Mediterranean and temperate zones cannot be clarified for lack of a stratigraphy in more explicit detail. Several findings favour the hypothesis of parallelism whereas the hitherto existing “pendulation theories” are not appropriate since they are partly based on the highly ambiguous Pluvial concept.
Zusammenfassung
Aufgrund verschiedener Befunde kann die ältere paläoklimatologische Vorstellung eines regelhaften Wechsels von feuchten “Pluvialen” und trockenen “Interpluvialen”, die in den Subtropen der Nordhemisphäre mit den Glazialen und Interglazialen Mitteleuropas korrespondieren sollten, nicht mehr befriedigen:1.Pollenanalytische Untersuchungen aus Spanien, Italien und Griechenland ergaben über-einstimmend waldarme oder sogar waldfreie Vegetationstypen, während die ältere Auffassung mit geschlossener Bewaldung während der Kaltzeiten rechnete (aufgrund vorausgesetzter Niederschlagserhöhung).2.Damit korrespondiert das Auftreten von Lößdecken in verschiedenen Teilgebieten des Mediterrangebietes, die auf kaltzeitliche Aridität schließen lassen, was durch die Lößschneckenfauna bestätigt wird.3.Die überwiegend als Indikatoren für sehr aride Verhältnisse angesehenen Kalkkrusten sind keine Oberflächenbildungen, sondern CCa-Horizonte von Böden. Ihre Bildung ist an Bedingungen mit Kalkabfuhr aus einem oberflächennahen Solum gebunden und setzt demzufolge jahreszeitliche Humidität voraus; die starke Kalkausfällung im Unterboden erfordert andererseits auch eine trockene Jahreszeit.4.Die in gleicher Weise als Indikatoren für höhere Niederschläge (“Pluvial”-Klima) herangezogenen Paläo-Böden und Hang schuttdecken sind mcht Produkte eines Klimatyps. Ihr in vielfachem Wechsel alternierendes Auftreten zeigt an, daß sie nicht gleichzeitige Bildungen sind, sondern zu verschiedenen Zeiten mit unterschiedlichen ökologischen Bedingungen entstanden. Und zwar setzt Bodenbildung hohe Versickerung und relative Abtragungsruhe voraus, Schuttverlagerung am Hang erfordert dagegen Bedingungen mit Dominanz des Oberflächenabflusses. Gerade die wichtigsten Indikatoren — Böden (z. T. mit Kalkkrusten-CCa-Horizonten) und Hangschuttdecken — erlauben also primär keine Schlußfolgerungen auf die absolute Niederschlagsmenge und ihre Veränderung, sondern auf landschaftsökologisch unterschiedliche Wirkungstypen des Niederschlages infolge eines unterschiedlichen Verhältnisses von Versickerung zu Oberflächenabfluß aufgrund unterschiedlicher Niederschlagsverteilung. Es wird vorgeschlagen, das irreführende Begriffspaar “Pluvial” — “Interpluvial” ganz aufzugeben und nur Begriffe zu benutzen, die nicht auf Hypothesen beruhen, sondern die direkt beobachtbare landschaftsökologische Grundzustände beschreiben: morphodynamische Aktivitätszeiten (mit Dominanz der Hangabtragung und ohne Bodenbildung) werden den morphodynamischen Stabilitätszeiten (mit Bodenbildung und fehlender oder sehr geringer Schwebstoffverlagerung an Hängen) gegenübergestellt. Über-gangszustände werden durch den Begriff “Teilaktivität” gekennzeichnet. Zur Gewinnung einer neuen paläoklimatischen Konzeption wurde auf mehreren Reisen nach Aufschlüssen in möglichst wenig durch Abtragungsphasen unterbrochenen Akkumulationsfolgen gesucht. Davon wurden bis jetzt ein Großprofil (Ses Penyes Rotjes/Mallorca) mit alt- und mittelpleistozänen Boden-Sediment-Serien (> 30 fossile Böden) sowie mehrere niedrigere Kliffprofile auf den Balearen und an der marokkanischen Atlantikküste mit jungpleistozänen Boden-Sediment-Serien einer detaillierten Analyse unterzogen. Folgende Ergebnisse scheinen uns wert, hervorgehoben zu werden: Wie in Mitteleuropa ist auch in den Tieflagen des Mediterrangebietes ein Alternieren von Zeiten mit Bodenbildung (Stabilitätszeiten) und von Zeiten mit starker Morphodynamik an Hängen, in den Talböden und auf Schwemmfächern (Aktivitätszeiten) festzustellen. Wie in Mitteleuropa treten die Paläoböden in den reicher gegliederten Profilen nicht isoliert, sondern in Bodenkomplexen auf, die nach Korrelation (z. T. sogar in Wechsellagerung) mit marinen Sedimenten der warmzeitlichen Meeresspiegelhochstände in die Interglazial — und Frühglazialabschnitte der quartären Kaltzeiten zu stellen sind. Im Gegensatz zu den Befunden an mitteleuropäischen Bodenkomplexen sind die Einzelböden im Mediterrangebiet in der Regel bodentypologisch nicht voneinander unterscheidbar; lediglich der basale Boden eines Komplexes ist oft durch eine (synoder parapedogenetische) Verkarstung des Kalkkrusten-CCa-Horizontes ausgezeichnet, was auf größere Humidität oder größere Bildungsdauer (bzw. beides) hinweist, so daß in ihm die korrelate Bildung der mitteleuropäischen Interglaziale (oder Teilen davon) zu sehen ist. Die Bodenkomplexe können — in Entsprechung zu den von KUKLA in der ČSSR festgestellten Befunden an Lößprofilen — aufgrund unterschiedlicher Sedimenttypen und Bodenbildungsintensitäten der Einzelböden in mehrere Subzyklen eingeteilt werden. Die hochkaltzeitlichen Abschnitte bestehen — je nach Standortsverhältnissen — überwiegend aus fein — bis grobklastischen Schwemmsedimenten oder regressionszeitlichen Dünenserien bzw. einer Wechsellagerung beider Bildungen. In den hochkaltzeitlichen Serien treten im Gegensatz zu den interglazial-frühglazialen Serien neben Bodensedimenten auch autochthone Böden stark zurück. Bodenbildungen fehlen allerdings nicht vollständig, sind aber von schwacher Intensität. Sehr schwache Böden (in allen Profilabschnitten) wie auch sehr stark ausgeprägte Böden können sämtlich CCa-Horizonte in Zementations- wie auch in lamellärer Kalkkrusten-Ausbildung aufweisen. Das bedeutet, daß in allen Bodenbildungszeiten, also sowohl im warmen als auch im kalten Abschnitt der quartären Warmzeit-Kaltzeit-Zyklen, mediterraner Klimacharakter mit starker sommerlicher Bodenaustrocknung herrschte. Die jüngste Sedimentfolge wird von mehreren Böden abgeschlossen, die in das Holozän und vermutlich auch in das Spätglazial zu stellen sind. Die Boden-Sediment-Profile in der mediterranen Stufe besitzen eine ebenso reiche und auffällig gleichartige Gliederung wie die am reichsten gegliederten Profile Mitteleuropas. Mit KUKLA kann man sie in Untere und Obere Serien einteilen. Die Unteren Serien sind vor allem durch Stabilitätszeiten gekennzeichnet, die nur durch relativ kurze Aktivitätsphasen getrennt waren, in denen zudem überwiegend nur der Zustand der Teilaktivität (mäßige Vegetationsauflichtung) erreicht wurde. Die Oberen Serien bestehen aus längeren Aktivitätsabschnitten, in denen neben Phasen mit Teilaktivität auch dem Zustand der Vollaktivität (beträchtliche Vegetationsauflichtung) größere Bedeutung zukam; eingeschaltete Stabilitätsphasen waren hier nur von kurzer Dauer. Das Holozän ist ein stratigrafischer Abschnitt, der unter natürlichen Bedingungen überwiegend durch morphodynamische Stabilität mit intensiver Bodenbildung gekennzeichnet war, da die Niederschlagsverteilung — obwohl akzentuierter als in Mitteleuropa — bis in die trockensten Gebiete hinein an Holzpflanzen reiche Vegetations-typen mit ausreichendem Bodenschutz begünstigte. Geschlossene Bodendecken findet man im Offenland fast nur bei geringen Hangneigungen, im Steilrelief nur in einigen größeren Waldgebieten (Beispiel: Korkeichenwälder in Katalonien). In sehr weiten Bereichen ist das Solum des holozänen Bodens weitgehend oder vollständig abgetragen, so daß das Gestein oder der CCa-Horizont weitflächig in Oberflächennähe anstehen bzw. direkt die Oberfläche bilden. Für die starke Kappung bzw. vollständige Ausräumung des Großteils der holozänen Bodendecke ist sicher die direkt und indirekt (z. B. durch Beweidung) anthropogen bedingte Vegetationszerstörung in großem Maße verantwortlich zu machen. Diese anthropogen ausgelöste, also quasinatürliche Abtragung ist weit weniger intensiv als die Abtragung in den stärkeren pleistozänen Aktivitätszeiten. Es überwiegt Teilaktivität, d. h. langsame Hangabtragung durch unkonzentrierten Oberflächenabfluß, die sich nicht auf den Fußflächen fortsetzt, sondern dort in Akkumulation übergeht. Abflußkonzentration mit Wiederaufleben präexistenter Hohlformen bzw. sogar Neubildung von Abflußkonzentrationsformen — also Hangzerschneidung — ist nur in tonreichen Gesteinen häufiger. Aber auch dann überwiegen im Fußflächenbereich Akkumulation oder aber Zerschneidung. Fälle mit rezenter Fußflächenabtragung und somit auch Ausweitung des Areals der Abtragungsfußflächen, also Vorkommen von rezenter Pedimentation, sind sehr selten und stets auf Gesteine mit hoher Abtragungsgunst beschränkt. In die gleiche Richtung weist, daß neugebildete Pedimente im Vergleich zu pleistozänen Vorzeitformen nur eine extrem kleine Ausdehnung haben. An mehreren Lokalitäten wurde beobachtet, daß in subrezenter Zeit Pedimentation größere Bedeutung hatte als heute. Dem entspricht, daß relativ häufig postpleistozäne Hangzerschneidungsformen festgestellt werden können, die sich anhand ihrer Bedeckung mit Hangschutt und Vegetation heute als inaktiv erweisen. Einzelbeobachtungen weisen darauf hin, daß dieser bzw. diesen subrezenten Phase(n) mit stärkerer Abtragung, die möglicherweise rein klimatisch oder durch Überlagerung klimatischer und anthropogener Einflüsse bedingt sind, z.T. sogar erheblicher Anteil an der Kappung bzw. Abräumung der postpleistozänen Bodendecke zukommt. Man muß also, und zwar besonders in den Trockengebieten, damit rechnen, daß die holozäne Periode überwiegender Stabilität — wie in Westafrika und Nordamerika nachgewiesen — durch klimatisch ausgelöste kurze Aktivitätsphasen unterbrochen gewesen sein könnte. Ein Vergleich der im Mediterrangebiet gewonnenen Ergebnisse mit den Wüstengebieten der zentralen Sahara ergibt zahlreiche Parallelen, allerdings auch einen deutlichen Unterschied: In den humiden Gebieten ist die Morphodynamik durch ein Alternieren von Stabilitäts- und Aktivitätszuständen (häufig nur Teilaktivitätszuständen) gekennzeichnet. In den Wüsten wird demgegenüber der Stabilitätszustand weitgehend durch den Teilaktivitätszustand ersetzt. Kräftige Böden fehlen nicht vollständig, sind hier aber auf die weniger häufigen Zeiten mit größter bodenklimatischer Humidität beschränkt. Obwohl ein direkter Vergleich der im Mediterrangebiet festgestellten Klimafolge mit den bisher vollständigsten Profilen der Sahara (Saoura-Tal) noch nicht möglich ist, muß als sicher gelten, daß geomorphodynamisch relevante Klimaschwankungen in der Sahara nicht seltener waren als in den humideren Subtropen und in Mitteleuropa. Die Frage, ob die Klimaschwankungen in der Sahara (und Westafrika) mit denen des Mediterrangebietes und der temperierten Zone parallel oder entgegengesetzt verliefen, kann mangels einer Feinstratigrafie nicht entschieden werden. Mehrere Befunde sprechen für die Parallelitätshypothese, wohingegen die bisherigen “Pendulationstheorien” nicht zutreffen, zumal da sie z. T. auf dem mehrdeutigen Pluvialbegriff aufbauen.
Resume
Sur la base de différentes découvertes, l'ancienne conception des paléoclimats ne donne plus satisfaction. Elle supposait une alternance de périodes pluviales humides et d'interpluviales sèches qui devaient coïncidé dans la zone subtropicale de l'hémisphère du nord avec les périodes glaciaires et interglaciaires de l'Europe centrale.1.Des analyses des pollens, en Espagne, en Italie et en Grèce, ont donnés des résultats concordants: des types de végétation qui sont caractérisés par pauvrement boisés ou même pas boisés, alors que l'ancienne théorie présupposait pendant les périodes froides la présence d'une couverture forestière ininterrompue, du fait de l'augmentation supposée des précipitations.2.A ces différents états de végétation correspond l'apparition de couvertures de loess dans différentes parties de la région méditerranéenne, qui permettent de conclure à l'existence d'une aridité de climal froid, ce qui est confirmé par la faune de mollusques du loess.3.Les croûtes calcaires, considérées la plus souvent comme les indices d'une extrème aridité, ne sont pas des formations de surface, mais les horizons-CCa des sols. D'un part, leur élaboration est liée à la décalcification des couches proches de la surface, ce que suppose une saison humide, tandis que d'autre part, la forte précipitation du calcaire dans le sous-sol demande du même une saison sèche.4.Les paléosols et les couvertures de débris de pente, qui étaient également considérés comme les indices pour des précipitations augmentées (climat “pluvial”), ne sont pas les produits d'un type de climat seulement. Leur apparition alternant de changements multiples démontre, qu'il ne s'agit pas de formations simultanées, mais qu'ils se sont évolués à des époques et conditions écologiques différentes. Certes, la pédogenèse présuppose une haute infiltration des eaux et une disparition relative de l'érosion, mais un déplacement de débris de pente demande des conditions avec dominance du ruissellement. Juste les indices les plus importants — l'existence des sols (partiellement des horizons-CCa de croûte calcaire) et des couvertures de débris de pente — ne permettent aucune conclusion sur la quantité absolue des précipitations et sa variation, mais on est capable de différencier entre les differents types des effets sur l'écologie du paysage causés par des précipitations différentes du fait d'un rapport variable entre l'infiltration et le ruissellement à cause des variations dans la répartition des pluies. Nous proposons d'abandonner complètement les dénominations “Pluvial” — “Interpluvial”, qui peuvent induire en erreur, et de n'utiliser que des termes qui, au lieu de reposer sur des hypothèses, sont dérivés de l'observation des états principaux de l'écologie du paysage: Aux périodes d'activité morphodynamique, où le transport des matériaux sur les pentes domine, sans qu'il y ait pédogenèse, on opposera des périodes de stabilité morphodynamique où la pédogenèse est très importante et où la répartition du matériel en suspension sur les pentes est presque inexistante. Les phases de transition seront nommées périodes d'activité morphodynamique partielle. Avant de tenter l'élaboration d'une nouvelle thèse concernant les paléoclimats, nous avons cherché, aux cours de nombreux voyages, des profils où les séries sédimentaires soient le moins possible interrompues par des phases d'érosion. Jusqu'ici nous avons pu en soumettre à une analyse détaillée: le haut profil Ses Penyes Rotjes (situé à Majorque), qui est riche de séries avec des sols et des sédiments alternants du haut at du moyen Pléistocène (plus que 30 sols fossiles). Les autres profils, d'une hauteur plus réduite, sont répartis dans les falaises côtières des Baléares et de la façade atlantique du Maroc. Ils sonst composés de séries de sols et de sédiments en alternance du Pléistocène récent. Les résultats suivants nous semblent dignes d'être soulignés: Comme en Europe centrale, on peut constater, dans les régions méditerranéennes de basse altitude, une alternance des périodes avec pédogenèse (périodes de stabilité morphodynamique) et des périodes de forte activité morphodynamique sur les pentes, dans les fonds de vallées et sur les cônes de déjections (périodes d'activité morphodynamique). Comme en Europe centrale également, les paléosols, dans les profils les plus richement diversifiés, n'apparaissent pas isolés mais en complexes de sols, qui l'on peut attribuer, selon la corrélation (partiellement même déposé alternativement) avec des sédiments marins de l'époque chaude des transgressions marines, aux périodes interglaciaires et aux entrées des périodes glaciaires des époques glaciaires du Quaternaire. Contrairement aux découvertes faites dans les complexes de sols de l'Europe centrale, les sols un à un de la région méditerranéenne ne se différencient pas en générale entre eux quant au type du sol. Seulement, le sol de base d'un complexe est souvent caractérisé par une évolution karstique (syn- ou para-pédogénétique) de la croûte calcaire, de l'horizon'CCa, ce qui indique un degré d'humidité plus grand, une formation plus longue ou une combinaison de ces deux facteurs, de sorte qu'on peut le regarder comme une formation parallèle à l'époque interglaciaire L'Holocène est une phase stratigraphique, qui est essentiellement marquée, dans des conditions naturelles, par sa stabilité morphodynamique avec pédogenèse intensive, car la répartition des pluies, bien que plus accentuées qu'en Europe centrale, favorisait jusque dans les régions les plus sèches des formations végétales plus riches en arbres, qui protègeaient suffisamment les sols. Actuellement, dans les régions peu boisées on ne trouve une couverture pédologique étendue que sur les pentes les moins accentuées ou seulement dans les quelques forêts les plus importantes, si le relief est extrèmement accidenté (comme p. ex. dans les bois de chênes lièges en Catalogne). Le solum du sol holocène a été presque complètement érodé sur de grandes surfaces, ainsi que la roche-mère ou l'horizon-CCa se trouvent à peu de profondeur ou ils-mêmes présentent la surface. La destruction directe ou indirecte (par la mise en pâturage) de la végétation par l'homme est à rendre responsable pour la plus grande part de ces arasements et même pour le déblaiement total d'une grande partie de la couverture pédologique holocène. Cette érosion, causée par l'homme, c'est-à-dire “quasinaturelle”, est bien moins forte que celle des périodes de plus forte acitivité morphodynamique du Pléistocène. L'activité partielle domine, c'est-à-dire lente érosion de pente à cause d'un ruissellement diffus et elle ne se prolonge pas sur les glacis, mais cède la place à l'accumulation. On ne trouve plus souvent de concentration du ruissellement, qui réactive les vallons en berceau et les vallées sèches ou crée même des formes nouvelles causées par le ruissellement concentré, c'est-à-dire la dissection des pentes, que dans les roches riches d'argile. Mais même dans ce cas on a sur les glacis d'accumulation ou aussi de dissection. Des cas avec érosion récente sur des glacis et ainsi aussi élargissement des glacis d'érosion, par conséquence l'existence de formation récente des pédiments, sont très rares et toujours limités aux roches bien favorables à l'érosion. Dans le même ordre d'idée, les pédiments nouveaux n'ont qu'une extension extrèmement réduite par rapport aux formes fossiles du Pléistocène. On a observé en de nombreux endroits que la formation des pédiments eut à l'époque sousrécente une plus grande importance que maintenant. On peut par suite découvrir assez souvent des formes de dissection de pente postérieures au Pléistocène et recouvertes de débris et de végétation, ce qui prouve qu'elles sont inactives. Quelques observations sporadiques indiquent de plus que cette ou ces phases d'érosion sous-récentes plus fortes qu'elles soient probablement uniquement causées par le climat ou par une combinaison des influences climatiques et humaines, peuvent avoir une grande part de responsabilité pour avoir coupé ou même enlever la couverture pédologique postérieure au Pléistocène. Il faut par conséquent, surtout dans les régions sèches, tenir compte du fait que la prépondérance de la stabilité morphodynamique dans l'Holocène — comme on a pu le prouver en Amérique et Afrique occidentale — peut avoir été interrompue par de courtes phases d'activité causée par un changement de climat. On peut relever de nombreuses coincidences en comparant les résultats obtenus dans la région méditerranéenne avec ceux du Sahara central, avec toutefois une différence évidente: Dans les régions humides, la morphodynamique est caractérisée par une alternance des phases de stabilité et d'activité (souvent seulement des phases d'activité partielle). Par contre, l'état de stabilité morphodynamique est notablement remplacé dans les déserts par l'état d'activité morphodynamique partielle. Les sols bien développés ne manquent pas totalement, mais leur formation se restreigne ici sur les époques moins nombreuses où règne la plus grande humidité pédoclimatique. Bien qu'une comparaison directe entre la séquence climatique de la région méditerranéenne avec les profils jusqu'à maintenant les plus complète du Sahara (vallée de Saoura) ne soit pas encore possible, on doit être certain, que les variations climatiques qui ont influencées la morphodynamique ne furent pas plus rares dans le Sahara que dans les subtropicales plus humides ou qu'en Europe centrale. La question de savoir si les variations climatiques au Sahara (et en Afrique occidentale) se sont produites simultanément ou en opposition avec celles de la zone tempérée ne peut être résolue, faute d'une stratigraphie détaillée. Nombre de découvertes confirment l'hypothèse du parallélisme, alors qu'elles ne concordent pas avec les “théorieś de la pendulation”, qui d'ailleurs sont basées sur le terme ambigu de “Pluvial”.
Resumen
Debido a diferentes resultados, ya no puede satisfacer la antigua concepción paleoclimatológica en cuanto a un cambio regular entre húmedo “pluvial” y seco “interpluvial”, que deberían corresponder en el subtrópico del hemisferio norte a glacial e interglacial en Centroeuropa:1.Investigaciones analíticas de polen en España, Italia y Grecia han dado análogamente tipos de vegetación pobres en bosques ó hasta sin bosques, mientras que la idea antigua presuponía bosques con vegetación cerrada durante los períodos glaciares (debido a un supuesto aumento de precipitaciones).2.Con esto corresponden las apariciones de capas de loess en diferentes partes de la región mediterránea, que dejan deducir un clima glacial árido, lo que se comprueba con la fauna de caracoles encontrada en el loess.3.Las costras calcáreas, tomadas predominantemente como indicadores para condiciones muy áridas no son una formación superficial, sino horizontes CCa de suelos. Su formación está ligada a condiciones con una escurrida de caliza de un solum cercano a la superficie y supone con esto una humedad estacional, el intenso precipitado de cal en el subsuelo requiere por otra parte una estación anual seca.4.Los paleo-sueolos y capas de escombros de falda tomadas igualmente como indicadores para precipitaciones mayores, no son producto de u n tipo de clima. Su aparición alternada de cambio múltiple demuestra, que no son de una formación a un mismo tiempo, sino que se formaron en distintos períodos de diferentes condiciones ecológicas. La formación de suelos presupone un alto rezumen y una relativa calma en cuanto a erosión, mientras que una dislocación de escombros de falda presupone condiciones con dominio de desagüe superficial. O sea que justamente los indicadores más importantes — suelos (en parte con horizontes CCa en forma de costra calcárea) y capas de escombros de falda — no permiten una deducción en cuanto a la cantidad absoluta de precipitaciones y su transformación, sino que tipos de los efectos diferentes de la precipitación en la ecología de paisaje, debido a una relación diferenciada de rezumen a desagüe superficial, por un reparto diferente de las precipitaciones. Se propone no usar los términos “pluvial” e “interpluvial”, que pueden llevar a errores, sino que usar sólo términos no basados en hipótesis, y que describan estados fundamentales ecológicos directamente observables: tiempos de actividad morfodinámica (con dominancia de erosión de falda y sin formación de suelos) se ponen en contraposición a tiempos de estabilidad morfodinámica (con formación de suelos y sin ó con muy poca dislocación de materia en suspensión en faldas). Estados de transición se caracterizan con el término “actividad parcial”. Para obtener un nuevo concepto paleoclimático se han buscado en varios viajes afloramientos posiblemente en series de acumulación que no se hayan interrumpido por fases de erosión. De estos se han sometido a un análisis detallado hasta ahora un perfil grande (Ses Penyes Rotjes/Mallorca) con series de suelos y sedimentos del Pleistoceno inferior y medio (más de 30 suelos fósiles), como varios perfiles de acantilados más bajos en las islas Baleares y en la costa atlántica de Marruecos con series de suelos y sedimentos del Pleistoceno superior. Habría que hacer resaltar los siguientes resultados: Se han comprobado en las partes bajas de la región mediterránea, como en Centroeuropa, un alternar de períodos con formación de suelos (períodes de estabilidad) y períodos con fuerte morfodinámica en faldas, vaguadas y sobre abanicos de deyección (periodos de actividad). Como en Centroeuropa no aparecen aislados los paleosuelos en los perfiles más divididos sino en complejos, que según su correlación (en parte hasta en estratos alternantes) con sedimentos marinos de las transgresiones interglaciares del mar, hay que atribuirlos a períodos interglaciares y periodos prematuros de los glaciales del Cuaternario. En contraposición a los resultados en los complejos de suelos centroeuropeos, no se pueden en regla general diferenciar tipológicamente los suelos singulares en la región mediterránea; solamente el suelo basal de un complejo está a menudo senalado por una formación de cárisco (syn- ó parapedogenética) de los horizontes CCa (costras calizas), lo que indica una mayor humedad, ó mayor tiempo de formación (ó ambas cosas), asi que se vea en él una formación correlativa del interglacial centroeuropeo (ó partes de él). Los complejos de suelos pueden ser divididos — conforme a los resultados obtenidos en perfiles de loess por KUKLA en la ČSSR — en varios subciclos según diferentes tipos de sedimentos e intensidad de formación de los diferentes suelos. Las secciones superiores de los glaciales están formadas — según las circunstancias locales — especialmente de aluviones de clasticidad fina hasta gruessa ó de series de dunas de períodos regresionarios ó un alternar de ambas formaciones. En las series de los glaciales superiores disminuyen ostensiblemente, en contraposición a las series interglaciares hasta glaciares prematuras, fuera de sedimentos de suelos, también suelos autóctonos. La formación de suelos no falta absolutamente, pero es de una intensidad débil. Suelos muy débiles (en todas las secciones de perfiles), como también suelos muy pronunciados, pueden mostrar todos los horizontes CCa en forma de cementación, como también en formación de costras calcáreas laminadas. Esto quiere decir que en todos los períodos de formación de suelos, ya sea en periodos cálidos como frios de los ciclos interglaciales — glaciales del Cuaternario, reinaba un clima de caraćter mediterráneo con fuerte disecación de suelo en verano. La serie de sedimentos más reciente concluye con varios suelos, que pertenecen al holoceno y probablemente también al glacial tardío (Würm superior). Los perfiles de suelos y sedimentos alternados en la zona mediterránea poseen una estructura, asimismo rica sorprendentemente semjante a los perfiles más ricos en Centroeuropa. Según KUKLA se pueden dividir en series “inferiores” y “superiores”. Las series inferiores están caracterizadas ante todo por períodos de estabilidad, que estaban separadas sólo por fases de actividad relativamente cortas, en las cuales además predominaba — en su mayoría — sólo el estado de actividad parcial (vegetación moderadamente aclarada). Las series superiores consisten en períodos de actividad más largos, en los cuales, se ha dado mayor importancia al estado de actividad plena (destrucción fuerte de la vegetación) paralelamente a les fases de actividad parcial. Fases intercaladas de estabilidad eran aqui de muy corta duración. El holoceno es un período estratigráfico, que estaba caracterizado — bajo condiciones normales — por predominante estabilidad morfodinámica con intensiva formación de suelos, ya que la repartición de precipitación — aúnque más acentuada que en Centroeuropa — favorecía hasta en las regiones más áridas a tipos de vegetación rica en plantas ligneas con suficiente protección de suelos. Capas cerradas de suelos se encuentran en el campo abierto casi solamente en regiones con poca inclinación; en relieves empinados sólo en algunas extensiones mayores de bosques (ejemplo: bosques de encinas de corcho en Cataluña). En áreas muy grandes el solum del suelo holoceno está bastante ó totalmente erodado, así que las rocas ó el horizonte CCa están en grandes extensiones cerca de la superficie ó forman directamente la superficie. Para la casi total ó total desaparición de gran parte de las capas de suelos holocenos, hay que hacer altamente responsable la directa ó indirecta destrucción antropógena de la vegetación (p. ej. por enpastamiento). Esta erosión causada por la actividad antropógena, sea “casi natural”, es bastante menos intensiva que la erosión en los períodos pleistocenos de activided más fuerte. Hay preponderantemente actividad parcial, esto quiere decir lenta erosión de falda por desagüe superficial no concentrado, que no sigue al pie de la falda, sino que pasa aqui a una acumulación. Concentraciones de desagüe con revivificación de formas cavernosas preexistentes ó hasta formación nueva de formas de desagüe — o sea cortes de falda — es sólo más frequente en rocas arcillosas. Pero también en este caso predominan acumulación ó erosión linear en las areas al pie de faldas. Casos de erosión areal reciente en extensiones al pie de faldas, y con esto también extensión del areal de pedimentos de erosión o sea presencia de pedimentación reciente, son bién raros y limitados siempre a rocas con alto propicio de erosión. Igualmente signicativo es, que pedimentos recién formados tienen, en comparación a formas anteriores del pleistoceno, sólo una extensión sumamente pequeña. En varias localidades se ha observado, que la pedimentación ha tenido mayor importancia en períodos subrecientes que hoy. A esto corresponde que se pueden comprobar frequentemente formas de cortes de falda postpleistocenas, que se muestran inactivas hoy debido al cubrimiento con escombros de falda y de vegetación. Observaciones esporádicas demuestran, que esta ó estas fases subrecientes con erosión más intensa causadas probablemente por influencias climáticas y antropógenas superpuestas aún pueden tener una grande responsabilidad en la erosión ó desaparición de las capas de suelo postpleistocenas. O sea que hay que contar, que, especialmente en regiones áridas, el período holoceno de predominante estabilidad (como se ha comprobado en Africa occidental y Norteamérica) podría haber estado interrumpido por cortas fases de actividad, causadas climáticamente. Una comparación entre los resultados de la región mediterránea y las regiones desérticas de la Sahara central, da numerosas paralelas, pero también una marcante diferencia: en las regiones húmedas está marcada la morfodinámica por un alternar de estados de estabilidad y actividad (frecuentemente sólo estados de actividad parcial), mientras que en los desiertos el estado de estabilidad es sustituido en gran parte por el de actividad parcial. Suelos substanciosos no faltan absolutamente, pero están limitados a los períodos no muy frecuentes de mayor humedad pedoclimática. Aúnque todavía no sea posible una comparación directa entre la secuencia climática comprobada en la región mediterránea con los perfiles hasta ahora más completos de la Sahara (valle de Saoura), tiene que ser seguro, que fluctuaciones climáticas geomorfodinámicamente relevantes en la Sahara, no eran menos frecuentes que en el subtrópico más húmedo y que en Centroeuropa. La pregunta, si es que las fluctuaciones climáticas en la Sahara (y en Africa occidental) transcurrían con las de la región mediterránea y de la zona temperada en forma paralela ó contraria, no se puede determinar debido a la falta de una estratigrafía minuciosa. Varios ejemplos se pronuncian en favor de la hipótesis de paralelidad, mientras que no son justas las “teorias de pendulación”, sobre todo por que están basadas en parte sobre el concepto pluvial ambiguo.",https://doi.org/10.1016/S0341-8162(73)80009-8,https://www.sciencedirect.com/science/article/pii/S0341816273800098,,,,1973,Quartäre Klimazyklen Im Westlichen Mediterrangebiet Und Ihre Auswirkungen Auf Die Reliefund Bodenentwicklung: vorwiegend nach Untersuchungen an Kliffprofilen auf den Balearen und an der marokkanischen Atlantikküste,von H. Rohdenburg and U. Sabelberg,article,ROHDENBURG197371,CATENA,,1,0341-8162,,,
,,217-283,,"Weighted oscillator strengths are tabulated for 6185 spectral lines in Ce II, some of which are found in the solar spectrum. They belong to transitions between the 4f5d2, 4f5d6s, 4f6s2, 4f26p, and 4f3 odd configurations and the 4f26s, 4f25d, 4f5d6p, 5d3, 4f6s6p, and 5d26s even configurations. The values were calculated by a method in which Slater parameters were first computed ab initio and then adjusted by means of a least-squares optimization routine so as to minimize discrepancies between measured and computed levels. Configuration interaction was included between all levels of the same parity. Landég values were also computed and compared with available measured data. Factors affecting the accurary of the data are discussed.",https://doi.org/10.1016/0092-640X(90)90003-3,https://www.sciencedirect.com/science/article/pii/0092640X90900033,,,,1990,Computed oscillator strengths and Landég values of Ce II,B.C. Fawcett,article,FAWCETT1990217,Atomic Data and Nuclear Data Tables,2,46,0092-640X,,,
,,253-326,,"Nuclear structure data available through December 1976 are compiled, and adopted level properties are given. The bulk of the data is presented pictorially for easy comparison. Experimental details, references, and additional comments, where required, are given in the text. All drawings, tables, and comments are reproduced from the computerized Evaluated Nuclear Structure Data File (ENSDF). Any additions or corrections desired by the users should be addressed to the compilers for maintenance and updating of the computer file.",https://doi.org/10.1016/S0090-3752(77)80010-0,https://www.sciencedirect.com/science/article/pii/S0090375277800100,,,,1977,Nuclear data sheets for A = 56,R.L. Auble,article,AUBLE1977253,Nuclear Data Sheets,3,20,0090-3752,,,
Handbook of Health Economics,,I-1-I-44,Handbook of Health Economics,,https://doi.org/10.1016/S1574-0064(00)80175-4,https://www.sciencedirect.com/science/article/pii/S1574006400801754,,Elsevier,,2000,Author Index,,incollection,2000I-1,,,1,1574-0064,,Anthony J. Culyer and Joseph P. Newhouse,
,,469-619,,"PART I of this reaction list for charged-particle-induced nuclear reactions has been prepared from the journal literature for the period from July 1970 through June 1971. Each published experimental paper is listed under the target nucleus in the nuclear reaction with a brief statement of the type of data in the paper. The nuclear reaction is denoted by A(a,b)B, where Ma≥ (one-nucleon mass). There is no restriction on energy. Nuclear reactions involving mesons in the outgoing channel are not included. Beginning with this supplement, theoretical papers which treat directly with the analysis of nuclear reaction data and results are included in the reaction list. In PART II is presented a reaction list for the Coulomb excitation reaction which has been prepared from the journal literature for the period from 1956 through June 1971.",https://doi.org/10.1016/S0092-640X(71)80029-3,https://www.sciencedirect.com/science/article/pii/S0092640X71800293,,,,1971,"Reaction list for charged-particle-induced nuclear reactions: Part I: Z=1 to Z=98 (H to Cf), July 1970–June 1971 Part II: Coulomb Excitation, 1956–June 1971",F.K. McGowan and W.T. Milner,article,MCGOWAN1971469,Atomic Data and Nuclear Data Tables,6,9,0092-640X,,,
,,247-253,,"The cause and management of injuries to the ampulla of Vater during operations on the stomach and duodenum are described. Nearly all of them occur during gastric resection for duodenal ulcer. In cases in which the injury was accidental, eight patients of a total of sixty-one died. Deliberate separation and reimplantation resulted in no deaths in ten patients. A method of duodenal advancement and anastomosis to the area of the ampulla together with drainage by transduodenal catheters of 2 to 4 F polyvinyl tubing in each duct is the most acceptable operative repair in these cases. Vagotomy with pyloroplasty is a preferred method of avoiding this injury.",https://doi.org/10.1016/0002-9610(67)90379-0,https://www.sciencedirect.com/science/article/pii/0002961067903790,,,,1967,Injury to the sphincter of oddi in the course of gastric and duodenal surgery,Thomas T. White and Eric R. Sanderson and Alan Morgan,article,WHITE1967247,The American Journal of Surgery,2,114,0002-9610,,,
,,1-232,,,https://doi.org/10.1016/S0022-328X(00)88806-3,https://www.sciencedirect.com/science/article/pii/S0022328X00888063,,,,1973,The organic compounds of cobalt(III),D. Dodd and M.D. Johnson,article,DODD19731,Journal of Organometallic Chemistry,1,52,0022-328X,,,
,,1-213,,Stopping powers and ranges are tabulated for all ions of atomic number 2 ≤ Z ≤ 103 in the energy region 2.5 ≤ EA ≤ 500 MeV/u for 36 solid materials. The calculations use stopping powers for α particles and a new parameterization for the heavy-ion effective charge which is deduced from a set of about 600 experimental stopping-power values covering an energy range from 3 to 90 MeV/u for 15 incident heavy ions and 18 solid stopping materials.,https://doi.org/10.1016/0092-640X(90)90001-Z,https://www.sciencedirect.com/science/article/pii/0092640X9090001Z,,,,1990,Range and stopping-power tables for 2.5–500 MeV/nucleon heavy ions in solids,F. Hubert and R. Bimbot and H. Gauvin,article,HUBERT19901,Atomic Data and Nuclear Data Tables,1,46,0092-640X,,,
,,274-278,,,https://doi.org/10.1016/0002-9610(67)90383-2,https://www.sciencedirect.com/science/article/pii/0002961067903832,,,,1967,General surgical complications associated with renal allotransplantation using related donors,Roy Cohn and Samuel Kountz and Robert Swenson and John Palmer,article,COHN1967274,The American Journal of Surgery,2,114,0002-9610,,,
,,199-323,,"The theory of semi-leptonic weak interactions is reviewed and confronted with present experimental data. The theoretical points emphasized are the basic tenets of the Cabibbo theory, the algebra of currents, and the relevance of strong interaction symmetries to the weak semi-leptonic amplitudes. The experimental data is discussed in detail, and future lines of investigation, necessary for testing detailed theoretical predictions and for resolving outstanding questions, are indicated.",https://doi.org/10.1016/0370-1573(72)90018-X,https://www.sciencedirect.com/science/article/pii/037015737290018X,,,,1972,Leptonic decays of hadrons,L.-M. Chounet and J.-M. Gaillard and M.K. Gaillard,article,CHOUNET1972199,Physics Reports,5,4,0370-1573,,,
,,180-189,,"Hemodynamic and metabolic studies of ten patients critically ill with diffuse bacterial peritonitis have been presented. The cardiac output and velocity of blood flow were normal. Total peripheral arterial resistance was markedly reduced in patients in whom systolic blood pressure was reduced to 75 mm. Hg or less despite normal cardiac output. Blood lactate levels were greatly elevated in these patients, indicative of a critical reduction in blood flow necessary to sustain normal metabolism of vital tissues. Our data indicate that an abnormal variation in distribution of blood flow is an outstanding circulatory alteration in patients with diffuse bacterial peritonitis. This hemodynamic effect may be explained by arteriovenous shunting in the systemic vascular bed. The site of such shunting is as yet unidentified, but presumably occurs in the area of peritoneal inflammation. Decreases in alveolar oxygen exchange also indicate the coexistence of arteriovenous shunting in the pulmonary circulation. Ventilatory failure and profound alterations in pulmonary function appear to be significant factors in the lethality of diffuse bacterial peritonitis.",https://doi.org/10.1016/0002-9610(67)90371-6,https://www.sciencedirect.com/science/article/pii/0002961067903716,,,,1967,Hemodynamic and metabolic changes associated with bacterial peritonitis,Leonard Rosoff and Max Weil and Edward C. Bradley and Clarence J. Berne,article,ROSOFF1967180,The American Journal of Surgery,2,114,0002-9610,,,
,,S217-S251,,,https://doi.org/10.1016/S1166-7087(10)70042-7,https://www.sciencedirect.com/science/article/pii/S1166708710700427,,,,2010,Recommandations en Onco-Urologie 2010 : Cancer de la prostate,L. Salomon and D. Azria and C. Bastide and P. Beuzeboc and L. Cormier and F. Cornud and D. Eiss and P. Eschwège and N. Gaschignard and C. Hennequin and V. Molinié and P. {Mongiat Artus} and J.-L. Moreau and Michel Péneau and M. Peyromaure and V. Ravery and X. Rebillard and P. Richaud and P. Rischmann and F. Rozet and F. Staerman and A. Villers and M. Soulié,article,SALOMON2010S217,Progrès en Urologie,,20,1166-7087,Recommandations 2010-2013 en onco-urologie Comité de Cancérologie de l’Association Française d’Urologie,,
,,eS1416-eS1638,,,https://doi.org/10.1016/j.physio.2011.04.003,https://www.sciencedirect.com/science/article/pii/S0031940611000708,,,,2011,Special Interest Report Abstracts,,article,2011eS1416,Physiotherapy,,97,0031-9406,World Physical Therapy 2011 Abstracts,,
Handbook of Health Economics,,I-1-I-44,,,https://doi.org/10.1016/S1574-0064(00)80049-9,https://www.sciencedirect.com/science/article/pii/S1574006400800499,,Elsevier,,2000,Author Index,,incollection,2000I-1,,,1,1574-0064,,,
,,971-1013,,,https://doi.org/10.1016/S0952-7915(05)80021-4,https://www.sciencedirect.com/science/article/pii/S0952791505800214,,,,1991,Autoimmunity,,article,1991971,Current Opinion in Immunology,6,3,0952-7915,,,
,,I-CLXXXIII,,,https://doi.org/10.1016/S1936-878X(22)00604-0,https://www.sciencedirect.com/science/article/pii/S1936878X22006040,,,,2022,Full issue PDF,,article,2022I,JACC: Cardiovascular Imaging,11,15,1936-878X,,,
,,279-284,,"Eighteen patients with severe congenital ventral abdominal wall defects were encountered in surgical practices in San Jose, California, from January 1, 1956, to December 31, 1965. Ten patients had defects which were not covered with a sac or membrane and appeared to have had a ruptured omphalocele existing many months before delivery. Distinctions are made between this group and the patients who have been categorized as having gastroschisis. Of the eight patients in whom a sac covered the congenital defect, there were six survivors. Of ten patients with no sac over the omphalocele defect, there were only two survivors. General considerations and details of surgical management are presented.",https://doi.org/10.1016/0002-9610(67)90384-4,https://www.sciencedirect.com/science/article/pii/0002961067903844,,,,1967,Omphalocele and related defects,Allen H. Johnson,article,JOHNSON1967279,The American Journal of Surgery,2,114,0002-9610,,,
,,1-166,Handbook of Nanostructured Materials and Nanotechnology,,https://doi.org/10.1016/B978-012513760-7/50053-8,https://www.sciencedirect.com/science/article/pii/B9780125137607500538,Burlington,Academic Press,978-0-12-513760-7,2000,Chapter 1 - Intercalation compounds in layered Host lattices: Supramolecular Chemistry in nanodimensions,Anton Lerf,incollection,LERF20001,,,,,,Hari Singh Nalwa,
,,17-318,,,https://doi.org/10.1016/S0022-2860(10)80004-3,https://www.sciencedirect.com/science/article/pii/S0022286010800043,,,,1994,Master listing,,article,199417,Journal of Molecular Structure,,316,0022-2860,,,
,,181-255,,"Calculated weighted oscillator strengths are tabulated for spectral lines of Fe III, Fe IV, Fe V, and Fe VI. The lines belong to transition arrays 3d6-3d54p and 3d54s-3d54p in Fe III, 3d5-3d44p and 3d44s-3d44p in Fe IV, 3d4-3d34p and 3d34s-3d34p in Fe V, and 3d3-3d24p and 3d24s-3d24p in Fe VI. For the calculations, Slater parameters are optimized on the basis of minimizing the discrepancies between observed and computed wavelengths. Configuration interaction was included among the 3dn, 3dn−14s, 3dn−24s2, 3dn−14d, and 3dn−15s even configurations and among the 3dn−14p, 3dn−24s4p, and 3dn−15p odd configurations, with 3p53dn+1 added for Fe VI. Calculated wavelengths are compared with observational data, and the compositions of energy levels are listed. This completes a series of similar computations for these complex configurations covering Fe I to Fe VI.",https://doi.org/10.1016/0092-640X(89)90019-3,https://www.sciencedirect.com/science/article/pii/0092640X89900193,,,,1989,"Computed oscillator strengths and energy levels for Fe III, Fe IV, Fe V, and Fe VI with calculated wavelengths and wavelengths derived from established data",B.C. Fawcett,article,FAWCETT1989181,Atomic Data and Nuclear Data Tables,2,41,0092-640X,,,
,,250-262,,"Small inflections in plots of the total yield of secondary electrons versus primary electron energy were reported more than fifty years ago and attributed variously to thresholds for the excitation of core states, and to diffraction of the incident electrons. Although the existence of these inflections was discounted by later researchers, recent studies of the derivative of the yield leave no doubt as to their reality or their origin. The spectrum of core excitation thresholds provides information on the composition of the surface region. Near-threshold structure is related to the electronic state of the atoms. Extended fine structure above the threshold can be inverted to obtain interatomic spacings even from relatively disordered surfaces. The principal limitation in these measurements results from diffraction of the incident electron beam, which produces variations in electron reflectivity. The extreme simplicity of the equipment required makes this technique available to essentially every surface science laboratory.",https://doi.org/10.1016/0378-5963(80)90076-8,https://www.sciencedirect.com/science/article/pii/0378596380900768,,,,1980,Surface spacings from the secondary electron yield,Robert L. Park,article,PARK1980250,Applications of Surface Science,3,4,0378-5963,,,
Developments in Petroleum Science,,258-365,Production and Transport of Oil and Gas,"Publisher Summary
Production by bottom-hole pumps is a mechanical technique. The fluid entering the well from the formation is lifted to the surface by a pump installed below the producing fluid level. The prime mover of the pump is installed either on the surface, or in the well; in the latter case, it is integral with the pump. The bottom-hole pump unit comprises all the mechanisms and equipment serving the purposes of production. The chapter discusses the sub-divisions of the bottom-hole pumps. The sucker-rod pump is a plunger pump performing a reciprocating motion. Its prime mover is installed on the surface. ways. If a crank and a flywheel are used, the installation is called a crank-type or walking-beam-type sucker-rod pump. long-stroke hydraulic pumps, a hydraulic means of transformation is adopted; the installation is called a hydraulic sucker-rod pump. If the transformation is by wireline and pulley, the installation is called a derrick-type sucker-rod pump. In rodless bottom-hole pump installations, the bottom-hole pump may be of plunger or centrifugal or some other type. Hydraulic pumps are driven by a hydraulic engine integral with them, driven in its turn by a power fluid to which pressure is imparted by a prime mover situated on the surface. This type is called a hydraulic (rodless) bottom-hole pump. Centrifugal pumps integral with an electric motor, and lowered to the well bottom, are called submersible pumps. Further rodless bottom-hole pumps include electric membmrbe pumps and sonic pumps.",https://doi.org/10.1016/S0376-7361(08)70157-2,https://www.sciencedirect.com/science/article/pii/S0376736108701572,,Elsevier,,1975,Chapter 4 Producing oil wells — 2,,incollection,1975258,,,3,0376-7361,,A.P. Szilas,
,,308-313,,Cerebrovascular insufficiency produced as a result of reversal of the flow in the vertebral artery secondary to occlusion in the proximal subclavian or innominate arteries is now termed the subclavian steal syndrome. Symptoms are primarily those of basilar artery insufficiency but forebrain ischemic symptoms also occur. The diagnosis is suspected when a difference in the blood pressure and pulse between the right and left arm is detected and it is confirmed by contrast arteriography demonstrating retrograde flow in the vertebral artery. Treatment is surgical relief of the arterial obstruction or stenosis in those patients with radiographically demonstrated subclavian steal syndrome. Two patients treated surgically are presented. One patient had occlusion of the right subclavian artery treated by thromboendarterectomy and patch graft through a transverse neck incision with resection of the clavicle. The other was treated in a similar fashion through a left posterolateral thoracotomy incision. Surgical therapy is effective.,https://doi.org/10.1016/0002-9610(67)90389-3,https://www.sciencedirect.com/science/article/pii/0002961067903893,,,,1967,Surgical treatment of the subclavian steal syndrome,R.Hewlett Lee and John H. Kieraldo and Robert W. Jamplis,article,LEE1967308,The American Journal of Surgery,2,114,0002-9610,,,
,,191-357,Supplements to the 2nd Edition of Rodd's Chemistry of Carbon Compounds,"Publisher Summary
This chapter discusses the basic constitution, classification, and nomenclature; occurrence, function, and isolation; structure and synthesis; and properties of carotenoids. A carotenoid is still easily recognized by its methyl(or modified methyl)-substituted polyene chain. The C50 and C45 carotenoids, which barely fall within the classical definition of carotenoids, are considered as straightforward di-and monoalkylated derivatives of the more usual C40 skeleton. There are several methods of converting a carotenoid with all its double bonds trans into an equilibrium mixture of cis/trans isomers. The most commonly used method involves briefly exposing a solution of the compound containing a trace of iodine to light. Many of the mono- and bi-cyclic carotenoids contain one or more chiral centers. These are usually at C(3), C(6), C(5), or associated with the allene group. In all 3-substituted carotenoids, the configuration at the 3-position is R (the -OH substituent is of the “β” type using steroid nomenclature), and in all carotenoids containing α-type end-group that at the 6-position is also R (the-H is “α”).",https://doi.org/10.1016/B978-044453346-3.50093-7,https://www.sciencedirect.com/science/article/pii/B9780444533463500937,Amsterdam,Elsevier,978-0-444-53346-3,1975,Chapter 7 - The Carotenoid Group,J.B. Davis,incollection,DAVIS1975191,,,,,,M.F. Ansell,
,,231-327,,,https://doi.org/10.1016/j.rco.2008.07.274,https://www.sciencedirect.com/science/article/pii/S003510400800545X,,,,2008,Résumé des communications,,article,2008231,Revue de Chirurgie Orthopédique et Réparatrice de l'Appareil Moteur,"7, Supplement ",94,0035-1040,83e réunion annuelle de la Société française de chirurgie orthopédique et traumatologique,,
,,230-238,,"Reticuloendothelial function has been studied in patients with cancer by determination of the rate of disappearance from the plasma of microaggregates of albumin. Comparison of the rate of disappearance in twenty-two patients with cancer as compared with fourteen patients without known cancer suggests that reticuloendothelial function was impaired in certain patients with cancer. Alterations in reticuloendothelial function were observed in nine patients undergoing palliative therapy, that is, administration of adrenocortical steroids, adrenalectomy, oophorectomy, administration of 5-fluorouracil, and radiation therapy. In these nine patients a favorable therapeutic response occurred in association with an increase in reticuloendothelial function, and an unfavorable response with decrease in reticuloendothelial function. These initial studies suggest that in man, important relationships exist between the reticuloendothelial system and the course of cancer.",https://doi.org/10.1016/0002-9610(67)90377-7,https://www.sciencedirect.com/science/article/pii/0002961067903777,,,,1967,Reticuloendothelial function in patients with cancer: Initial observations,Arthur J. Donovan,article,DONOVAN1967230,The American Journal of Surgery,2,114,0002-9610,,,
,,161-207,,,https://doi.org/10.1016/0009-5907(63)81012-1,https://www.sciencedirect.com/science/article/pii/0009590763810121,,,,1963,A comprehensive bibliography of separations of organic substances by counter-current distribution,C.G. Casinovi,article,CASINOVI1963161,Chromatographic Reviews,,5,0009-5907,,,
,,IFC-S388,,,https://doi.org/10.1016/j.jacc.2017.04.005,https://www.sciencedirect.com/science/article/pii/S0735109717369097,,,,2017,Full Issue PDF,,article,2017IFC,Journal of the American College of Cardiology,"16, Supplement ",69,0735-1097,22nd Cardiovascular Summit TCTAP 2017,,
,,1-267,,,https://doi.org/10.1016/0014-5793(86)81419-3,https://www.sciencedirect.com/science/article/pii/0014579386814193,,,,1986,Index of biochemical reviews 1985,,article,19861,FEBS Letters,,207,0014-5793,,,
,,333-339,,,https://doi.org/10.1016/0002-9610(67)90393-5,https://www.sciencedirect.com/science/article/pii/0002961067903935,,,,1967,Gastric secretory tests: Pro and con,Edward Passaro and H.Earl Gordon,article,PASSARO1967333,The American Journal of Surgery,2,114,0002-9610,,,
,,254-258,,Several experimental technics for the production of acute and chronic pulmonary edema and the collection of pulmonary lymph are described. The response of the pulmonary lymph system in acute and chronic failure was studied. The studies suggest that the pulmonary lymphatics are capable of expanding and may play an important role in the removal of fluid from the lung.,https://doi.org/10.1016/0002-9610(67)90380-7,https://www.sciencedirect.com/science/article/pii/0002961067903807,,,,1967,Significance of changes in the pulmonary lymph flow in acute and chronic experimental pulmonary edema,Sanford E. Leeds and Herman N. Uhley and John J. Sampson and Meyer Friedman,article,LEEDS1967254,The American Journal of Surgery,2,114,0002-9610,,,
,,I-CLXXX,,,https://doi.org/10.1016/S2666-0849(21)00145-5,https://www.sciencedirect.com/science/article/pii/S2666084921001455,,,,2021,Full Issue PDF,,article,2021I,JACC: Case Reports,3,3,2666-0849,,,
,,253-321,,"We present a discussion of the interaction of atoms with a partially polarised radiation field. We take to some extent into account the differences in the populations of atomic states, quantum interference effects which occur when atomic states are overlapping, and collisional relaxation. The theory is presented in such a way that it is particularly suitable for an application to solar lines.",https://doi.org/10.1016/0370-1573(71)90011-1,https://www.sciencedirect.com/science/article/pii/0370157371900111,,,,1971,The interaction of atoms with polarised light,F.K. Lamb and D. {Ter Haar},article,LAMB1971253,Physics Reports,4,2,0370-1573,,,
International Review of Cytology,,245-363,,"Publisher Summary
The cells of Diptera have been used as a model system in a wide variety of experiments designed to probe the organization of the eukaryotic genome. The cells of these organisms lend themselves readily to both cytological and biochemical investigations using specific techniques, such as light and electron microscopic autoradiography, immunofluorescence, salt or sucrose density gradient and gel electrophoretic analyses, hybridization in situ, and molecular cloning-recombinant DNA studies. This chapter reviews the research carried out in past years using dipteran model systems, specifically three families—the Drosophilidae, the Chironomidae, and the Sciaridae. Six separate areas of research are considered. They are chromatin structure, middle repeated DNA (MR DNA), highly repeated DNA (HR DNA), satellites, and heterochromatin, puffs, heat shock, and mechanisms of gene control: the nonhistone proteins.",https://doi.org/10.1016/S0074-7696(08)61184-5,https://www.sciencedirect.com/science/article/pii/S0074769608611845,,Academic Press,,1981,"The Diptera as a Model System in Cell and Molecular Biology11This paper is dedicated to the memory of Dr. Martin Hagopian, our colleague and friend, who originally recognized the value of a comprehensive review on dipteran systems to cell and molecular biologists.",Elena C. Zegarelli-Schmidt and Reba Goodman,incollection,ZEGARELLISCHMIDT1981245,,,71,0074-7696,,G.H. Bourne and J.F. Danielli and K.W. Jeon,
Methods in Enzymology,,79-143,Metabolism of Amino Acids and Amines Part A,"Publisher Summary
This chapter describes the microbiological and genetic handling of Neurospora crassa. It also reviews the biochemical methods of Neurospora. The simpler techniques followed by more complex modifications applicable to careful and sustained research are described. Neurospora crassa is a eukaryotic organism, a member of the fungal class Ascomycetes. As an ascomycete, it is related to yeasts, and as a fungus, it is more distantly related to mushrooms. The primary value of Neurospora in research is that the fungus is eukaryotic, can be handled as easily as bacteria, and thus provides a valuable basis of comparison between prokaryotes and eukaryotes in molecular biology. Several methods for the measurement of growth in Neurospora include measurement of the rate of mycelial elongation in race tubes, measurement of the amount of growth in stationary or shaken liquid culture after selected time intervals, and measurement of the doubling time in logarithmically growing culture. To study the physiological interaction of homologous genes in Neurospora crassa, different haploid nuclei must be associated in the same cell, where they function in a common cytoplasm.",https://doi.org/10.1016/0076-6879(71)17168-6,https://www.sciencedirect.com/science/article/pii/0076687971171686,,Academic Press,,1970,[4] Genetic and microbiological research techniques for Neurospora crassa,Rowland H. Davis and Frederick J. {de Serres},incollection,DAVIS197079,,,17,0076-6879,,,
,,1-115,,,https://doi.org/10.1016/S0370-2693(05)00296-0,https://www.sciencedirect.com/science/article/pii/S0370269305002960,,,,2005,Master index to volumes 601–610,,article,20051,Physics Letters B,,601-610,0370-2693,,,
Journal of Chromatography Library,,371-641,Bioaffinity Chromatography,"Publisher Summary
This chapter discusses the use of bioaffinity chromatography (BAC) in the isolation, determination, or removal of biologically active substances. The preparation of specific sorbents utilizing the exceptional properties of biologically active substances to form specific and reversible complexes has enormously facilitated the isolation of a number of antibodies, antigens and haptens, cells and cell organelles, cofactors and vitamins, and glycoproteins and saccharides. The different conditions applied during BAC depend on the nature of the substances to be isolated. In high-performance liquid bioaffinity chromatography (HPLBAC), the biospecificity of BAC is combined with a high-performance (pressure) technology based on the rigid particles of a uniform small size (high-performance liquid chromatography, HPLC). The separation times in HPLBAC are short (minutes) compared to hours for traditional, soft-gel BAC. Moreover, HPLBAC users have at their disposal a wide selection of HPLC equipment, including high-speed pumps, sophisticated injection units, detectors of various kinds, auto-sampling devices, and data-handling capabilities. This enables the users to fine-tune the separation process conveniently and promote higher productivity.",https://doi.org/10.1016/S0301-4770(08)60994-X,https://www.sciencedirect.com/science/article/pii/S030147700860994X,,Elsevier,,1993,"Chapter 9 Bioaffinity Chromatography in the Isolation, Determination or Removal of Biologically Active Substances",,incollection,1993371,,,55,0301-4770,,Jaroslava Turková,
,,3107-3214,,"We describe the physics and data included in the Reference Input Parameter Library, which is devoted to input parameters needed in calculations of nuclear reactions and nuclear data evaluations. Advanced modelling codes require substantial numerical input, therefore the International Atomic Energy Agency (IAEA) has worked extensively since 1993 on a library of validated nuclear-model input parameters, referred to as the Reference Input Parameter Library (RIPL). A final RIPL coordinated research project (RIPL-3) was brought to a successful conclusion in December 2008, after 15 years of challenging work carried out through three consecutive IAEA projects. The RIPL-3 library was released in January 2009, and is available on the Web through http://www-nds.iaea.org/RIPL-3/. This work and the resulting database are extremely important to theoreticians involved in the development and use of nuclear reaction modelling (ALICE, EMPIRE, GNASH, UNF, TALYS) both for theoretical research and nuclear data evaluations. The numerical data and computer codes included in RIPL-3 are arranged in seven segments: MASSES contains ground-state properties of nuclei for about 9000 nuclei, including three theoretical predictions of masses and the evaluated experimental masses of Audi et al. (2003). DISCRETE LEVELS contains 117 datasets (one for each element) with all known level schemes, electromagnetic and γ-ray decay probabilities available from ENSDF in October 2007. NEUTRON RESONANCES contains average resonance parameters prepared on the basis of the evaluations performed by Ignatyuk and Mughabghab. OPTICAL MODEL contains 495 sets of phenomenological optical model parameters defined in a wide energy range. When there are insufficient experimental data, the evaluator has to resort to either global parameterizations or microscopic approaches. Radial density distributions to be used as input for microscopic calculations are stored in the MASSES segment. LEVEL DENSITIES contains phenomenological parameterizations based on the modified Fermi gas and superfluid models and microscopic calculations which are based on a realistic microscopic single-particle level scheme. Partial level densities formulae are also recommended. All tabulated total level densities are consistent with both the recommended average neutron resonance parameters and discrete levels. GAMMA contains parameters that quantify giant resonances, experimental gamma-ray strength functions and methods for calculating gamma emission in statistical model codes. The experimental GDR parameters are represented by Lorentzian fits to the photo-absorption cross sections for 102 nuclides ranging from 51V to 239Pu. FISSION includes global prescriptions for fission barriers and nuclear level densities at fission saddle points based on microscopic HFB calculations constrained by experimental fission cross sections.",https://doi.org/10.1016/j.nds.2009.10.004,https://www.sciencedirect.com/science/article/pii/S0090375209000994,,,,2009,RIPL – Reference Input Parameter Library for Calculation of Nuclear Reactions and Nuclear Data Evaluations,R. Capote and M. Herman and P. Obložinský and P.G. Young and S. Goriely and T. Belgya and A.V. Ignatyuk and A.J. Koning and S. Hilaire and V.A. Plujko and M. Avrigeanu and O. Bersillon and M.B. Chadwick and T. Fukahori and Zhigang Ge and Yinlu Han and S. Kailas and J. Kopecky and V.M. Maslov and G. Reffo and M. Sin and E.Sh. Soukhovitskii and P. Talou,article,CAPOTE20093107,Nuclear Data Sheets,12,110,0090-3752,Special Issue on Nuclear Reaction Data,,
,,452-544,,,https://doi.org/10.1016/S0022-2860(98)00744-3,https://www.sciencedirect.com/science/article/pii/S0022286098007443,,,,1998,97–98 Author index,,article,1998452,Journal of Molecular Structure,,472-473,0022-2860,Infrared and Raman Spectroscopy Literature Data Base,,
,,8-118,,,https://doi.org/10.1016/S0092-640X(72)80019-6,https://www.sciencedirect.com/science/article/pii/S0092640X72800196,,,,1972,Reaction list for charged-particle-induced nuclear reactions,,article,19728,Atomic Data and Nuclear Data Tables,1,11,0092-640X,,,
,,359-431,Metabolism of Sulfur Compounds (Third Edition),,https://doi.org/10.1016/B978-0-12-299257-5.50016-6,https://www.sciencedirect.com/science/article/pii/B9780122992575500166,,Academic Press,978-0-12-299257-5,1975,CHAPTER 9 - Sulfohydrolases,K.S. Dodgson and F.A. Rose,incollection,DODGSON1975359,,,,,,David M. Greenberg,Third Edition
Advances in Agronomy,,197-319,,"This review reveals that crop residues of common cultivated crops are an important resource not only as a source of significant quantities of nutrients for crop production but also affecting soil physical, chemical, and biological functions and properties and water and soil quality. When crop residues are returned to the soils, their decomposition can have both positive and negative effects on crop production and the environment. Our aim as agricultural scientists is to increase the positive effects. This can only be achieved with the better understanding of residue, soil, and management factors and their interactions, which affect the decomposition and nutrient release processes. Data on nitrogen benefits and nitrogen recoveries from residues show that a considerable potential exists from residues, especially leguminous residues, not only in meeting the N demands of the succeeding crops, but also in increasing the long-term fertility of the soils. In addition, crop residues and their proper management affects the soil quality either directly or indirectly. Intensive cropping systems are very diverse and complex, so no one residue management system is superior under all situations. Ideally, crop residue management practices should be selected to enhance crop yields with a minimum adverse effect on the environment. It is suggested that in each cropping system, the constraints to production and sustainability should be identified and conceptualized to guide toward the best option. Multidisciplinary and integrated efforts by soil scientists, agronomists, ecologists, environmentalists, and economists are needed to design a system approach for the best choice of crop residue management system to enhance both agricultural productivity and sustainability.",https://doi.org/10.1016/S0065-2113(08)60846-9,https://www.sciencedirect.com/science/article/pii/S0065211308608469,,Academic Press,,1999,"Crop Residues and Management Practices: Effects on Soil Quality, Soil Nitrogen Dynamics, Crop Yield, and Nitrogen Recovery",K. Kumar and K.M. Goh,incollection,KUMAR1999197,,,68,0065-2113,,Donald L. Sparks,
,,267-273,,"Acute addition lactic acidosis causes marked cardiac slowing, decreased cardiac output, and a progressive rise in the central venous pressure in the dog, suggesting increased vagal activity as well as decreased myocardial function. Bilateral cervical vagotomy and atropine in large dosages were employed to evaluate the role of vagal innervation in producing bradycardia and rhythm changes during acute lactic acidosis. These experimental procedures increased cardiac rate but did not improve cardiac output after the induction of lactic acidosis. Isoproterenol was compared with norepinephrine as a therapeutic agent to improve myocardial function during acidosis. Norepinephrine administration increased arterial pressure by 16 per cent, but did not improve cardiac output or cardiac rate when infused during acidosis. By contrast, isoproterenol caused a 10 per cent fall in arterial pressure, a 93.5 per cent increase in the cardiac output, and a 32 per cent increase in cardiac rate. These experimental findings suggest that increased vagal activity is a cause for the bradycardia and rhythm changes observed during acute lactic acidosis. Isoproterenol was an effective therapeutic agent to improve cardiac output, decrease peripheral resistance, and increase cardiac rate during severe acidosis. The application of these findings to the management of low perfusion states has been discussed.",https://doi.org/10.1016/0002-9610(67)90382-0,https://www.sciencedirect.com/science/article/pii/0002961067903820,,,,1967,"Atropine, norepinephrine, and isoproterenol and the cardiac response to experimental lactic acidosis",Louis L. Smith and Martin Silberschmid and David B. Hinshaw,article,SMITH1967267,The American Journal of Surgery,2,114,0002-9610,,,
,,239-246,,"To evaluate the technical results of operative treatment of stenosis of the internal carotid artery, arteriographic assessment was used in one hundred consecutive procedures. Operative arteriograms were taken routinely at the completion of the endarterectomy and again two to eight weeks later. Late follow-up assessment was obtained by repeating the arteriograms whenever symptoms recurred or when the five-year follow-up period was reached. One fourth of the hundred arteriograms taken at the completion of operation revealed an unsuspected defect in the repair. In all but one of these patients immediate revision was carried out. The end point of the operation was a widely patent vessel as demonstrated by angiography. Follow-up arteriography at the time of discharge from the hospital revealed the only technical failure in the hundred operations, which was in the one patient in whom revision was not performed. Late follow-up examination revealed continued patency at the five year period in all but one instance, an asymptomatic occlusion which was found in a patient who had died of myocardial infarction. Since 25 per cent of the patients had unsuspected intraluminal defects or thrombosis, it is obvious that routine operative arteriograms will increase the technical success of carotid endarterectomy. When the operative arteriogram demonstrates a good result, long-term patency of the artery after endarterectomy is assured.",https://doi.org/10.1016/0002-9610(67)90378-9,https://www.sciencedirect.com/science/article/pii/0002961067903789,,,,1967,Technical result of carotid endarterectomy: Arteriographic assessment,F.William Blaisdell and Robert Lim and Albert D. Hall,article,BLAISDELL1967239,The American Journal of Surgery,2,114,0002-9610,,,
,,S1-S82,,,https://doi.org/10.1016/j.jcct.2017.05.005,https://www.sciencedirect.com/science/article/pii/S1934592517301272,,,,2017,Abstracts of the 12th Annual Scientific Meeting of the Society of Cardiovascular Computed Tomography,,article,2017S1,Journal of Cardiovascular Computed Tomography,"4, Supplement ",11,1934-5925,,,
,,I-CLIX,,,https://doi.org/10.1016/S2666-0849(20)30423-X,https://www.sciencedirect.com/science/article/pii/S266608492030423X,,,,2020,Full Issue PDF,,article,2020I,JACC: Case Reports,5,2,2666-0849,,,
,,173-179,,,https://doi.org/10.1016/0002-9610(67)90370-4,https://www.sciencedirect.com/science/article/pii/0002961067903704,,,,1967,The Pacific Coast: Its population and its medical manpower,Leon Goldman,article,GOLDMAN1967173,The American Journal of Surgery,2,114,0002-9610,,,
,,340-350,,,https://doi.org/10.1016/0002-9610(67)90394-7,https://www.sciencedirect.com/science/article/pii/0002961067903947,,,,1967,Wounds of the great vessels of the thorax: Diagnosis and surgical approach in twenty-four cases,Lyman A. Brewer and Richard Carter,article,BREWER1967340,The American Journal of Surgery,2,114,0002-9610,,,
,,259-266,,The complications with the use of polyethylene catheters are discussed and the world literature is reviewed. The twenty-six previously reported cases of polyethylene catheter embolus are analyzed. Ten cases of embolus from our teaching hospitals are reviewed and an additional thirteen cases from the Los Angeles area are added. The mortality from catheter embolus is high unless vigorous surgical measures are instituted for removal. The factors leading to catheter breakage and the measures to be taken for prevention are discussed. Treatment for catheter embolus is outlined.,https://doi.org/10.1016/0002-9610(67)90381-9,https://www.sciencedirect.com/science/article/pii/0002961067903819,,,,1967,Complications of indwelling venous catheters: With particular reference to catheter embolus,Richard B. Doering and Edward A. Stemmer and John E. Connolly,article,DOERING1967259,The American Journal of Surgery,2,114,0002-9610,,,
,,I-CCIX,,,https://doi.org/10.1016/S2666-0849(20)31398-X,https://www.sciencedirect.com/science/article/pii/S266608492031398X,,,,2020,Full Issue PDF,,article,2020I,JACC: Case Reports,15,2,2666-0849,,,
,,409-515,Handbook of Naturally Occurring Compounds,,https://doi.org/10.1016/B978-0-12-213601-6.50010-X,https://www.sciencedirect.com/science/article/pii/B978012213601650010X,,Academic Press,978-0-12-213601-6,1975,31 LINEAR ACETOGENINS,T.K. DEVON and A.I. SCOTT,incollection,DEVON1975409,,,,,,T.K. DEVON and A.I. SCOTT,
,,315-476,Biogenesis of Natural Compounds (Second Edition),,https://doi.org/10.1016/B978-0-08-002925-2.50012-7,https://www.sciencedirect.com/science/article/pii/B9780080029252500127,,Pergamon,978-0-08-002925-2,1963,CHAPTER 6 - THE BIOGENESIS OF CARBOHYDRATES,PETER BERNFELD,incollection,BERNFELD1963315,,,,,,PETER BERNFELD,Second Edition
,,1-232,,"This reaction list for charged-particle-induced nuclear reactions has been prepared from the journal literature for the period from 1948 through April 1969. Each published experimental paper is listed under the target nucleus in the nuclear reaction with a brief statement of the type of data in the paper. The nuclear reaction is denoted by A(a,b)B, where Ma≥ (one-nucleon mass). There is no restriction on energy. Nuclear reactions involving mesons in the outgoing channel are not included.",https://doi.org/10.1016/S0092-640X(69)80038-0,https://www.sciencedirect.com/science/article/pii/S0092640X69800380,,,,1969,Reaction list for charged-particle-induced nuclear reactions: Part B: Z=28 to Z=99 (Ni to Es),F.K. McGowan and W.T. Milner and H.J. Kim and Wanda Hyatt,article,MCGOWAN19691,Atomic Data and Nuclear Data Tables,1,7,0092-640X,,,
,,213-221,,"It has been shown that hepatic venous outflow obstruction is the primary hemodynamic lesion in cirrhosis. Furthermore, considerable evidence indicates that both the increased production of lymph and the formation of ascites in experimental and human cirrhosis are caused by the elevation of intrahepatic pressure which results from the outflow obstruction. Accordingly, the capacity of end to side and side to side portacaval shunts to reduce intrahepatic pressure was evaluated by measuring the effects of these procedures on pressure and lymph flow in the thoracic duct of fifty dogs. Portacaval shunts of both types were made in normal animals and in dogs with congestive cirrhosis, portal hypertension, and massive ascites produced by ligation of the hepatic veins. Normal dogs and dogs with cirrhosis but without shunts served as controls. Hepatic vein ligation resulted in massive ascites, which averaged 4.0 L., portal hypertension which averaged 208 mm. of saline solution, a mean thirteenfold increase in thoracic duct lymph flow, and a mean elevation of thoracic duct pressure which was almost three times the normal level. The end to side portacaval shunt reduced the high rate of lymph production and the elevated pressure significantly, but a fivefold increase in lymph flow and an approximately twofold elevation of thoracic duct pressure persisted. The side to side portacaval shunt lowered thoracic duct pressure to normal in every dog, and either abolished the excessive lymph formation or markedly reduced the rate of lymph production. The results of this study indicate that the side to side portacaval shunt is more effective than the end to side anastomosis in overcoming intrahepatic hypertension and decompressing the obstructed hepatic vascular bed. These findings represent an important consideration in the selection of surgical therapy for intractable cirrhotic ascites, and may have some bearing on the effects of portacaval shunts on nutrition of the hepatic parenchyma.",https://doi.org/10.1016/0002-9610(67)90375-3,https://www.sciencedirect.com/science/article/pii/0002961067903753,,,,1967,Effect of portacaval shunts on lymph flow in the thoracic duct: Experiments with normal dogs and dogs with cirrhosis and ascites,Marshall J. Orloff and Bernard Goodhead and Colin W.O. Windsor and Michael E. Musicant and David L. Annetts,article,ORLOFF1967213,The American Journal of Surgery,2,114,0002-9610,,,
,,B371-B432,,,https://doi.org/10.1016/0021-9673(93)80492-Q,https://www.sciencedirect.com/science/article/pii/002196739380492Q,,,,1993,Liquid column chromatography,,article,1993B371,Journal of Chromatography A,2,650,0021-9673,,,
,,320-322,,"The careful selection of patients with nodular goiter for probable malignancy increases the likelihood of finding thyroid cancer at operation. All other patients with thyroid nodules must be carefully followed up and evaluated frequently to determine the possible need for operation. The thyroid lobe (or isthmus) containing a suspected lesion should be removed for microscopic pathologic examination, which is the only certain way to diagnose cancer of the thyroid. In most operable cases of cancer of the thyroid gland, thyroidectomy is completed because cancer cells are frequently found in the contralateral lobes; however, unilateral lobectomy is sufficient treatment for localized malignant adenoma. Appropriate neck dissections are indicated if cervical nodes are hard and enlarged or otherwise strongly suspected of containing metastases. In selected cases in which thyroid cancer is known or believed to have extended substernally beyond the possibility of removal by cervical incision, mediastinal dissection may be performed.",https://doi.org/10.1016/0002-9610(67)90391-1,https://www.sciencedirect.com/science/article/pii/0002961067903911,,,,1967,Surgical removal of cancer of the thyroid gland,Horace J. McCorkle,article,MCCORKLE1967320,The American Journal of Surgery,2,114,0002-9610,,,
,,i-250,,,https://doi.org/10.1016/0370-2693(78)90929-2,https://www.sciencedirect.com/science/article/pii/0370269378909292,,,,1978,Review of particle properties: Particle data group,C. Bricman and C. Dionisi and R.J. Hemingway and M. Mazzucato and L. Montanet and N. Barash-Schmidt and R.C. Crawford and M. Roos and A. Barbaro-Galtieri and C.P. Horne and R.L. Kelly and M.J. Losty and A. Rittenberg and T.G. Trippe and G.P. Yost and B. Armstrong,article,BRICMAN1978i,Physics Letters B,2,75,0370-2693,,,
,,210-292,,,https://doi.org/10.1016/j.molimm.2014.07.010,https://www.sciencedirect.com/science/article/pii/S0161589014001801,,,,2014,"Abstracts of the XXV International Complement Workshop, 14–18 September 2014, Rio de Janeiro, Brazil",,article,2014210,Molecular Immunology,2,61,0161-5890,"XXV International Complement Workshop September 14-18, 2014 - Rio de Janeiro, Brazil",,
,,65-80,,,https://doi.org/10.1016/0958-1669(92)90129-7,https://www.sciencedirect.com/science/article/pii/0958166992901297,,,,1992,Analytical biotechnology,,article,199265,Current Opinion in Biotechnology,1,3,0958-1669,,,
,,S677-S727,,,https://doi.org/10.1111/j.1469-0691.2007.01735.x,https://www.sciencedirect.com/science/article/pii/S1198743X14646243,,,,2007,Author Index,,article,2007S677,Clinical Microbiology and Infection,,13,1198-743X,,,
,,265-389,Ecology of the Lakes of East-Central New York,,https://doi.org/10.1016/B978-0-12-107303-9.50010-3,https://www.sciencedirect.com/science/article/pii/B9780121073039500103,,Academic Press,978-0-12-107303-9,1980,Limnology of Saratoga Lake,Donald B. Aulenbach and Nicholas L. Clesceri and James J. Ferris,incollection,AULENBACH1980265,,,,,,Jay A. Bloomfield,
,,371-441,,,https://doi.org/10.1016/0022-2860(93)85035-S,https://www.sciencedirect.com/science/article/pii/002228609385035S,,,,1993,Author index,,article,1993371,Journal of Molecular Structure,,290,0022-2860,,,
,,1-221,,"Compilation of Energy Levels for A = 13, 14 and 15 Nuclei, With Emphasis on Material Leading to information about the Structure of the A = 13–15 Systems.",https://doi.org/10.1016/0375-9474(70)90002-3,https://www.sciencedirect.com/science/article/pii/0375947470900023,,,,1970,Energy levels of light nuclei A = 13–15,F. Ajzenberg-Selove,article,AJZENBERGSELOVE19701,Nuclear Physics A,1,152,0375-9474,,,
,,499-583,,"This Reaction List for charged-particle-induced nuclear reactions has been prepared from the journal literature for the period July 1972 through June 1973. Each published experimental paper is listed under the target nucleus in the nuclear reaction with a brief statement of the type of data in the paper. The nuclear reaction is denoted by A(a,b)B, where Ma≥ (one nucleon mass). There is no restriction on energy. Nuclear reactions involving mesons in the outgoing channel are not included. Theoretical papers which treat directly with the analysis of nuclear reaction data and results are included in the Reaction List.",https://doi.org/10.1016/0092-640X(73)90006-5,https://www.sciencedirect.com/science/article/pii/0092640X73900065,,,,1973,"Reaction list for charged-particle-induced nuclear reactions Z = 1 to Z = 98 (H to Cf), July 1972–June 1973",F.K. McGowan and W.T. Milner,article,MCGOWAN1973499,Atomic Data and Nuclear Data Tables,6,12,0092-640X,,,
Developments in Geotechnical Engineering,,223-406,Elastic Analysis of Soil-Foundation Interaction,,https://doi.org/10.1016/B978-0-444-41663-6.50011-7,https://www.sciencedirect.com/science/article/pii/B9780444416636500117,,Elsevier,,1979,CHAPTER 6 - Analysis of Finite Plates,,incollection,1979223,,,17,0165-1250,,A.P.S. SELVADURAI,
,,302-307,,"The technic of Schilling, Joel, and Shurley [2] has been adapted to the study of oxygen tension, carbon dioxide tensions, and hydrogen ion concentration in wound fluid. The gas tensions have been shown to be characteristic of those present at the advancing edge of the granulation tissue. Oxygen tensions were very low in the early phases of healing and rose as healing progressed. Carbon dioxide tensions were low five days after wounding but rose thereafter, probably because of increased production of carbon dioxide by the healing tissue. The low hydrogen ion concentration primarily reflects the high carbon dioxide tensions of wound fluid. The significance of these data is discussed.",https://doi.org/10.1016/0002-9610(67)90388-1,https://www.sciencedirect.com/science/article/pii/0002961067903881,,,,1967,Respiratory gas tensions and pH in healing wounds,Thomas K. Hunt and Patrick Twomey and Bengt Zederfeldt and J.Englebert Dunphy,article,HUNT1967302,The American Journal of Surgery,2,114,0002-9610,,,
Methods in Plant Biochemistry,,111-188,Carbohydrates,,https://doi.org/10.1016/B978-0-12-461012-5.50010-0,https://www.sciencedirect.com/science/article/pii/B9780124610125500100,,Academic Press,,1990,4 - Disaccharides,GAD AVIGAD,incollection,AVIGAD1990111,,,2,1059-7522,,P.M. DEY,
,,222-229,,,https://doi.org/10.1016/0002-9610(67)90376-5,https://www.sciencedirect.com/science/article/pii/0002961067903765,,,,1967,Expanded clinical and research uses of composite tissue transfers on isolated vascular pedicles,Robert A. Chase,article,CHASE1967222,The American Journal of Surgery,2,114,0002-9610,,,
,,297-301,,,https://doi.org/10.1016/0002-9610(67)90387-X,https://www.sciencedirect.com/science/article/pii/000296106790387X,,,,1967,Cecostomy: An analysis of 102 cases,Paul P. Jackson and Robert M. Baird,article,JACKSON1967297,The American Journal of Surgery,2,114,0002-9610,,,
,,323-332,,Twenty-two cases of cecal volvulus in a geriatric hospital population are presented. The diagnosis is primarily derived from patterns determined by roentgenography. Most commonly colonic distention appeared to precipitate the volvulus in a geriatric patient with an anatomic arrangement conducive to volvulus. A search for the cause of the distention should be made. Early diagnosis and operation are imperative if vascular complications with their attendant morbidity and mortality are to be avoided. In one third of our patients the cecum was folded upward over bands across the ascending colon. This entity is not recognized by many surgeons. The operative mortality of eight of twenty patients was related to severe concomitant disease.,https://doi.org/10.1016/0002-9610(67)90392-3,https://www.sciencedirect.com/science/article/pii/0002961067903923,,,,1967,Volvulus of the ascending colon: A report of twenty-two cases,William W. Krippaehne and R.Mark Vetto and Charles C. Jenkins,article,KRIPPAEHNE1967323,The American Journal of Surgery,2,114,0002-9610,,,
,,A481-A527,,,https://doi.org/10.1016/0011-7471(76)91340-1,https://www.sciencedirect.com/science/article/pii/0011747176913401,,,,1976,Oceanographic abstract Part II,,article,1976A481,Deep Sea Research and Oceanographic Abstracts,"8, Supplement ",23,0011-7471,,,
,,314-319,,"Membranes with capabilities which promise to produce a clinically effective artificial lung are now available. Silicone rubber, 18 mil Teflon, and cellophane all transfer carbon dioxide satisfactorily. These substances, as well as the thicker films of Teflon, appear to be adequate for oxygen transfer, although cellophane does it rather poorly. Turbulence is of considerable importance in the transfer of oxygen. A fruitful line of investigation might be that of evaluating the maximal degree of turbulence that one can introduce to an oxygenating system without producing blood damage. One could use the Reynolds∗∗Re = pVDu where p = density, V = velocity, D = inside diameter of conduit, and u = viscosity. number as a guide to quantitating the degree of turbulence produced and perhaps devise a scheme that produces even greater turbulent flow than that which we have described. Perhaps other membrane substances could be considered or those previously discarded could be re-evaluated in the light of improved turbulent flow. For example, cellophane, which is a wettable membrane and theoretically more desirable, might be made to transfer oxygen more satisfactorily, with improved flow characteristics. Other wettable membranes might also be devised and tested. One might suggest that the ideal gas exchange membrane would be one that is wettable, durable, easily fabricated into lung units, and sufficiently thin. It would need to provide adequate carbon dioxide and oxygen transfer in a highly turbulent flow system which also involves a tolerable amount of blood damage.",https://doi.org/10.1016/0002-9610(67)90390-X,https://www.sciencedirect.com/science/article/pii/000296106790390X,,,,1967,Properties of synthetic membranes in extracorporeal circuits,Sherman W. Day and Dean K. Crystal and Clyde L. Wagner and Jay M. Kranz,article,DAY1967314,The American Journal of Surgery,2,114,0002-9610,,,
Methods in Immunology and Immunochemistry,,1-125,"Agglutination, Complement, Neutralization, and Inhibition","Publisher Summary
Agglutination is a sensitive method for the detection of antibody because much less antibody is required to agglutinate particles containing antigenic patches on their surfaces than is needed to aggregate antigens in free solution. This chapter provides an overview of agglutination and fiocculation. It discusses direct hemagglutination and indirect hemagglutination. The slide agglutination technique provides a simple and rapid means of determining blood groups. The method is most frequently employed in ABO and Rh grouping. The procedure may be carried out on microscope slides, large glass plates, or white porcelain or plastic tiles. The chapter reviews slide agglutination and tube agglutination. The cell-counting assay method of Wilkie and Becker makes possible the quantitative estimation of hemagglutinin activity and describes the course of the reaction as a curve that relates agglutination response to concentration of hemagglutinins. The chapter explains inhibition of hemagglutination by antibodies and antibody-like reagents in semi-quantitative tube tests. It further discusses bacterial agglutination, immobilization of motile bacteria by anti-flagellar antibody, agglutination of spermatozoa, agglutination with antigen on inert particles.",https://doi.org/10.1016/B978-0-12-754404-5.50007-2,https://www.sciencedirect.com/science/article/pii/B9780127544045500072,,Academic Press,,1977,CHAPTER 16 - Agglutination and Flocculation,,incollection,19771,,,4,00766917,,CURTIS A. WILLIAMS and MERRILL W. CHASE,
,,211-283,,"Presented in both English and SI units are tables of the thermodynamic properties of normal butane over the temperature range -22 to +122°F (-30 to +50°C). Values are tabulated of the volume, enthalpy, and entropy for the subcooled liquid, the saturated liquid and vapor and the superheated vapor in both unit systems. The data used to calculate these properties have been carefully evaluated and include very recent values of the low temperature heat capacity of the vapor. Two enthalpy-entropy charts (Mollier diagrams), one in each of the unit systems are presented. These are suitable for the design of machinery used in thermo-mechanical energy cycles such as the freezing and eutectic processes for treating sea water and waste water. The calculated thermodynamic properties are the only ones available for n-butane which cover the above complete temperature range.",https://doi.org/10.1016/S0011-9164(00)82202-X,https://www.sciencedirect.com/science/article/pii/S001191640082202X,,,,1978,Thermodynamic properties of normal butane at refrigeration temperatures,Ronald T. Kurnik and Allen J. Barduhn,article,KURNIK1978211,Desalination,3,26,0011-9164,,,
,,549-609,,,https://doi.org/10.1016/0955-0674(89)90019-7,https://www.sciencedirect.com/science/article/pii/0955067489900197,,,,1989,Bibliography of the current world literature,,article,1989549,Current Opinion in Cell Biology,3,1,0955-0674,,,
,,e1-e242,,,https://doi.org/10.1016/S2213-1779(23)00780-1,https://www.sciencedirect.com/science/article/pii/S2213177923007801,,,,2024,Full Issue PDF,,article,2024e1,JACC: Heart Failure,1,12,2213-1779,,,
,"Internet of Things, Computational linguistic, Artificial Intelligence, First order logic, Cognitive architectures, Meta-reasoning",104269,,"In the last decade, the market of Internet of Things has become quite disruptive, together with commercial clouds providing connection between every sort of devices and the global network, supported by vocal assistants. On the other hands, such commercial products are limited to work on limited domains, although easily scalable, without aspiring to higher level of reasoning in the field of Decisions Making. In this work, we show a way towards the design of an architecture for building cognitive agents leveraging Natural Language Processing. Such agents will be not based on clouds and do not require any semantic training, plus they will be able of deduction on facts and rules in First Order Logic inferred directly from Natural Language. After the description of the architecture and its underlying components, a case-study is provided to show the effectiveness in cases of direct commands and routines, subordinated also by a Meta-Reasoning in a conceptual space, parsing the utterances with promising real-time performances.",https://doi.org/10.1016/j.engappai.2021.104269,https://www.sciencedirect.com/science/article/pii/S0952197621001160,,,,2021,"Caspar: Towards decision making helpers agents for IoT, based on natural language and first order logic reasoning",Carmelo Fabio Longo and Francesco Longo and Corrado Santoro,article,LONGO2021104269,Engineering Applications of Artificial Intelligence,,104,0952-1976,,,
,"Conversational agent, Generative artificial intelligence, Generative AI, ChatGPT, Large language models",102642,,"Transformative artificially intelligent tools, such as ChatGPT, designed to generate sophisticated text indistinguishable from that produced by a human, are applicable across a wide range of contexts. The technology presents opportunities as well as, often ethical and legal, challenges, and has the potential for both positive and negative impacts for organisations, society, and individuals. Offering multi-disciplinary insight into some of these, this article brings together 43 contributions from experts in fields such as computer science, marketing, information systems, education, policy, hospitality and tourism, management, publishing, and nursing. The contributors acknowledge ChatGPT’s capabilities to enhance productivity and suggest that it is likely to offer significant gains in the banking, hospitality and tourism, and information technology industries, and enhance business activities, such as management and marketing. Nevertheless, they also consider its limitations, disruptions to practices, threats to privacy and security, and consequences of biases, misuse, and misinformation. However, opinion is split on whether ChatGPT’s use should be restricted or legislated. Drawing on these contributions, the article identifies questions requiring further research across three thematic areas: knowledge, transparency, and ethics; digital transformation of organisations and societies; and teaching, learning, and scholarly research. The avenues for further research include: identifying skills, resources, and capabilities needed to handle generative AI; examining biases of generative AI attributable to training datasets and processes; exploring business and societal contexts best suited for generative AI implementation; determining optimal combinations of human and generative AI for various tasks; identifying ways to assess accuracy of text produced by generative AI; and uncovering the ethical and legal issues in using generative AI across different contexts.",https://doi.org/10.1016/j.ijinfomgt.2023.102642,https://www.sciencedirect.com/science/article/pii/S0268401223000233,,,,2023,"Opinion Paper: “So what if ChatGPT wrote it?” Multidisciplinary perspectives on opportunities, challenges and implications of generative conversational AI for research, practice and policy",Yogesh K. Dwivedi and Nir Kshetri and Laurie Hughes and Emma Louise Slade and Anand Jeyaraj and Arpan Kumar Kar and Abdullah M. Baabdullah and Alex Koohang and Vishnupriya Raghavan and Manju Ahuja and Hanaa Albanna and Mousa Ahmad Albashrawi and Adil S. Al-Busaidi and Janarthanan Balakrishnan and Yves Barlette and Sriparna Basu and Indranil Bose and Laurence Brooks and Dimitrios Buhalis and Lemuria Carter and Soumyadeb Chowdhury and Tom Crick and Scott W. Cunningham and Gareth H. Davies and Robert M. Davison and Rahul Dé and Denis Dennehy and Yanqing Duan and Rameshwar Dubey and Rohita Dwivedi and John S. Edwards and Carlos Flavián and Robin Gauld and Varun Grover and Mei-Chih Hu and Marijn Janssen and Paul Jones and Iris Junglas and Sangeeta Khorana and Sascha Kraus and Kai R. Larsen and Paul Latreille and Sven Laumer and F. Tegwen Malik and Abbas Mardani and Marcello Mariani and Sunil Mithas and Emmanuel Mogaji and Jeretta Horn Nord and Siobhan O’Connor and Fevzi Okumus and Margherita Pagani and Neeraj Pandey and Savvas Papagiannidis and Ilias O. Pappas and Nishith Pathak and Jan Pries-Heje and Ramakrishnan Raman and Nripendra P. Rana and Sven-Volker Rehm and Samuel Ribeiro-Navarrete and Alexander Richter and Frantz Rowe and Suprateek Sarker and Bernd Carsten Stahl and Manoj Kumar Tiwari and Wil {van der Aalst} and Viswanath Venkatesh and Giampaolo Viglia and Michael Wade and Paul Walton and Jochen Wirtz and Ryan Wright,article,DWIVEDI2023102642,International Journal of Information Management,,71,0268-4012,,,
,"Malware detection, Obfuscated malware, Ensemble learning, Stacking, Deep learning, Pearson correlation coefficient",200283,,"Since the advent of malware, it has reached a toll in this world that exchanges billions of data daily. Millions of people are victims of it, and the numbers are not decreasing as the year goes by. Malware is of various types in which obfuscation is a special kind. Obfuscated malware detection is necessary as it is not usually detectable and is prevalent in the real world. Although numerous works have already been done in this field so far, most of these works still need to catch up at some points, considering the scope of exploration through recent extensions. In addition to that, the application of a hybrid classification model is yet to be popularized in this field. Thus, in this paper, a novel hybrid classification model named, MalHyStack, has been proposed for detecting such obfuscated malware within the network. This proposed working model is built incorporating a stacked ensemble learning scheme, where conventional machine learning algorithms namely, Extremely Randomized Trees Classifier (ExtraTrees), Extreme Gradient Boosting (XgBoost) Classifier, and Random Forest are used in the first layer which is then followed by a deep learning layer in the second stage. Before utilizing the classification model for malware detection, an optimum subset of features has been selected using Pearson correlation analysis which improved the accuracy of the model by more than 2 % for multiclass classification. It also reduces time complexity by approximately two and three times for binary and multiclass classification, respectively. For evaluating the performance of the proposed model, a recently published balanced dataset named CIC-MalMem-2022 has been used. Utilizing this dataset, the overall experimental results of the proposed model represent a superior performance when compared to the existing classification models.",https://doi.org/10.1016/j.iswa.2023.200283,https://www.sciencedirect.com/science/article/pii/S2667305323001084,,,,2023,MalHyStack: A hybrid stacked ensemble learning framework with feature engineering schemes for obfuscated malware analysis,Kowshik Sankar Roy and Tanim Ahmed and Pritom Biswas Udas and Md. Ebtidaul Karim and Sourav Majumdar,article,ROY2023200283,Intelligent Systems with Applications,,20,2667-3053,,,
,"Cognitive development, Educational robotics, Selective trust, Human-robot interaction",105814,,"We expect children to learn new words, skills, and ideas from various technologies. When learning from humans, children prefer people who are reliable and trustworthy, yet children also forgive people's occasional mistakes. Are the dynamics of children learning from technologies, which can also be unreliable, similar to learning from humans? We tackle this question by focusing on early childhood, an age at which children are expected to master foundational academic skills. In this project, 168 4–7-year-old children (Study 1) and 168 adults (Study 2) played a word-guessing game with either a human or robot. The partner first gave a sequence of correct answers, but then followed this with a sequence of wrong answers, with a reaction following each one. Reactions varied by condition, either expressing an accident, an accident marked with an apology, or an unhelpful intention. We found that older children were less trusting than both younger children and adults and were even more skeptical after errors. Trust decreased most rapidly when errors were intentional, but only children (and especially older children) outright rejected help from intentionally unhelpful partners. As an exception to this general trend, older children maintained their trust for longer when a robot (but not a human) apologized for its mistake. Our work suggests that educational technology design cannot be one size fits all but rather must account for developmental changes in children's learning goals.",https://doi.org/10.1016/j.cognition.2024.105814,https://www.sciencedirect.com/science/article/pii/S0010027724001008,,,,2024,School-age children are more skeptical of inaccurate robots than adults,Teresa Flanagan and Nicholas C. Georgiou and Brian Scassellati and Tamar Kushnir,article,FLANAGAN2024105814,Cognition,,249,0010-0277,,,
,"Ransomware, Malware, Access control, Ransomware mitigation, Intrusion prevention",103160,,"The advancement of modern Operating Systems (OSs), and the popularity of personal computing devices with Internet connectivity, have facilitated the proliferation of ransomware attacks. Ransomware has evolved from executable programs encrypting user files, to novel attack vectors including fileless command scripts, information exfiltration and human-operated ransomware. Many anti-ransomware studies have been published, but many of them assumed newer ransomware variants only performed file encryption, were similar to existing variants, and often did not consider those novel attack vectors. We have defined an updated ransomware threat model to include those novel attack vectors, and redefined false positives and false negatives in the context of ransomware mitigation. We proposed to apply both program-centric and user-centric access control to combat ransomware, but only delegate access control decisions that users are capable of making to users, while enforcing non-negotiable access control decisions by OS and software developers. We have designed a Staged Event-Driven Access Control (SEDAC) approach to incorporate both program-centric and user-centric access control measures, and demonstrated a prototype on Windows OS. Our prototype was able to intercept more types of ransomware attack vectors than existing proposals. We hope to convince OS and software architects to incorporate our design to better combat ransomware.",https://doi.org/10.1016/j.cose.2023.103160,https://www.sciencedirect.com/science/article/pii/S0167404823000706,,,,2023,Applying staged event-driven access control to combat ransomware,Timothy McIntosh and A.S.M. Kayes and Yi-Ping Phoebe Chen and Alex Ng and Paul Watters,article,MCINTOSH2023103160,Computers & Security,,128,0167-4048,,,
,"Extreme Programming, Object, Object-Oriented Programming, Procedural languages, Spiral Model, Systems Development Life Cycle, Waterfall Model",429-477,CISSP Study Guide (Third Edition),"Chapter 9 introduces Domain 8 of the CISSP, Software Development Security. The most important aspects of this domain are related to managing the development of software and applications. Approaches to software development that attempt to reduce the likelihood of defects or flaws are a key topic in this domain. In particular, the Waterfall, Spiral, and Rapid Application Development (RAD) models of the software development are considered. Another significant portion of this chapter is dedicated to understanding the principles of Object Oriented programming and design. A basic discussion of several types of software vulnerabilities and the issues surrounding disclosure of the vulnerabilities are also a topic for this domain. Finally, databases, being a key component of many applications, are considered.",https://doi.org/10.1016/B978-0-12-802437-9.00009-6,https://www.sciencedirect.com/science/article/pii/B9780128024379000096,Boston,Syngress,978-0-12-802437-9,2016,"Chapter 9 - Domain 8: Software Development Security (Understanding, Applying, and Enforcing Software Security)",Eric Conrad and Seth Misenar and Joshua Feldman,incollection,CONRAD2016429,,,,,,Eric Conrad and Seth Misenar and Joshua Feldman,Third Edition
,"GUI testing, GUI-based testing, Software testing, Code review, Modern code review, Guidelines, Practices",107299,,"Context:
Review of software artifacts, such as source or test code, is a common practice in industrial practice. However, although review guidelines are available for source and low-level test code, for GUI-based testing artifacts, such guidelines are missing.
Objective:
The goal of this work is to define a set of guidelines from literature about production and test code, that can be mapped to GUI-based testing artifacts.
Method:
A systematic literature review is conducted, using white and gray literature to identify guidelines for source and test code. These synthesized guidelines are then mapped, through examples, to create actionable, and applicable, guidelines for GUI-based testing artifacts.
Results:
The results of the study are 33 guidelines, summarized in nine guideline categories, that are successfully mapped as applicable to GUI-based testing artifacts. Of the collected literature, only 10 sources contained test-specific code review guidelines. These guideline categories are: perform automated checks, use checklists, provide context information, utilize metrics, ensure readability, visualize changes, reduce complexity, check conformity with the requirements and follow design principles and patterns.
Conclusion:
This pivotal set of guidelines provides an industrial contribution in filling the gap of general guidelines for review of GUI-based testing artifacts. Additionally, this work highlights, from an academic perspective, the need for future research in this area to also develop guidelines for other specific aspects of GUI-based testing practice, and to take into account other facets of the review process not covered by this work, such as reviewer selection.",https://doi.org/10.1016/j.infsof.2023.107299,https://www.sciencedirect.com/science/article/pii/S0950584923001532,,,,2023,Code review guidelines for GUI-based testing artifacts,Andreas Bauer and Riccardo Coppola and Emil Alégroth and Tony Gorschek,article,BAUER2023107299,Information and Software Technology,,163,0950-5849,,,
,"Software Defined Networking, Attack detection and mitigation, Network security, Middlebox management, Traffic management, Policy management, Traffic engineering, Smart grid security",89-108,,"Software Defined Networking (SDN) has emerged as a new networking paradigm for managing different kinds of networks ranging from enterprise to home network through software enabled control. The logically centralized control plane and programmability offers a great opportunity to improve network security, like implementing new mechanisms to detect and mitigate various threats, as well as enables deploying security as a service on the SDN controller. Due to the increasing and fast development of SDN, this paper provides an extensive survey on the application of SDN on enhancing the security of computer networks. In particular, we survey recent research studies that focus on applying SDN for network security including attack detection and mitigation, traffic monitoring and engineering, configuration and policy management, service chaining, and middlebox deployment, in addition to smart grid security. We further identify some challenges and promising future directions on SDN security, compatibility and scalability issues that should be addressed in this field.",https://doi.org/10.1016/j.jnca.2019.01.019,https://www.sciencedirect.com/science/article/pii/S108480451930027X,,,,2019,The application of Software Defined Networking on securing computer networks: A survey,Rishikesh Sahay and Weizhi Meng and Christian D. Jensen,article,SAHAY201989,Journal of Network and Computer Applications,,131,1084-8045,,,
,"automatic text mining, web crawlers, text classification, intelligent transportation systems, machine learning, tf-idf, n-gram, naïve Bayes algorithm, linear classifier, sentiment analysis",626-635,,"The paper addresses the task of analyzing traffic safety in the Northwestern Federal District according to the reviews published in the Web. To accomplish the task, the authors developed a system of automatic review classification based on a sentiment classifier. They analyzed open source libraries for data mining, developed a web crawler using Scrapy framework, written in Python 3, and collected reviews. They also considered the methods of text vectorization and lemmatization and their application in the Scikit-Learn library: Bag-of-Words, N-gram, CountVectorizer, and TF-IDF Vectorizer. For the purpose of classification, the authors used the naïve Bayes algorithm and a linear classifier model with stochastic gradient descent optimization. A base of tagged Twitter reviews was used as a training set. The classifier was trained using cross-validation and ShuffleSplit strategies. The authors also tested and compared the classification results for different classifiers. As a result of validation, the best model was determined. The developed system was applied to analyze the quality of roads in the Northwestern Federal District. Based on the outcome, the roads were marked-up in color to illustrate the results of the research.",https://doi.org/10.1016/j.trpro.2020.10.074,https://www.sciencedirect.com/science/article/pii/S2352146520308255,,,,2020,Traffic safety evaluation in Northwestern Federal District using sentiment analysis of Internet users’ reviews,Yaroslav Seliverstov and Svyatoslav Seliverstov and Igor Malygin and Oleg Korolev,article,SELIVERSTOV2020626,Transportation Research Procedia,,50,2352-1465,XIV International Conference on Organization and Traffic Safety Management in Large Cities (OTS-2020),,
Intelligent Data-Centric Systems,"Explainable artificial intelligence, Interpretable machine learning, Machine learning model, User interface",295-310,Innovations in Artificial Intelligence and Human-Computer Interaction in the Digital Era,"Artificial intelligence–based systems are developed and successfully used for applications like home appliances, defense systems, virtual assistance, robotics, self-driving vehicles, and many more. Their success lies in accurate and timely decision-making ability. But the other side of these systems is a lack of transparency that can be described as black box. Due to the opaque nature of existing artificial intelligence systems, researchers are not able to interpret the decisions that have been derived from given input situations. The lack of openness not only causes the end users to resist trusting the system but also tends to make it difficult for machine learning engineers to detect and mitigate the fault in case of failure in deriving desired output. The solution is to open the black box working nature of the system and provide required explanations as well interpretations to making the whole processes humanly understandable and meaningful. This chapter focuses on the need for explainable artificially intelligent systems, present paradigms that exist to achieve it, along with various forms of explanations expected by different stakeholders and challenges in the field of making transparent systems in the direction of trustworthy human–computer interaction.",https://doi.org/10.1016/B978-0-323-99891-8.00006-1,https://www.sciencedirect.com/science/article/pii/B9780323998918000061,,Academic Press,978-0-323-99891-8,2023,Chapter 11 - Challenges and future work directions in artificial intelligence with human-computer interaction,Mahesh H. Panchal and Shaileshkumar D. Panchal,incollection,PANCHAL2023295,,,,,,Surbhi {Bhatia Khan} and Suyel Namasudra and Swati Chandna and Arwa Mashat and Fatos Xhafa,
,"Blockchain platforms, Cryptocurrency, User-generated content provisioning, Token supply mechanism, Coarsened exact matching",103989,,"This study investigates the impact of cryptocurrency rewards and token prices on user-generated content (UGC) provision by content creators on a blockchain-based platform. Analyzing data from the Steemit platform, we find that although an increase in total reward value incentivizes UGC contributions, the rise in token prices alone does not lead to a surge in UGC. Instead, token prices have a mediating role in the relationship between total rewards earned by content creators and the volume of UGC they produce. Furthermore, we observe that an increase in UGC does not lead to a corresponding rise in the platform's market capitalization, as increased website traffic intensifies competition for rewards from a constant pool, suggesting that heightened user engagement does not translate to enhanced market capitalization. These findings imply that carefully designed reward mechanisms are crucial for sustaining user engagement and content creation amidst market fluctuations. Our study underscores the importance of a comprehensive approach to incentivizing user participation and ensuring platform growth, as a mere increase in token prices may not guarantee sustained engagement or an associated increase in market capitalization.",https://doi.org/10.1016/j.im.2024.103989,https://www.sciencedirect.com/science/article/pii/S0378720624000715,,,,2024,Do cryptocurrency rewards improve platform valuations?,Hemang Subramanian and Florent Rouxelin,article,SUBRAMANIAN2024103989,Information & Management,6,61,0378-7206,,,
Intelligence-Based Medicine: Subspecialty Series,,481-501,Intelligence-Based Cardiology and Cardiac Surgery,,https://doi.org/10.1016/B978-0-323-90534-3.17001-5,https://www.sciencedirect.com/science/article/pii/B9780323905343170015,,Academic Press,978-0-323-90534-3,2024,Glossary,,incollection,2024481,,,,,,Anthony C. Chang and Alfonso Limon,
,"Anomaly detection, Machine Learning, Internet of Things (IoT), Smart home, Cybersecurity, Cyber attacks, Systematic literature review (SLR)",100792,,"Smart homes, leveraging IoT technology to interconnect various devices and appliances to the internet, enable remote monitoring, automation, and control. However, collecting sensitive personal and business data assets renders smart homes a target for cyberattacks. Anomaly detection is a promising approach for identifying malicious behavior in smart homes. Yet, the current literature primarily discusses IoT-related cyberattacks and gives limited attention to detecting anomalies specific to the smart home context. Furthermore, there is a lack of datasets that accurately represent the complexity inherent in a smart home environment in terms of users with varying levels of expertise and diverse, evolving types of devices. Therefore, this paper presents a systematic literature review (SLR) that focuses on using anomaly detection to identify cyberattacks in smart home environments. The SLR includes an adapted taxonomy that classifies existing anomaly detection methods and a critical analysis of the current state of knowledge and future research challenges. Our findings show a growing interest in detecting cyberattacks with anomaly-based models in smart homes using centralized and network-based features. Ensemble and deep learning techniques are popular methods for detecting these anomalies. However, the limited diversity of cyberattacks in existing datasets and the absence of comprehensive datasets representing the complexity of smart home environments call for further research to improve the generalizability of detection models.",https://doi.org/10.1016/j.iot.2023.100792,https://www.sciencedirect.com/science/article/pii/S2542660523001154,,,,2023,Anomaly-based cyberattacks detection for smart homes: A systematic literature review,Juan Ignacio Iturbe Araya and Helena Rifà-Pous,article,ARAYA2023100792,Internet of Things,,22,2542-6605,,,
,"Network security, Tsallis entropy, DDoS attack",79-87,,"Distributed Denial-of-Service attacks have been a challenge to cyberspace, as the attackers send a large number of attack packets similar to the normal traffic, to throttle legitimate flows. These attacks intentionally disrupt the services offered by the systems resulting in heavy cost. A flash crowd or flash event is an unexpected surge in the number of visitors to a particular website resulting in a sudden increase in server load. Flash crowds, which are legitimate flows, are difficult to be discriminated from Distributed Denial-of-Service attacks that are illicit flows. Effective and accurate detection of Distributed Denial of Service attacks still remains a challenge due to the difficulty in its detection and the false alerts generated in the case of flash crowds. There is a trade off between detection rate and false positive rate. This work deals with an efficient and early detection of distributed denial of service attacks and discriminates flash crowd by considering two network traffic parameters such as packet size and destination IP address. Using these traffic features two attributes are computed and its generalized entropies are calculated. The threshold is computed using the mean value of network attributes to detect the attacks. Threshold updater can automatically adjust the threshold values according to the changes in the channel conditions. The data sets used to evaluate the performance of the proposed approach are the MIT Lincoln Laboratory DARPA data set and a data set generated in a University network. Experimental results show this research approach achieves higher detection rate and lower false positives in a much reduced processing time as compared to the existing methods.",https://doi.org/10.1016/j.jpdc.2021.02.019,https://www.sciencedirect.com/science/article/pii/S074373152100040X,,,,2021,Discriminating flash crowds from DDoS attacks using efficient thresholding algorithm,Jisa David and Ciza Thomas,article,DAVID202179,Journal of Parallel and Distributed Computing,,152,0743-7315,,,
,"Network intrusion detection, Deep learning, Class imbalance, Gaussian mixture model, Convolutional neural network",107315,,"Network Intrusion Detection System (NIDS) is a key security device in modern networks to detect malicious activities. However, the problem of imbalanced class associated with intrusion detection dataset limits the classifier’s performance for minority classes. To improve the detection rate of minority classes while ensuring efficiency, we propose a novel class imbalance processing technology for large-scale dataset, referred to as SGM, which combines Synthetic Minority Over-Sampling Technique (SMOTE) and under-sampling for clustering based on Gaussian Mixture Model (GMM). We then design a flow-based intrusion detection model, SGM-CNN, which integrates imbalanced class processing with convolutional neural network, and investigate the impact of different numbers of convolution kernels and different learning rates on model performance. The advantages of the proposed model are verified using the UNSW-NB15 and CICIDS2017 datasets. The experimental results show that i) for binary classification and multiclass classification on the UNSW-NB15 dataset, SGM-CNN achieves a detection rate of 99.74% and 96.54%, respectively; ii) for 15-class classification on the CICIDS2017 dataset, it achieves a detection rate of 99.85%. We compare five imbalanced processing methods and two classification algorithms, and conclude that SGM-CNN provides an effective solution to imbalanced intrusion detection and outperforms the state-of-the-art intrusion detection methods.",https://doi.org/10.1016/j.comnet.2020.107315,https://www.sciencedirect.com/science/article/pii/S1389128620300712,,,,2020,An effective convolutional neural network based on SMOTE and Gaussian mixture model for intrusion detection in imbalanced dataset,Hongpo Zhang and Lulu Huang and Chase Q. Wu and Zhanbo Li,article,ZHANG2020107315,Computer Networks,,177,1389-1286,,,
,"Spoken dialogue systems, Automatic speech recognition, End of turn detection, Natural language processing, Neural networks",104189,,"An End-Of-Turn Detection Module (EOTD-M) is an essential component of automatic Spoken Dialogue Systems. The capability of correctly detecting whether a user’s utterance has ended or not improves the accuracy in interpreting the meaning of the message and decreases the latency in the answer. Usually, in dialogue systems, an EOTD-M is coupled with an Automatic Speech Recognition Module (ASR-M) to transmit complete utterances to the Natural Language Understanding unit. Mistakes in the ASR-M transcription can have a strong effect on the performance of the EOTD-M. The actual extent of this effect depends on the particular combination of ASR-M transcription errors and the sentence featurization techniques implemented as part of the EOTD-M. In this paper we investigate this important relationship for an EOTD-M based on semantic information and particular characteristics of the speakers (speech profiles). We introduce an Automatic Speech Recognition Simulator (ASR-SIM) that models different types of semantic mistakes in the ASR-M transcription as well as different speech profiles. We use the simulator to evaluate the sensitivity to ASR-M mistakes of a Long Short-Term Memory network classifier trained in EOTD with different featurization techniques. Our experiments reveal the different ways in which the performance of the model is influenced by the ASR-M errors. We corroborate that not only is the ASR-SIM useful to estimate the performance of an EOTD-M in customized noisy scenarios, but it can also be used to generate training datasets with the expected error rates of real working conditions, which leads to better performance.",https://doi.org/10.1016/j.engappai.2021.104189,https://www.sciencedirect.com/science/article/pii/S0952197621000361,,,,2021,Analysis of the sensitivity of the End-Of-Turn Detection task to errors generated by the Automatic Speech Recognition process,César Montenegro and Roberto Santana and Jose A. Lozano,article,MONTENEGRO2021104189,Engineering Applications of Artificial Intelligence,,100,0952-1976,,,
,"Keystroke dynamics, Keyboard, USB, Malicious, Malware, Concealment, Authentication, Supply chain attack",240-269,,"Concealing malicious components within widely used USB peripherals has become a popular attack vector utilizing social engineering techniques and exploiting users’ trust in USB devices. This vector enables the attacker to easily penetrate an organization's computers even when the target is secured or in an air-gapped network. Such malicious concealment can be done as part of a supply chain attack or during the device manufacturing process. In cases where the device allows the user to update its firmware, a supply chain attack may involve changing just the device's firmware, thus compromising the device without the need for concealment. A compromised device can impersonate other devices like keyboards in order to send malicious keystrokes to the computer. However, the keystrokes generated maliciously do not match human keystroke characteristics, and therefore they can be easily detected by security tools that are designed to continuously verify the user's identity based on his/her keystroke dynamics. In this paper, we present Malboard, a sophisticated attack based on designated hardware concealment, which automatically generates keystrokes that have the attacked user's behavioral characteristics; in this attack these keystrokes are injected into the computer in the form of malicious commands and thus can evade existing detection mechanisms designed to continuously verify the user's identity based on keystroke dynamics. We implemented this novel attack and evaluated its performance on 30 subjects performing three different keystroke tasks; we evaluated the attack against three existing detection mechanisms, and the results show that our attack managed to evade detection in 83–100% of the cases, depending on the detection tools in place. Malboard was proven to be effective in two scenarios: either by a remote attacker using wireless communication to communicate with Malboard or by an inside attacker (malicious employee) that physically operates and uses Malboard. In addition, in order to address the evasion gap, we developed three different modules aimed at detecting keystroke injection attacks in general, and particularly, the more sophisticated Malboard attack. Our proposed detection modules are trusted and secured, because they are based on three side-channel resources which originate from the interaction between the keyboard, user, and attacked host. These side-channel resources include (1) the keyboard's power consumption, (2) the keystrokes’ sound, and (3) the user's behavior associated with his/her ability to respond to displayed textual typographical errors. Our results showed that each of the proposed detection modules is capable of detecting the Malboard attack in 100% of the cases, with no misses and no false positives; using them together as an ensemble detection framework will assure that an organization is immune to the Malboard attack in particular and other keystroke injection attacks in general.",https://doi.org/10.1016/j.cose.2019.05.008,https://www.sciencedirect.com/science/article/pii/S0167404818309957,,,,2019,Malboard: A novel user keystroke impersonation attack and trusted detection framework based on side-channel analysis,Nitzan Farhi and Nir Nissim and Yuval Elovici,article,FARHI2019240,Computers & Security,,85,0167-4048,,,
,"Dataset, Crop, Computer vision, Precision agriculture, Robotics, Data sharing, Images",105760,,"Computer vision technologies have attracted significant interest in precision agriculture in recent years. At the core of robotics and artificial intelligence, computer vision enables various tasks from planting to harvesting in the crop production cycle to be performed automatically and efficiently. However, the scarcity of public image datasets remains a crucial bottleneck for fast prototyping and evaluation of computer vision and machine learning algorithms for the targeted tasks. Since 2015, a number of image datasets have been established and made publicly available to alleviate this bottleneck. Despite this progress, a dedicated survey on these datasets is still lacking. To fill this gap, this paper makes the first comprehensive but not exhaustive review of the public image datasets collected under field conditions for facilitating precision agriculture, which include 15 datasets on weed control, 10 datasets on fruit detection, and 9 datasets on miscellaneous applications. We survey the main characteristics and applications of these datasets, and discuss the key considerations for creating high-quality public image datasets. This survey paper will be valuable for the research community on the selection of suitable image datasets for algorithm development and identification of where creation of new image datasets is needed to support precision agriculture.",https://doi.org/10.1016/j.compag.2020.105760,https://www.sciencedirect.com/science/article/pii/S0168169920312709,,,,2020,A survey of public datasets for computer vision tasks in precision agriculture,Yuzhen Lu and Sierra Young,article,LU2020105760,Computers and Electronics in Agriculture,,178,0168-1699,,,
,"Blockchain, Smart contracts, P2P, Consensus, Ledger, Testing, Verification, Validation, Simulation, Benchmarking, Software testing, Security testing, Performance testing, System under test, Formal verification, Platform testing",100492,,"As blockchain technology is gaining popularity in industry and society, solutions for Verification and Validation (V&V) of blockchain-based software applications (BC-Apps) have started gaining equal attention. To ensure that BC-Apps are properly developed before deployment, it is paramount to apply systematic V&V to verify their functional and non-functional requirements. While existing research aims at addressing the challenges of engineering BC-Apps by providing testing techniques and tools, blockchain-based software development is still an emerging research discipline, and therefore, best practices and tools for the V&V of BC-Apps are not yet sufficiently developed. In this paper, we provide a comprehensive survey on V&V solutions for BC-Apps. Specifically, using a layered approach, we synthesize V&V tools and techniques addressing different components at various layers of the BC-App stack, as well as across the whole stack. Next, we provide a discussion on the challenges associated with BC-App V&V, and summarize a set of future research directions based on the challenges and gaps identified in existing research work. Our study aims to highlight the importance of BC-App V&V and pave the way for a disciplined, testable, and verifiable BC development.",https://doi.org/10.1016/j.cosrev.2022.100492,https://www.sciencedirect.com/science/article/pii/S1574013722000314,,,,2022,"Blockchain verification and validation: Techniques, challenges, and research directions",Dusica Marijan and Chhagan Lal,article,MARIJAN2022100492,Computer Science Review,,45,1574-0137,,,
,"HIP, CAPTCHA, Machine learning, Gender classification, Side-channel attack",744-756,,"Human Interactive Proofs (HIPs 11Human Interaction Proof, or also Human Interactive Proof. or CAPTCHAs 22Completely Automated Public Turing test to tell Computers and Humans Apart.) have become a first-level security measure on the Internet to avoid automatic attacks or minimize their effects. All the most widespread, successful or interesting CAPTCHA designs put to scrutiny have been successfully broken. Many of these attacks have been side-channel attacks. New designs are proposed to tackle these security problems while improving the human interface. FunCAPTCHA is the first commercial implementation of a gender classification CAPTCHA, with reported improvements in conversion rates. This article finds weaknesses in the security of FunCAPTCHA and uses simple machine learning (ML) analysis to test them. It shows a side-channel attack that leverages these flaws and successfully solves FunCAPTCHA on 90% of occasions without using meaningful image analysis. This simple yet effective security analysis can be applied with minor modifications to other HIPs proposals, allowing to check whether they leak enough information that would in turn allow for simple side-channel attacks.",https://doi.org/10.1016/j.cose.2017.05.005,https://www.sciencedirect.com/science/article/pii/S0167404817301128,,,,2017,Using machine learning to identify common flaws in CAPTCHA design: FunCAPTCHA case analysis,Carlos Javier Hernández-Castro and María D. R-Moreno and David F. Barrero and Stuart Gibson,article,HERNANDEZCASTRO2017744,Computers & Security,,70,0167-4048,,,
,"BDI Agents, Robotics, UAVs, ROS, Jason",10000-10005,,"This paper proposes and evaluates an embedded architecture aimed to promote the utilization of cognitive agents in cooperation with the Robotic Operating System (ROS), serving as an alternative for programming intelligent robots. It promotes the programming abstraction level in two directions. The first direction regards using cognitive agents facilities for programming the robots intelligence, consisting of its perceptions and related actions. The second direction exploits the facilities of using ROS layers for programming the robot interaction with its sensors and actuators. The paper reports experiments of using agents to command simulated UAVs while measuring performance metrics that allowed us to evaluate the benefits of the proposed architecture.",https://doi.org/10.1016/j.ifacol.2020.12.2718,https://www.sciencedirect.com/science/article/pii/S2405896320334819,,,,2020,Embedded Architecture Composed of Cognitive Agents and ROS for Programming Intelligent Robots,Gustavo R. Silva and Leandro B. Becker and Jomi F. Hübner,article,SILVA202010000,IFAC-PapersOnLine,2,53,2405-8963,21st IFAC World Congress,,
,"General data protection regulation, Controller, Joint controller, Household exception, Virtual assistant, Google assistant",105689,,"This article provides an overview and critical examination of the rules for determining who qualifies as controller or joint controller under the General Data Protection Regulation. Using Google Assistant – an artificial intelligence-driven virtual assistant – as a case study, we argue that these rules are overreaching and difficult to apply in the present-day information society and Internet of Things environments. First, as a consequence of recent developments in case law and supervisory guidance, these rules lead to a complex and ambiguous test to determine (joint) control. Second, due to advances in technological applications and business models, it is increasingly challenging to apply such rules to contemporary processing operations. In particular, as illustrated by the Google Assistant, individuals will likely be qualified as joint controllers, together with Google and also third-party developers, for at least the collection and possible transmission of other individuals’ personal data via the virtual assistant. Third, we identify follow-on issues relating to the apportionment of responsibilities between joint controllers and the effective and complete protection of data subjects. We conclude by questioning whether the framework for determining who qualifies as controller or joint controller is future-proof and normatively desirable.",https://doi.org/10.1016/j.clsr.2022.105689,https://www.sciencedirect.com/science/article/pii/S026736492200036X,,,,2022,A Matter of (Joint) control? Virtual assistants and the general data protection regulation,Jurriaan {van Mil} and João Pedro Quintais,article,VANMIL2022105689,Computer Law & Security Review,,45,0267-3649,,,
,"Nontarget analysis, Disinfection byproducts, Ultrahigh-resolution mass spectrometry, Dissolved organic matter, Compounds of emerging concerns",120694,,"Halogenated organic compounds (HOCs), widely present in various environments, are generally formed by natural processes (e.g., photochemical halogenation) and anthropogenic activities (e.g., water disinfection and anthropogenic discharge of HOCs), posing health and environmental risks. Therefore, in-depth knowledge of the molecular composition, transformation, and fate of HOCs is crucial to regulate and reduce their formation. Because of the extremely complex nature of HOCs and their precursors, the molecular composition of HOCs remains largely unknown. The Fourier transform ion cyclotron resonance mass spectrometry (FT-ICR MS) offers the most powerful resolution and mass accuracy for the simultaneous molecular-level characterization of HOCs and their precursors. However, there is still a paucity of reviews regarding the comprehensive characterization of HOCs by FT-ICR MS. Based on the FT-ICR MS, the formation mechanism, sample pretreatment, and analysis methods were summarized for two typical HOCs classes, namely halogenated disinfection byproducts and per- and polyfluoroalkyl substances in this review. Moreover, we have highlighted data analysis methods and some typical applications of HOCs using FT-ICR MS and proposed suggestions for current issues. This review will deepen our understanding of the chemical characterization of HOCs and their formation mechanisms and transformation at the molecular level in aquatic systems, facilitating the application of the state-of-the-art FT-ICR MS in environmental and geochemical research.",https://doi.org/10.1016/j.watres.2023.120694,https://www.sciencedirect.com/science/article/pii/S004313542301134X,,,,2023,Characterization of halogenated organic compounds by the Fourier transform ion cyclotron resonance mass spectrometry: A critical review,Shixi Wu and Manabu Fujii and Xin Yang and Qing-Long Fu,article,WU2023120694,Water Research,,246,0043-1354,,,
,"Building information modelling, Concurrent engineering, Design collaboration, Knowledge graphs, Semantic enrichment",101711,,"The technological tools people use for designing buildings have progressed from drawings to descriptive geometry, and from computer-aided drafting and design (CAD) to building information modelling (BIM). Yet despite their use of state-of-the-art BIM technology, the multidisciplinary teams that design modern buildings still face numerous challenges. Building models lack sufficient semantic content to properly express design intent, concurrent design is difficult due to the need for operators to maintain model consistency and integrity manually, managing design variations is cumbersome due to the packaging of information in files, and collaboration requires making-do with imperfect interoperability between application software. In response, we propose a ‘Cloud BIM’ (CBIM) approach to building modelling that seeks to automate maintenance of consistency across federated discipline-specific models by enriching models with semantic information that encapsulates design intent. The approach requires a new ontology to represent knowledge about the relationships between building model objects within and across disciplines. Discipline-specific building models are stored together with their data schema in knowledge graphs, and linked using objects and relationships from the CBIM ontology. The links are established using artificially intelligent semantic enrichment methods that recognize patterns of location, geometry, topology and more. Software methods that operate along CBIM relationship chains can detect inconsistencies that arise across disciplines and act to inform users, propose meaningful corrections, and apply them if approved. Future CBIM systems may provide designers with the functionality for collaborative multidisciplinary design by maintaining model consistency and managing versioning at the object level.",https://doi.org/10.1016/j.aei.2022.101711,https://www.sciencedirect.com/science/article/pii/S1474034622001690,,,,2022,Toward artificially intelligent cloud-based building information modelling for collaborative multidisciplinary design,Rafael Sacks and Zijian Wang and Boyuan Ouyang and Duygu Utkucu and Siyu Chen,article,SACKS2022101711,Advanced Engineering Informatics,,53,1474-0346,,,
," bioprinting, Robotic bioprinting platform, Path planning algorithm",e00139,,"The aim of this work is to design a robotic bioprinting platform able to fabricate a three-dimensional structure onto irregular surfaces. With respect to the limitations of current in vitro bioprinting approach, widely used in scaffold-based tissue engineering – handling difficulty, risk of contamination, shape not matching with the defect site – this robotic bioprinter can offer an innovative solution allowing in situ bioprinting, a direct dispensing of biological materials onto and into the damaged site. The robotic platform was developed starting from the 5 degrees-of-freedom open source MOVEO robot from BCN3D. The hardware and the software of the original project were re-engineered to control the robot using LinuxCNC, a path planning algorithm was developed in Matlab®, and the end-effector was equipped with a pneumatic extruder. The algorithm automatically projects any generic printing pattern on the surface on which the scaffold will be 3D bioprinted. For each point, the algorithm calculates the joint angles to keep the end effector always perpendicular to the surface. A g-code file is then exported to Linux CNC adding parameters to control the air pressure and the printing speed. The robotic platform was tested to evaluate its performances. Resolution (~200 ​μm) and repeatability were estimated and preliminary in situ bioprinting tests were performed onto different irregular surfaces, including a physiologically relevant bone model.",https://doi.org/10.1016/j.bprint.2021.e00139,https://www.sciencedirect.com/science/article/pii/S2405886621000129,,,,2021,Robotic platform and path planning algorithm for in situ bioprinting,Gabriele Maria Fortunato and Gabriele Rossi and Amedeo Franco Bonatti and Aurora {De Acutis} and Christian Mendoza-Buenrostro and Giovanni Vozzi and Carmelo {De Maria},article,FORTUNATO2021e00139,Bioprinting,,22,2405-8866,,,
,"Computer science, Network, Network topology",103217,,"Summary
Link prediction is a paradigmatic problem in network science, which aims at estimating the existence likelihoods of nonobserved links, based on known topology. After a brief introduction of the standard problem and evaluation metrics of link prediction, this review will summarize representative progresses about local similarity indices, link predictability, network embedding, matrix completion, ensemble learning, and some others, mainly extracted from related publications in the last decade. Finally, this review will outline some long-standing challenges for future studies.",https://doi.org/10.1016/j.isci.2021.103217,https://www.sciencedirect.com/science/article/pii/S2589004221011858,,,,2021,Progresses and challenges in link prediction,Tao Zhou,article,ZHOU2021103217,iScience,11,24,2589-0042,,,
,"DDoS, Attack detection, Mitigation, Fog computing, VNF",51-62,,"Distributed denial of service (DDoS) cyber-attack poses a severe threat to the industrial Internet of Things (IIoT) operation due to the security vulnerabilities resulted from increased connectivity and openness, and the large number of deployed low computation power devices. This paper applies Fog computing concept in DDoS mitigation by allocating traffic monitoring and analysis work close to local devices, and, on the other hand, coordinating and consolidating work to cloud central servers so as to achieve fast response while at low false alarm rate. The mitigation scheme consists of real-time traffic filtering via field firewall devices, which are able to reversely filter the signature botnet attack packets; offline specification based traffic analysis via virtualized network functions (VNFs) in the local servers; and centralized coordination via cloud server, which consolidates and correlates the information from the distributed local servers to make a more accurate decision. The proposed scheme is tested in an industrial control system testbed and the experiments evaluate the detection time and rate for two types of DDoS attacks and demonstrate the effectiveness of the scheme.",https://doi.org/10.1016/j.cose.2019.04.017,https://www.sciencedirect.com/science/article/pii/S0167404818311349,,,,2019,A fog computing based approach to DDoS mitigation in IIoT systems,Luying Zhou and Huaqun Guo and Gelei Deng,article,ZHOU201951,Computers & Security,,85,0167-4048,,,
,"Blockchain, Alternative financing solutions, Initial coin offerings, Asymmetrical information",101966,,"This article analyzes the main problems and the solutions adopted in the market for Initial Coin Offerings (ICO), to anticipate the future of this market and determine implications for issuers, investors and regulators. ICOs represent an alternative and innovative financing solution that has experienced spectacular growth and notoriety in recent years. ICOs rely on Blockchain protocols and the ICO market is, therefore, characterized as decentralized, disintermediated and unregulated. Our results show that although the ICO market is innovative, it already displays many of the problems of traditional financial markets, and that these problems were at the genesis of the last financial crisis. Our analysis of the problems and solutions adopted shows a tension between what the Blockchain technology offers, and the problems associated with the financing of innovation. Considering the problems and solutions adopted, we no longer expect the ICO market to be characterized as disintermediated, unregulated or even decentralized in the near future. Furthermore, it is a real possibility that ICOs may end up being a progressor model eventually replaced by similar but more specialized financing models, some of which may already exist. With respect to the particular solutions of the ICO market, while some represent the realization of the potential of Blockchain, others such as forks have important Governance implications with the potential to create as many problems as the ones they address.",https://doi.org/10.1016/j.irfa.2021.101966,https://www.sciencedirect.com/science/article/pii/S1057521921002842,,,,2022,Challenges of the market for initial coin offerings,Pablo {de Andrés} and David Arroyo and Ricardo Correia and Alvaro Rezola,article,DEANDRES2022101966,International Review of Financial Analysis,,79,1057-5219,,,
,"Mobile robots, Path planning, Deep reinforcement learning, Deep Q-Learning, Dueling neural network, ROS",111503,,"Path planning is a key requirement for mobile robots employed for different tasks such as rescue or transport missions. Conventional methods such as A* or Dijkstra to tackle path planning problem need a premise map of the robot's environment. Nowadays, dynamic path planning is a popular research topic, which drives mobile robots without prior static requirements. Deep reinforcement learning (DRL), which is another popular research area, is being harnessed to solve dynamic path planning problem by the researchers. In this study, Deep Q-Networks, which is a subdomain of DRL are opted to solve dynamic path planning problem. We first employ well known techniques Double Deep Q-Networks (D2QN) and Dueling Double Deep Q-Networks (D3QN) to train a model which can drive a mobile robot in environments with static and dynamic obstacles within 3 different configurations. Then we propose D3QN with Prioritized Experience Replay (PER) extension in order to further optimize the DRL model. We created a test bed to measure the performance of the DRL models against 99 randomly generated goal locations. According to our experiments, D3QN-PER method performs better than D2QN and D3QN in terms of path length and travel time to the goal without any collisions. Robot Operating System and Gazebo simulation environment is utilized to realize the training and testing environments, thus, the trained DRL models can be deployed to any ROS compatible robot seamlessly.",https://doi.org/10.1016/j.asoc.2024.111503,https://www.sciencedirect.com/science/article/pii/S1568494624002771,,,,2024,Dynamic path planning via Dueling Double Deep Q-Network (D3QN) with prioritized experience replay,Mehmet Gök,article,GOK2024111503,Applied Soft Computing,,158,1568-4946,,,
,"Decentralization, Immutable, Independence, Interoperability, Privacy, Protection, Trustless, Web3, Web3+, Web3.0",553-581,Handbook of Digital Currency (Second Edition),"The Internet has undergone numerous changes since its emergence in 1969 and has now become an indispensable aspect of modern life. With the introduction of the World Wide Web by Tim Berners-Lee, the Internet has transformed into a tool for sharing and accessing vast amounts of information. As the Internet evolves toward its third iteration, Web3+ offers a decentralized solution that empowers users and returns control over the Internet to them. With the rise of cryptocurrency and blockchain, Web3+ focuses on data ownership and protection, making the Internet more secure and fair for everyone. In this article, we will explore the differences between Web 1.0, Web 2.0, Web 3.0, Web3, and Web3+ and how they shape the future of the Internet.",https://doi.org/10.1016/B978-0-323-98973-2.00052-6,https://www.sciencedirect.com/science/article/pii/B9780323989732000526,San Diego,Academic Press,978-0-323-98973-2,2024,"Chapter 28 - Understanding the Evolution of the Internet: Web 1.0 to Web3.0, Web3, and Web 3+∗∗The article is written with the help of ChatGPT to enhance the writing style. ChatGPT also assisted the author in verification of some information.",Zheng JinCheng and David Lee Kuo Chuen,incollection,JINCHENG2024553,,,,,,David {Lee Kuo Chuen},Second Edition
,"Model driven engineering, Software engineering, Artificial intelligence, Machine learning, Systematic literature review",107423,,"Context:
Machine Learning (ML) has become widely adopted as a component in many modern software applications. Due to the large volumes of data available, organizations want to increasingly leverage their data to extract meaningful insights and enhance business profitability. ML components enable predictive capabilities, anomaly detection, recommendation, accurate image and text processing, and informed decision-making. However, developing systems with ML components is not trivial; it requires time, effort, knowledge, and expertise in ML, data processing, and software engineering. There have been several studies on the use of model-driven engineering (MDE) techniques to address these challenges when developing traditional software and cyber–physical systems. Recently, there has been a growing interest in applying MDE for systems with ML components.
Objective:
The goal of this study is to further explore the promising intersection of MDE with ML (MDE4ML) through a systematic literature review (SLR). Through this SLR, we wanted to analyze existing studies, including their motivations, MDE solutions, evaluation techniques, key benefits and limitations.
Method:
Our SLR is conducted following the well-established guidelines by Kitchenham. We started by devising a protocol and systematically searching seven databases, which resulted in 3934 papers. After iterative filtering, we selected 46 highly relevant primary studies for data extraction, synthesis, and reporting.
Results:
We analyzed selected studies with respect to several areas of interest and identified the following: (1) the key motivations behind using MDE4ML; (2) a variety of MDE solutions applied, such as modeling languages, model transformations, tool support, targeted ML aspects, contributions and more; (3) the evaluation techniques and metrics used; and (4) the limitations and directions for future work. We also discuss the gaps in existing literature and provide recommendations for future research.
Conclusion:
This SLR highlights current trends, gaps and future research directions in the field of MDE4ML, benefiting both researchers and practitioners.",https://doi.org/10.1016/j.infsof.2024.107423,https://www.sciencedirect.com/science/article/pii/S0950584924000284,,,,2024,Model driven engineering for machine learning components: A systematic literature review,Hira Naveed and Chetan Arora and Hourieh Khalajzadeh and John Grundy and Omar Haggag,article,NAVEED2024107423,Information and Software Technology,,169,0950-5849,,,
,"Public health, Trust in science, Trust in health authorities, Information-seeking responses and reliance, Epidemics, Infectious disease outbreaks, Pandemics",100721,,"Research suggests trust in experts and authorities are important correlates of compliance with public health measures during infectious disease outbreaks. Empirical evidence on the dynamics of reliance on scientists and public health authorities during the early phases of an epidemic outbreak is limited. We examine these processes during the COVID-19 outbreak in Italy by leveraging data from Twitter and two online surveys, including a survey experiment. We find that reliance on experts followed a curvilinear path. Both Twitter and survey data showed initial increases in information-seeking from expert sources in the three weeks after the detection of the first case. Consistent with these increases, knowledge about health information linked to COVID-19 and support for containment measures was widespread, and better knowledge was associated with stronger support for containment policies. Both knowledge and containment support were positively associated with trust in science and public health authorities. However, in the third week after the outbreak, we detected a slowdown in responsiveness to experts. These processes were corroborated with a survey experiment, which showed that those holding incorrect beliefs about COVID-19 gave no greater – or even lower – importance to information when its source was stated as coming from experts than when the source was unstated. Our results suggest weakened trust in public health authorities with prolonged exposure to the epidemic as a potential mechanism for this effect. Weakened responsiveness to expert sources may increase susceptibility to misinformation and our results call for efforts to sustain trust in adapting public health response.",https://doi.org/10.1016/j.ssmph.2020.100721,https://www.sciencedirect.com/science/article/pii/S235282732030358X,,,,2021,Reliance on scientists and experts during an epidemic: Evidence from the COVID-19 outbreak in Italy,Pietro Battiston and Ridhi Kashyap and Valentina Rotondi,article,BATTISTON2021100721,SSM - Population Health,,13,2352-8273,,,
,"Internet energy consumption, CO emission, Online advertising, Invalid traffic",177-200,,"There are no commonly agreed ways to assess the total energy consumption of the Internet. Estimating the Internet's energy footprint is challenging because of the interconnectedness associated with even seemingly simple aspects of energy consumption. The first contribution of this paper is a common modular and layered framework, which allows researchers to assess both energy consumption and CO2e emissions of any Internet service. The framework allows assessing the energy consumption depending on the research scope and specific system boundaries. Further, the proposed framework allows researchers without domain expertise to make such an assessment by using intermediate results as data sources, while analyzing the related uncertainties. The second contribution is an estimate of the energy consumption and CO2e emissions of online advertising by utilizing our proposed framework. The third contribution is an assessment of the energy consumption of invalid traffic associated with online advertising. The second and third contributions are used to validate the first. The online advertising ecosystem resides in the core of the Internet, and it is the sole source of funding for many online services. Therefore, it is an essential factor in the analysis of the Internet's energy footprint. As a result, in 2016, online advertising consumed 20–282 TWh of energy. In the same year, the total infrastructure consumption ranged from 791 to 1334 TWh. With extrapolated 2016 input factor values without uncertainties, online advertising consumed 106 TWh of energy and the infrastructure 1059 TWh. With the emission factor of 0.5656 kg CO2e/kWh, we calculated the carbon emissions of online advertising, and found it produces 60 Mt CO2e (between 12 and 159 Mt of CO2e when considering uncertainty). The share of fraudulent online advertising traffic was 13.87 Mt of CO2e emissions (between 2.65 and 36.78 Mt of CO2e when considering uncertainty). The global impact of online advertising is multidimensional. Online advertising affects the environment by consuming significant amounts of energy, leading to the production CO2e emissions. Hundreds of billions of ad dollars are exchanged yearly, placing online advertising in a significant role economically. It has become an important and acknowledged component of the online-bound society, largely due to its integration with the Internet and the amount of revenue generated through it.",https://doi.org/10.1016/j.eiar.2018.08.004,https://www.sciencedirect.com/science/article/pii/S0195925517303505,,,,2018,Environmental impact assessment of online advertising,M. Pärssinen and M. Kotila and R. Cuevas and A. Phansalkar and J. Manner,article,PARSSINEN2018177,Environmental Impact Assessment Review,,73,0195-9255,,,
,"Malware detection, Semantic information, Heterogeneous subgraph, Deep learning, Graph convolutional network",103846,,"As the most popular mobile platform, Android has become the major attack target of malware, and thus there is an urgent need to effectively thwart them. Recently, the graph-based technique has been a promising solution for malware detection, which highly depends on graph structures to capture behaviors separating the malware from the benign apps. However, existing graph-based malware detection approaches still suffer from high computation cost in constructing or updating a graph for APK under detection, high false negative and false positive. To cope with these issues, we propose a novel global heterogeneous graph-based Android malware detection approach, named GHGDroid. A global heterogeneous graph (GHG) with a good updatability is first built on large-scale Android applications to characterize complex relationships among APKs and sensitive APIs. And then, using the GHG, a multi-layer graph convolutional network based embedding method is proposed to learn APK embeddings for well capturing behaviors that can separate malware from benign. Finally, using APK embeddings as well their labels, a malware classifier is trained. Experiments on real-world Android applications show that GHGDroid achieves 99.17 % F1-score, which outperforms the state-of-the-art approaches. Moreover, GHGDroid spends about 8 s on detecting an APK, which shows that it has a good potential as a practical tool for the Android malware detection task.",https://doi.org/10.1016/j.cose.2024.103846,https://www.sciencedirect.com/science/article/pii/S0167404824001470,,,,2024,GHGDroid: Global heterogeneous graph-based android malware detection,Lina Shen and Mengqi Fang and Jian Xu,article,SHEN2024103846,Computers & Security,,141,0167-4048,,,
,"IoT botnet, Adaptive learning, Ensemble learning, Online learning",84-95,,"With the number of Internet of Things (IoT) devices proliferating, the traffic volume of IoT-based attacks has shown a gradually increasing trend. The IoT botnet attack, which aims to commit real, efficient, and profitable cybercrimes, has become one of the most severe IoT threats. Applying traditional techniques to IoT is difficult due to its particular characteristics, such as resource-constrained devices, massive volumes of data, and real-time requirements. In this paper, we explore an adaptive online learning strategy for real-time IoT botnet attack detection. Furthermore, we operate the proposed adaptive strategy in conjunction with online ensemble learning. To evaluate the proposed strategy, we use real IoT traffic data, including benign traffic data and botnet traffic data infected by Mirai. In real-time IoT botnet attack detection, our experimental results demonstrate that the proposed adaptive online learning strategy achieves remarkable performance.",https://doi.org/10.1016/j.ins.2021.05.076,https://www.sciencedirect.com/science/article/pii/S0020025521005697,,,,2021,Adaptive online learning for IoT botnet detection,Zhou Shao and Sha Yuan and Yongli Wang,article,SHAO202184,Information Sciences,,574,0020-0255,,,
,"Internet of Things, Fog computing, Intrusion detection and prevention",109154,,"Currently, the Internet of Things is spreading in all areas that apply computing resources. An important ally of the IoT is fog computing. It extends cloud computing and services to the edge of the network. Smart environments are becoming real and possible through IoT and fog computing. However, they are not free from security threats and vulnerabilities. This makes special security techniques indispensable. Security is one of the biggest challenges to ensuring an optimal IoT and Fog environment. Combined with the significant damage generated by application attacks, this fact creates the need to focus efforts in this area. This need can be proven through existing reviews of the state-of-the-art that pointed out several open aspects that need greater research effort. In this way, this article presents a Systematic Literature Review (SLR) considering the context of intrusion detection and prevention in environments based on fog computing and IoT. This review addresses more than 100 studies that were included after undergoing an extensive inclusion/exclusion process with well-defined criteria. From these studies, information was extracted to build a view of the current state-of-the-art and answer the research questions of this study. In this way, we identify the state-of-the-art, open questions and possibilities for future research.",https://doi.org/10.1016/j.comnet.2022.109154,https://www.sciencedirect.com/science/article/pii/S1389128622002651,,,,2022,Intrusion detection and prevention in fog based IoT environments: A systematic literature review,Cristiano Antonio {de Souza} and Carlos Becker Westphall and Renato Bobsin Machado and Leandro Loffi and Carla Merkle Westphall and Guilherme Arthur Geronimo,article,DESOUZA2022109154,Computer Networks,,214,1389-1286,,,
,"Big data, Outdoor recreation, Social media, Mobile device data, Machine learning, Novel data",100668,,"With researchers increasingly interested in big data research, this conceptual paper describes how large datasets, secondary data, and associated analysis techniques can be used to understand outdoor recreation. Some types of large, secondary datasets that have been increasingly used in outdoor recreation research include social media, mobile device data, and trip reports or online reviews. First, we give a brief overview of big data terms and outline the steps involved in conducting big data research. In doing so, we describe data sources and analysis techniques relevant for outdoor recreation, and review how they have been applied in previous published works. We then describe opportunities, limitations, and considerations of using big data. Finally, we outline several questions researchers may consider when designing, conducting, reporting, and reviewing outdoor recreation research using big data. Overall, big data approaches can expand our understanding of outdoor recreation and, by addressing key questions, may help researchers harness the strengths of big data while ensuring quality and integrity.",https://doi.org/10.1016/j.jort.2023.100668,https://www.sciencedirect.com/science/article/pii/S2213078023000658,,,,2023,"What is “big data” and how should we use it? The role of large datasets, secondary data, and associated analysis techniques in outdoor recreation research",Dani T. Dagan and Emily J. Wilkins,article,DAGAN2023100668,Journal of Outdoor Recreation and Tourism,,44,2213-0780,Social media and other user created content for outdoor recreation and nature-based tourism research,,
,"Engineering, Energy engineering, Social sciences, Research methodology social sciences",106166,,"Summary
Geoengineering techniques such as solar radiation management (SRM) could be part of a future technology portfolio to limit global temperature change. However, there is public opposition to research and deployment of SRM technologies. We use 814,924 English-language tweets containing #geoengineering globally over 13 years (2009–2021) to explore public emotions, perceptions, and attitudes toward SRM using natural language processing, deep learning, and network analysis. We find that specific conspiracy theories influence public reactions toward geoengineering, especially regarding “chemtrails” (whereby airplanes allegedly spray poison or modify weather through contrails). Furthermore, conspiracies tend to spillover, shaping regional debates in the UK, USA, India, and Sweden and connecting with broader political considerations. We also find that positive emotions rise on both the global and country scales following events related to SRM governance, and negative and neutral emotions increase following SRM projects and announcements of experiments. Finally, we also find that online toxicity shapes the breadth of spillover effects, further influencing anti-SRM views.",https://doi.org/10.1016/j.isci.2023.106166,https://www.sciencedirect.com/science/article/pii/S2589004223002432,,,,2023,Conspiracy spillovers and geoengineering,Ramit Debnath and David M. Reiner and Benjamin K. Sovacool and Finn Müller-Hansen and Tim Repke and R. Michael Alvarez and Shaun D. Fitzgerald,article,DEBNATH2023106166,iScience,3,26,2589-0042,,,
,"Building energy system, Building load prediction, Building energy forecasting, Machine learning, Feature engineering, Data engineering",116452,,"The surge of machine learning and increasing data accessibility in buildings provide great opportunities for applying machine learning to building energy system modeling and analysis. Building load prediction is one of the most critical components for many building control and analytics activities, as well as grid-interactive and energy efficiency building operation. While a large number of research papers exist on the topic of machine-learning-based building load prediction, a comprehensive review from the perspective of machine learning is missing. In this paper, we review the application of machine learning techniques in building load prediction under the organization and logic of the machine learning, which is to perform tasks T using Performance measure P and based on learning from Experience E. Firstly, we review the applications of building load prediction model (task T). Then, we review the modeling algorithms that improve machine learning performance and accuracy (performance P). Throughout the papers, we also review the literature from the data perspective for modeling (experience E), including data engineering from the sensor level to data level, pre-processing, feature extraction and selection. Finally, we conclude with a discussion of well-studied and relatively unexplored fields for future research reference. We also identify the gaps in current machine learning application and predict for future trends and development.",https://doi.org/10.1016/j.apenergy.2021.116452,https://www.sciencedirect.com/science/article/pii/S0306261921000209,,,,2021,A review of machine learning in building load prediction,Liang Zhang and Jin Wen and Yanfei Li and Jianli Chen and Yunyang Ye and Yangyang Fu and William Livingood,article,ZHANG2021116452,Applied Energy,,285,0306-2619,,,
,"Cancer, Chemotherapy, Social media, Twitter, Side effect, Deep learning",92-100,,"Objective
Twitter has become one of the most popular social media platforms that offers real-world insights to healthy behaviors. The purpose of this study was to assess and compare perceptions about chemotherapy of patients and health-care providers through analysis of chemo-related tweets.
Materials and methods
Cancer-related Twitter accounts and their tweets were obtained through using Tweepy (Python library). Multiple text classification algorithms were tested to identify the models with best performance in classifying the accounts into individual and organization. Chemotherapy-specific tweets were extracted from historical tweetset, and the content of these tweets was analyzed using topic model, sentiment analysis and word co-occurrence network.
Results
Using the description in Twitter users’ profiles, the accounts related with cancer were collected and coded as individual or organization. We employed Long Short Term Memory (LSTM) network with GloVe word embeddings to identify the user into individuals and organizations with accuracy of 85.2%. 13, 273 and 14,051 publicly available chemotherapy-related tweets were retrieved from individuals and organizations, respectively. The content of the chemo-related tweets was analyzed by text mining approaches. The tweets from individual accounts pertained to personal chemotherapy experience and emotions. In contrast with the personal users, professional accounts had a higher proportion of neutral tweets about side effects. The information about the assessment of response to chemotherapy was deficient from organizations on Twitter.
Discussion
Examining chemotherapy discussions on Twitter provide new lens into content and behavioral patterns associated with treatments for cancer patients. The methodology described herein allowed us to collect relatively large number of health-related tweets over a greater time period and exploit the potential power of social media, which provide comprehensive view on patients’ perceptions of chemotherapy.
Conclusion
This study sheds light on using Twitter data as a valuable healthcare data source for helping oncologists (organizations) in understanding patients’ experiences while undergoing chemotherapy, in developing personalize therapy plans, and a supplement to the clinical electronic medical records (EMRs).",https://doi.org/10.1016/j.ijmedinf.2018.10.002,https://www.sciencedirect.com/science/article/pii/S1386505618304325,,,,2018,Utilizing Twitter data for analysis of chemotherapy,Ling Zhang and Magie Hall and Dhundy Bastola,article,ZHANG201892,International Journal of Medical Informatics,,120,1386-5056,,,
,"Mobile Robots, Multisensor Integration, Simultaneous Localization, Mapping, Robotics, Sensors, Cameras, Encoders, Embedded systems",323-328,,"The goal of this paper is to present a concept and implementation of an Environment Detection System. The system is supposed to collect data from sensors attached to the mobile robot and then enhance the map of the environment by this information. Moreover, the data can be processed to get valuable information about the environment or its change. The open-source implementation of the system is written for Robot Operating System. Thus, the system can handle data from different sensors using a unified way. It is possible by employing the messaging mechanism implemented in the Robot Operating System. Another contribution of this paper are records of our testing runs with a 6WD mobile robot equipped by multiple sensors, which can be used as a dataset for SLAM and Environment Detection System implementations.",https://doi.org/10.1016/j.ifacol.2019.12.681,https://www.sciencedirect.com/science/article/pii/S2405896319326308,,,,2019,Environment detection system for localization and mapping purposes,P. Neduchal and L. Bureš and M. Železný,article,NEDUCHAL2019323,IFAC-PapersOnLine,27,52,2405-8963,16th IFAC Conference on Programmable Devices and Embedded Systems PDES 2019,,
,"Emerging technologies, Network-level security and protection, Network communications, Network Protocols, Protection mechanisms, Quality analysis and evaluation, System issues, Security and Privacy Protection, Authentication, Communications Applications, Virtual reality, Security and Protection, Artificial, augmented, and virtual realities, Invasive software (viruses, worms, Trojan horses), Unauthorized access (hacking, phreaking)",102923,,"The allure of the metaverse along with Virtual Reality (VR) technologies and speed at which they are deployed may shift focus away from security and privacy fundamentals. In this work we employ classic exploitation techniques against cutting edge devices to obtain equally novel results. The unique features of the Virtual Reality landscape set the stage for our primary account of a new attack, the Man-in-the-Room (MitR). This attack, realized from a vulnerable social networking application led to both worming and botnet capabilities being adapted for VR with potential critical impacts affecting millions of users. Our work improves the state-of-the-art in Virtual Reality (VR) security and socio-technical research in VR. It shares several analytical and attacking tools, example exploits, evaluation dataset, and vulnerability signatures with the scientific and professional communities to ensure secure VR software development. The presented results demonstrate the detection and prevention of VR vulnerabilities, and raise questions in the law and policy domains pertaining to VR security and privacy.",https://doi.org/10.1016/j.cose.2022.102923,https://www.sciencedirect.com/science/article/pii/S0167404822003157,,,,2023,Rise of the Metaverse’s Immersive Virtual Reality Malware and the Man-in-the-Room Attack & Defenses,Martin Vondráček and Ibrahim Baggili and Peter Casey and Mehdi Mekni,article,VONDRACEK2023102923,Computers & Security,,127,0167-4048,,,
,"Information credibility evaluation, Fake news detection, Adversarial networks, Reinforcement learning",453-473,,"A series of deep learning approaches extract a large number of credibility features to detect fake news on the Internet. However, these extracted features still suffer from many irrelevant and noisy features that restrict severely the performance of the approaches. In this paper, we propose a novel model based on Adversarial Networks and inspirited by the Shared-Private model (ANSP), which aims at reducing common, irrelevant features from the extracted features for information credibility evaluation. Specifically, ANSP involves two tasks: one is to prevent the binary classification of true and false information for capturing common features relying on adversarial networks guided by reinforcement learning. Another extracts credibility features (henceforth, private features) from multiple types of credibility information and compares with the common features through two strategies, i.e., orthogonality constraints and KL-divergence for making the private features more differential. Experiments first on two six-label LIAR and Weibo datasets demonstrate that ANSP achieves state-of-the-art performance, boosting the accuracy by 2.1%, 3.1%, respectively and then on four-label Twitter16 validate the robustness of the model with 1.8% performance improvements.",https://doi.org/10.1016/j.ins.2019.12.040,https://www.sciencedirect.com/science/article/pii/S002002551931151X,,,,2020,Discovering differential features: Adversarial learning for information credibility evaluation,Lianwei Wu and Yuan Rao and Ambreen Nazir and Haolin Jin,article,WU2020453,Information Sciences,,516,0020-0255,,,
,"Social accountability, Social media, Panama papers, Big data and quantitative methods, Accounting interventions",38-53,,"The potential of social media to disseminate, aggregate, channel and democratize social accountability processes has encouraged a variety of organizations to actively promote and champion such initiatives. These initiatives typically envision a three step social accountability process where, for example, the publication of previously-private financial information about the inappropriate wealth accumulation activities of politicians and their business allies (step #1), combined with social media dissemination and discussion of these activities (step #2), can result in an accountability conversation that spills out of the medium and that sometimes results in positive social change (step #3). The current study examines Twitter reactions to the International Consortium of Investigative Journalist’s (ICIJ) publication of the Panama Papers. The analysis illustrates that there was a Twitter reaction: furthermore, that there were different styles of response and that certain styles were more likely to elicit an audience reaction, especially if the tweeter was a journalist or organization. While the provided analysis focuses on step #2 within the social accountability process, the results imply that publicly-interested accounting academics qua activists can facilitate social accountability by helping to make previously-private financial information public and by cultivating sympathetic individuals within the traditional media as well as within organizations that are active on social media.",https://doi.org/10.1016/j.cpa.2019.04.003,https://www.sciencedirect.com/science/article/pii/S1045235418302314,,,,2019,Twitter and social accountability: Reactions to the Panama Papers,Dean Neu and Greg Saxton and Abu Rahaman and Jeffery Everett,article,NEU201938,Critical Perspectives on Accounting,,61,1045-2354,,,
,"Machine Learning, Metabolic Engineering, Synthetic Biology, Deep Learning",34-60,,"Machine learning provides researchers a unique opportunity to make metabolic engineering more predictable. In this review, we offer an introduction to this discipline in terms that are relatable to metabolic engineers, as well as providing in-depth illustrative examples leveraging omics data and improving production. We also include practical advice for the practitioner in terms of data management, algorithm libraries, computational resources, and important non-technical issues. A variety of applications ranging from pathway construction and optimization, to genetic editing optimization, cell factory testing, and production scale-up are discussed. Moreover, the promising relationship between machine learning and mechanistic models is thoroughly reviewed. Finally, the future perspectives and most promising directions for this combination of disciplines are examined.",https://doi.org/10.1016/j.ymben.2020.10.005,https://www.sciencedirect.com/science/article/pii/S109671762030166X,,,,2021,Machine learning for metabolic engineering: A review,Christopher E. Lawson and Jose Manuel Martí and Tijana Radivojevic and Sai Vamshi R. Jonnalagadda and Reinhard Gentz and Nathan J. Hillson and Sean Peisert and Joonhoon Kim and Blake A. Simmons and Christopher J. Petzold and Steven W. Singer and Aindrila Mukhopadhyay and Deepti Tanjore and Joshua G. Dunn and Hector {Garcia Martin},article,LAWSON202134,Metabolic Engineering,,63,1096-7176,Tools and Strategies of Metabolic Engineering,,
,,207-221,Eleventh Hour CISSP® (Third Edition),,https://doi.org/10.1016/B978-0-12-811248-9.09992-7,https://www.sciencedirect.com/science/article/pii/B9780128112489099927,,Syngress,978-0-12-811248-9,2017,Index,,incollection,2017207,,,,,,Eric Conrad and Seth Misenar and Joshua Feldman,Third Edition
,"Cyber security, Cloud computing, Machine learning, Deep learning, Recurrent neural network",102662,,"The reliability of Internet of Things (IoT) connected devices is heavily dependent on the security model employed to protect user data and prevent devices from engaging in malicious activity. Existing approaches for detecting phishing, distributed denial of service (DDoS), and Botnet attacks often focus on either the device or the back-end. In this paper, we propose a cloud-based distributed deep learning framework for phishing and Botnet attack detection and mitigation. The model comprises two key security mechanisms working cooperatively, namely: (1) a Distributed Convolutional Neural Network (DCNN) model embedded as an IoT device micro-security add-on for detecting phishing and application layer DDoS attacks; and (2) a cloud-based temporal Long-Short Term Memory (LSTM) network model hosted on the back-end for detecting Botnet attacks, and ingest CNN embeddings to detect distributed phishing attacks across multiple IoT devices. The distributed CNN model, embedded into a ML engine in the client's IoT device, allows us to detect and defend the IoT device from phishing attacks at the point of origin. We create a dataset consisting of both phishing and non-phishing URLs to train the proposed CNN add-on security model, and select the N_BaIoT dataset for training the back-end LSTM model. The joint training method minimizes communication and resource requirements for attack detection, and maximizes the usefulness of extracted features. In addition, an aggregation of schemes allows the automatic fusion of multiple requests to improve the overall performance of the system. Our experiments show that the IoT micro-security add-on running the proposed CNN model is capable of detecting phishing attacks with an accuracy of 94.3% and a F-1 score of 93.58%. Using the back-end LSTM model, the model detects Botnet attacks with an accuracy of 94.80% using all malicious data points in the used dataset. Thus, the findings demonstrate that the proposed approach is capable of detecting attacks, both at device and at the back-end level, in a distributed fashion.",https://doi.org/10.1016/j.jnca.2020.102662,https://www.sciencedirect.com/science/article/pii/S1084804520301363,,,,2020,Detecting Internet of Things attacks using distributed deep learning,Gonzalo {De La Torre Parra} and Paul Rad and Kim-Kwang Raymond Choo and Nicole Beebe,article,DELATORREPARRA2020102662,Journal of Network and Computer Applications,,163,1084-8045,,,
,"India stack, Digital public infrastructure, Digital transformation, Aadhaar, Unified payments interface",105947,,"India is going through a transformative phase in its digital journey. A large part of this is enfolding in the field of digital public infrastructures as the ‘India Stack’ branded suite of technological solutions permeates through areas like digital identity, instant payments, digital commerce, and consent management. The paper traces the socio-technical imaginaries that have fueled India's digital transformation strategy and how India Stack acquired its central place in that scheme. Drawing upon India's performance on global ICT-related indices and the OECD's Good Practice Principles for Public Service Design and Delivery, the paper also examines how the country is faring in translating its visions of digital transformation into outcomes. It identifies reliance on coercive digital adoption strategies, lack of participative decision-making, and insufficient accountability safeguards as some of the fault lines in India's path to fair and equitable digital transformation.",https://doi.org/10.1016/j.clsr.2024.105947,https://www.sciencedirect.com/science/article/pii/S0267364924000141,,,,2024,Stack is the New Black?: Evolution and Outcomes of the ‘India-Stackification’ Process,Smriti Parsheera,article,PARSHEERA2024105947,Computer Law & Security Review,,52,0267-3649,,,
,"Digital innovation, Socio-technical artifact, Design science research, Information systems scalability",103263,,"We posit that design science enables the creation of in-class introductory college courses that can scale to large numbers of students, under resource constraints. We build on the centrality of human interactions in learning environments and conceptualize a college course as a socio-technical (ST) artifact. Grounded in the intervention theory, we draw meta-requirements guiding the design of college courses that leverage IT to scale, while maintaining the centrality of the professor’s role. We use the design-build-evaluate cycle to instantiate the ST artifact and demonstrate its feasibility using evaluation episodes as prescribed by the Framework for Evaluation in Design Science Research.",https://doi.org/10.1016/j.im.2019.103263,https://www.sciencedirect.com/science/article/pii/S0378720619300394,,,,2020,Designing scalability in required in-class introductory college courses,Gabriele Piccoli and Marcin Łukasz Bartosiak and Biagio Palese and Joaquin Rodriguez,article,PICCOLI2020103263,Information & Management,8,57,0378-7206,,,
,"AI assurance, AI explainability, detecting bias, natural language processing, large language models",371-427,AI Assurance,"AI methods are becoming more common in the field of economics, but these models must be bias-free, fair, and explainable. In other words, we need AI assurance. Economic forecasting has benefited from machine learning techniques, such as neural networks, to increase model performance, but these AI techniques must be audited, accountable, and interpretable to be useful for economic policymaking. The rise of natural language processing and large language models has created new challenges for economic policymaking institutions, which need to be aware of AI assurance and how to harness them safely.",https://doi.org/10.1016/B978-0-32-391919-7.00025-1,https://www.sciencedirect.com/science/article/pii/B9780323919197000251,,Academic Press,978-0-323-91919-7,2023,11 - Assuring AI methods for economic policymaking,Anderson Monken and William Ampeh and Flora Haberkorn and Uma Krishnaswamy and Feras A. Batarseh,incollection,MONKEN2023371,,,,,,Feras A. Batarseh and Laura J. Freeman,
,"Open-domain dialogue generation, Teamwork generation framework, Semantics extractor, Conversation model",108376,,"Many existing conversation models that are based on the encoder–decoder framework incorporate complex encoders. These powerful encoders serve to enrich the context vectors, so that the generated responses are more diverse and informative. However, these approaches face two potential challenges. First, the high complexity of the encoder means relative simplicity of the decoder. There is a danger that the decoder becomes too simple to effectively capture previously generated information. As a result, the decoder may produce duplicated and self-contradicting responses. Second, by having a complex encoder, the model may generate incoherent responses because the complex context vectors may deviate from the true semantics of context. In this work, we propose a conversation model named “THINK” (Teamwork generation Hover around Impressive Noticeable Keywords) that is equipped with a complex decoder to avoid generating duplicated and self-contradicting responses. The model also simplifies the context vectors and increases the coherence of generated responses in a reasonable way. For this model, we propose Teamwork generation framework and Semantics extractor. Compared with other baselines, both automatic and human evaluation showed the advantages of our model.",https://doi.org/10.1016/j.knosys.2022.108376,https://www.sciencedirect.com/science/article/pii/S0950705122001423,,,,2022,THINK: A novel conversation model for generating grammatically correct and coherent responses,Bin Sun and Shaoxiong Feng and Yiwei Li and Jiamou Liu and Kan Li,article,SUN2022108376,Knowledge-Based Systems,,242,0950-7051,,,
,"Blockchain, Bitcoin, Ethereum, Hyperledger, Algorand, Ripple, IOTA, Tangle, Smart contracts, Hashing, Security, Cryptography, Trust, Attacks, Vulnerabilities, Consensus",183-195,,"Distributed ledgers stimulate innovative services and enabled new applications in several domains, creating new concepts for trust and regulation. However, this backbone that is enabling novelties and abridging businesses comes with drawbacks and security flaws. In this paper, we evaluate several Distributed Ledger Technologies (DLTs) features depicting the Bitcoin, Ripple, Ethereum, Hyperledger, Algorand and IOTA networks. We focus on their security challenges and expose numerous threats and vulnerabilities. For instance, we have simulated a few of their possible attacks proving them non-immune. In the other hand, we show a few of their malicious use cases. Meticulously presenting DLTs menaces and flaws, we are not involved in preferring any specific DLT network.",https://doi.org/10.1016/j.future.2020.06.044,https://www.sciencedirect.com/science/article/pii/S0167739X17330650,,,,2020,On distributed ledgers security and illegal uses,Joanna Moubarak and Maroun Chamoun and Eric Filiol,article,MOUBARAK2020183,Future Generation Computer Systems,,113,0167-739X,,,
,"Nighttime lights imagery, Twitter, Socioeconomic factors, Location-based social media, The United States",1-10,,"Nighttime lights (NTL) imagery is one of the most commonly used tools to quantitatively study socioeconomic systems over large areas. In this study we aim to use location-based social media big data to challenge the primacy of NTL imagery on estimating socioeconomic factors. Geo-tagged tweets posted in the contiguous United States in 2013 were retrieved to produce a tweet image with the same spatial resolution of the NTL imagery (i.e., 0.00833° × 0.00833°). Sum tweet (the total number of tweets) and sum light (summed DN value of the NTL image) of each state or county were obtained from the tweets and the NTL images, respectively, to estimate three important socioeconomic factors: personal income, electric power consumption, and fossil fuel carbon dioxide emissions. Results show that sum tweet is a better measure of personal income and electric power consumption while carbon dioxide emissions can be more accurately estimated by sum light. We further exploited that African-Americans adults are more likely than White seniors to post geotagged tweets in the US, yet did not find any significant correlations between proportions of the subpopulations and the estimation accuracy of the socioeconomic factors. Existence of saturated pixels and blooming effects and failure to remove gas flaring reduce quality of NTL imagery in estimating socioeconomic factors, however, such problems are nonexistent in the tweet images. This study reveals that the number of geo-tagged tweets has great potential to be deemed as a substitute of brightness of NTL to assess socioeconomic factors over large geographic areas.",https://doi.org/10.1016/j.isprsjprs.2018.08.018,https://www.sciencedirect.com/science/article/pii/S0924271618302375,,,,2018,Tweets or nighttime lights: Comparison for preeminence in estimating socioeconomic factors,Naizhuo Zhao and Guofeng Cao and Wei Zhang and Eric L. Samson,article,ZHAO20181,ISPRS Journal of Photogrammetry and Remote Sensing,,146,0924-2716,,,
,"Data flow diagram, Access control, Information flow",111138,,"The security of software-intensive systems is frequently attacked. High fines or loss in reputation are potential consequences of not maintaining confidentiality, which is an important security objective. Detecting confidentiality issues in early software designs enables cost-efficient fixes. A Data Flow Diagram (DFD) is a modeling notation, which focuses on essential, functional aspects of such early software designs. Existing confidentiality analyses on DFDs support either information flow control or access control, which are the most common confidentiality mechanisms. Combining both mechanisms can be beneficial but existing DFD analyses do not support this. This lack of expressiveness requires designers to switch modeling languages to consider both mechanisms, which can lead to inconsistencies. In this article, we present an extended DFD syntax that supports modeling both, information flow and access control, in the same language. This improves expressiveness compared to related work and avoids inconsistencies. We define the semantics of extended DFDs by clauses in first-order logic. A logic program made of these clauses enables the automated detection of confidentiality violations by querying it. We evaluate the expressiveness of the syntax in a case study. We attempt to model nine information flow cases and six access control cases. We successfully modeled fourteen out of these fifteen cases, which indicates good expressiveness. We evaluate the reusability of models when switching confidentiality mechanisms by comparing the cases that share the same system design, which are three pairs of cases. We successfully show improved reusability compared to the state of the art. We evaluated the accuracy of confidentiality analyses by executing them for the fourteen cases that we could model. We experienced good accuracy.",https://doi.org/10.1016/j.jss.2021.111138,https://www.sciencedirect.com/science/article/pii/S0164121221002351,,,,2022,Detecting violations of access control and information flow policies in data flow diagrams,Stephan Seifermann and Robert Heinrich and Dominik Werle and Ralf Reussner,article,SEIFERMANN2022111138,Journal of Systems and Software,,184,0164-1212,,,
,"IoT-Fog networks, Data security, Intrusion Detection System (IDS), Received Signal Strength (RSS), Rate Limiting (RL)",103778,,"The Internet of Things (IoT) has recently received a lot of attention from the information and communication technology community. It has turned out to be a crucial development for harnessing the incredible power of wireless media in the real world. The nature of IoT-Fog networks requires the use of defense techniques who are light and mobile-aware. The edge resources in such a distributed environment are open to various safety hazards. DDoS UDP flooding attacks are the most frequent threats to edge resources in IoT-Fog networks. It is crucial for sabotaging fog gateways and can overcome traditional data filtering techniques. This paper introduces M-RL, a lightweight intrusion detection system with mobility awareness that can detect DDoS UDP flooding attacks while taking into account adversarial IoT devices that engage in IP spoofing. To this end, this paper analyzes the malicious behaviors that result in anonymity against Rate Limiting and Received Signal Strength (RSS)-based approaches, combines their advantages, and addresses their vulnerabilities. We test our method in different contexts to achieve that goal, and we find that it may decrease the accuracy of the RL, RSS, and RSS-RL methods to 70%, 48.9%, and 64.3%, respectively. The outcomes demonstrate the proposed approach's resistance to software-based source address forgery, impersonation, and signal modification. It offers more than 99% accuracy and supports node mobility. In this case, the best possible accuracy of the previous methods is 77%.",https://doi.org/10.1016/j.cose.2024.103778,https://www.sciencedirect.com/science/article/pii/S0167404824000798,,,,2024,M-RL: A mobility and impersonation-aware IDS for DDoS UDP flooding attacks in IoT-Fog networks,Saeed Javanmardi and Meysam Ghahramani and Mohammad Shojafar and Mamoun Alazab and Antonio M. Caruso,article,JAVANMARDI2024103778,Computers & Security,,140,0167-4048,,,
,"Memory forensics, Keystroke loggers, Malware detection, Emulation, Incident response, Reverse engineering",101872,,"Advances in malware development have led to the widespread use of attacker toolkits that do not leave any trace in the local filesystem. This negatively impacts traditional investigative procedures that rely on filesystem analysis to reconstruct attacker activities. As a solution, memory forensics has replaced filesystem analysis in these scenarios. Unfortunately, existing memory forensics tools leave many capabilities inaccessible to all but the most experienced investigators, who are well versed in operating systems internals and reverse engineering. The goal of the research described in this paper is to make investigation of one of the greatest threats that organizations face, userland keyloggers, less error-prone and less dependent on manual reverse engineering. To accomplish this, we have added significant new capabilities to HookTracer, which is an engine capable of emulating code discovered in a physical memory captures and recording all actions taken by the emulated code. Based on this work, we present new memory forensics capabilities, embodied in a new Volatility plugin, hooktracer_messagehooks, that uses Hooktracer to automatically decide whether a hook in memory is associated with a malicious keylogger or benign software. We also include a detailed case study that illustrates our technique’s ability to successfully analyze very sophisticated keyloggers, such as Turla.",https://doi.org/10.1016/j.cose.2020.101872,https://www.sciencedirect.com/science/article/pii/S0167404820301450,,,,2020,Hooktracer: Automatic Detection and Analysis of Keystroke Loggers Using Memory Forensics,Andrew Case and Ryan D. Maggio and Md Firoz-Ul-Amin and Mohammad M. Jalalzai and Aisha Ali-Gombe and Mingxuan Sun and Golden G. Richard,article,CASE2020101872,Computers & Security,,96,0167-4048,,,
,"Large language models, LLMs, GPT-3, ChatGPT, GPT-4, Transformers, LLM survey",100048,,"Large language models (LLMs) are a special class of pretrained language models (PLMs) obtained by scaling model size, pretraining corpus and computation. LLMs, because of their large size and pretraining on large volumes of text data, exhibit special abilities which allow them to achieve remarkable performances without any task-specific training in many of the natural language processing tasks. The era of LLMs started with OpenAI’s GPT-3 model, and the popularity of LLMs has increased exponentially after the introduction of models like ChatGPT and GPT4. We refer to GPT-3 and its successor OpenAI models, including ChatGPT and GPT4, as GPT-3 family large language models (GLLMs). With the ever-rising popularity of GLLMs, especially in the research community, there is a strong need for a comprehensive survey which summarizes the recent research progress in multiple dimensions and can guide the research community with insightful future research directions. We start the survey paper with foundation concepts like transformers, transfer learning, self-supervised learning, pretrained language models and large language models. We then present a brief overview of GLLMs and discuss the performances of GLLMs in various downstream tasks, specific domains and multiple languages. We also discuss the data labelling and data augmentation abilities of GLLMs, the robustness of GLLMs, the effectiveness of GLLMs as evaluators, and finally, conclude with multiple insightful future research directions. To summarize, this comprehensive survey paper will serve as a good resource for both academic and industry people to stay updated with the latest research related to GLLMs.",https://doi.org/10.1016/j.nlp.2023.100048,https://www.sciencedirect.com/science/article/pii/S2949719123000456,,,,2024,A survey of GPT-3 family large language models including ChatGPT and GPT-4,Katikapalli Subramanyam Kalyan,article,KALYAN2024100048,Natural Language Processing Journal,,6,2949-7191,,,
,"Analytical derivatives, algorithmic differentiation, robot manipulators, optimal control, predictive control",78-83,,"In the context of nonlinear model predictive control (NMPC) for robot manipulators, we address the problem of enabling the mixed and transparent use of algorithmic differentiation (AD) and efficient analytical derivatives of rigid-body dynamics (RBD) to decrease the solution time of the subjacent optimal control problem (OCP). Efficient functions for RBD and their analytical derivatives are made available to the numerical optimization framework CasADi by overloading the operators in the implementations made by the RBD library Pinocchio and adding a derivative-overloading feature to CasADi. A comparison between analytical derivatives and AD is made based on their influence on the solution time of the OCP, showing the benefits of using analytical derivatives for RBD in optimal control of robot manipulators.",https://doi.org/10.1016/j.ifacol.2021.11.156,https://www.sciencedirect.com/science/article/pii/S240589632102200X,,,,2021,"Mixed Use of Analytical Derivatives and Algorithmic Differentiation for NMPC of Robot Manipulators⁎⁎The authors would like to thank Flanders Make SBO MULTIROB: “Rigorous approach for programming and optimal control of multi-robot systems”, FWO project G0A6917N of the Research Foundation - Flanders (FWO - Flanders), and KU Leuven-BOF PFV/10/002 Centre of Excellence: Optimization in Engineering (OPTEC) for supporting this research.",Alejandro Astudillo and Justin Carpentier and Joris Gillis and Goele Pipeleers and Jan Swevers,article,ASTUDILLO202178,IFAC-PapersOnLine,20,54,2405-8963,"Modeling, Estimation and Control Conference MECC 2021",,
,,455-479,Intelligence-Based Medicine,,https://doi.org/10.1016/B978-0-12-823337-5.00024-X,https://www.sciencedirect.com/science/article/pii/B978012823337500024X,,Academic Press,978-0-12-823337-5,2020,Glossary,,incollection,2020455,,,,,,Anthony C. Chang,
,"Modern code review, Software quality, Code reviewers recommendation, Search-based software engineering",106908,,"Contemporary software development is distributed and characterized by high dynamics with continuous and frequent changes to fix defects, add new user requirements or adapt to other environmental changes. To manage such changes and ensure software quality, modern code review is broadly adopted as a common and effective practice. Yet several open-source as well as commercial software projects have adopted peer code review as a crucial practice to ensure the quality of their software products using modern tool-based code review. Nevertheless, the selection of peer reviewers is still merely a manual and hard task especially with the growing size of distributed development teams. Indeed, it has been proven that inappropriate peer reviewers selection can consume more time and effort from both developers and reviewers and increase the development costs and time to market. To address this problem, we introduce a multi-objective search-based approach, named WhoReview, to find the optimal set of peer reviewers for code changes. We use the Indicator-Based Evolutionary Algorithm (IBEA) to find the best set of code reviewers that are (1) most experienced with the code change to be reviewed, while (2) considering their current workload, i.e., the number of open code reviews they are working on. We conduct an empirical study on 4 long-lived open source software projects to evaluate our approach. The obtained results show that WhoReview outperforms state-of-the-art approach by an average precision of 68% and recall of 77%. Moreover, we deployed our approach in an industrial context and evaluated it qualitatively from developers perspective. Results show the effectiveness of our approach with a high acceptance ratio in identifying relevant reviewers.",https://doi.org/10.1016/j.asoc.2020.106908,https://www.sciencedirect.com/science/article/pii/S1568494620308462,,,,2021,WhoReview: A multi-objective search-based approach for code reviewers recommendation in modern code review,Moataz Chouchen and Ali Ouni and Mohamed Wiem Mkaouer and Raula Gaikovina Kula and Katsuro Inoue,article,CHOUCHEN2021106908,Applied Soft Computing,,100,1568-4946,,,
Intelligent Data-Centric Systems,"Artificial intelligence, autonomous vehicles, facial recognition, AI writing assistant, AI image generator, human needs",259-278,Ethics in Online AI-based Systems,"While advancing artificial intelligence (AI) applications have brought ease and benefit to human life in meeting our physical needs, it is less obvious how they would impact psychological needs. This study analyzes three emerging technologies—autonomous vehicles; facial recognition systems; and AI writing or image generators—from the perspective of six fundamental human needs; certainty, variety, significance, connection, growth, and contribution. Our core human needs can greatly influence the acceptability, feasibility, and utility of these technologies. A prognosis of the human needs implications of AI can help algorithm designers, policymakers, regulators, and end users mitigate the risks and accentuate its benefits.",https://doi.org/10.1016/B978-0-443-18851-0.00004-4,https://www.sciencedirect.com/science/article/pii/B9780443188510000044,,Academic Press,978-0-443-18851-0,2024,Chapter 13 - Artificial intelligence and basic human needs: the shadow aspects of emerging technology,Tay Keong Tan,incollection,TAN2024259,,,,,,Santi Caballé and Joan Casas-Roma and Jordi Conesa,
,"Flaky tests, Non-deterministic tests, Test bugs, Software testing, Multivocal review",111837,,"Flaky tests (tests with non-deterministic outcomes) pose a major challenge for software testing. They are known to cause significant issues, such as reducing the effectiveness and efficiency of testing and delaying software releases. In recent years, there has been an increased interest in flaky tests, with research focusing on different aspects of flakiness, such as identifying causes, detection methods and mitigation strategies. Test flakiness has also become a key discussion point for practitioners (in blog posts, technical magazines, etc.) as the impact of flaky tests is felt across the industry. This paper presents a multivocal review that investigates how flaky tests, as a topic, have been addressed in both research and practice. Out of 560 articles we reviewed, we identified and analysed a total of 200 articles that are focused on flaky tests (composed of 109 academic and 91 grey literature articles/posts) and structured the body of relevant research and knowledge using four different dimensions: causes, detection, impact and responses. For each of those dimensions, we provide categorization and classify existing research, discussions, methods and tools With this, we provide a comprehensive and current snapshot of existing thinking on test flakiness, covering both academic views and industrial practices, and identify limitations and opportunities for future research.",https://doi.org/10.1016/j.jss.2023.111837,https://www.sciencedirect.com/science/article/pii/S0164121223002327,,,,2023,"Test flakiness’ causes, detection, impact and responses: A multivocal review",Amjed Tahir and Shawn Rasheed and Jens Dietrich and Negar Hashemi and Lu Zhang,article,TAHIR2023111837,Journal of Systems and Software,,206,0164-1212,,,
,"Denial of service, Web server, Defense, Enlargement, Availability",103363,,"Denial-of-Service (DoS) attacks are becoming increasingly common and undermine the availability of widely used web servers. Even if DoS attacks cannot be rendered completely harmless, ready-to-use defense modules and solutions to mitigate their effect are highly beneficial for site administrators. Unfortunately, there is a lack of measurement studies that explore the pros and cons of common DoS web server defense modules in order to understand their limitations and to drive practitioners’ choices. This paper presents an empirical study of the ubiquitous Apache web server, with an assessment of two well-known pluggable defense modules and an enlargement technique that provides the server with additional resources. Measurements are based on a mixture of flooding and slow DoS attacks. The experimentation shows that, in spite of the large availability of pluggable security modules that can be usefully deployed in practice, there is not a bulletproof defense solution to mitigate the DoS attacks in hand. The findings of our analysis can be useful to support the deployment of proper defense mechanisms, as well as the development of robust and effective solutions for DoS protection.",https://doi.org/10.1016/j.jnca.2022.103363,https://www.sciencedirect.com/science/article/pii/S1084804522000303,,,,2022,No more DoS? An empirical study on defense techniques for web server Denial of Service mitigation,Marta Catillo and Antonio Pecchia and Umberto Villano,article,CATILLO2022103363,Journal of Network and Computer Applications,,202,1084-8045,,,
,,3536-3543.e6,,"Summary
Bilateral symmetry defines much of the animal kingdom and is crucial for numerous functions of bilaterian organisms. Genetic approaches have discovered highly conserved patterning networks that establish bilateral symmetry in early embryos,1 but how this symmetry is maintained throughout subsequent morphogenetic events remains largely unknown.2 Here we show that the terminal patterning system—which relies on Ras/ERK signaling through activation of the Torso receptor by its ligand Trunk3—is critical for preserving bilateral symmetry during Drosophila body axis elongation, a process driven by cell rearrangements in the two identical lateral regions of the embryo and specified by the dorsal-ventral and anterior-posterior patterning systems.4 We demonstrate that fluctuating asymmetries in this rapid convergent-extension process are attenuated in normal embryos over time, possibly through noise-dissipating forces from the posterior midgut invagination and movement. However, when Torso signaling is attenuated via mutation of Trunk or RNAi directed against downstream Ras/ERK pathway components, body axis elongation results in a characteristic corkscrew phenotype,5 which reflects dramatic reorganization of global tissue flow and is incompatible with viability. Our results reveal a new function downstream of the Drosophila terminal patterning system in potentially active control of bilateral symmetry and should motivate systematic search for similar symmetry-preserving regulatory mechanisms in other bilaterians.",https://doi.org/10.1016/j.cub.2023.07.050,https://www.sciencedirect.com/science/article/pii/S0960982223009892,,,,2023,Maintaining symmetry during body axis elongation,Celia M. Smits and Sayantan Dutta and Vishank Jain-Sharma and Sebastian J. Streichan and Stanislav Y. Shvartsman,article,SMITS20233536,Current Biology,16,33,0960-9822,,,
,"Fake news, Inconsistency graph, Energy flow",101985,,"Recently, the term “fake news” has been broadly and extensively utilized for disinformation, misinformation, hoaxes, propaganda, satire, rumors, click-bait, and junk news. It has become a serious problem around the world. We present a new system, FaNDS, that detects fake news efficiently. The system is based on several concepts used in some previous works but in a different context. There are two main concepts: an Inconsistency Graph and Energy Flow. The Inconsistency Graph contains news items as nodes and inconsistent opinions between them for edges. Energy Flow assigns each node an initial energy and then some energy is propagated along the edges until the energy distribution on all nodes converges. To illustrate FaNDS we use the original data from the Fake News Challenge (FNC-1). First, the data has to be reconstructed in order to generate the Inconsistency Graph. The graph contains various subgraphs with well-defined shapes that represent different types of connections between the news items. Then the Energy Flow method is applied. The nodes with high energy are the candidates for being fake news. In our experiments, all these were indeed fake news as we checked each using several reliable web sites. We compared FaNDS to several other fake news detection methods and found it to be more sensitive in discovering fake news items.",https://doi.org/10.1016/j.datak.2022.101985,https://www.sciencedirect.com/science/article/pii/S0169023X22000040,,,,2022,FaNDS: Fake News Detection System using energy flow,Jiawei Xu and Vladimir Zadorozhny and Danchen Zhang and John Grant,article,XU2022101985,Data & Knowledge Engineering,,139,0169-023X,,,
,"Jargons identification, Information security, Feature engineering, Word embedding, Transfer learning, Vectors projection",103033,,"When cybercriminals communicate with their customers in underground markets, they tend to use secure and customizable instant messaging (IM) software, i.e. Telegram. It is a popular IM software with over 700 million monthly active users (MAU) up to June 2022. In recent years, more and more dark jargons (i.e. an innocent-looking replacement of sensitive terms) appear frequently on Telegram. Therefore, jargons identification is one of the most significant research perspectives to track online underground markets and cybercrimes. This paper proposes a novel Chinese Jargons Identification Framework (CJI-Framework) to identify dark jargons. Firstly, we collect chat history from Telegram groups that are related to the underground market and construct the corpus TUMCC (Telegram Underground Market Chinese Corpus), which is the first Chinese corpus in jargons identification research field. Secondly, we extract seven brand-new features which can be classified into three categories: Vectors-based Features (VF), Lexical analysis-based Features (LF), and Dictionary analysis-based Features (DF), to identify Chinese dark jargons from commonly-used words. Based on these features, we then run a statistical outlier detection to decide whether a word is a jargon. Furthermore, we employ a word vector projection method and a transfer learning method to improve the effect of the framework. Experimental results show that CJI-Framework achieves a remarkable performance with an F1-score of 89.66%. After adaptation for English, it performs better than state-of-the-art English jargons identification method as well. Our built corpus and code have been publicly released to facilitate the reproduction and extension of our work.",https://doi.org/10.1016/j.ipm.2022.103033,https://www.sciencedirect.com/science/article/pii/S030645732200142X,,,,2022,Identification of Chinese dark jargons in Telegram underground markets using context-oriented and linguistic features,Yiwei Hou and Hailin Wang and Haizhou Wang,article,HOU2022103033,Information Processing & Management,5,59,0306-4573,,,
,"Domain Generation Algorithm, Command, Control server, Network Security, Machine Learning",403-412,,"Command and control(C&C) servers are being more frequently used in cyberattacks in recent years. A malware-infected machine is controlled and directed by an attacker using a command-and-control server in order to steal data from the network. To hide their servers, attackers commonly employ a domain generation algorithm that generates domain names for them by concatenating words from word lists. Some of the algorithmically-generated domain names are used to connect to the C&C server. With the emergence of sophisticated domain generation algorithms, detecting such domains has become a challenge, which in turn poses a severe danger to computer networks. In this paper, we are proposing a concept called centrality, which is used as one of the features to analyze the words in the domain names generated by the domain generation algorithm malware. For classification, we are using Naïve Bayes, KNN, SVM, Decision Trees, Random Forest and logistic regression. Experimental results showed that Random Forest gave the highest classification accuracy rate of 88.64% and Naive Bayes gave the lowest accuracy of 44.32%.",https://doi.org/10.1016/j.procs.2022.12.042,https://www.sciencedirect.com/science/article/pii/S1877050922021135,,,,2022,A model to detect domain names generated by DGA malware,T Divya and P.P Amritha and Sangeetha Viswanathan,article,DIVYA2022403,Procedia Computer Science,,215,1877-0509,4th International Conference on Innovative Data Communication Technology and Application,,
,"COVID-19, Digital health, Audio processing, Computational paralinguistics",108289,,"The Coronavirus (COVID-19) pandemic impelled several research efforts, from collecting COVID-19 patients’ data to screening them for virus detection. Some COVID-19 symptoms are related to the functioning of the respiratory system that influences speech production; this suggests research on identifying markers of COVID-19 in speech and other human generated audio signals. In this article, we give an overview of research on human audio signals using ‘Artificial Intelligence’ techniques to screen, diagnose, monitor, and spread the awareness about COVID-19. This overview will be useful for developing automated systems that can help in the context of COVID-19, using non-obtrusive and easy to use bio-signals conveyed in human non-speech and speech audio productions.",https://doi.org/10.1016/j.patcog.2021.108289,https://www.sciencedirect.com/science/article/pii/S0031320321004696,,,,2022,AI-Based human audio processing for COVID-19: A comprehensive overview,Gauri Deshpande and Anton Batliner and Björn W. Schuller,article,DESHPANDE2022108289,Pattern Recognition,,122,0031-3203,,,
,"Open source MATLAB/GNU Octave, Discontinuous Galerkin method, Vectorization, Coupled modeling, Shallow–water equations, Cahn–Hilliard equation",3-41,,"The present work documents the current state of development for our MATLAB/GNU Octave-based open source toolbox FESTUNG (Finite Element Simulation Toolbox for UNstructured Grids). The goal of this project is to design a user-friendly, research-oriented, yet computationally efficient software tool for solving partial differential equations (PDEs). Since the release of its first version, FESTUNG has been actively used for research and teaching purposes such as the design of novel algorithms and discretization schemes, benchmark studies, or just providing students with an easy-to-learn software package to study advanced numerical techniques and good programming practices. For spatial discretization, the package employs various discontinuous Galerkin (DG) methods, while different explicit, implicit, or semi-implicit Runge–Kutta schemes can be used for time stepping. The current publication discusses the most important aspects of our toolbox such as the code design concepts and various discretization procedures illustrated in some detail using a standard advection–diffusion–reaction equation. Moreover, we present selected applications already supported in FESTUNG including solvers for the two-dimensional shallow-water equations, the Cahn–Hilliard equation, and a coupled multi-physics model of free surface/subsurface flow.",https://doi.org/10.1016/j.camwa.2020.08.018,https://www.sciencedirect.com/science/article/pii/S0898122120303254,,,,2021,"FESTUNG 1.0: Overview, usage, and example applications of the MATLAB/GNU Octave toolbox for discontinuous Galerkin methods",Balthasar Reuter and Hennes Hajduk and Andreas Rupp and Florian Frank and Vadym Aizinger and Peter Knabner,article,REUTER20213,Computers & Mathematics with Applications,,81,0898-1221,Development and Application of Open-source Software for Problems with Numerical PDEs,,
,"DGA, Ensemble Learning, PRNG, Malware",1129-1136,,"Domain Generation Algorithms are the new source of mediators which will provide the attackers an intelligent way of avoiding detection at the host level. Typically, before the existence of DGA, the malware was having a hardcoded command and control (C&C) IP address. That hardcoded mechanism is prone to detection and thus how DGA came into existence. Domain Generation Algorithms use the traditional cryptographic principles of Pseudo-random number generators (PRNGs) to generate a list of domain names to which malware communicates. In this paper, we constructed a list of 44 features (lexical+statistical) from domain names and used the ensemble approaches like C5.0, Random Forest, Gradient Boosting and CART to classify DGA domain names. C5.0 stands out as the best one with an accuracy value of 0.9704.",https://doi.org/10.1016/j.procs.2020.04.121,https://www.sciencedirect.com/science/article/pii/S1877050920310991,,,,2020,An Ensemble Approach For Algorithmically Generated Domain Name Detection Using Statistical And Lexical Analysis,P. Mohan Anand and T. Gireesh Kumar and P.V. Sai Charan,article,ANAND20201129,Procedia Computer Science,,171,1877-0509,Third International Conference on Computing and Network Communications (CoCoNet'19),,
,"leader social media, Social media, Leadership, Twitter, Facebook",101580,,"The proliferation of digital data has opened the door for a 21st-century social science that explores human relationships on an unprecedented scale. A particular area of interest is that of leader social media (SM) usage. As studies on leader SM usage have grown dramatically in the past several years, we take stock of the extant literature across various research disciplines. Within this manuscript, we contextualize leader SM usage and demonstrate how it compares to analogous concepts. We subsequently abridge relevant findings and reflect on methodological and theoretical components of the research studies identified in this review. Further, we outline the nature of SM data and provide practical recommendations for leadership scholars to capitalize on this rich data source in their investigations. We also offer a theoretical framework and summary of how scholars have studied leader SM usage. Specifically, this review article synthesizes the current literature while also elevating the academic rigor of leader SM research.",https://doi.org/10.1016/j.leaqua.2021.101580,https://www.sciencedirect.com/science/article/pii/S1048984321000850,,,,2022,"Tweet, like, subscribe! Understanding leadership through social media use",Michael J. Matthews and Samuel H. Matthews and Dawei(David) Wang and Thomas K. Kelemen,article,MATTHEWS2022101580,The Leadership Quarterly,1,33,1048-9843,The Leadership Quarterly Yearly Review (LQYR) for 2022,,
,"Cybersecurity, Artificial intelligence, Machine learning, Deep learning, Cyber-threat, Botnets, Intrusion detection, Spam filtering, Encrypted traffic analysis",109032,,"As the number of Internet-connected systems rises, cyber analysts find it increasingly difficult to effectively monitor the produced volume of data, its velocity and diversity. Signature-based cybersecurity strategies are unlikely to achieve the required performance for detecting new attack vectors. Moreover, technological advances enable attackers to develop sophisticated attack strategies that can avoid detection by current security systems. As the cyber-threat landscape worsens, we need advanced tools and technologies to detect, investigate, and make quick decisions regarding emerging attacks and threats. Applications of artificial intelligence (AI) have the potential to analyze and automatically classify vast amounts of Internet traffic. AI-based solutions that automate the detection of attacks and tackle complex cybersecurity problems are gaining increasing attention. This paper comprehensively presents the promising applications of deep learning, a subfield of AI based on multiple layers of artificial neural networks, in a wide variety of security tasks. Before critically and comparatively surveying state-of-the-art solutions from the literature, we discuss the key characteristics of representative deep learning architectures employed in cybersecurity applications, we introduce the emerging trends in deep learning, and we provide an overview of necessary resources like a generic framework and suitable datasets. We identify the limitations of the reviewed works, and we bring forth a vision of the current challenges of the area, providing valuable insights and good practices for researchers and developers working on related problems. Finally, we uncover current pain points and outline directions for future research to address them.",https://doi.org/10.1016/j.comnet.2022.109032,https://www.sciencedirect.com/science/article/pii/S1389128622001864,,,,2022,"A survey on deep learning for cybersecurity: Progress, challenges, and opportunities",Mayra Macas and Chunming Wu and Walter Fuertes,article,MACAS2022109032,Computer Networks,,212,1389-1286,,,
,"Behavioral biometrics, Keystroke dynamics, Multi-user model, X-means",106982,,"In recent years, keystroke dynamics has gained popularity as a reliable means of verifying user identity in remote systems. Due to its high performance in verification and the fact that it does not require additional effort from the user, keystroke dynamics has become one of the most preferred second factor of authentication. Despite its prominence, it has one major limitation: keystroke dynamics algorithms are good at fitting a model to one user and one user only. When such algorithms try to fit a model to more than one user, the verification accuracy decreases dramatically. However, in real-world applications it is common practice for two or more users to use the same credentials, such as in shared bank accounts, shared social media profiles, and shared streaming licenses which allow multiple users in one account. In these cases, keystroke dynamics solutions become unreliable. To address this limitation, we propose a method that can leverage existing keystroke dynamics algorithms to automatically determine the number of users sharing the account and accurately support accounts that are shared with multiple users. We evaluate our method using eight state-of-the-art keystroke dynamics algorithms and three public datasets, with up to five different users in one model, achieving an average improvement in verification of 9.2% for the AUC and 8.6% for the EER in the multi-user cases, with just a negligible reduction of 0.2% for the AUC and 0.3% for the EER in the one-user cases.",https://doi.org/10.1016/j.knosys.2021.106982,https://www.sciencedirect.com/science/article/pii/S0950705121002458,,,,2021,Supporting unknown number of users in keystroke dynamics models,Itay Hazan and Oded Margalit and Lior Rokach,article,HAZAN2021106982,Knowledge-Based Systems,,221,0950-7051,,,
,"Bayesian inference, Hamiltonian Monte Carlo, Gaussian mixture models",25-30,,"This paper considers the problem of estimating linear dynamic system models when the observations are corrupted by random disturbances with nonstandard distributions. The paper is particularly motivated by applications where sensor imperfections involve significant contribution of outliers or wrap-around issues resulting in multi-modal distributions such as commonly encountered in robotics applications. As will be illustrated, these nonstandard measurement errors can dramatically compromise the effectiveness of standard estimation methods, while a computational Bayesian approach developed here is demonstrated to be equally effective as standard methods in standard measurement noise scenarios, but dramatically more effective in nonstandard measurement noise distribution scenarios.",https://doi.org/10.1016/j.ifacol.2018.09.085,https://www.sciencedirect.com/science/article/pii/S2405896318317452,,,,2018,"Sparse Bayesian ARX models with flexible noise distributions⁎⁎This work was supported by the Australian Research Council Discovery Project DP140104350. The EEG data was kindly provided by Eline Borch Petersen and Thomas Lunner at Eriksholm Research Centre, Oticon A/S, Denmark.",Johan Dahlin and Adrian Wills and Brett Ninness,article,DAHLIN201825,IFAC-PapersOnLine,15,51,2405-8963,18th IFAC Symposium on System Identification SYSID 2018,,
,"Machine learning, Cloud security, DDoS Attack, DoS attack, Industry 4.0, Early detection, Botnet, Feature transformation, Classification",107955,,"ABSTRACT
Recent advancements in artificial intelligence and machine learning technologies have laid the flagstone for the fourth industrial revolution, Industry 4.0. The industry 4.0 is at a very high momentum when compared to previous revolutions witnessed by humans in a way which was never anticipated. Cyber Physical Systems and Cloud computing are the basis for Industry 4.0. An ongoing research challenge in cloud computing is the immediate need to address security and data availability challenges coined in modern networking environments. For instance, DDoS attacks in cloud are continuously throwing new challenges to network community which makes detection of these attacks, an ongoing research challenge with respect to cloud security. At the outset, the research reported in this work has addressed three important contributions (i) A new gaussian based traffic attribute-pattern similarity function for evolutionary feature clustering to achieve feature transformation-based dimensionality reduction, (ii) A Gaussian based network traffic similarity function for similarity computation between network traffic instances and (iii) A machine learning model SWASTHIKA which uses feature transformation traffic for detection of low rate and high-rate network attacks. For experimental study, the most recent benchmark dataset namely IoT DoS and DDoS attack dataset available at IEEE Dataport is considered as this dataset has highly non-linear traffic instances which are like the real-world traffic. The performance evaluation of the proposed machine learning model SWASTHIKA is done by considering various classifier evaluation parameters such as accuracy, precision, detection rate, and F-Score. The experiment results proved that the attack detection rate of SWASTHIKA is significantly better compared to state of art machine learning classifiers.",https://doi.org/10.1016/j.compeleceng.2022.107955,https://www.sciencedirect.com/science/article/pii/S0045790622002324,,,,2022,A Feature Similarity Machine Learning Model for DDoS Attack Detection in Modern Network Environments for Industry 4.0,Swathi Sambangi and Lakshmeeswari Gondi and Shadi Aljawarneh,article,SAMBANGI2022107955,Computers and Electrical Engineering,,100,0045-7906,,,
,"Reconnaissance, OSINT, footprinting, DNS, human recon, whois",31-106,Penetration Tester's Open Source Toolkit (Fourth Edition),This chapter covers information gathering by focusing on reconnaissance and learning as much about a target as possible before you actually interact with it. This is typically a very stealthy part of penetration testing and is the first step in gathering the information that you need to move forward with testing.,https://doi.org/10.1016/B978-0-12-802149-1.00002-6,https://www.sciencedirect.com/science/article/pii/B9780128021491000026,Boston,Syngress,978-0-12-802149-1,2017,Chapter 2 - Reconnaissance,Jeremy Faircloth,incollection,FAIRCLOTH201731,,,,,,Jeremy Faircloth,Fourth Edition
,"IoT security, Markov-chain, Anomaly detection, Blockchain, Collaborative security",75-97,,"Due to their rapid growth and deployment, the Internet of things (IoT) have become a central aspect of our daily lives. Unfortunately, IoT devices tend to have many vulnerabilities which can be exploited by an attacker. Unsupervised techniques, such as anomaly detection, can be used to secure these devices in a plug-and-protect manner. However, anomaly detection models must be trained for a long time in order to capture all benign behaviors. Furthermore, the anomaly detection model is vulnerable to adversarial attacks since, during the training phase, all observations are assumed to be benign. In this paper, we propose (1) a novel approach for anomaly detection and (2) a lightweight framework that utilizes the blockchain to ensemble an anomaly detection model in a distributed environment. Blockchain framework incrementally updates a trusted anomaly detection model via self-attestation and consensus among the IoT devices. We evaluate our method on a distributed IoT simulation platform, which consists of 48 Raspberry Pis. The simulation demonstrates how the approach can enhance the security of each device and the security of the network as a whole.",https://doi.org/10.1016/j.jpdc.2020.06.008,https://www.sciencedirect.com/science/article/pii/S0743731520303154,,,,2020,Lightweight collaborative anomaly detection for the IoT using blockchain,Yisroel Mirsky and Tomer Golomb and Yuval Elovici,article,MIRSKY202075,Journal of Parallel and Distributed Computing,,145,0743-7315,,,
,"Lake temperature, Lake warming, Stratification, Mixing, Numerical model, Open source",125874,,"Lake temperature responses to climate forcing are of interest on account of the important linkages between water temperature and ecosystem processes. This paper describes a new 1-dimensional (1D) numerical model code and its application to investigations of multi-scale linkages between the vertical temperature structure and meteorological forcing. UCLAKE is implemented as highly portable open-source software, based on computationally efficient algorithms, and able to resolve sub-daily (e.g., hourly) dynamics while retaining the efficiency to simulate multi-decadal time scales. A UCLAKE model is calibrated and validated against thermistor profile time series for a small upland lake in North Wales, UK. Some of the challenges in 1D model calibration are explored and a sensitivity analysis reveals a dependence of optimal parameter set values on water column depth and time. An exploratory 52-year hindcast simulation demonstrates the computational efficiency of UCLAKE for multi-decadal studies of trends in lake temperature that vary with depth. A supplementary application of UCLAKE to Windermere, in the English Lake District, demonstrates its performance for larger and deeper lakes.",https://doi.org/10.1016/j.limno.2021.125874,https://www.sciencedirect.com/science/article/pii/S0075951121000268,,,,2021,Simulating seasonal to multi-decadal variation in lake thermal response to meteorological forcing using the UCLAKE 1-dimensional model code,Luis A. Morales-Marín and Jon R. French and Helene Burningham and Chris Evans and Annette Burden,article,MORALESMARIN2021125874,Limnologica,,88,0075-9511,,,
,"Unsupervised definition embeddings, Semantic features of glosses, Context words, Auto-encoding models, Natural language processing",111883,,"For both humans and machines to acquire vocabulary, it is effective to learn words from context while using dictionaries as an auxiliary tool. It has been shown in previous linguistic studies that for humans, glossing either target words to be learned or words comprising context is an effective approach. For machines, however, previous NLP studies are mainly focused on the former. In this paper, we investigate the potentiality of context words-glossed setting. During pre-training BERT, to infuse context words with semantic features of glosses, we propose DG embeddings — the unsupervised definition embeddings learned from dictionaries and glossaries. To employ unsupervised learning is inspired by a real-world scenario of dictionary use called headword search. This can also prevent a technical duplicate from happening, as learning words from context is already based on auto-encoding models with self-supervised learning. BERT-base is used for evaluation, and we refer to BERT-base with DG embeddings as DG-BERT. According to our experimental results, compared to the vanilla BERT, DG-BERT shows the following strengths: faster pre-training convergence, noticeable improvements on various downstream tasks, a better grasp of figurative semantics, more accurate self-attention for collocation of phrases, and higher sensitivity to context words for target-word predictions in psycholinguistic diagnostics.",https://doi.org/10.1016/j.knosys.2024.111883,https://www.sciencedirect.com/science/article/pii/S0950705124005173,,,,2024,DG Embeddings: The unsupervised definition embeddings learned from dictionary and glossary to gloss context words of Cloze task,Xiaodong Liu and Rafal Rzepka and Kenji Araki,article,LIU2024111883,Knowledge-Based Systems,,296,0950-7051,,,
,"Minimum description length, Short text messages, Semantic indexing, Text categorization, Machine learning",314-325,,"The popularity and reach of short text messages commonly used in electronic communication have led spammers to use them to propagate undesired content. This is often composed by misleading information, advertisements, viruses, and malwares that can be harmful and annoying to users. The dynamic nature of spam messages demands for knowledge-based systems with online learning and, therefore, the most traditional text categorization techniques can not be used. In this study, we introduce the MDLText, a text classifier based on the minimum description length principle, to the context of filtering undesired short text messages. The proposed approach supports incremental learning and, therefore, its predictive model is scalable and can adapt to continuously evolving spamming techniques. It is also fast, with computational cost increasing linearly with the number of samples and features, which is very desirable for expert systems applied to real-time electronic communication. In addition to the dynamic nature of these messages, they are also short and usually poorly written, rife with slangs, symbols, and abbreviations that difficult text representation, learning, and filtering. In this scenario, we also investigated the benefits of using text normalization and semantic indexing techniques. We showed these techniques can improve the text content quality and, consequently, enhance the performance of the expert systems for spamming detection. Based on these findings, we propose a new hybrid ensemble approach that combines the predictions obtained by the classifiers using the original text samples along with their variations created by applying text normalization and semantic indexing techniques. It has the advantages of being independent of the classification method and the results indicated it is efficient to filter undesired short text messages.",https://doi.org/10.1016/j.eswa.2017.04.055,https://www.sciencedirect.com/science/article/pii/S0957417417303056,,,,2017,Towards filtering undesired short text messages using an online learning approach with semantic indexing,Renato M. Silva and Tulio C. Alberto and Tiago A. Almeida and Akebo Yamakami,article,SILVA2017314,Expert Systems with Applications,,83,0957-4174,,,
,"Industrial megaprojects, Knowledge representation, Project analytics, Risk analysis, Ontology, Semantic web",101164,,"The fourth industrial revolution has affected most industries, including construction and those within the delivery chain of megaprojects. These major paradigm shifts, however, did not considerably improve the track record in predicting project outcomes and estimating required resources. One reason is the lack of unified data definitions and expandable knowledge representation across project lifecycle to represent megaprojects for analytics. This paper proposes and evaluates a unified ontology for project knowledge representation that facilitates data collection, processing, and utilization for industrial megaprojects through their lifecycle. The proposed Uniform Project Ontology, or UPonto, provides a data infrastructure for project analytics by enabling logical deductions and inferences, and flexible expansion and partitioning of the data utilizing linked data and the semantic web. The ontology facilitates cost normalization processes, temporal queries, and graph queries using SPARQL, while defining universal semantics for a wide range of project risk factors and characteristics based on comprehensive research of the empirical project risk and success literature augmented by practical considerations gained through expert consultations. UPonto forms the basis for a project knowledge graph to utilize unstructured data; it as well provides semantic definitions for smart IoT agents to consume project risk data and knowledge.",https://doi.org/10.1016/j.aei.2020.101164,https://www.sciencedirect.com/science/article/pii/S147403462030135X,,,,2020,Ontology-based knowledge representation for industrial megaprojects analytics using linked data and the semantic web,Pouya Zangeneh and Brenda McCabe,article,ZANGENEH2020101164,Advanced Engineering Informatics,,46,1474-0346,,,
,"Cloud computing, Network intrusion detection system, Deep Neural Network, Genetic algorithm, Simulated Annealing Algorithm, CICIDS dataset 2017, NSL-KDD dataset, CIDDS-001 dataset",291-317,,"The appealing features of Cloud Computing continue to fuel its adoption and its integration in many sectors such industry, governments, education and entertainment. Nevertheless, uploading sensitive data to public cloud storage services poses security risks such as integrity, availability and confidentiality to organizations. Moreover, the open and distributed (decentralized) structure of the cloud has resulted this class of computing, prone to cyber attackers and intruders. Thereby, it is imperative to develop an anomaly network intrusion system to detect and prevent both inside and outside assaults in cloud environment with high detection precision and low false warnings. In this work, we propose an intelligent approach to build automatically an efficient and effective Deep Neural Network (DNN) based anomaly Network IDS using a hybrid optimization framework (IGASAA) based on Improved Genetic Algorithm (IGA) and Simulated Annealing Algorithm (SAA). The IDS resulted is called “MLIDS” (Machine Learning based Intrusion Detection System). Genetic Algorithm (GA) is improved through optimization strategies, namely Parallel Processing and Fitness Value Hashing, which reduce execution time, convergence time and save processing power. Moreover, SAA was incorporated to IGA with the aim to optimize its heuristic search. Our approach consists of using IGASAA in order to search the optimal or near-optimal combination of most relevant values of the parameters included in construction of DNN based IDS or impacting its performance, like feature selection, data normalization, architecture of DNN, activation function, learning rate and Momentum term, which ensure high detection rate, high accuracy and low false alarm rate. For simulation and validation of the proposed method, CloudSim 4.0 simulator platform and three benchmark IDS datasets were used, namely CICIDS2017, NSL-KDD version 2015 and CIDDS-001. The implementation results of our model demonstrate its ability to detect intrusions with high detection accuracy and low false alarm rate, and indicate its superiority in comparison with state-of-the-art methods.",https://doi.org/10.1016/j.cose.2019.06.013,https://www.sciencedirect.com/science/article/pii/S0167404819301221,,,,2019,Intelligent approach to build a Deep Neural Network based IDS for cloud environment using combination of machine learning algorithms,Zouhair Chiba and Noreddine Abghour and Khalid Moussaid and Amina {El omri} and Mohamed Rida,article,CHIBA2019291,Computers & Security,,86,0167-4048,,,
,"Dialogue act, Deep learning, LSTM, Word embeddings, Word2vec",175-193,,"Dialogue act recognition is an important component of a large number of natural language processing pipelines. Many research works have been carried out in this area, but relatively few investigate deep neural networks and word embeddings. This is surprising, given that both of these techniques have proven exceptionally good in most other language-related domains. We propose in this work a new deep neural network that explores recurrent models to capture word sequences within sentences, and further study the impact of pretrained word embeddings. We validate this model on three languages: English, French and Czech. The performance of the proposed approach is consistent across these languages and it is comparable to the state-of-the-art results in English. More importantly, we confirm that deep neural networks indeed outperform a Maximum Entropy classifier, which was expected. However, and this is more surprising, we also found that standard word2vec embeddings do not seem to bring valuable information for this task and the proposed model, whatever the size of the training corpus is. We thus further analyse the resulting embeddings and conclude that a possible explanation may be related to the mismatch between the type of lexical-semantic information captured by the word2vec embeddings, and the kind of relations between words that is the most useful for the dialogue act recognition task.",https://doi.org/10.1016/j.csl.2017.07.009,https://www.sciencedirect.com/science/article/pii/S0885230816300456,,,,2018,On the effects of using word2vec representations in neural networks for dialogue act recognition,Christophe Cerisara and Pavel Král and Ladislav Lenc,article,CERISARA2018175,Computer Speech & Language,,47,0885-2308,,,
,,100313,,,https://doi.org/10.1016/j.fsisyn.2022.100313,https://www.sciencedirect.com/science/article/pii/S2589871X22000985,,,,2023,Interpol review of digital evidence for 2019–2022,Paul Reedy,article,REEDY2023100313,Forensic Science International: Synergy,,6,2589-871X,,,
,"Neural network, MNIST, CIFAR10, Splitting, Nesterov, Dynamical system",178-190,,"In the following paper we present a new type of optimization algorithms adapted for neural network training. These algorithms are based upon sequential operator splitting technique for some associated dynamical systems. Furthermore, we investigate through numerical simulations the empirical rate of convergence of these iterative schemes toward a local minimum of the loss function, with some suitable choices of the underlying hyper-parameters. We validate the convergence of these optimizers using the results of the accuracy and of the loss function on the MNIST, MNIST-Fashion and CIFAR 10 classification datasets.",https://doi.org/10.1016/j.neunet.2020.03.018,https://www.sciencedirect.com/science/article/pii/S0893608020300952,,,,2020,New optimization algorithms for neural network training using operator splitting techniques,Cristian Daniel Alecsa and Titus Pinţa and Imre Boros,article,ALECSA2020178,Neural Networks,,126,0893-6080,,,
,"Digital media, Misinformation, Diffusion, Networks, Relational niche, COVID-19",103004,,"This study explores why some fake news publishers are able to propagate misinformation while others receive little attention on social media. Using COVID-19 vaccine tweets as a case study, this study combined the relational niche framework with pooled and multilevel models that address the unobserved heterogeneity. The results showed that, as expected, ties to accounts with more followers were associated with more fake news tweets, retweets, and likes. However, more surprisingly, embedding with fake news publishers had an inverted U-shaped association with diffusion, whereas social proximity to mainstream media was positively associated. Although the effect of influential users is in line with opinion leader theory, the newly-identified effects of social proximity to reliable sources and embeddedness suggest that the key to fake news virality is to earn greater organizational status and modest, not overly, echo chambers. This study highlights the potential of dynamic media networks to shape the misinformation market.",https://doi.org/10.1016/j.ssresearch.2024.103004,https://www.sciencedirect.com/science/article/pii/S0049089X24000267,,,,2024,Fake news virality: Relational niches and the diffusion of COVID-19 vaccine misinformation,Chen-Shuo Hong,article,HONG2024103004,Social Science Research,,120,0049-089X,,,
,"Semantic localisation, Indoor localisation, Patterns, Movements, Time-series, Pattern syntax, Mobility",101946,,"While UbiComp research has steadily improved the performance of localisation systems, the analysis of such datasets remains largely unaddressed. In this paper, we present a tool to facilitate querying and analysis of localisation time-series with a focus on semantic localisation. Drawing on well-established models to represent movement and mobility, we first develop a query language for localisation datasets. We then develop a software library in R that implements this querying. We use case studies to demonstrate how our programming tool can be used to query localisation datasets. Our work addresses an important gap in localisation research, by providing a flexible tool that can model and analyse localisation data programmatically and in real time.",https://doi.org/10.1016/j.pmcj.2024.101946,https://www.sciencedirect.com/science/article/pii/S1574119224000725,,,,2024,A toolkit for localisation queries,Gabriele Marini and Jorge Goncalves and Eduardo Velloso and Raja Jurdak and Vassilis Kostakos,article,MARINI2024101946,Pervasive and Mobile Computing,,103,1574-1192,,,
Translational and Applied Genomics,"Reproducibility, Replication, Rigor, Genomic research, Experimental methodology, Ethical legal social implications, ELSI, Data availability, Open science",3-22,Rigor and Reproducibility in Genetics and Genomics,"The scientific method is the fundamental framework used to make observations, identify and address unanswered questions, and interpret outcomes against the context of existing knowledge and predictions. As scientific investigations become increasingly complex and are conducted with rapidly evolving technologies, a high degree of rigor is necessary to develop and conduct experiments while also ensuring the ability to reliably reproduce results. This introductory chapter provides a brief overview of the scientific method and highlights the challenges of rigor and reproducibility in present-day genetic and biomedical research. Furthermore, this chapter demonstrates how these challenges have impacted public discourse and trust in scientific—particularly biomedical—research. Finally, suggestions for addressing these challenges are presented, including the use of “open science” to redefine research parameters and encourage collaboration.",https://doi.org/10.1016/B978-0-12-817218-6.00012-7,https://www.sciencedirect.com/science/article/pii/B9780128172186000127,,Academic Press,978-0-12-817218-6,2024,Chapter 1 - Rigor and reproducibility in genetic research and the effects on scientific reporting and public discourse,Monika H.M. Schmidt and Douglas F. Dluzen,incollection,SCHMIDT20243,,,,,,Douglas F. Dluzen and Monika H.M. Schmidt,
,"Malware Analysis, Malware Persistence, Incident Response",88-97,,"In the public imagination Cybersecurity is very much about malware, even though malware constitutes only part of all the threats faced by Cybersecurity experts. However, malware is still one of the best methods to gain persistent access and control of a target system. Malware is often combined with a well socially-engineered phishing attack that deceives a user to gain a foothold on a system. Once the attakcer gains a beachhead in the victim’s network, it may be used to download additional payloads and exploit vulnerabilities, to gain more control and access within a network. Using malware as their foothold, attackers are able to to conduct reconnaissance, gather intelligence (e.g., exfiltration of intellectual property) or simply inflict damage or extortion (e.g., ransomware). All of this has to be done in a way that allows an attacker to retain access for as long as possible; the ability to do so is called persistence, and this paper examines the different techniques used by malware to accomplish persistence in an ever evolving landscape.",https://doi.org/10.1016/j.procs.2020.08.010,https://www.sciencedirect.com/science/article/pii/S1877050920318342,,,,2020,Malware Persistence Mechanisms,Zane Gittins and Michael Soltys,article,GITTINS202088,Procedia Computer Science,,176,1877-0509,Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 24th International Conference KES2020,,
,"Co-oriented Scansis (CoS) model, Crisis communication, Situational Crisis Communication Theory (SCCT), AI crisis, Scansis, Moral outrage",102360,,"This study presents the Co-oriented Scansis (CoS) model, which provides a comprehensive understanding of scansis—a recently identified crisis type integrated into the Situational Crisis Communication Theory (SCCT). Using a crisis case of Scatter Lab, a South Korean AI company, as a model case, the study applies the CoS model to analyze the perceptions and meta-perceptions of both the organization and the public regarding the crisis. The data collection involved three official statements released by Scatter Lab and an analysis of 365 reviews from the Google Play users' reviews page of Science of Love—the app used by Scatter Lab to collect intimate conversations between romantic partners. The findings highlight the utility of the CoS model in explaining how Scatter Lab's AI crisis evolved into a scansis. Specifically, the organization's failure to accurately comprehend the public's perception of the crisis (second level co-orientation) and the resulting discrepancy between the organization and the public's perceptions (third level co-orientation) contributed to moral outrage, ultimately leading to a scansis. The study concludes by discussing the theoretical contributions of the CoS model and its practical implications for crisis management.",https://doi.org/10.1016/j.pubrev.2023.102360,https://www.sciencedirect.com/science/article/pii/S0363811123000759,,,,2023,"Introducing the Co-oriented Scansis (CoS) model: A case of chatbot, Lee-Luda",Heesoo Jang and Suman Lee,article,JANG2023102360,Public Relations Review,4,49,0363-8111,,,
,"Web of Things, Internet of Things, Web of Things Discovery, Semantic Interoperability, Semantic Web, Ontology",997-1006,,"Buildings are the largest energy consumers in Europe and are responsible for approximately 40% of EU energy consumption and 36% of the greenhouse gas emissions in Europe. Two-thirds of the building consumption is for residential buildings. To achieve energy efficiency, buildings are being integrated with IoT devices through the use of smart IoT services. For instance, a smart space heating service reduces energy consumption by dynamically heating apartments based on indoor and outdoor temperatures. The W3C recommends the use of the Web of Things (WoT) standard to enable IoT interoperability on the Web. However, in the context of a smart building, the ability to search and discover building metadata and IoT devices available in the WoT ecosystems remains a challenge due to the limitation of the current WoT Discovery, which only includes a directory containing only IoT devices metadata without including building metadata. Integrating the IoT device's metadata with building metadata in the same directory can provide better discovery capabilities to the IoT services providers. In this paper, we integrate building metadata into the W3C WoT Discovery through the construction of a Building Description JSON-LD file. This Building Description is integrated into the W3C WoT Discovery and based on the domOS Common Ontology (dCO) to achieve semantic interoperability in smart residential buildings for the WoT IoT ecosystem within the Horizon 2020 domOS project. This integration results in a Thing and Building Description Directory. dCO integrates the SAREF core ontology with the Thing Description ontology, devices, and building metadata. We have implemented and validated the WoT discovery on top of a WoT Thing and Building Description Directory. The WoT Discovery implementation is also made available for the WoT community.",https://doi.org/10.1016/j.procs.2022.09.155,https://www.sciencedirect.com/science/article/pii/S1877050922010377,,,,2022,Web of Things Semantic Interoperability in Smart Buildings,Amir Laadhar and Junior Dongo and Søren Enevoldsen and Frédéric Revaz and Dominique Gabioud and Torben Bach Pedersen and Martin Meyer and Brian Nielsen and Christian Thomsen,article,LAADHAR2022997,Procedia Computer Science,,207,1877-0509,Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 26th International Conference KES2022,,
,"IoT, BOTNET, RNN, Bi-GRU, SMIE",103064,,"The botnet have developed into a severe risk to Internet of Things (IoT) systems as a result of manufacturers ‘insufficient security policies and end users’ lack of security awareness. By default, several ports are open and user credentials are left unmodified. ML and DL strategies have been suggested in numerous latest research for identifying and categorising botnet assaults in the IoT context, but still, it has a few issues like high error susceptibility, working only with a large amount of data, poor quality, and data acquisition. This research provided use of a brand-new IoT botnet detector built on an improved hybrid classifier. The proposed work's main components are ""pre-processing, feature extraction, feature selection, and attack detection."" Following that, the improved Information Gain (IIG) model is used to choose the most reliable characteristics from the received information. To detect an attack, a hybrid classifier is utilized which can be constructed by integrating the optimized Bi-GRU with the Recurrent Neural Network (RNN). To increase the detection accuracy of IoT-BOTNETS, a novel hybrid optimization approach called SMIE (Slime Mould with Immunity Evolution) is created by conceptually integrating two conventional optimization modes: Coronavirus herd immunity optimizer (CHIO) and the Slime mould algorithm. The final output of the hybrid classifier displays the presence or absence of IoT-BOTNET attacks. The projected model's accuracy is 97%, which is 22.6%, 18.5%, 27.8%, 22.6%, and 24.8% higher than the previous models like GWO+ HC, SSO+ HC, WOA+ HC, SMA+ HC, and CHIO+ HC, respectively.",https://doi.org/10.1016/j.cose.2022.103064,https://www.sciencedirect.com/science/article/pii/S0167404822004564,,,,2023,Intelligent IoT-BOTNET attack detection model with optimized hybrid classification model,Balaganesh Bojarajulu and Sarvesh Tanwar and Thipendra Pal Singh,article,BOJARAJULU2023103064,Computers & Security,,126,0167-4048,,,
,"Natural Language Generation, Human evaluation, Recommendations, Literature review, Open science, Ethics",101151,,"Currently, there is little agreement as to how Natural Language Generation (NLG) systems should be evaluated, with a particularly high degree of variation in the way that human evaluation is carried out. This paper provides an overview of how (mostly intrinsic) human evaluation is currently conducted and presents a set of best practices, grounded in the literature. These best practices are also linked to the stages that researchers go through when conducting an evaluation research (planning stage; execution and release stage), and the specific steps in these stages. With this paper, we hope to contribute to the quality and consistency of human evaluations in NLG.",https://doi.org/10.1016/j.csl.2020.101151,https://www.sciencedirect.com/science/article/pii/S088523082030084X,,,,2021,Human evaluation of automatically generated text: Current trends and best practice guidelines,Chris {van der Lee} and Albert Gatt and Emiel {van Miltenburg} and Emiel Krahmer,article,VANDERLEE2021101151,Computer Speech & Language,,67,0885-2308,,,
,"Automotive engine, Multi-stage hybrid algorithm, Assembly line configuration, Process sequence",13-26,,"Engines are the most expensive and technology-intensive components in automobiles, so an optimized configuration of the automotive engine assembly line (AEAL) is anticipated to improve efficiency and reduce cost. The traditional methods for assembly line configuration can mainly work out a proper machine number, but they generally ignore process sequences that could also influence the buffer cost derived from the assignment of divergence and confluence buffers. Simultaneously, how to reduce the number of variables in the algorithm iteration process to improve computational efficiency is rarely considered in the existing studies. To bridge the gaps, this study proposes a multi-stage hybrid algorithm based on a backtracking searching algorithm (BSA) to realize an effective configuration that can further improve production efficiency and reduce equipment cost for sequence-dependent AEALs. First, an AEAL configuration model is developed to involve machine number and process sequence as decision variables and aims to satisfy multiple objectives concerned with equipment cost and cycle time. Then, a multi-stage hybrid algorithm is proposed to efficiently acquire the optimal solutions to machine number and process sequence in multiple stages that can improve computational efficiency. Finally, the effectiveness and superiority of the proposed method are validated via a case study. The numerical results show that the proposed method can effectively improve production efficiency and reduce equipment cost for sequence-dependent AEALs with a better convergence and diversity performance.",https://doi.org/10.1016/j.jmsy.2022.11.014,https://www.sciencedirect.com/science/article/pii/S0278612522002059,,,,2023,Multi-stage hybrid algorithm-enabled optimization of sequence-dependent assembly line configuration for automotive engine,Miao Yang and Congbo Li and Ying Tang and Wei Wu and Yan Lv,article,YANG202313,Journal of Manufacturing Systems,,66,0278-6125,,,
,"Cybersecurity, Deep learning, Adversarial machine learning, Cyber threats, Adversarial examples",122223,,"Over the last few years, the adoption of machine learning in a wide range of domains has been remarkable. Deep learning, in particular, has been extensively used to drive applications and services in specializations such as computer vision, natural language processing, machine translation, and cybersecurity, producing results that are comparable to or even surpass the performance of human experts. Nevertheless, machine learning systems are vulnerable to adversarial attacks, especially in nonstationary environments where actual adversaries exist, such as the cybersecurity domain. In this work, we comprehensively survey and present the latest research on attacks based on adversarial examples against deep learning-based cybersecurity systems, highlighting the risks they pose and promoting efficient countermeasures. To that end, adversarial attack methods are first categorized according to where they occur and the attacker’s goals and capabilities. Then, specific attacks based on adversarial examples and the respective defensive methods are reviewed in detail within the framework of eight principal cybersecurity application categories. Finally, the main trends in recent research are outlined, and the impact of recent advancements in adversarial machine learning is explored to provide guidelines and directions for future research in cybersecurity. In summary, this work is the first to systematically analyze adversarial example-based attacks in the cybersecurity field, discuss possible defenses, and highlight promising directions for future research.",https://doi.org/10.1016/j.eswa.2023.122223,https://www.sciencedirect.com/science/article/pii/S0957417423027252,,,,2024,Adversarial examples: A survey of attacks and defenses in deep learning-enabled cybersecurity systems,Mayra Macas and Chunming Wu and Walter Fuertes,article,MACAS2024122223,Expert Systems with Applications,,238,0957-4174,,,
,"Abtract Syntax Tree (AST), Tree-based convolutional neural networks(TBCNN), Support Vector Machines (SVMs), K-Nearest Neighbors (kNN)",12-25,,"Analyzing source code to solve software engineering problems such as fault prediction, cost, and effort estimation always receives attention of researchers as well as companies. The traditional approaches are based on machine learning, and software metrics obtained by computing standard measures of software projects. However, these methods have faced many challenges due to limitations of using software metrics which were not enough to capture the complexity of programs. To overcome the limitations, this paper aims to solve software engineering problems by exploring information of programs' abstract syntax trees (ASTs) instead of software metrics. We propose two combination models between a tree-based convolutional neural network (TBCNN) and k-Nearest Neighbors (kNN), support vector machines (SVMs) to exploit both structural and semantic ASTs' information. In addition, to deal with high-dimensional data of ASTs, we present several pruning tree techniques which not only reduce the complexity of data but also enhance the performance of classifiers in terms of computational time and accuracy. We survey many machine learning algorithms on different types of program representations including software metrics, sequences, and tree structures. The approaches are evaluated based on classifying 52000 programs written in C language into 104 target labels. The experiments show that the tree-based classifiers dramatically achieve high performance in comparison with those of metrics-based or sequences-based; and two proposed models TBCNN + SVM and TBCNN + kNN rank as the top and the second classifiers. Pruning redundant AST branches leads to not only a substantial reduction in execution time but also an increase in accuracy.",https://doi.org/10.1016/j.datak.2017.07.003,https://www.sciencedirect.com/science/article/pii/S0169023X17300344,,,,2018,Automatically classifying source code using tree-based approaches,Anh Viet Phan and Phuong Ngoc Chau and Minh Le Nguyen and Lam Thu Bui,article,PHAN201812,Data & Knowledge Engineering,,114,0169-023X,Special Issue on Knowledge and Systems Engineering (KSE 2016),,
,"Altmetrics, PlumX, Citations, Readers, Tweets, Longitudinal study",579-589,,"The main objective of this study is to describe the life cycle of altmetric and bibliometric indicators in a sample of publications. Altmetrics (Downloads, Views, Readers, Tweets, and Blog mentions) and bibliometric counts (Citations) (in this study, the indicators will be capitalized to differentiate them from the general language) of 5185 publications (19,186 observations) were extracted from PlumX to observe their distribution according to the publication age. Correlations between these metrics were calculated from month to month to observe the evolution of these relationships. The results showed that mention metrics (Tweets and Blog mentions) are the earliest metrics that become available most quickly and have the shortest life cycle. Next, Readers are the metrics with the highest prevalence and with the second fastest growth. Views and Downloads show a continuous growth, being the indicators with the longest life cycles. Finally, Citations are the slowest indicators and have a low prevalence. Correlations show a strong relationship between mention metrics and Readers and Downloads, and between Readers and Citations. These results enable us to create a schematic diagram of the relationships between these metrics from a longitudinal view.",https://doi.org/10.1016/j.joi.2018.06.001,https://www.sciencedirect.com/science/article/pii/S1751157717302870,,,,2018,The life cycle of altmetric impact: A longitudinal study of six metrics from PlumX,José Luis Ortega,article,ORTEGA2018579,Journal of Informetrics,3,12,1751-1577,,,
,"New materialism, Distant reading, Computerized text analysis, Video games, Blizzard, Copypasta, Memes",102725,,"In 2019, video game giant Blizzard banned a competitive e-sports player who made a pro-Hong Kong statement during a post-game interview. The international game community responded with outrage, organizing both on- and offline actions to provoke change within the organization. This article examines the #BoycottBlizzard gaming counterpublic via deceptively discrete mixed methods: a new materialist investigation of protest gear and a distant reading of a Reddit dataset of 3500 posts between October 7 and 10, 2019. The investigation concludes that gas masks demonstrate nonhuman aleatory agency in the #BoycottBlizzard protest movement, by inserting subversive subtext into costumes and gameplay. Online, protestors relied heavily on other resistance tactics, including using Twitch copypasta spam; this article suggests this form of resistance functions similarly to a sit-in. Finally, the article iconographically tracks the rise and dissemination of a particular meme image representing the movement's appointed mascot, a Chinese climatologist named Mei. Ultimately, the Blitzchung counterpublic achieved only modest success; the player's ban was reversed and his prize money reinstated, but many protestors considered Blizzard's response milquetoast. However, this analysis proposes that the Blitzchung counterpublic likely emboldened the 2021 #BoycottBlizzard movement and may in some measure be responsible for its success.",https://doi.org/10.1016/j.compcom.2022.102725,https://www.sciencedirect.com/science/article/pii/S8755461522000330,,,,2022,"“Our world is worth fighting for”: Gas mask agency, copypasta sit-ins, and the material-discursive practices of the Blitzchung controversy",Elizabeth F. Chamberlain,article,CHAMBERLAIN2022102725,Computers and Composition,,65,8755-4615,,,
,"Feature-based malicious website detection, Web security, Supervised learning, Feature selection",102374,,"Website features and characteristics have shown the ability to detect various web threats – phishing, drive-by downloads, and command and control (C2). Prior research has thoroughly explored the practice of choosing features ahead of time (a priori) and building detection models. However, there is an opportunity to investigate new techniques and features for detection. We perform a comprehensive evaluation of discovering features for malicious website detection versus selecting features a priori. We gather 46,580 features derived from a response to a web request and, through a series of feature selection techniques, discover features for detection and compare their performance to those used in prior research. We build several detection models using unsupervised and supervised learning algorithms over various sampling and feature transformation scenarios. Our approach is evaluated on a diverse dataset composed of common threats on the internet. Overall, we find that discovered features can achieve more efficient and comparable detection performance to a priori features with 66% fewer features and can achieve a Matthews Correlation Coefficient (MCC) of up to 0.9008.",https://doi.org/10.1016/j.cose.2021.102374,https://www.sciencedirect.com/science/article/pii/S016740482100198X,,,,2021,Discovering features for detecting malicious websites: An empirical study,John McGahagan and Darshan Bhansali and Ciro Pinto-Coelho and Michel Cukier,article,MCGAHAGAN2021102374,Computers & Security,,109,0167-4048,,,
,,551-595,CISSP® Study Guide (Fourth Edition),,https://doi.org/10.1016/B978-0-443-18734-6.00010-6,https://www.sciencedirect.com/science/article/pii/B9780443187346000106,,Syngress,978-0-443-18734-6,2023,,,incollection,2023551,,,,,,Eric Conrad and Seth Misenar and Joshua Feldman,Fourth Edition
Handbook of Powder Technology,,52-82,Particle Size Enlargement,,https://doi.org/10.1016/B978-1-4832-5666-5.50008-6,https://www.sciencedirect.com/science/article/pii/B9781483256665500086,,Elsevier Science B.V.,,1980,Chapter 3 - Agitation Methods – Tumbling Agglomeration,,incollection,198052,,,1,0167-3785,,C.E. CAPES,
,,I-CLXXXII,,,https://doi.org/10.1016/S2213-1779(24)00488-8,https://www.sciencedirect.com/science/article/pii/S2213177924004888,,,,2024,Full issue PDF,,article,2024I,JACC: Heart Failure,7,12,2213-1779,,,
,,577-614,,,https://doi.org/10.1016/S0002-7138(09)61691-5,https://www.sciencedirect.com/science/article/pii/S0002713809616915,,,,1967,With Suggestions for a Correlation of Psychic and Hormonal Organizations: PART II PREPUBERTY DIFFUSION AND REINTEGRATION,Judith S. Kestenberg,article,KESTENBERG1967577,Journal of the American Academy of Child Psychiatry,4,6,0002-7138,,,
,,12-49,,Results are presented of differential cross-section measurements for the reaction π−p→π0n;π0→γγ at 22 incident pion momenta between 618 and 2724 MeV/c. The results are in good agreement with those of other experiments. They represent the first comprehensive set of high statistics measurements of the π−p charge-exchange differential cross section at closely spaced momenta in the resonance region.,https://doi.org/10.1016/0550-3213(76)90562-9,https://www.sciencedirect.com/science/article/pii/0550321376905629,,,,1976,Differential cross-section measurements in π−p charge exchange scattering from 620 to 2730 MeV/c,R.M. Brown and A.G. Clark and P.J. Duke and W.M. Evans and R.J. Gray and E.S. Groves and R.J. Ott and H.R. Renshall and T.P. Shah and A.J. Shave and J.J. Thresher and M.W. Tyrrell,article,BROWN197612,Nuclear Physics B,1,117,0550-3213,,,
,,110-132,,"A series of time-dependent radiative/convective models are presented for the atmosphere of Uranus. The effects of atmospheric dynamics have been omitted from the models. The inclination of the pole of rotation to the pole of the orbit, approximately 90°, produces large seasonal changes in the insolation. Because of the relatively small flow of heat from the interior, these seasonal changes cause the effective temperature, which is about 60°K, to vary through the 84-year orbital period by ∼5°K at the poles, ∼4°K at ±60° latitude, ∼2°K at ±30° latitude, and ∼0.5°K at the equator. For a particular latitude, the minimum effective temperature and the maximum convective flow of heat from the interior occur near the end of the period when the sun remains below the horizon during the Uranian day. If the methane mixing ratio is not limited by its saturated vapor pressure (SVP) in the convective region, the maximum convective flow would be a few times the orbital average convective flow and persist for an interval of several years. On the other hand, if the methane mixing ratio is limited by its SVP in the convective regions, the maximum convective flow could be orders of magnitude greater than the orbital average and could persist for less than an hour. If the orbital mean internal heat flow is negligible, the difference in effective temperatures between 30 and 60° latitude would be in the range 2 to 4°K. If the internal heat is taken to be about the maximum allowable and is assumed to be redistributed in the interior in a manner to compensate for the minimum in insolation at low latitudes, the corresponding temperature difference would be in the range 12 to 2°K. In either case, the existing theory of atmospheric dynamics for the outer planets indicates that such large temperature differences will drive large-scale motions which would in turn reduce these temperature differences.",https://doi.org/10.1016/0019-1035(83)90073-8,https://www.sciencedirect.com/science/article/pii/0019103583900738,,,,1983,The seasonal variation of the thermal structure of the atmosphere of Uranus,L. Wallace,article,WALLACE1983110,Icarus,1,54,0019-1035,,,
,,223-246,,,https://doi.org/10.1016/S1567-5688(10)71060-6,https://www.sciencedirect.com/science/article/pii/S1567568810710606,,,,2010,Author Index,,article,2010223,Atherosclerosis Supplements,2,11,1567-5688,Abstracts of the 78th EAS Congress,,
Methods in Immunology and Immunochemistry,,411-427,"Agglutination, Complement, Neutralization, and Inhibition",,https://doi.org/10.1016/B978-0-12-754404-5.50012-6,https://www.sciencedirect.com/science/article/pii/B9780127544045500126,,Academic Press,,1977,Author Index,,incollection,1977411,,,4,00766917,,CURTIS A. WILLIAMS and MERRILL W. CHASE,
,,263-281,,"We present a type checking algorithm for establishing a session-based discipline in a π-calculus with name matching. We account for analysing processes exhibiting different behaviours in the branches of the if-then-else by imposing an affine discipline for session types. This permits to obtain type-safety or absence of communication errors while accepting processes of the form if x=y then P else 0 that install a session protocol P whenever the test succeeds, and abort otherwise. To this aim we define a type system based on a notion of context split, and we prove that it satisfies subject reduction and type-safety. We implement the type system in a split-free type checking algorithm, and we prove that processes accepted by the algorithm are well-typed. We then show that processes that are typed and do not contain Wait for deadlocks – an input and its corresponding output (or vice versa) are in the same thread instead of in parallel ones – are accepted by the algorithm, thus providing a partial completeness result. We conclude by investigating the expressiveness of the typing system and show that our theory subsumes recent works on linear and session types.",https://doi.org/10.1016/j.jlap.2013.05.003,https://www.sciencedirect.com/science/article/pii/S156783261300026X,,,,2013,Algorithmic type checking for a pi-calculus with name matching and session types,Marco Giunti,article,GIUNTI2013263,The Journal of Logic and Algebraic Programming,8,82,1567-8326,Automated Specification and Verification of Web Systems,,
,,220-272,Selected Papers in Molecular Biology by Jacques Monod,,https://doi.org/10.1016/B978-0-12-460482-7.50025-7,https://www.sciencedirect.com/science/article/pii/B9780124604827500257,,Academic Press,978-0-12-460482-7,1978,LA BIOSYNTHÈSE INDUITE DES ENZYMES (ADAPTATION ENZYMATIQUE),JACQUES MONOD and MELVIN COHN,incollection,MONOD1978220,,,,,,André Lwoff and Agnes Ullmann,
,,817-838,,"All known artificial satellites launched during 1965 are listed chronologically. Lifetimes, weights, dimensions and orbital details are given for instrumented satellites and their final-stage rockets. Other fragments are listed without these details. The methods used in compiling the Table are outlined.
Реферат
Дaeтcя пepeчeнь, в чpoнoлoгичecкoм пopядкe, вceч иэвecтныч иcкyccт-вeнныч cпyтникoв Эeмли, эaпyщeнныч в тeчeниe 1965г. cooбщayтcя вpeмя пpeбыaaния cпyтникoa нa opбитe, aec, paзмepы и дeтaли opбит длн ocнaщeнныч пpибopaми cпyтникoa и ич пocлeднecтyпeнчaтыч paкeт. Пepeчиcляютcя и дpyгиe oтдeльныe фaктopы, иo бeи дeтaлeй. a oбщич чepтaч oпиcыaaeтcя пpимeнeнный для cocтaaлeния этoй тaблицы cнocoб.",https://doi.org/10.1016/0032-0633(66)90089-4,https://www.sciencedirect.com/science/article/pii/0032063366900894,,,,1966,Table of the earth satellites launched in 1965,D.G. King-Hele and Eileen Quinn,article,KINGHELE1966817,Planetary and Space Science,9,14,0032-0633,,,
,,S677-S727,,,https://doi.org/10.1016/S0924-8579(07)00138-0,https://www.sciencedirect.com/science/article/pii/S0924857907001380,,,,2007,Author Index,,article,2007S677,International Journal of Antimicrobial Agents,,29,0924-8579,17th ECCMID/25th ICC Abstracts,,
,"Basin analysis, Hydrocarbon potential",2-34,,"Depositional sequence mapping has been used to analyse the late Devonian to Recent geologic evolution and hydrocarbon habitat of north Alaska and northwest Canada. Eight depositional megasequences have been identified, each of which records a discrete, major phase of basin evolution. The three oldest megasequences are named the Ellesmerian and reflect deposition on a subsiding fold belt terrane. We name the subsequent two megasequences of early Jurassic to Aptian age, the Beaufortian. They record a 100 m.y. period of extension during which a Jurassic failed rift episode was followed by onset of the successful rift episode in the Hauterivian. This extension led to the opening of the oceanic Canada Basin. The final three megasequences record geographically distinct pulses of Brookian orogenesis. The major proven hydrocarbon habitat occurs on the Barrow Arch of north Alaska. This is a volumetrically large, but greatly restricted, hydrocarbon province, which developed as a result of constructive interference between Beaufortian rift and Brookian orogenic tectonics. Two other, relatively minor, hydrocarbon provinces have also been discovered. They are the Mackenzie Delta and Kugmallit Trough provinces of northwest Canada, which developed in passively subsided basins, located just beyond the influence of Brookian orogenic uplift.",https://doi.org/10.1016/0264-8172(87)90019-5,https://www.sciencedirect.com/science/article/pii/0264817287900195,,,,1987,Geologic evolution and hydrocarbon habitat of the ‘Arctic Alaska Microplate’,Richard J. Hubbard and Steven P. Edrich and R. {Peter Rattey},article,HUBBARD19872,Marine and Petroleum Geology,1,4,0264-8172,,,
,,123-171,,This paper deals with the problems of applying a unification procedure in a mechanization of the full type theory. The early sections describe the unification problem and an algorithm which produces a complete set of unifiers. The special case of the 2nd order problem is differentiated. Then there is presented an extensive proof of completeness of the algorithm. The later sections are devoted to application of the unification in mechanical theorem proving. A generalization of the resolution principle as well as some specialized strategies are presented.,https://doi.org/10.1016/0304-3975(76)90021-9,https://www.sciencedirect.com/science/article/pii/0304397576900219,,,,1976,Mechanizing ω-order type theory through unification,D.C. Jensen and T. Pietrzykowski,article,JENSEN1976123,Theoretical Computer Science,2,3,0304-3975,,,
,,52-60,,"d-Glyceraldehyde-3-phosphate dehydrogenase forms a ternary complex with Ag+ and nicotinamide-adenine dinucleotide accompanied by the loss of enzymic activity and by a change of light absorption in the 300–400 mμ region. The ternary complex shows maximum absorption at 335 mμ. The ternary complex can be crystallized. The formation of the complex is reversible, the native enzyme-coenzyme complex being restored by the addition of mercaptoethanol. Maximum yield of the complex is obtained when about 4 moleequiv of Ag+ are added; the addition of more Ag+ results in the disintegration of the ternary complex and nicotinamide-adenine dinucleotide is severed from the enzyme.",https://doi.org/10.1016/0005-2787(65)90608-8,https://www.sciencedirect.com/science/article/pii/0005278765906088,,,,1965,On the ternary complex formation of d-glyceraldehyde-3-phosphate dehydrogenase with nicotimide-adenine dinucleotide and Ag+,L. Bross,article,BROSS196552,Biochimica et Biophysica Acta (BBA) - Nucleic Acids and Protein Synthesis,1,96,0005-2787,,,
Progress in Brain Research,,213-252,Role of The Forebrain in Sensation and Behavior,"Publisher Summary
This chapter reviews the present understanding of the organization and functional properties of descending systems and recent advances that have come from single unit recording in awake monkeys using new techniques that reveal the synaptic connections of single premotor neurons with motoneurons of agonist and antagonist muscles. The technique of spike-triggered averaging of electromyogram activity in awake monkeys is yielding new information at the level of individual premotor neurons concerning the sign, strength, and distribution of synaptic effects from descending systems to spinal motoneurons. The chapter emphasizes the role of descending systems in the control of limb movements, although it is recognized that locomotion and other motor behaviors involving axial, head, and/or facial muscles may involve similar principles. It also emphasizes motor control in primates, although relevant data from the cat and other species will be included where no primate data are available.",https://doi.org/10.1016/S0079-6123(08)63054-X,https://www.sciencedirect.com/science/article/pii/S007961230863054X,,Elsevier,,1991,Chapter 11 Neural mechanisms underlying corticospinal and rubrospinal control of limb movements,Paul D. Cheney and Eberhard E. Fetz and Klaus Mewes,incollection,CHENEY1991213,,,87,0079-6123,,G. Holstege,
,,1-40,,"One-particle and two-particle inclusive distributions are considered in the light of future production experiments at CERN Intersecting Storage Rings machine. We discuss the general properties of those models which are based on factorized approximations to the production amplitudes and are in agreement with some general hypotheses like the Feynman scaling law. First the role of phase space arguments is clarified and the importance of detecting correlations in high energy production experiments as an hint for understanding the underlying dynamics is emphasized. Then two peculiar (and, in a sense, complementary) kinds of correlation in two-particle inclusive distributions are examined: the one coming from multiperipheral dynamics with Lorentz pole exchanges, the other due to “direct channel” resonances. Some general properties of inclusive distributions are expressed in terms of quantities which are suitable for direct measurement.",https://doi.org/10.1016/0550-3213(71)90107-6,https://www.sciencedirect.com/science/article/pii/0550321371901076,,,,1971,On two-particle correlations in high energy production experiments,A. Bassetto and M. Toller and L. Sertorio,article,BASSETTO19711,Nuclear Physics B,1,34,0550-3213,,,
,,197-210,,,https://doi.org/10.1016/S0016-0032(33)90342-7,https://www.sciencedirect.com/science/article/pii/S0016003233903427,,,,1833,¶ List of French patents,,article,1833197,Journal of the Franklin Institute,3,16,0016-0032,,,
HP Technologies,,97-150,"OpenVMS with Apache, WASD, and OSU","Publisher Summary
There are two sides to managing access to the server resources, namely outside and the inside. It is important to control which and how many entities from outside the system can get at what's inside and in what way. This, however, brings up the issues of user identification, either anonymously or identifiably. Resource mapping, access control, and authentication are often closely intertwined. The server maps the URL into a resource name recognizable by the operating system and determines any access restrictions on that resource. If the access is restricted to particular users, than the server authenticate the requester as one of the users. Several types of authentications are available to web server and structurally all of them work the same way. There are files that only certain people should be able to run. This can be achieved by restricting or allowing access to pages in a variety of ways such as using the IP address it comes from and using the “Referer” header. In this context, each of the servers has particular strengths and weaknesses as Ohio State University DECthreads HTTP Server (OSU) have different people authenticate in different ways, some against the UAF and some against a file-specific password. Compaq Secure Web Server (CSWS) uses arbitrarily complicated access-control logic.",https://doi.org/10.1016/B978-155558264-7/50088-4,https://www.sciencedirect.com/science/article/pii/B9781555582647500884,Burlington,Digital Press,978-1-55558-264-7,2003,7 - Managing Access to Your Server Resources,Alan Winston,incollection,WINSTON200397,,,,,,Alan Winston,
,,1-58,,,https://doi.org/10.1016/0020-708X(63)90075-9,https://www.sciencedirect.com/science/article/pii/0020708X63900759,,,,1963,"Report of the European meeting on the microbiology of irradiated foods: Paris, 20–23 April 1960",,article,19631,The International Journal of Applied Radiation and Isotopes,1,14,0020-708X,,,
,,644-665,,,https://doi.org/10.1016/0959-440X(93)90094-2,https://www.sciencedirect.com/science/article/pii/0959440X93900942,,,,1993,Egineering and design,,article,1993644,Current Opinion in Structural Biology,4,3,0959-440X,,,
,,1-47,,"Diss Mere is a small lake around which the town of Diss has developed. Pollen analysis of the lake sediments deposited during the last 7000 years yielded a rich pollen and spore flora. Numerical methods were used to sort the pollen taxa into recurrent groups, which are groups of taxa with similar occurrences through time. With the aid of the recurrent groups the pollen diagram was interpreted in terms of the vegetational history of the catchment. The calcareous sediments were unsuitable for radiocarbon dating, but a chronology was established by correlation with nearby sites and by comparison with historical records. People may have lived in the mid-Holocene forest, and created small clearances prior to the Ulmus decline. After the Ulmus decline at ca. 3000 BC, the forest became more open, but eventually human activity declined, and clearings were colonised by secondary scrub. Subsequently, Bronze Age people lived by the lake. They cleared substantial parts of the Quercus/Corylus-dominated forests on the slopes and the Tilia-dominated forest on the plateau above. Dereliction and scrub development, particularly by Taxus, at the end of the Bronze Age, was followed by Iron Age colonisation. Superior technology lead to almost complete forest clearance and farming of the catchment, and the origin of the town. The town developed through Medieval time, and cultivation became specialised with Cannabis (hemp) and Linum (flax) cultivation. After the collapse of the hemp industry, arable farming prevailed. The lake becamme highly eutrophic due to nutrient addition from farming and from the town. Eventually a proper sewage treatment was installed. The uppermost pollen record reflects the conversion of the non-urbanised part of the catchment to parkland.",https://doi.org/10.1016/0034-6667(93)90079-A,https://www.sciencedirect.com/science/article/pii/003466679390079A,,,,1993,"The development of the cultural landscape around Diss Mere, Norfolk, UK, during the past 7000 years",Sylvia M. Peglar,article,PEGLAR19931,Review of Palaeobotany and Palynology,1,76,0034-6667,,,
,,535-591,Building DMZs For Enterprise Networks,"Publisher Summary
This chapter focuses on the Windows 2000 Server referred as a popular choice for deployment to Internet-facing networks. Despite Microsoft's poor reputation for security in such hostile environments, it is quite possible to secure Windows 2000. Windows 2000's built-in security mechanisms highlight the poor planning that all too often accompanies a new Windows 2000 DMZ server build. The chapter assists the systems engineer to avoid the most common pitfalls in deploying Windows 2000 to a hostile Internet-facing environment using mostly on onboard, built-in tools. Windows 2000 gives some planning, forethought, and creative nondefault configuration steps. Windows 2000 is too risky at the time of building DMZ hosts; too many older, less secure defaults are retained in the name of backward compatibility. Windows 2000 has the feature of “remembering” service pack installed files and so newly installed components install using the most current service pack version by referencing the source files listed. This somewhat under documented feature enhancement of Windows 2000, introduced in Service Pack 1, saves a significant amount of time and eliminates the human error that used to be associated with making minor system state changes to a running Windows server.",https://doi.org/10.1016/B978-193183688-3/50016-X,https://www.sciencedirect.com/science/article/pii/B978193183688350016X,Rockland,Syngress,978-1-931836-88-3,2003,Chapter 13 - Windows 2000 Bastion Hosts,Robert J. Shimonski and Will Schmied and Thomas W. Shinder and Victor Chang and Drew Simonis and Damiano Imperatore,incollection,SHIMONSKI2003535,,,,,,Robert J. Shimonski and Will Schmied and Thomas W. Shinder and Victor Chang and Drew Simonis and Damiano Imperatore,
,,81-115,,,https://doi.org/10.1016/S0014-5793(98)80003-3,https://www.sciencedirect.com/science/article/pii/S0014579398800033,,,,1997,Keyword index to volumes 400–420,,article,199781,FEBS Letters,,400-420,0014-5793,,,
,,4740-4748,,"The δ-lactone derived from tetra-N-acetylchitotetraose (TACL) has been prepared by oxidation of tetra-N-acetyl-chitotetraose with iodine. The binding of TACL to lysozyme has been investigated by its inhibition of the lysozymecatalyzed lysis of Micrococcus lysodeikticus cells and by its perturbation of the tryptophyl fluorescence spectrum of lysozyme. At pH 6.2 the concentration of TACL that is required for 50% inhibition of the rate of lysis is 0.7 µm, which is 1/110 of the concentration of the unmodified tetrasaccharide that is required for such inhibition. The association constants for the binding of TACL to lysozyme over the pH range from 2 to 8 were obtained by fluorescence measurements. Their pH dependence shows that TACL binds most strongly to the species of lysozyme in which the carboxyl group of glutamate 35 is dissociated. In agreement with this result, the fluorescence-pH profile of the TACL-lysozyme complex indicates that the pK of glutamate 35 is about 4.7 in the complex, whereas the pK of glutamate 35 in the enzyme alone is about 6.0. The value of the association constant for the binding of TACL at pH 5.0 and 25° is 3.3 x 106m-1, which is 32 times larger than that for the binding of the unmodified tetrasaccharide under the same conditions. On the basis of these results and of the similarity between the known conformation of the lactone ring and the proposed conformation of the transition state for lysozyme-catalyzed reactions (both half-chair ones), we conclude that TACL is a transition state analog for lysozyme. Furthermore, with these results we can estimate that the affinity of Subsite D of lysozyme for the half-chair conformation of the pyranose ring of N-acetylglucosamine is greater by a factor of 6 x 103 than its affinity for the chair conformation and thus contributes this factor to catalysis.",https://doi.org/10.1016/S0021-9258(19)44974-0,https://www.sciencedirect.com/science/article/pii/S0021925819449740,,,,1972,A Transition State Analog for Lysozyme,Isaac I. Secemski and Sherwin S. Lehrer and Gustav E. Lienhard,article,SECEMSKI19724740,Journal of Biological Chemistry,15,247,0021-9258,,,
,,10-32,,"The anterior chamber of the enucleated rabbit eye was perfused with tissue culture medium (TC 199); the temperature of the medium (35°C), the intraocular pressure (20 mmHg), and the rate of perfusion (0·33 cc/min) were controlled. The corneal surface of the living rabbit was bathed with 0·9% sodium chloride solution after the aqueous humor had been replaced with silicone oil. These procedures did not affect the normal corneal thickness for a period of 4 hr. Various degrees of hypertonicity were produced in the perfusing solutions by the addition of various solutes, i.e. sodium chloride, urea, glucose, sucrose, raflinose, and albumin. When a cornea came into contact with a hypertonic solution, its thickness rapidly decreased, reaching a new steady state in 10–15 min. When TC 199 or 0·9% sodium chloride solution was then applied, the thickness rapidly increased to the original level. An analysis of the time sequence of the changes in corneal thickness, from the viewpoint of the thermodynamics of irreversible processes, yielded values for the hydraulic conductivity of the corneal epithelium and endothelium and for their reflection coefficients with the different solutes used. The hydraulic conductivity of the epithelium and endothelium, respectively, was approximately 1·0 × 10−4 mm/min msOm l−1 and 2·3 × 10−4 mm/min mOsm l−1. The reflection coefficient of the epithelium was 1 with all solutes used; that of the endothelium was 0·6 with urea and sodium chloride and 1 with solutes of larger molecular weights than glucose.",https://doi.org/10.1016/S0014-4835(67)80049-6,https://www.sciencedirect.com/science/article/pii/S0014483567800496,,,,1967,The permeability of the corneal epithelium and endothelium to water,Sahchi Mishima and Bengt O. Hedbys,article,MISHIMA196710,Experimental Eye Research,1,6,0014-4835,,,
,"Serum-free medium, Chemically defined medium, Neurons in vitro, Cerebral cortex, Rat",301-334,,"The present study describes a series of experiments which have led to a substantially improved serum-free, chemically defined medium (CDM) for long-term culturing of reaggregated fetal rat cerebral cortex tissue. A reduction of the original medium concentrations of the hormones insuline, T3 and corticosterone, on the one hand, and an enrichment of the medium with the vitamins A, C and E, the unsaturated fatty acids linoleic and linolenic acid, and biotin, L-carnitine, D(+)-galactose, glutathione (reduced) and ethanolamine, on the other hand, formed the most important chemical adjustments of the medium. With the aid of this CDM (encoded R12), the light- and electron microscopic architecture of the tissue could be kept in a good condition (superior to that seen earlier in serum-supplemented medium) up to 23 days in vitro. From that time on, the neuronal network lying between the reaggregates degenerated for the largest part, while a portion of the large neurons (probably pyramidal cells) plus some of the neuronal network within the reaggregates degenerated too. This degeneration process continued during the following weeks, but the reaggregates nevertheless retained most of their mass, so that both small and large neuronal cell bodies (visible in transparent regions at the edge of the reaggregates) remained in good condition up to at least 103 DIV. Stout, thick nerve bundles interconnecting the reaggregates, also survived up to this point. Electron microscopic evaluation of such ‘aged’ reaggregates revealed degenerating as well as healthy regions. The latter had indeed retained healthy-looking pyramidal and non-pyramidal neurons, embedded within a dense neuropil which was often traversed by myelinated axons. The numerical synapse density in such selected, healthy tissue regions reached its maximum during the sixth week in vitro, followed by a rapid decrease and a stabilization at about half the peak values. The present culture system has opened the possibility for performing controlled quantitative studies on the relationship between structure and function of cerebral cortex tissues during development and aging, on its dependence on nutrients, hormones and drugs, and on special factors synthesized by the tissue and released into the nutrient medium.",https://doi.org/10.1016/0149-7634(84)90055-1,https://www.sciencedirect.com/science/article/pii/0149763484900551,,,,1984,"Towards an improved serum-free, chemically defined medium for long-term culturing of cerebral cortex tissue",H.J. Romijn and F. {van Huizen} and P.S. Wolters,article,ROMIJN1984301,Neuroscience & Biobehavioral Reviews,3,8,0149-7634,,,
,,813-840,,,https://doi.org/10.1016/S0959-437X(05)80145-5,https://www.sciencedirect.com/science/article/pii/S0959437X05801455,,,,1992,Prokaryotes and lower eukaryotes,,article,1992813,Current Opinion in Genetics & Development,5,2,0959-437X,,,
,,I-CXXXIII,,,https://doi.org/10.1016/S2213-1779(23)00497-3,https://www.sciencedirect.com/science/article/pii/S2213177923004973,,,,2023,Full Issue PDF,,article,2023I,JACC: Heart Failure,"8, Part 2",11,2213-1779,THT Special Issue,,
,,149-165,,,https://doi.org/10.1016/0144-8617(89)90023-4,https://www.sciencedirect.com/science/article/pii/0144861789900234,,,,1989,Bibliography on carbohydrate polymers,,article,1989149,Carbohydrate Polymers,2,11,0144-8617,,,
,"Immunoblotting, Dot blotting, Slot blotting, Dot immunobinding, Electrophoresis, Western Blotting, (Methods), (Review)",153-187,,,https://doi.org/10.1016/0022-1759(89)90394-3,https://www.sciencedirect.com/science/article/pii/0022175989903943,,,,1989,Immunoblotting and dot blotting,D.I. Stott,article,STOTT1989153,Journal of Immunological Methods,2,119,0022-1759,,,
,"African horse sickness virus (AHSV), AHSV genome, AHSV proteins, bluetongue virus (BTV), epizootic haemorrhagic disease virus (EHDV), virus-like particles (VLPs), core-like particles (CLPs), cross-hybridization analyses, virus neutralization, Virus de la maladie du cheval African (AHSV), BTV, virus de la maladie hémorrhagique épizootique du cerf (EHDV), VLPs, CLPs, analyses par Western-blot, neutralisation, ELISA",243-273,,"African horse sickness virus (AHSV), of which there are nine serotypes (AHSV-1, -2, etc.), is a member of Orbivirus genus within the Reoviridae family. Both in morphology and molecular constituents AHSV particles are comparable to those of bluetongue virus (BTV), the prototype virus of the genus. The two viruses have seven structural proteins (VP1–7) organized in two layered capsid. The outer capsid is composed of VP2 and VP5. The inner capsid, or core, is composed of two major proteins, VP3 and VP7, and three minor proteins, VP1, VP4 and VP6. Within the core is the virus genome. This genome consists of 10 double-stranded (ds)RNA segments of different sizes, three large, designated L1–L3, three medium, M4–M6, and four small, S7–S10. In addition to the seven stuctural proteins that are coded by seven of the RNA species, four non-structural proteins, NS1, NS2, NS3 and NS3A, are coded by three RNA segments, M5, S8 and S10. The two smallest proteins (NS3 and NS3A) are synthesized by the S10 RNA segment, probably from different in-frame translation initiation codons. Nucleotide sequences of eight RNA segments (L2, L3, M4, M5, M6, S7, S8 and S10) and the predicted amino acid sequences of the encoded gene products are also available, mainly representing one serotype, AHSV-4. In this review the properties of the AHSV genes and gene products are discussed. The sequence and hybridization analyses of the different AHSV dsRNA segments indicate that the segments that code for the core proteins, as well as those that code for NS1 and NS2 proteins, are highly conserved between the different virus serotypes. However, the RNA encoding NS3 and NS3A, and the two segments encoding the outer capsid proteins, are more variable between the AHSV serotypes. A close phylogenetic relationship between AHSV, BTV and epizootic haemorrhagic disease virus (EHDV), three Culicoides-transmitted orbiviruses, has been revealed when the equivalent sequences of genes and gene products are compared. Recently, the four major AHSV capsid proteins have been expressed using recombinant baculoviruses. Biochemically and antigenically these proteins are similar to the authentic proteins. Since the AHSV VP7 protein is highly conserved among the different serotypes, it has been utilized as a diagnostic reagent. The expressed VP7 protein has also been purified to homogeneity and crystallized for three-dimensional X-ray analysis. The expressed outer capsid proteins, VP2 and VP5, have been purified and used to raise antisera in rabbits. The VP2 antisera neutralize virus infections in vitro indicating the importance of this protein for vaccine development.
Résumé
Le virus de la maladie du cheval Africain (AHSV), pour lequel il existe neuf sérotypes (AHSV-1, -2, etc.), est un membre du genre des Orbivirus dans la famille des Reoviridae. Les composants morphologiques et moléculaires des particules de l'AHSV sont comparables à celles du virus “bluetongue” (BTV), virus référence de ce genre. Ces deux virus possèdent sept protéines structurales différentes (VP1–7) réparties en deux capsides. La capside externe est composée de VP2 et de VP5. La capside interne, ou “core”, est composée de deux protéines majeures, VP3 et VP7, et de trois protéines mineures, VP1, VP4 et VP6. Le génome, localisé dans la capside interne, est composé de dix segments d'ARN double-brin (ds) de tailles différentes, trois grands, désignes L1–L3, trois moyens, M4–M6, et quatre petits, S7–S10. En plus de sept protéines structurales codées par sept fragments d'ARN, quatre protéines non structurales, NS1, NS2, NS3 et NS3A, sont codés par les segments M5, S8 et S10, respectivement. Les deux protéines de petite taille (NS3 et NS3A) sont synthetisées à partir du segment d'ARN S10, probablement suite a l'initiation de la traduction a partir de deux phases de lectures différentes. La séquence nucléotidique de huit segments d'ARN (L2, L3, M4, M5, M6, S7, S8 et S10) ainsi qui les séquences en acide aminés qui en sont déduites, sont désormais connues, représentant le sérotype AHSV-4. Les propriétés des genes et de leurs produits sont discutées. Les analyses de séquences ainsi que celles des hybridations moléculaires des différents segments d'ARN indiquent que les segments codant pour les proteines de la capside interne (core), ainsi que ceux codant pour les protéines NS1 et NS2, sont hautement conservés. Cependant, le segment codant pour NS3 et NS3A, ainsi que deux autres segments codant pour des protéines de la capside externe, sont plus variables entre les différents sérotypes AHSV. Des relations phylogénétiques entre l'AHSV, le BTV et le virus de la maladie hémorrhagique épizootique du cerf (EHDV), trois orbivirus transmis par des moucherons, ont été mis en évidence lors de la comparaison de séquences équivalentes de gènes et de leurs produits. Les quatre protéines de capside majeures de l'AHSV ont été recemment exprimées dans le système d'expression du baculovirus recombinant. Les protéines exprimées sont biochimiquement et antigéniquement identiques aux protéines naturelles. Puisque la protéine VP7 de l'AHSV et hautement conservée dans les différents sérotypes, elle a été utilisée comme outil de diagnostic sensible de groupespécifique. La protéine VP7 exprimée a ensuite été purifiée et cristallisée pour une analyse tridimentionnelle par rayons X. Les protéines exprimées de la capside externe, VP2 et VP5 ont aussi été purifiées puis ont été utilisées pour la production d'antiserum par des lapins. L'antiserum de VP2 obtenu neutralise in vitro des infections virales, ce qui met en évidence son importance pour le développement de vaccins.",https://doi.org/10.1016/0147-9571(94)90046-9,https://www.sciencedirect.com/science/article/pii/0147957194900469,,,,1994,African horse sickness virus structure,Polly Roy and Peter {P.C. Mertens} and Ignacio Casal,article,ROY1994243,"Comparative Immunology, Microbiology and Infectious Diseases",3,17,0147-9571,,,
,,1659-1699,,"The total structure of enmein, a diterpene, isolated from Isodon trichocarpus Kudo has been established as shown in the formula If.",https://doi.org/10.1016/0040-4020(66)80156-4,https://www.sciencedirect.com/science/article/pii/0040402066801564,,,,1966,"Constitution and stereochemistry of enmein, a diterpene from isodon trichocarpus kudo",T. Kubota and T. Matsuura and T. Tsutsui and S. Uyeo and H. Irie and A. Numata and T. Fujita and T. Suzuki,article,KUBOTA19661659,Tetrahedron,5,22,0040-4020,,,
,,I-CIII,,,https://doi.org/10.1016/S2772-3747(22)00084-9,https://www.sciencedirect.com/science/article/pii/S2772374722000849,,,,2022,Full Issue PDF,,article,2022I,JACC: Asia,2,2,2772-3747,,,
,"Homology, Cornuta, Stylophora, France, Ordovician, Mitrata, Homologie, Cornuta, Stylophora, France, Ordovicien, Mitrata",421-458,,"Plate homologies are identified and discussed in cornute stylophoran echinoderms. The main resultsare: 1) the homology of the posterior zygal plate in all cornutes and, 2) the non-homology of the spinal process, which can be borne by two distinct plates from the marginal frame. A functional analysis of stylophoran “accessory orifices” as exchange systems is realised: they are interpreted as respiratory structures. Sutural pores of Phyllocystis blayaci and cothurnopores could represent exothecal pore-structures, and lamellipores endothecal pore-structures. Other possible means of respiration are also envisaged in cornutes. A systematic revision of the Order Cornuta is also presented. The new genus Arauricystis is proposed for two species of cornutes previously assigned to the genus Cothurnocystis.. Two new species of cornutes from the Lower Arenig (Lower Ordovician) of Montagne Noire (Southern France) are described, Ampelocarpus landeyranensis nov. gen. et nov. sp. and Thoralicystis ubaghsi nov. sp.. A new cornute from the Llandeilo (Middle Ordovician) of Brittany (Western France), Scotiaecystis guilloui nov. sp. is also described. Finally, a cladistic analysis of cornutes confirms the results obtained by the identification of plate homologies: 1) cornutes and mitrates are sister-groups, 2) Ceratocystis belongs to the stem-group of both cornutes and mitrates, 3) Amygdalothecida and Cothurnocystida are sister-groups and, 4) Protocystites belongs to the stem-group of both Amygdalothecida and Cothurnocystida.
Résumé
Les homologies de plaques entre les divers genres de cornutes (échinodermes stylophores) sont identifiées et discutées. Les principaux résultats sont: 1) l'homologie de la plaque zygale postérieure chez tous les cornutes et, 2) la non-homologie de la spinale, susceptible d'être développée par deux plaques marginales distinctes. L'analyse morpho-fonctionnelle des “orifices accessoires” des stylophores en tant que système d'échange permet de les proposer comme structures respiratoires. D'autres moyens de respiration sont également envisagés chez les cornutes. Une révision systématique de l'Ordre Cornuta est également réalisée. Le genre nouveau Arauricystis est proposé pour deux espèces de cornutes attribuées jusqu'alors au genre Cothurnocystis.. Trois nouvelles espèces de cornutes sont décrites dans l'Arenig inférieur (Ordovicien inférieur) de la Montagne Noire (France méridionale), Ampelocarpus landeyranensis nov.gen. et nov. sp. et Thoralicystis ubaghsi nov. sp., et dans le Llandeilo (Ordovicien moyen) de Bretagne (Ouest de la France), Scotiaecystis guilloui nov. sp.. Enfin, l'analyse cladistique confirme les résultats obtenus par la reconnaissance des homologies de plaques, à savoir que: 1) cornutes et mitrates sont groupes-frères, 2) Ceratocystis appartient au groupe-souche des cornutes et des mitrates, 3) Amygdalothecida et Cothurnocystida sont groupes-frères et, 4) Protocystites appartient au groupe-souche des Amygdalothecida et des Cothurnocystida.",https://doi.org/10.1016/S0016-6995(99)80019-9,https://www.sciencedirect.com/science/article/pii/S0016699599800199,,,,1999,"New Ordovician cornutes(Echinodermata, Stylophora) from Montagne Noire and Brittany (France) and a revision of the order Cornuta Jaekel 1901: To the memory of Jean Chauvel",Bertrand Lefebvre and Daniel Vizcaino,article,LEFEBVRE1999421,Geobios,3,32,0016-6995,,,
Methods in Enzymology,,659-688,Immunochemical Techniques Part J,"Publisher Summary
This section of the book Methods in Enzymology lists the names of authors who have contributed their work. Numbers given in parentheses are footnote reference numbers and indicate that an author's work is referred to, although the name is not cited in the text.",https://doi.org/10.1016/S0076-6879(86)32049-4,https://www.sciencedirect.com/science/article/pii/S0076687986320494,,Academic Press,,1986,Author index,,incollection,1986659,,,132,0076-6879,,,
,,7-16,,,https://doi.org/10.1111/j.1435-5597.1966.tb01339.x,https://www.sciencedirect.com/science/article/pii/S1056819023009314,,,,1966,A REGIONALIST'S VIEW OF PUBLIC SECTOR PLANNING IN A CAPITALIST SOCIETY,CHARLES L. LEVEN,article,LEVEN19667,Papers in Regional Science,1,17,1056-8190,,,
,,119-132,,,https://doi.org/10.1016/0025-5416(78)90112-X,https://www.sciencedirect.com/science/article/pii/002554167890112X,,,,1978,Engineering materials science,C.J. McHargue and J.R. Cost and C.A. Wert,article,MCHARGUE1978119,Materials Science and Engineering,1,35,0025-5416,Directions in Energy-related Basic Materials Research,,
,,1-80,,,https://doi.org/10.1016/S0304-3479(88)80055-3,https://www.sciencedirect.com/science/article/pii/S0304347988800553,,,,1988,Слово и премудрость (“логосная структура”): “Проглас” Константина Философа,В.Н. Топоров,article,TOPOROV19881,Russian Literature,1,23,0304-3479,,,
International Review of Forestry Research,,39-113,,,https://doi.org/10.1016/B978-1-4831-9975-7.50007-7,https://www.sciencedirect.com/science/article/pii/B9781483199757500077,,Elsevier,,1964,Improvement of Forest Growth on Poorly Drained Peat Soils,LEO HEIKURAINEN,incollection,HEIKURAINEN196439,,,1,0074-7726,,JOHN A. ROMBERGER and PEITSA MIKOLA,
,,11-IN9,,"The cross-reacting antigenic determinants between lens proteins and other tissues of Xenopus laevis and the chick have been studied by immunodiffusion, immunoelectrophoresis and the Osserman technique, using antisera detceting minor as well as major antigenic determinants of the lens proteins. All tissues tested contained some antigenic determinants similar to those found in lens proteins and it was demonstrated that all of the major classes of lens proteins contained such cross-reacting groups. The pattern of cross-reactivity varied both qualitatively and quantitatively from tissue to tissue and there were no lens antigens which were found in all of the other tissues tested. The cross-reacting material from extralenticular tissue is not always identical in molecular form to that obtained from the lens. The results of the Osserman tests have been interpreted as indicating heterogeneity in a population of protein molecules which may be based either on a heteropolymer structure or on the selective binding of cross-reacting antigenic moieties. The results described are taken to mean that much tissue specificity is the result of a unique selection of antigens genetically available, any one of which may be found in other tissues, rather than being due exclusively to the possession of some specific protein restricted to that tissue.",https://doi.org/10.1016/S0014-4835(68)80022-3,https://www.sciencedirect.com/science/article/pii/S0014483568800223,,,,1968,A re-examination of the organ specificity of lens antigens,R.M. Clayton and J.C. Campbell and D.E.S. Truman,article,CLAYTON196811,Experimental Eye Research,1,7,0014-4835,,,
,,1375-1393,,"Summary
Lactulose is produced from lactose during the heat processing and storage of certain dairy products. This sugar is somewhat sweeter and more soluble than lactose. It also seems to have unique growth-promoting properties for certain desirable types of Lactobacilli in the intestinal tract of the infant. The chemistry and possible nutritional roles of this sugar are reviewed. The relationship of lactulose to bifidus factor and other carbohydrate moieties of milk also are considered.",https://doi.org/10.3168/jds.S0022-0302(61)89899-8,https://www.sciencedirect.com/science/article/pii/S0022030261898998,,,,1961,Presence and Significance of Lactulose in Milk Products: A Review1,Susumu Adachi and Stuart Patton,article,ADACHI19611375,Journal of Dairy Science,8,44,0022-0302,,,
,,131-173,,"During Mesozoic time the Northwest Australian continental margin and the Thakkhola region of North Central Nepal were “adjacent” passive margins, off Northeast Gondwana. The relatively sediment-starved basins provide excellent opportunities for studying the early structural and depositional evolution of the Indian Ocean, during the Triassic/Jurassic rifting stages (Neo-Tethys), and the Jurassic/Cretaceous transition from rifting to drifting. Nepalese and Australian paleomagnetic studies indicate subtropical paleolatitudes during the Late Triassic to Early Jurassic, but higher latitudes of 35–40°S during the Late Jurassic to Early cretaceous, prior to the sustained northward flight of Australia and Greater India in the Late Cretaceous to Cenozoic. The latitudinal position of the basins and type of sediment are related. Principal continental margin formation along the northern edge of eastern Gondwana started in late Permian to Triassic time. By late Triassic-early Jurassic time platform carbonates with thin, lagoonal shales were laid down in a subtropical climate. The Carnian to “Rhaetian” siliciclastics and carbonates show repeated shallowing-upward sequences. Subsequent southward drift of “Greater India” and Australia during mid-Jurassic time replaced carbonates with more siliciclastic sediment input. Widespread erosion was caused during local uplift of parts of the Northwest Australian continental margin as a result of Jurassic late-rift block faulting. A mid-Callovian-early Oxfordian hiatus in Nepal is a submarine condensed sequence and non-tectonic in origin. In Nepal, the overlying 250 m thick organic-rich dark shales, which are correlated to the Oxfordian/Kimmeridgian clays of circum-Atlantic hydrocarbon bearing basins, can be traced along the northern Himalayan range. These shales probably represent an extensive continental slope deposit formed in a “high-productivity of organics” belt. The diverse foraminiferal microfauna of the belt was previously only known from boreal Laurasia. The Callovian “break up” uncorformity off Northwest Australia is actually a post-rift unconformity and precedes the onset of seafloor spreading by about 5–10 m.y. Seafloor spreading, leading to formation of the present Indian Ocean, started in the Argo Abyssal Plain around 155 Ma ago, in late Jurassic time. Australia and Greater India, including Northern Nepal, separated as early as in the late Valanginian, about 130 Ma ago. Altered ash layers off Northwest Australia record an important volcanic phase in Berriasian-Valanginian time. Mafic volcaniclastics in Nepalese deltaic sediments also testify to continental margin volcanic activity, which may be a precursor to the slightly younger Rajmahal traps in eastern India. An important tectonic event off Northwest Australia took place in Aptian time, 120-115 Ma ago, when hemipelagic sedimentation changed gradually into more pelagic sedimentation, with sharply decreasing rates of deposition. In Nepal, this marks the transition from coarse to fine-grained, organic-rich terrigenous clastics, leading eventually to more carbonate-bearing strata during the mid-Cretaceous global sealevel highstand.",https://doi.org/10.1016/0025-3227(91)90007-Q,https://www.sciencedirect.com/science/article/pii/002532279190007Q,,,,1991,Stratigraphic evolution of Mesozoic continental margin and oceanic sequences: Northwest Australia and northern Himalayas,Felix M Gradstein and Ulrich von Rad,article,GRADSTEIN1991131,Marine Geology,1,102,0025-3227,,,
,,97-328,,,https://doi.org/10.1016/0022-0728(84)80002-9,https://www.sciencedirect.com/science/article/pii/0022072884800029,,,,1984,Subject index,,article,198497,Journal of Electroanalytical Chemistry and Interfacial Electrochemistry,1,166,0022-0728,,,
,,59-86,,"Hydrothermal experiments have been performed investigating granodiorite-water, waste glass-water and granodiorite-waste glass-water systems in the temperature range 100–350°C at pressures of 50 or 60 MPa. Experimental equipment consisted of closed-system large-volume gas-pressurised reaction vessels. Run durations lasted from less than one day to one hundred days at fluid/solid mass ratios between 0.4 and 6. Fluids generated in the granodiorite-water experiments were alkaline (pH = 7.4–8.9) with low total dissolved solids (< 500 ppm) and low chloride (< 40 ppm) and sulphate (< 30 ppm) contents. Silica concentrations in solution approximate to theoretical values in the quartz-water system at 100° and 150°C, although 200°C fluids show evidence of re-equilibration during the quenching process. From available thermodynamic data, the chemistries of the 100° and 150°C fluids appear to be governed by feldspar-water equilibria, whilst at 200°C, feldspar-montmorillonite reactions dominate the fluids. Montmorillonite is an identified secondary phase at 200°C. From these preliminary data, the “evolved groundwaters” produced through reaction of granodiorite and water at high temperatures seem suitable for canister preservation, actinide immobilisation and compatibility with bentonite as a backfill material. Two sodium borosilicate glasses containing simulated waste components have been used in a kinetic study of dissolution at 100° and 150°C, 60 MPa. The dissolution of both glasses is governed by parabolic kinetics with run-lengths up to 14 days, and this is interpreted as being controlled by diffusion through a surface layer. This surface layer develops through incongruent dissolution of the glass and is enhanced by saturation of major components in solution and precipitation of secondary-mineral forms. The crystallinity of this alteration layer is increased by increasing time and temperature of the reaction. SEM and XRD analysis have indicated that at 100° and 150°C the layer is largely amorphous with traces of a poorly crystalline dioctahedral smectite. At 200°C the layer consists of fairly well crystallised smectite and at 350°C degradation of the glass is rapid and the solid reaction products are composed of a complex mineral assemblage including smectite, a lithium-sodium borosilicate hydrate, aegirine, riebeckite, albite, stillwellite, zektzerite and two barium molybdates. Some of these mineral phases incorporate and concentrate waste components, e.g., the zektzerite may contain up to 20 wt.% zirconium oxide, 2.5 wt.% caesium oxide and 0.7 wt.% uranium oxide. The rates of release of certain radionuclides have been investigated in granodiorite-waste glass-water systems. This study has revealed that the rate of release of a particular nuclide is a function of temperature and time. Caesium leach rates obtained in this manner are at least an order of magnitude lower than leach rates derived from refluxing dynamic leach tests. This is because incongruent dissolution of the glass, saturation of major components in solution and precipitation of mineral phases incorporating waste components in these closed-system experiments all serve to lower rates of radionuclide release. The work was carried out by N.E.R.C.-I.G.S. under contract to the U.K. Department of the Environment and the Commission of the European Communities.",https://doi.org/10.1016/0009-2541(82)90039-0,https://www.sciencedirect.com/science/article/pii/0009254182900390,,,,1982,Hydrothermal behaviour of simulated waste glass—And waste—Rock interactions under repository conditions,D. Savage and N.A. Chapman,article,SAVAGE198259,Chemical Geology,1,36,0009-2541,Geochemistry of Radioactive Waste Disposal,,
,,189-260,,"The study of the physical properties of alkali halide mixed crystals has been a subject of wide interest in the recent past. The main aim of this review is to provide a survey of the current state of knowledge about the nature of imperfections present and their role in understanding various properties associated with alkali halide mixed crystals. An attempt has been made to distinguish different types of mixed crystals, the conditions for the formation of a mixed crystal, the local strains that arise in the lattice due to the difference in the size of the ions that constitute the mixed crystal. The results obtained from various studies such as ionic conductivity, dielectric loss, microhardness, radiation hardening, colour centres, thermoluminescence, optical absorption etc. on alkali halide mixed crystals are presented. The non-linear variation of electrical conductivity, microhardness, half widths of many colour centre bands with composition have been discussed in terms of the concentration of various defects present in them. The aspects of the problem described include: 1.a) Dislocation density and distribution studies.2.b) Influence of dislocations and grain boundaries on transport properties of these crystals.3.c) Role of ionic size on microhardness.4.d) Lesser rate of hardening in mixed crystals due to irradiation.5.e) Stability of colour centres in mixed crystals in comparison with the end products, finally the present position and out look are summarized.",https://doi.org/10.1016/0146-3535(84)90002-9,https://www.sciencedirect.com/science/article/pii/0146353584900029,,,,1984,Growth and characterization of alkali halide mixed crystals,V.Hari Babu and U.V.Subba Rao,article,BABU1984189,Progress in Crystal Growth and Characterization,3,8,0146-3535,Special Issue on Alkali Halides,,
,,447-484,Phytopathogenic Prokaryotes,,https://doi.org/10.1016/B978-0-12-509002-5.50033-1,https://www.sciencedirect.com/science/article/pii/B9780125090025500331,,Academic Press,978-0-12-509002-5,1982,Chapter 21 - Preservation of Phytopathogenic Prokaryotes,JOHN P. SLEESMAN,incollection,SLEESMAN1982447,,,,,,Mark S. Mount and George H. Lacy,
,,211-252,,,https://doi.org/10.1016/0883-153X(94)90111-2,https://www.sciencedirect.com/science/article/pii/0883153X94901112,,,,1994,Tables of contents,,article,1994211,Polymer Contents,4,11,0883-153X,,,
,,503-536,,"The DNA of cotton, Gossypium hirsutum, has been characterized as to spectral characteristics, buoyant density in CsCl, base composition, and genetic complexity. The haploid genome size is found to bo 0.795 pg DNA/cell. However, the amount of DNA per cell in the cotyledons increases during embryogenesis to an average ploidy level of 12N in the mature seed cotyledons. Reassociation kinetics indicate that this increase is due to endoreduplication of the entire genome. Non-repetitive deoxynucleotide sequences account for approximately 60.5% of the cotton genome (C0t12pure¶¶Abbreviations used: C0t, product of DNA concentration (mol nucleotido l−1) × time(s); C0t12, that C0t value at which one-half of a kinetic component of DNA will have reassociated; C0t12 pure, that C0t value at which one-half of a kinetic component of DNA would have reassociated if only that component were present, calculated as the product of C0t12 × the fraction of the genome in that kinetic component; 5 MeC, 5-methylcytosine; rDNA, ribosomal RNA cistrons. = 437); highly repetitive sequences (> 10,000 repetition frequency) constitute about 7.7% of the genome. (C0t12 pure = 4.6 × 10−4) and intermediately repetitive sequences constitute the remaining 27% of the genome (C0t12 pure = 1.46). Hybridization of 125I-labeled cytoplasmic ribosomal RNA to whole-cell DNA on filters and in solution indicate approximately 300 to 350 copies of the rRNA cistrons per haploid genome. The interspersion of repetitive sequences that reassociate between C0t values of 0.1 and 50 with non-repetitive sequences of the cotton genome has been examined by determining the reassociation kinetics of DNA of varying fragment lengths and by the electron microscopy of reassociated molecules. About 60% of the genome consists of non-repetitive regions that average 1800 base-pairs interpersed with repetitive sequences that average 1250 base-pairs. Approximately 20% of the genome may be involved in a longer period interspersion pattern containing non-repetitive sequences of approximately 4000 base-pairs between repetitive sequences. Most of the individual sequences of the interspersed repetitive component are much smaller than the mass average size, containing between 200 and 800 base-pairs. Sequence divergence is evident among the members of this component. Highly repetitive sequence elements that are reassociated by a C0t value of 0.1 average 2500 base-pairs in length, appear to have highly divergent regions and do not appear to be highly clustered. A portion of this highly repetitive component reassociates by C0t = 10−4, zero-time binding DNA, and accounts for less than 3% of the genome. At least a third of these sequences appear by electron microscopy to be intramolecular duplexes (palindromes) of 150 to 200 base-pairs and to occur in clusters.",https://doi.org/10.1016/0022-2836(76)90242-4,https://www.sciencedirect.com/science/article/pii/0022283676902424,,,,1976,Developmental biochemistry of cotton seed embryogenesis and germination: VII. Characterization of the cotton genome,Virginia Walbot and L.S. Dure,article,WALBOT1976503,Journal of Molecular Biology,4,101,0022-2836,,,
Control and Dynamic Systems,,161-217,Advances in Theory and Applications,,https://doi.org/10.1016/B978-0-12-012717-7.50011-5,https://www.sciencedirect.com/science/article/pii/B9780120127177500115,,Academic Press,,1981,Stochastic Differential Game Techniquesa aThe material presented in this chapter was sponsored in part under an AFSOR grant.,B. MONS,incollection,MONS1981161,,,17,0090-5267,,C.T. LEONDES,
,,1-188,,,https://doi.org/10.1016/0014-5793(90)80357-O,https://www.sciencedirect.com/science/article/pii/001457939080357O,,,,1990,Index of biochemical reviews,,article,19901,FEBS Letters,,268,0014-5793,,,
,,159-194,Computer-Based Medical Consultations: Mycin,,https://doi.org/10.1016/B978-0-444-00179-5.50010-X,https://www.sciencedirect.com/science/article/pii/B978044400179550010X,,Elsevier,978-0-444-00179-5,1976,"Chapter 4 - Model of Inexact Reasoning in Medicine††Much of the material in this chapter has appeared in an article in Mathematical Biosciences [Shortliffe, 1975a]. That paper was co-authored with Dr. Bruce Buchanan who contributed substantially to the development of the model.",Edward Hance Shortliffe,incollection,SHORTLIFFE1976159,,,,,,Edward Hance Shortliffe,
,,594-612,,,https://doi.org/10.1016/S0041-3879(25)80094-1,https://www.sciencedirect.com/science/article/pii/S0041387925800941,,,,1925,Book notices and abstracts,,article,1925594,Tubercle,12,6,0041-3879,,,
,,A595-A621,,,https://doi.org/10.1016/S0011-7471(76)80007-1,https://www.sciencedirect.com/science/article/pii/S0011747176800071,,,,1976,Oceanographic bibliography: Part II,,article,1976A595,Deep Sea Research and Oceanographic Abstracts,"10, Supplement ",23,0011-7471,,,
,,105-166,,"This study of waterlain glaciogenic sediments is designed to present both a review and new information on glaciogenic subaquatic deposits of differing age in a number of localities in North and South America and South Africa. The Late Paleozoic glaciogenic deposits of the Parana´Basin in Brazil and the Karoo Basin of South Africa are singled out for special attention as they show a reasonably complete lateral sequence of terrestrial to off-shore glaciogenic sedimentation. Although the environment of subaquatic glaciogenic sedimentation varies from one area to the next, certain common elements are found which can be used to develop a generalized model for both glaciomarine and glaciolacustrine sedimentation. For descriptive purposes, the model is divided into two broad categories: a shelf facies and a basinal facies. The shelf facies is marked by massive diamicton(ite) which may be 200 m or more in thickness and which is frequently overlain by a complex of clastic sediments consisting primarily of gravity and fluid flows. The basinal facies is marked by products of subaquatic slumps and more distal turbidites and glaciomarine sediments. New terminology is introduced. The massive diamicton(ite), which is diagnostic of the shelf facies, probably represents deposition from the base of active ice in a subaquatic environment and is termed undermelt diamicton(ite). The gravity and fluid flows which are usually found overlying undermelt diamicton(ite) and in the basinal facies are subdivided into six categories: glaciogenic subaquatic outwash, glaciogenic suspension flow, glaciogenic chaotic debris flow, glaciogenic subaquatic debris flow, glaciogenic slurry flow and glaciogenic turbidity flow. The relative abundance of undermelt diamicton(ite) and the various types of gravity and fluid flows can be used to define inner shelf, outer shelf, inner basin and outer basin facies of glaciomarine sedimentation.",https://doi.org/10.1016/0012-8252(84)90023-0,https://www.sciencedirect.com/science/article/pii/0012825284900230,,,,1984,"Nature and classification of waterlain glaciogenic sediments, exemplified by Pleistocene, Late Paleozoic and Late Precambrian deposits",C.P. Gravenor and V. {von Brunn} and A. Dreimanis,article,GRAVENOR1984105,Earth-Science Reviews,2,20,0012-8252,,,
,"kidney calculi, lithotripsy",699-702,,"Ureteral stents reduce complications after extracorporeal shock wave lithotripsy (ESWL**Dornier Medical Systems, Inc., Marietta, Georgia.) and contribute to successful stone passage. However, some reports note complications that are attributed to indwelling ureteral stents. We randomized 64 patients with large renal calculi (stone burden more than 200mm.2) for in situ treatment or treatment with a prophylactically inserted stent. We used a 6Ch round stent with single-coiled ends or a triangular shaped stent with double-coiled ends. Patients were treated with a Siemens Lithostar lithotriptor.† After 3 months we evaluated the results of treatment and post-ESWL morbidity. Of the in situ group (23 patients) treatment complications consisted of fever in 3, pyelonephritis in 1 and steinstrasse in 3. After 3 months 8 patients (35%) were free of stones. Of the stented population (41 patients) treatment complications consisted of fever in 7, pyelonephritis in 1, steinstrasse in 6 and bladder discomfort in almost half of the patients. Stent calcification and stent migration were also seen in 7 and 10 patients, respectively. Calcified stents had been in situ longer than noncalcified stents. The round stents migrated and calcified more often than the more rigid triangular stents. After 3 months 18 of the stented patients were stone-free (44%). We conclude that ureteral stents do not reduce post-ESWL complications. They are clearly associated with morbidity and do not improve stone passage markedly. Therefore, patients with a stone burden of more than 200mm.2 should be treated in situ without auxiliary stenting.",https://doi.org/10.1016/S0022-5347(17)38428-8,https://www.sciencedirect.com/science/article/pii/S0022534717384288,,,,1991,Extracorporeal shock wave lithotripsy for large renal calculi: The role of ureteral stents. A Randomized Trial,Alexander F. Bierkens and AD J.M. Hendrikx and Wim A.J.G. Lemmens and Frans M.J. Debruyne,article,BIERKENS1991699,The Journal of Urology,4,145,0022-5347,,,
,,39-56,,,https://doi.org/10.1016/0003-4843(78)90007-4,https://www.sciencedirect.com/science/article/pii/0003484378900074,,,,1978,Compactness for omitting of types,Miroslav Benda,article,BENDA197839,Annals of Mathematical Logic,1,14,0003-4843,,,
,,123-254,,"Goodland, R.J.A. and Irwin, H.S., 1974. An ecological discussion of the environmental impact of the highway construction program in the Amazon Basin. Landscape Plann., 1: 123–254. Started in 1970, the 6 368 km Transamazônica, the 2 465 km Perimetral Norte and the 1 747 km Cuiabá—Santarém highways lacerating the Amazon jungle are now nearing completion. Large-scale cattle ranching and peasant agriculture by thousands of government-assisted settlers are being officially hastened along these highways. The likely environmental consequences of these activities is discussed. Human ecology and nosogeography. Diseases likely to increase due to increase in vectors; vectors encouraged by construction methods; route planning and known disease foci; effect of settlements, deforestation and agriculture on disease. Malaria, onchocerciasis, schistosomiasis, trypanosomiasis and verminoses: relation between indigenous and alloch-thonous human populations; remediation. Amerindians. Lack of information on location and numbers even of already contacted tribes. Tribes to be disturbed by highways; governmental policy and the constitution. Effect of relocation on survival, national parks, disease, sedentary vs nomadic habits, money economy and education. Ecological perceptions and abilities of the Amerindian; their potential role in Amazonia. Deforestation and agriculture. Direct and closed nutrient cycles in tropical wet forest, implications for vegetational management. Methods and degree of extirpation: erosion, laterization, decreased fertility. Pests and weeds competing with crops; adverse effects of fertilizer; lack of dry season or winter. Climatic change. Sustainable agroecosystems; fish, riparian communities, mixed tree plantations and refining methods. Ecological considerations of cattle raising. Fauna and faunation. Unknown, rare and endangered taxa; occurrence, value and preservation, state of knowledge, population equilibria of pests, disease vectors, rodents. Role of faunation in nutrient dynamics. Use of faunation in forest ecosystem harvest and raising of indigenous fauna. Flora and vegetation. Physiognomic types of vegetation; undiscovered species and their characteristics; species extinction by exploitation, regeneration of forest, conservation areas.",https://doi.org/10.1016/0304-3924(74)90018-5,https://www.sciencedirect.com/science/article/pii/0304392474900185,,,,1974,An ecological discussion of the environmental impact of the highway construction program in the Amazon basin,R.J.A. Goodland and Howard S. Irwin,article,GOODLAND1974123,Landscape Planning,,1,0304-3924,,,
,,65-137,,"Adhesion between biological cells and various surfaces is explained in terms of various models, including coagulation at primary or secondary minima of free energy, macromolecular bridges or matrices, and specialized structures at the surfaces of some cells. These models are used to predict the magnitudes of force necessary to detach a cell in the limiting cases of peeling and simultaneous separation over finite areas of contact. Diverse experimental assays of cellular adhesiveness are reviewed and the forces applied to individual cells are estimated. A very wide range of the forces applied to cells in different assays suggests that different mechanisms of bonding are dominant for different types of cells and surfaces under various conditions of growth and chemical environment. The peeling mode of separation is most consistent with the magnitudes of applied force used experimentally in the detachment of cells.",https://doi.org/10.1016/0079-6816(81)90009-5,https://www.sciencedirect.com/science/article/pii/0079681681900095,,,,1981,Adhesion and detachment of biological cellsin vitro,Martin A. Hubbe,article,HUBBE198165,Progress in Surface Science,2,11,0079-6816,,,
Advances in Pharmacology,,1-52,,"Publisher Summary
This chapter discusses the hereditary factors causing clinically significant variations in human responsiveness to drugs and the substantial advances made in pharmacogenetics. Along with past much recent work that has been reviewed in the chapter is devoted to these genetically transmitted conditions, but only a few new examples have been described. In the chapter, the term pharmacogenetics is applied to clinically significant consequences of hereditary variations in the handling of drugs. The chapter deals mainly with an increasing body of data on the defects in human and only tangentially with the very large literature, concerning animal experiments. Search for hereditary variations, affecting the way the body handles drugs, has until recently turned up almost exclusively traits inherited as single factors— that is, traits produced by point mutations at a single genetic locus and transmitted, either as Mendelian dominants or recessives. Investigation of the responsiveness of the general population to a drug in terms of the amount of a drug required to produce a given effect may take the form of a continuous unimodal distribution curve or of a discontinuous polymodal curve. Until recently, studies of drug responses that yield a normal or continuous distribution curve have been almost entirely ignored in pharmacogenetic investigations. To construct unimodal, Gaussian distribution curves large populations are required. Furthermore, genotypes are hard to deduce from such curves. In contrast, discontinuous, bimodal, or trimodal curves of response obtained from disorders transmitted as Mendelian dominants or recessives are more easily analyzed because each discrete curve generally corresponds to a different genotype.",https://doi.org/10.1016/S1054-3589(08)60558-X,https://www.sciencedirect.com/science/article/pii/S105435890860558X,,Academic Press,,1970,Recent Progress in Pharmacogenetics,Elliot S. Vesell,incollection,VESELL19701,,,7,1054-3589,,Silvio Garattini and A. Goldin and F. Hawking and I.J. Kopin,
,,328-389,Steroids in Nonmammalian Vertebrates,,https://doi.org/10.1016/B978-0-12-370350-7.50010-8,https://www.sciencedirect.com/science/article/pii/B9780123703507500108,,Academic Press,978-0-12-370350-7,1972,"Chapter 6 - ANDROGENS IN FISHES, AMPHIBIANS, REPTILES, AND BIRDS",R. OZON,incollection,OZON1972328,,,,,,David R Idler,
,,153-300,,,https://doi.org/10.1016/j.prp.2005.03.001,https://www.sciencedirect.com/science/article/pii/S0344033805000518,,,,2005,Abstracts DGP Wuppertal 2005,,article,2005153,Pathology - Research and Practice,3,201,0344-0338,,,
,,1-28,Contemporary Practice of Chromatography,,https://doi.org/10.1016/B978-0-444-42410-5.50004-3,https://www.sciencedirect.com/science/article/pii/B9780444424105500043,Amsterdam,Elsevier,978-0-444-42410-5,1984,Chapter 1 - FUNDAMENTAL RELATIONSHIPS OF CHROMATOGRAPHY,Colin F. Poole and Sheila A. Schuette,incollection,POOLE19841,,,,,,Colin F. Poole and Sheila A. Schuette,
,,287-320,,"This paper presents an extension of the Nelson-Winter model of Schumpeterian competition that focuses on certain features of the ‘historical’ shape of industry evolution, particularly on the relative importance of entrants and established firms as sources of innovation.",https://doi.org/10.1016/0167-2681(84)90004-0,https://www.sciencedirect.com/science/article/pii/0167268184900040,,,,1984,Schumpeterian competition in alternative technological regimes,Sidney G. Winter,article,WINTER1984287,Journal of Economic Behavior & Organization,3,5,0167-2681,,,
,,1470-1482,,,https://doi.org/10.1016/0016-5085(79)90418-9,https://www.sciencedirect.com/science/article/pii/0016508579904189,,,,1979,Hormonal control of rat liver regeneration,H.L. Leffert and K.S. Koch and T. Moran and B. Rubalcava,article,LEFFERT19791470,Gastroenterology,6,76,0016-5085,,,
,,91-116,,"Stable-isotopic, clay-mineralogic, and bulk-chemical analyses were conducted on paleosols of the Neogene Siwalik sections in northern Pakistan in order to reconstruct floodplain environments over the past ∼ 17 Ma. The stable carbon isotopic composition of soil carbonate (mean δ13C (PDB) = -10.2%) and associated organic matter (mean δ13C (PDB) = −24.1%) in paleosols representing 17− ∼ 7.3 Ma reveal that floodplain vegetation was dominated by C3 plants. At 7.3 Ma, a shift toward more positive carbon isotopic values began, signaling the gradual expansion of C4 grasses onto the floodplain. From 6 Ma to present, carbon isotopic values for paleosol carbonate (mean δ13C (PDB) = +0.6%) and organic matter (mean δ13C (PDB) = −14.4%) are uniformly enriched in 13C, indicating the presence of nearly pure C4 grassland. The scarcity of kaolinite and abundance of smectite and pedogenic carbonate in most paleosols suggest that rainfall in the region remained 1.0–1.25 m/yr or less for the entire 17 Ma of record. Paleosols in the lower portion of the section lack organic A horizons but have reddish B horizons often containing secondary iron-oxide nodules. Leaching depths of soil carbonate in these older paleosols are typically greater than those in the Plio-Pleistocene part of the section, where organic A horizons are common, and B horizons are markedly more yellow. The combined evidence suggests that the mature paleosols in the pre-7.3 Ma part of the record are dominantly calcareous Alfisols or Mollisols that once underlay nearly pure C3 vegetation, perhaps trees and shrubs, while calcareous Mollisols underlying C4 grassland dominate the upper part of the record. The carbon- and oxygen-isotopic trends in the paleosol record in Pakistan are also evident in the diet of fossil mammals, and in paleosols from Nepal, thus demonstrating that these paleoenvironmental changes in floodplain vegetation may be continent-wide. Local effects, such as the development or intensification of the Asian Monsoon driven by uplift of the Tibetan Plateau, may have led to the expansion of C4 grasses. If, however, the expansion of C4 grasses proves globally synchronous, then a larger scale cause, such as a marked decrease in ϱCO2, may be the driving mechanism.",https://doi.org/10.1016/0031-0182(94)00108-K,https://www.sciencedirect.com/science/article/pii/003101829400108K,,,,1995,Expansion of C4 grasses in the Late Miocene of Northern Pakistan: evidence from stable isotopes in paleosols,Jay Quade and Thure E. Cerling,article,QUADE199591,"Palaeogeography, Palaeoclimatology, Palaeoecology",1,115,0031-0182,Long Records of Continental Ecosystems: Paleogene of Wyoming-Montana and Neogene of Pakistan,,
,,ii-xxiii,,,https://doi.org/10.1016/0143-4179(83)90041-0,https://www.sciencedirect.com/science/article/pii/0143417983900410,,,,1983,"Monthly bibliography on Neuropeptides prepared by the University of Sheffield Biomedical Information Service Sheffield S10 2TN, England",,article,1983ii,Neuropeptides,6,3,0143-4179,,,
,"Cross-correlation, FORTRAN, Marine geoacoustics",75-100,,"Cross-correlation is a method used for comparing two similar signals. CRSCOR is a general purpose program which integrates three tasks: the management, cross-correlation, and graphical display of signals and cross-correlation functions on a PC workstation. Program variables relating to these tasks may be changed through menus thereby precluding the need for recompiling and relinking. Cross-correlation is performed by Fast Fourier Transform with optional use of an 8087 math coprocessor for increasing throughput. The program has a modular architecture with 46 subroutines which simplifies modification of source code if necessary. CRSCOR was developed as part of an overall study of acoustical signals which have interacted with the ocean bottom. From data collected over the continental rise east of Cape Hatteras, tests were conducted on a series of signals from adjacent bottom paths with the grazing angle of each path differing by about 0.3°. Each member of the series was cross-correlated with the first member. Peak values of the cross-correlation function obtained from unfiltered signals were significantly lower than were the peak values from the band-pass filtered (90–200 Hz) versions of these signals indicating that the high-frequency spectrum is more sensitive to path grazing angle than the lower frequency spectrum.",https://doi.org/10.1016/0098-3004(90)90078-8,https://www.sciencedirect.com/science/article/pii/0098300490900788,,,,1990,An interactive fortran program for crosscorrelation of signals on a PC with CGA graphics: an application in marine geoacoustics,Roddy V. Amenta,article,AMENTA199075,Computers & Geosciences,1,16,0098-3004,,,
,,53-109,Introduction to Biophysical Methods for Protein and Nucleic Acid Research,"Publisher Summary
There are various techniques for separating proteins and nucleic acids based on their chemical and physical properties. In particular, the intrinsic charges of proteins and nucleic acids are much exploited in biochemistry. Electrophoresis, isoelectric focusing, ion-exchange chromatography, and mass spectrometry use the characteristic charges of molecules to separate them. Electrophoresis is the motion of charged particles in externally applied electric fields. Electrophoresis is the highest resolution method available for the separation of proteins and nucleic acids. Gel electrophoresis is the most used electrophoretic technique. Electrophoresis evolved from Tiselius' fundamentally simple moving boundary technique in a free solution to one- and two-dimensional gel systems is capable of exquisite resolution of highly complex mixtures. Sophisticated capillary instruments with online detection bring automation to the analytical processes. Most kinds of electrophoresis are relatively inexpensive and easy to perform, and the results are easy to interpret. It is not possible to obtain quantitative structural data from electrophoresis, but valuable qualitative information about the relative charges and sizes of macromolecules can be acquired from it.",https://doi.org/10.1016/B978-012286230-4/50003-1,https://www.sciencedirect.com/science/article/pii/B9780122862304500031,San Diego,Academic Press,978-0-12-286230-4,1995,Chapter 2 - Electrophoretic Methods,David E. Garfin,incollection,GARFIN199553,,,,,,Jay A. Glasel and Murray P. Deutscher and Murray P. Deutscher,
,,315-361,,,https://doi.org/10.1016/0304-3479(80)90019-8,https://www.sciencedirect.com/science/article/pii/0304347980900198,,,,1980,К определению стиля модерн в русской и чешской поэзии,Моймир Григар,article,GRIGAR1980315,Russian Literature,4,8,0304-3479,,,
American College of Laboratory Animal Medicine,,335-374,Nonhuman Primates in Biomedical Research,"Publisher Summary
Effective maintenance of breeding colonies of nonhuman primates is based on a number of factors. The first of these is the basic knowledge of the reproductive physiology of the species involved. The status of nonhuman primate research is such that there are often large gaps in breeding knowledge, particularly in the species that are not normally held in captivity or are heavily involved in research programs. For effective breeding of these animals, it must rely on reports from zoological gardens and private or commercial colonies. Field studies of the animal's activities in the wild are very useful in establishing breeding colonies. The final factor is the common sense husbandry that individuals acquire through work with a large variety of animals in captive situations. This chapter discusses the methods that have been used to breed a variety of species in domestic and international facilities. It also discusses the detection and monitoring of pregnancy, and prenatal growth and development.",https://doi.org/10.1016/B978-012088661-6/50021-1,https://www.sciencedirect.com/science/article/pii/B9780120886616500211,San Diego,Academic Press,978-0-12-088661-6,1995,Chapter 14 - Breeding,Andrew G. Hendrickx and W. Richard Dukelow,incollection,HENDRICKX1995335,,,,,,B. Taylor Bennett and Christian R. Abee and Roy Henrickson,
,,104247,,,https://doi.org/10.1016/j.orggeochem.2021.104247,https://www.sciencedirect.com/science/article/pii/S0146638021000681,,,,2021,GEOCHEMISTRY ARTICLES – April 2021,,article,2021104247,Organic Geochemistry,,161,0146-6380,,,
,,465-500,Nanocolloids,,https://doi.org/10.1016/B978-0-12-801578-0.18001-4,https://www.sciencedirect.com/science/article/pii/B9780128015780180014,Amsterdam,Elsevier,978-0-12-801578-0,2016,Author Index,,incollection,2016465,,,,,,M. Sánchez Domínguez and C. Rodríguez Abreu,
Developments in Plant Genetics and Breeding,,423-441,Isozymes,,https://doi.org/10.1016/B978-0-444-42227-9.50024-X,https://www.sciencedirect.com/science/article/pii/B978044442227950024X,,Elsevier,,1983,Eucalyptus,GAVIN F. MORAN and J. CHARLES BELL,incollection,MORAN1983423,,,1,0168-7972,,Steven D. Tanksley and Thomas J. Orton,
,,305-321,,"The design of core support structures of a pressurized water reactor requires the solution of structural problems with a degree of sophistication that is not usual to other types of power generating plants. This situation arises not only from the complexity of both the structures and the external loads, but also from safety specifications requiring a precise knowledge of component behavior. The analytical problems derived from normal and abnormal operation covers a wide range of static and dynamic problems. Extensive use of modern, high-speed computing tools is required to solve these problems. Linear and nonlinear analyses for static and dynamic problems use computer programs of varied complexity, leading to the use of newly developed techniques in the area of finite elements and numerical stability of integration methods. The present paper reviews the existing type of analytical problems faced in design, and the methods used to solve them.",https://doi.org/10.1016/0029-5493(72)90146-X,https://www.sciencedirect.com/science/article/pii/002954937290146X,,,,1972,Analytical problems associated with core support structure of PWR,George J. Böhm,article,BOHM1972305,Nuclear Engineering and Design,2,18,0029-5493,,,
,,179-184,,,https://doi.org/10.1016/S0008-6215(00)87098-6,https://www.sciencedirect.com/science/article/pii/S0008621500870986,,,,1979,Professor Roy L. Whistler,James N. BeMiller,article,BEMILLER1979179,Carbohydrate Research,2,70,0008-6215,,,
,,1-25,,,https://doi.org/10.1016/j.mambio.2012.07.005,https://www.sciencedirect.com/science/article/pii/S1616504712000869,,,,2012,"86th Annual Conference of the German Society of Mammalogy (Deutsche Gesellschaft für Säugetierkunde e.V.) Frankfurt a.M., 4th–8th September 2012",,article,20121,Mammalian Biology,,77,1616-5047,,,
,", Apoeynaceae, coronaridine, voacristine, tabernaemontanine, dregamine, α-amyrin acetate, lupeol acetate, α-amyrin, lupeol, sitosterol.",1652-1653,,,https://doi.org/10.1016/0031-9422(75)85375-1,https://www.sciencedirect.com/science/article/pii/0031942275853751,,,,1975,Terpenoids and alkaloids of the leaves of Tabernaemontana coronaria,Bani Talapatra and Amarendra Patra and Talapatra {Sunil K},article,TALAPATRA19751652,Phytochemistry,7,14,0031-9422,,,
,,e1-e216,,,https://doi.org/10.1016/S2213-1779(24)00002-7,https://www.sciencedirect.com/science/article/pii/S2213177924000027,,,,2024,Full Issue PDF,,article,2024e1,JACC: Heart Failure,2,12,2213-1779,,,
,,703-807,Encyclopedia of Information Systems,,https://doi.org/10.1016/B0-12-227240-4/00202-1,https://www.sciencedirect.com/science/article/pii/B0122272404002021,New York,Elsevier,978-0-12-227240-0,2004,Subject Index,,incollection,2004703,,,,,,Hossein Bidgoli,
,,31-46,,"An attempt was made to analyze what types of adrenergic receptors are involved in the mechanisms for aqueous humour production and drainage and to determine the maximum effects of these receptors. The parameters determined were: mean arterial blood pressure, intraocular pressure, rate of aqueous flow via Schlemm's canal, rate of flow through uvcoscleral routes and gross facility of outflow. The recipient venous pressure was calculated. Isoproterenol, 0·1 and 1·0 μg/ml, perfused through the anterior chamber increased the rate of aqueous humour production and the gross facility of outflow and tended to increase the rate of uveoscleral drainage of aqueous humour. A dose of 10 μg/ml produced more variable results than the lower doses. Norepinephrine perfused through the anterior chamber at a dose of 1 or 10 μg/ml had no significant effect on the gross facility of outflow or the rate of aqueous formation. Neither isoproterenol nor norepinephrine had statistically significant effects on the intraocular pressure and the recipient venous pressure. Stimulation of the cervical sympathetic nerves to the eye gave a probably significant increase in the rate of aqueous humour formation. After beta-receptor blockade with propranolol, 5 mg/kg, neither the effects on the rate of aqueous formation nor those on the facility of outflow could be elicited. The results suggest that there are adreuergic beta-receptors in the ciliary processes and in the chamber angle of the monkey eye which stimulate the secretion of aqueous humour and increase the facility of outflow, respectively. The average effect of maximum adrenergic beta-receptor stimulation was to increase the rate of aqueous formation by about 30% and to raise the facility of outflow by about 55%.",https://doi.org/10.1016/S0014-4835(70)80006-9,https://www.sciencedirect.com/science/article/pii/S0014483570800069,,,,1970,"Effects of norepinephrine, isoproterenol and sympathetic stimulation on aqueous humour dynamics in vervet monkeys",Anders Bill,article,BILL197031,Experimental Eye Research,1,10,0014-4835,,,
,,iii-xxix,,,https://doi.org/10.1016/0045-6535(89)90277-4,https://www.sciencedirect.com/science/article/pii/0045653589902774,,,,1989,"Subject and author index vol. 19, 1989",,article,1989iii,Chemosphere,,19,0045-6535,,,
,,489-500,,,https://doi.org/10.1016/S0144-8617(09)00086-1,https://www.sciencedirect.com/science/article/pii/S0144861709000861,,,,2009,Bibliography,,article,2009489,Carbohydrate Polymers,3,76,0144-8617,,,
Elsevier Oceanography Series,,275-350,The Baltic Sea,"Publisher Summary
The evolution of the contemporary fish fauna of the Baltic Sea has been mostly influenced by (1) changeability of environmental conditions during the short history of this sea, (2) horizontal and vertical configuration of the Baltic Sea, determining its brackish-water character, with dominating two-layered water mass, as well as the character of currents, and (3) climate. The main components of the contemporary fish fauna of the Baltic Sea, the arctic, marine-boreal, anadromous, katadromous, and fresh-water fishes, have immigrated into this sea at different times by various ways. Marine species in the Baltic Sea could have adapted mainly eurihaline species being capable to endure a relatively low temperature. The species composition of its fish fauna was probably different. It is probable that, especially during the Litorina time with the warmest climate and the highest salinity in the history of the Baltic Sea, a number of marine fishes immigrated into the Baltic basin. Because of environmental conditions in the Baltic Sea, a characteristic distribution of fishes has become established. Because of a low content or absence of oxygen in the bottom layers of the deep areas, the fishes are periodically or permanently absent. In the northern part of the Baltic Sea, mainly plankton eating herring and sprat, are constantly abundant and to a smaller degree also the flounder. In the southern and southwestern Baltic Sea, more marine fishes including benthos-eaters and predatory fishes are relatively abundant.",https://doi.org/10.1016/S0422-9894(08)70143-0,https://www.sciencedirect.com/science/article/pii/S0422989408701430,,Elsevier,,1981,Chapter 6 Fishes and Fisheries,Evald Ojaveer and Arne Lindroth and Ole Bagge and Hannu Lehtonen and Jorma Toivonen,incollection,OJAVEER1981275,,,30,0422-9894,,Aarno Voipio,
,,1-67,,,https://doi.org/10.1016/S0304-3479(89)80020-1,https://www.sciencedirect.com/science/article/pii/S0304347989800201,,,,1989,Дешифровка,Jerzy Faryno,article,FARYNO19891,Russian Literature,1,26,0304-3479,The Russian Avant-Garde XXXIII The Zagreb Symposia IX,,
,,84-97,,"Polyribosomes prepared from both the membrane (bound polyribosomes) and cytoplasmic (free polyribosomes) fractions of tobacco mosaic virus (TMV)-infected tobacco leaves were found to contain small RNAs of several sizes which, by molecular hybridization with denatured double-stranded TMV-RNA, were shown to consist of portions of the TMV-RNA genome. In addition, full-length (30 S) TMV-RNA was found on the free but not the bound polyribosomes. These RNAs were associated with all sizes of polyribosomes as analyzed on sucrose gradients, with the larger species of RNA predominating the regions containing the larger polyribosomes. A heterogeneous population of replicative intermediate molecules was associated with the bound, but not the free polyribosomes. Here, too, the molecules were distributed throughout the polyribosome gradient. The possible functions of the ribosome-associated RNAs as messenger RNAs for viral-coded proteins are discussed.",https://doi.org/10.1016/0042-6822(75)90373-6,https://www.sciencedirect.com/science/article/pii/0042682275903736,,,,1975,Replication of tobacco mosaic virus: VI. Replicative intermediate and TMV-RNA-related RNAs associated with polyribosomes,Roger N. Beachy and Milton Zaitlin,article,BEACHY197584,Virology,1,63,0042-6822,,,
,"Tomato, TYLCV, Molecular biology, Whitefly transmission, Control methods, Genetic improvement",151-196,,"Tomato yellow leaf curl geminivirus (TYLCV), transmitted by the whitefly Bemisia tabaci (Gennadius) is one of the most devastating diseases of cultivated tomato (Lycopersicon esculentum Mill.). TYLCV causes economic losses up to 100% in tomato crop in many tropical and subtropical regions, and is spreading towards new areas. The increasing economic importance of TYLCV has resulted in the need for accurate detection and identification procedures, stimulating intensive research efforts focused on virus biology, diversity, and epidemiology to develop successful control strategies. Breeding for resistance appears to be the best approach to control this disease, but to date only partially resistant hybrids are commercially available. Search for new sources of disease resistance needs to be intensified. The purpose of this paper is to collect and summarize all these efforts, offering an updated review of these new approaches on virus transmission, molecular biology, variability, diagnostic methods, and potential ways to control. This will lead to a better understanding of the virus-vector-host relationships, key factors in the adoption of disease control measures.",https://doi.org/10.1016/S0304-4238(96)00945-4,https://www.sciencedirect.com/science/article/pii/S0304423896009454,,,,1996,Viral diseases causing the greatest economic losses to the tomato crop. II. The Tomato yellow leaf curl virus — a review,Belén Picó and María José Díez and Fernando Nuez,article,PICO1996151,Scientia Horticulturae,3,67,0304-4238,,,
,,241-264,,"The Symposium was devoted primarily to the visual mechanism. In the selection of the 34 participants an effort was made to represent the various disciplines, which nowadays are brought to bear on the elucidation of the processes taking place in the photoreceptor cell upon illumination. In this report the abstracts of each of the individual papers are presented together with highlights of the discussion. These are followed by transcribed and edited reports of four Round Table Discussions on the topics:o1.Current insights in visual pigment structure. (Chairman: C. D. Bridges)2.Which step in the photolytic cycle is responsible for the visual excitation mechanism? (Chairman: E. W. Abrahamson)3.Present status of the three hypotheses proposed for the visual excitation process. (Chairman: B. Rosenberg)4.Relation between photolytic and electrophysiologic events. (Chairman: S. L. Bonting)",https://doi.org/10.1016/S0014-4835(69)80037-0,https://www.sciencedirect.com/science/article/pii/S0014483569800370,,,,1969,Report on the symposium on the biochemistry of the retina,S.L. Bonting and F.J.M. Daemen,article,BONTING1969241,Experimental Eye Research,2,8,0014-4835,,,
,,291-496,,,https://doi.org/10.1016/j.imbio.2004.09.001,https://www.sciencedirect.com/science/article/pii/S0171298504000828,,,,2004,"Joint Annual Meeting of the German and Dutch Societies for Immunology (JAMI) (20-23 October 2004, Maastricht, the Netherlands)",,article,2004291,Immunobiology,4,209,0171-2985,,,
,,195-291,,,https://doi.org/10.1016/0098-2997(94)90042-6,https://www.sciencedirect.com/science/article/pii/0098299794900426,,,,1994,Prions and related neurological diseases,Maurizio Pocchiari,article,POCCHIARI1994195,Molecular Aspects of Medicine,3,15,0098-2997,,,
,"British Heterobasidiomycetes, , New species",94-108,,"Accounts are given of the following members of the Auriculariales: Eocronartium muscicola Herpobasidium filicinum and Helicogloea lagerheimii; additional localities for Hirneola auricula-judae var. laciea are also listed; and members of the Tremellales: Tremella steidleri which is new to Britain Stypella versiformis, Protodontia subgelatinosa and P. ellipsospora n.sp. Additional localities for Heterochaetella dubia are also cited.",https://doi.org/10.1016/S0953-7562(09)81269-0,https://www.sciencedirect.com/science/article/pii/S0953756209812690,,,,1990,New or interesting records of British Heterobasidiomycetes,Derek A. Reid,article,REID199094,Mycological Research,1,94,0953-7562,,,
,,I-CXVI,,,https://doi.org/10.1016/S2452-302X(24)00124-4,https://www.sciencedirect.com/science/article/pii/S2452302X24001244,,,,2024,Full Issue PDF,,article,2024I,JACC: Basic to Translational Science,4,9,2452-302X,,,
,,1-25,,"In this inquiry the author confronts the historiographical view of the rise of the Capetians to power, as represented by the Historia Francorum Senonensis, with historical reality. He comes to the conclusion that the medieval historian, writing in the thirties of the eleventh century, sought by the selection, combination, interpretation, and presentation of his passages to propagate a view which had originated at the archbishop's court at Sens. The actual political motive was the dispute of Sens with Reins over coronation rights; it was this that explains the anti-Capetian tendency of the author's account of the dynastic change in 987. Moreover, it is possible to discern a political consciousness which was able to consider the West-Frankish/French monarchy as independent from dynastic considerations. We are thus dealing not with a historiographical statement of the Carolingian point of view, but with the reaction to a particular situation in ecclesiastical politics combined with a non-personal theory of the state.",https://doi.org/10.1016/0304-4181(78)90038-6,https://www.sciencedirect.com/science/article/pii/0304418178900386,,,,1978,Die historia francorum senonensis und der Aufstieg des Hauses Capet,Joachim Ehlers,article,EHLERS19781,Journal of Medieval History,1,4,0304-4181,,,
,,61-78,,,https://doi.org/10.1016/j.biopsycho.2016.04.010,https://www.sciencedirect.com/science/article/pii/S0301051116301077,,,,2016,"International Society for Advancement of Respiratory Psychophysiology. Proceedings of the annual meeting September 19–21, 2014",,article,201661,Biological Psychology,,118,0301-0511,,,
Annual Reports on Fermentation Processes,,213-356,,"Publisher Summary
This chapter discusses microbial biomass (MB), which, as a source of nutrients, is receiving worldwide attention. Microbes can be grown in renewable and synthetic substrates, and the resulting biomass can be employed as a nutrient source as produced or after processing through animal feed rations or in processed food products. The imminent world food crisis has encouraged research and development activities related to the production and processing of MB. The standard process for MB production as developed for large-scale capital intensive operations consists of a single-species operation carried out in synthetic substrates, where biomass is reproduced aerobically and continuously in a highly diluted aqueous media under mesophilic temperatures and in large-scale plants. This operation is followed by cell recovery, washing, and drying where a nonviable, easily stored biomass powder is obtained. There is repetitive research work that does not produce new insights to process development; however, there have been outstanding new ideas brought to the general attention, which have increased the number of process alternatives available.",https://doi.org/10.1016/B978-0-12-040307-3.50013-5,https://www.sciencedirect.com/science/article/pii/B9780120403073500135,,Elsevier,,1984,Chapter 8 - Microbial Biomass from Renewables: A Second Review of Alternatives,Carlos Rolz,incollection,ROLZ1984213,,,7,0140-9115,,GEORGE T. TSAO,
,,293-320,,,https://doi.org/10.1016/0016-0032(48)90727-3,https://www.sciencedirect.com/science/article/pii/0016003248907273,,,,1848,English and foreign mining glossary,,article,1848293,Journal of the Franklin Institute,4,45,0016-0032,,,
Applied Biochemistry and Bioengineering,,189-280,Immobilized Microbial Cells,"Publisher Summary
This chapter discusses immobilized living cells, their advantages, and their applications in industry. Over the past two decades, there have been rapid developments in the use of enzymes as catalysts for industrial, analytical, and medical purposes and a new field of research called enzyme technology. Current and industrial applications of continuous single-enzyme reactions are carried out using immobilized microbial cells. Immobilized living cells should be preferred to immobilized enzymes for degradative and synthetic reactions in industry; another major advantage of immobilized cells is that the operational stability of the immobilized living cells may often be greatly enhanced by the regeneration of the enzyme activities of the immobilized cells. The use of immobilized cells enables greater control throughout the reaction. The applications of immobilized living cells are not limited to the production of chemical fermentation products but have been extended to the production of viral particles or synchronous cells, the chromatographic separation of special cells, the culturing of animal tissue, and, more recently, the immobilization and use of plant cells in the production of alkaloids.",https://doi.org/10.1016/B978-0-12-041104-7.50011-7,https://www.sciencedirect.com/science/article/pii/B9780120411047500117,,Elsevier,,1983,Immobilized Living Cells and Their Applications,John F. Kennedy and Joaquim M.S. Cabral,incollection,KENNEDY1983189,,,4,0147-0248,,Ichiro Chibata and Lemuel B. Wingard,
,,335-406,,"In this study I integrate marine and continental biostratigraphy, magnetic polarity stratigraphy, and radioisotopic chronology in a synthetic correlation of middle Eocene strata from the western United States. More than 2000 m of section were sampled from volcaniclastic deposits, Aycross and Tepee Trail Formations (northwestern Wyoming); lacustrine and fluviatile deposits, Washakie Formation (southwestern Wyoming); and intertonguing marine and continental strata, La Jolla and Poway Groups (San Diego area, California). Detailed demagnetization studies on numerous pilot samples from all three field areas revealed moderately complex magnetizations. Most sample NRM's are dominated by a strong normal polarity magnetic component; alternating field demagnetization does not consistently isolate the primary magnetization. High blocking temperature hematite is frequently a significant carrier of remanence. Therefore, most samples were subjected to detailed, stepwise alternating field and thermal demagnetization to 600–650°C. The East Fork Basin area (northwestern Wyoming) magnetic polarity sequence consists of five major polarity intervals, A- to E-; the thick Washakie Formation sequence contains four, A+ to D-; and the San Diego area sequence has four polarity intervals, A- to D+. A new biochronologic interval, the Shoshonian Land Mammal Subage (Earliest Uintan), is defined and characterized. In all three field areas Shoshonian (Earliest Uintan) faunas and the Bridgerian/Uintan boundary occur within a single long reversed polarity interval. Correlation of marine biostratigraphy between the San Diego area section and deep sea sections allows precise identification of San Diego polarity interval B+ as Chron C21N. Therefore, the Bridgerian/Uintan boundary and earliest Uintan faunas occur within the reversed interval of Chron C20R. High-temperature, KAr dates bracketing this horizon in northwestern Wyoming provide an age estimate of approximately 49.5 Ma for the top of Chron C21N and 49 Ma for the Bridgerian/Uintan boundary. Berggren et al. (1985) use the age estimate of 49.5 Ma for the top of anomaly 21 (younger boundary of Chron C21N) as one calibration point for the generation of a Paleogene geochronology. The methodology and conclusions of this geochronology are compared to those of other recent geochronologies. Data from independent studies integrating high temperature radioisotopic dates, biochronology, and magnetochronology are used to test the validity of the Berggren et al. (1985) geochronology.",https://doi.org/10.1016/0031-0182(86)90155-0,https://www.sciencedirect.com/science/article/pii/0031018286901550,,,,1986,Correlation and geochronology of middle Eocene strata from the Western United States,John Joseph Flynn,article,FLYNN1986335,"Palaeogeography, Palaeoclimatology, Palaeoecology",2,55,0031-0182,Global stratigraphic correlation of Mesoic-Cenozoic sediments of oceans and continents,,
,,1114-1132,,"Summary
An attempt has been made to review the available information on the uses of lactose in animal and human feeding. From the information reviewed, the following conclusions can be drawn:1.Lactose is tolerated by the rat up to about 25% of the diet. Above this level poor growth, diarrhea, alopecia, and cataract formation result.2.Young pigs and dairy calves are able to tolerate extremely high levels of lactose. This tolerance for lactose decreases with the age of the animal.3.Poultry, either young or old, are unable to utilize even moderate levels of lactose.4.Lactose has a definite effect on the intestinal tract of all animals. This effect is characterized by a lowering of the acidity and a change of the intestinal flora to an acidophilic type.5.Lactose stimulates the synthesis of B-vitamins by the intestinal bacteria in both mammals and poultry.6.Lactose feeding causes a change in the phospholipids of the tissues of animals fed diets containing large amounts of lactose.7.Lactose favorably influences the absorption, retention, and utilization of calcium, phosphorus, and magnesium. This may or may not be related to the change in pH of the intestinal tract following lactose feeding.8.Lactose is well-tolerated by the human adult and it may be used in therapy against constipation and diarrhea.9.Lactose finds wide use in infant feeding and should be considered the carbohydrate of choice for the modification of cow's milk and for the formulation of infant foods. It is especially useful as an additive to human milk for the feeding of premature infants.10.Lactose has been shown to improve the problem-solving ability of rats, which suggests a nutritive value not found in other carbohydrates.11.Lactose has been shown to protect the rat against alloxan poisoning. Sucrose and starch did not give this protecting action against alloxan poisoning.12.Lactose has been shown to be a lipotropic agent and a sparer of choline.13.Lactose allows normal reproduction in the rat. This was not true for sucrose.",https://doi.org/10.3168/jds.S0022-0302(57)94603-9,https://www.sciencedirect.com/science/article/pii/S0022030257946039,,,,1957,Lactose in Animal and Human Feeding: A Review,R.L. Atkinson and F.H. Kratzer and G.F. Stewart,article,ATKINSON19571114,Journal of Dairy Science,9,40,0022-0302,,,
,,183-205,,"The magnetic properties of the binary rare-earth compounds with the nitrogen-group elements are briefly discussed, emphasizing the NaCl-type phases, for which the main magnetic data are collected.",https://doi.org/10.1016/0304-8853(78)90121-X,https://www.sciencedirect.com/science/article/pii/030488537890121X,,,,1978,Magnetic properties of the rare earth pnictides,F. Hulliger,article,HULLIGER1978183,Journal of Magnetism and Magnetic Materials,3,8,0304-8853,,,
,,I-LXXIII,,,https://doi.org/10.1016/S2772-3747(24)00194-7,https://www.sciencedirect.com/science/article/pii/S2772374724001947,,,,2024,FULL ISSUE PDF,,article,2024I,JACC: Asia,7,4,2772-3747,,,
,,125,,,https://doi.org/10.1016/S1569-9056(08)60218-3,https://www.sciencedirect.com/science/article/pii/S1569905608602183,,,,2008,FERTILITY IN MEN WITH CHRONIC RENAL FAILURE BEFORE AND AFTER KIDNEY TRANSPLANTATION,J. Nohra and A. Zairi and G. Ghazal and N. Kamar and L. Rostaing and P. Plante and E. Huyghe,article,NOHRA2008125,European Urology Supplements,3,7,1569-9056,23rd Annual Congress of the European Association of Urology,,
,"Anomaly-based IDS, Attacks, Cloud computing, DoS, IDS, Intrusions, Malware, Mobile devices, Signature-based IDS, Smartphones, Trojans",109-130,Computer and Information Security Handbook (Third Edition),"This chapter discusses intrusion detection applications for two contemporary environments: mobile devices and cloud computing. The chapter starts by introducing the most well-known mobile device operating systems and cloud computing models. Next, the chapter discusses the risks to which these environments are exposed as a result of intrusions, and the sources and origins of attacks in both environments. Furthermore, classes of malware and types of attacks are explained. In addition, the chapter explores techniques employed by mobile malware as well as techniques employed by intrusions that infect cloud computing systems. The chapter also gives a variety of new examples of malware that infect mobile phones and intrusions into cloud computing systems. Moreover, the chapter discusses types of intrusion detection systems and explains performance metrics for evaluating intrusion detection systems in both environments.",https://doi.org/10.1016/B978-0-12-803843-7.00006-5,https://www.sciencedirect.com/science/article/pii/B9780128038437000065,Boston,Morgan Kaufmann,978-0-12-803843-7,2017,Chapter 6 - Intrusion Detection in Contemporary Environments,Tarfa Hamed and Rozita Dara and Stefan C. Kremer,incollection,HAMED2017109,,,,,,John R. Vacca,Third Edition
,"Decentralized autonomous manufacturing, Blockchain 3.0, Mass individualization, Industry 5.0, Resilient manufacturing systems",95-114,,"Manufacturers are increasingly aware of the importance of system resilience against unexpected disruptive occurrences, such as the recent global Covid-19 pandemic and geopolitical wars in Europe. Meanwhile, Decentralized Autonomous Organization (DAO) is recently envisioned as the Blockchain 3.0 stage, in which enabling DAO in the manufacturing domain could be a promising attempt and will lead to decentralized autonomous manufacturing. Blockchain-enabled smart contracts and decentralized applications have the characteristics of verifiability, decentralization, transparency, autonomy, and tamper-proofing, which can enable a mass individualization paradigm to realize the promising Industry 5.0 vision of resilience. DAO provides a probable manner to regulate cross-prosumer activities under the Industry 5.0 context. Inspired by this vision, our paper reviews the literature on Decentralized Manufacturing (DM) and Autonomous Manufacturing (AM). Then, these two streams of efforts are unified, and a manufacturing paradigm, named Decentralized Autonomous Manufacturing (DAM), is defined towards resilience in Industry 5.0. In this paper, a reference architecture of the DAM is given. Followed by a comprehensive investigation of the key enablers, challenges, and barriers in the implementation of DAM, based on the insights from this analysis, future research directions of DAM are highlighted. We believe that our effort can lay a foundation for positioning DAM in futuristic Industry 5.0 research and engineering practice.",https://doi.org/10.1016/j.jmsy.2023.08.023,https://www.sciencedirect.com/science/article/pii/S0278612523001723,,,,2023,Towards resilience in Industry 5.0: A decentralized autonomous manufacturing paradigm,Jiewu Leng and Yuanwei Zhong and Zisheng Lin and Kailin Xu and Dimitris Mourtzis and Xueliang Zhou and Pai Zheng and Qiang Liu and J. Leon Zhao and Weiming Shen,article,LENG202395,Journal of Manufacturing Systems,,71,0278-6125,,,
,"Modern code review, Bad practices, Conformance checking, Code review smell, Process smell, Process debt",106737,,"Context:
Code review is a crucial step of the software development life cycle in order to detect possible problems in source code before merging the changeset to the codebase. Although there is no consensus on a formally defined life cycle of the code review process, many companies and open source software (OSS) communities converge on common rules and best practices. In spite of minor differences in different platforms, the primary purpose of all these rules and practices leads to a faster and more effective code review process. Non-conformance of developers to this process does not only reduce the advantages of the code review but can also introduce waste in later stages of the software development.
Objectives:
The aim of this study is to provide an empirical understanding of the bad practices followed in the code review process, that are code review (CR) smells.
Methods:
We first conduct a multivocal literature review in order to gather code review bad practices discussed in white and gray literature. Then, we conduct a targeted survey with 32 experienced software practitioners and perform follow-up interviews in order to get their expert opinion. Based on this process, a taxonomy of code review smells is introduced. To quantitatively demonstrate the existence of these smells, we analyze 226,292 code reviews collected from eight OSS projects.
Results:
We observe that a considerable number of code review smells exist in all projects with varying degrees of ratios. The empirical results illustrate that 72.2% of the code reviews among eight projects are affected by at least one code review smell.
Conclusion:
The empirical analysis shows that the OSS projects are substantially affected by the code review smells. The provided taxonomy could provide a foundation for best practices and tool support to detect and avoid code review smells in practice.",https://doi.org/10.1016/j.infsof.2021.106737,https://www.sciencedirect.com/science/article/pii/S0950584921001877,,,,2022,Towards a taxonomy of code review smells,Emre Doğan and Eray Tüzün,article,DOGAN2022106737,Information and Software Technology,,142,0950-5849,,,
,"Digital forensics, Malware, Machine learning, Registry hives, Windows Registry, Windows 7/8/10, Sandbox, Agentless sandbox, Cuckoo",139-155,,"Digital investigators often get involved with cases, which seemingly point the responsibility to the person to which the computer belongs, but after a thorough examination malware is proven to be the cause, causing loss of precious time. Whilst Anti-Virus (AV) software can assist the investigator in identifying the presence of malware, with the increase in zero-day attacks and errors that exist in AV tools, this is something that cannot be relied upon. The aim of this paper is to investigate the behaviour of malware upon various Windows operating system versions in order to determine and correlate the relationship between malicious software and OS artifacts. This will enable an investigator to be more efficient in identifying the presence of new malware and provide a starting point for further investigation. The study analysed several versions of the Windows operating systems (Windows 7, 8.1 and 10) and monitored the interaction of 90 samples of malware (across three categories of the most prevalent (Trojan, Worm, and Bot) and 90 benign samples through the Windows Registry. Analysis of the interactions has provided a rich source of knowledge about how various forms of malware interact with key areas of the Registry. Using this knowledge, the study sought to develop an approach to predict the presence and type of malware present through an analysis of the Registry. To this end, different classifiers such as Neural Network, Random forest, Decision tree, Boosted tree and Logistic regression were tested. It was observed that Boosted tree was resulting in a correct classification of over 72% – providing the investigator with a simple approach to determining which type of malware might be present independent and faster than an Antivirus. The modelling of these findings and their integration in an application or forensic analysis within an existing tool would be useful for digital forensic investigators.",https://doi.org/10.1016/j.jisa.2019.04.013,https://www.sciencedirect.com/science/article/pii/S2214212618306367,,,,2019,A proactive malicious software identification approach for digital forensic examiners,Muhammad Ali and Stavros Shiaeles and Nathan Clarke and Dimitrios Kontogeorgis,article,ALI2019139,Journal of Information Security and Applications,,47,2214-2126,,,
,,459-473,,,https://doi.org/10.1016/S1042-3699(20)30131-X,https://www.sciencedirect.com/science/article/pii/S104236992030131X,,,,2001,A Clinical Approach to Periodontal Regeneration,Myron Nevins and Marc L. Nevins and Marcelo Camelo and James T. Mellonig,article,NEVINS2001459,Oral and Maxillofacial Surgery Clinics of North America,3,13,1042-3699,,,
,"Ransomware, Malware, Access control, Ransomware mitigation, Intrusion prevention",103160,,"The advancement of modern Operating Systems (OSs), and the popularity of personal computing devices with Internet connectivity, have facilitated the proliferation of ransomware attacks. Ransomware has evolved from executable programs encrypting user files, to novel attack vectors including fileless command scripts, information exfiltration and human-operated ransomware. Many anti-ransomware studies have been published, but many of them assumed newer ransomware variants only performed file encryption, were similar to existing variants, and often did not consider those novel attack vectors. We have defined an updated ransomware threat model to include those novel attack vectors, and redefined false positives and false negatives in the context of ransomware mitigation. We proposed to apply both program-centric and user-centric access control to combat ransomware, but only delegate access control decisions that users are capable of making to users, while enforcing non-negotiable access control decisions by OS and software developers. We have designed a Staged Event-Driven Access Control (SEDAC) approach to incorporate both program-centric and user-centric access control measures, and demonstrated a prototype on Windows OS. Our prototype was able to intercept more types of ransomware attack vectors than existing proposals. We hope to convince OS and software architects to incorporate our design to better combat ransomware.",https://doi.org/10.1016/j.cose.2023.103160,https://www.sciencedirect.com/science/article/pii/S0167404823000706,,,,2023,Applying staged event-driven access control to combat ransomware,Timothy McIntosh and A.S.M. Kayes and Yi-Ping Phoebe Chen and Alex Ng and Paul Watters,article,MCINTOSH2023103160,Computers & Security,,128,0167-4048,,,
,"botnet, Internet service provider, best practices, botmaster, bot-header, denial of service, malware, zombie, Trojan horse, distributed access",223-238,Computer and Information Security Handbook (Second Edition),"This chapter addresses the issue of Internet service provider (ISP) network protection, with a focus on addressing bots and botnets, which are a serious and growing problem for end users and ISP networks. Botnets are formed by maliciously infecting end-user computers and other devices with bot (from the word robot) software through a variety of means, and surreptitiously controlling the devices remotely to transmit onto the Internet spam and other attacks (targeting both end users and the network itself). This chapter examines potentially relevant existing best practices (BPs) and identifies additional best practices to address this growing problem. The chapter also identifies best practices that address protection for end users as well as the network. The best practices are organized into the logical steps required to address botnets. The first step is prevention, followed by detection, notification, and then mitigation. In addition, the best practices on privacy considerations are also identified to address the handling of customer information in botnet response. The best practices identified are primarily for use by ISPs that provide service to consumer end users on residential broadband networks, but may apply to other end users and networks as well. It is critical to note that best practices in general are not applicable in every situation because of multiple factors. Therefore, the best practices are intended to be voluntary in nature for ISPs and may not apply in all contexts (and thus for a host of reasons should not be made mandatory). With this understanding, this chapter recommends that the best practices can be implemented by ISPs, where applicable, in order to address the growing botnet problem in consumer end-user devices and ISP networks.",https://doi.org/10.1016/B978-0-12-394397-2.00012-X,https://www.sciencedirect.com/science/article/pii/B978012394397200012X,Boston,Morgan Kaufmann,978-0-12-394397-2,2013,Chapter 12 - The Botnet Problem,Daniel Ramsbrock and Xinyuan Wang,incollection,RAMSBROCK2013223,,,,,,John R. Vacca,Second Edition
,"Axonal projection, Bötzinger complex, VRG, nucleus retroambiguus, Intracellular labeling, Neurobiotin",141-153,,"In anesthetized and artificially-ventilated rats, the morphological properties of decrementing expiratory (E-DEC) neurons were studied using intracellular recording and labeling with Neurobiotin. Sixteen E-DEC neurons were successfully labeled; ten of which were cranial motoneurons located in the facial (FN) and ambiguus (NA) nuclei. Two interneurons were labeled in the Bötzinger complex (BOT) and the ventral respiratory group (VRG) rostral to the obex, and the remaining four in the VRG caudal to the obex. All the interneurons had extensive intramedullary collaterals within the ventrolateral medulla. Terminal-like boutons were distributed ventral to the NA at the level of the BOT, both ventral to and within the NA at the level rostral to the obex and largely within the cell column tentatively designed as the ambiguous-retroambiguus complex (NA/NRA) caudal to the obex. The four interneurons in the NA/NRA had axons projecting to the spinal cord as well. The extensive intramedullary projections suggest that these E-DEC interneurons of the BOT and the VRG play a significant role in respiration. The simultaneous projections from the caudal E-DEC neurons to both the spinal cord and the NA suggest that these neurons also play integrative roles in non-respiratory behaviors including vocalization, swallowing and defecation.",https://doi.org/10.1016/S0168-0102(02)00095-0,https://www.sciencedirect.com/science/article/pii/S0168010202000950,,,,2002,Morphology of the decrementing expiratory neurons in the brainstem of the rat,Yoshiaki Saito and Ikuko Tanaka and Kazuhisa Ezure,article,SAITO2002141,Neuroscience Research,2,44,0168-0102,,,
,"bipolar disorders, carbamazepine, carcinogenesis, neuroblastoma, pregnancy, teratogenesis",445-454,,,https://doi.org/10.1016/S0278-5846(98)00016-5,https://www.sciencedirect.com/science/article/pii/S0278584698000165,,,,1998,Congenital neuroblastoma in a bot born to a woman with bipolar disorder treated with carbamazepine during pregnancy,Trino Baptista and Hilarion Araujo and Pedro Rada and Luis Hernández,article,BAPTISTA1998445,Progress in Neuro-Psychopharmacology and Biological Psychiatry,3,22,0278-5846,,,
,"Personality traits, Large-scale distributed projects, Ecosystems, Apache, Big five, Five-Factor model, Open source software, Human aspects, Psychometric analysis, Computational personality detection",1-20,,"Context
Large-scale distributed projects are typically the results of collective efforts performed by multiple developers with heterogeneous personalities.
Objective
We aim to find evidence that personalities can explain developers’ behavior in large scale-distributed projects. For example, the propensity to trust others — a critical factor for the success of global software engineering — has been found to influence positively the result of code reviews in distributed projects.
Method
In this paper, we perform a quantitative analysis of ecosystem-level data from the code commits and email messages contributed by the developers working on the Apache Software Foundation (ASF) projects, as representative of large scale-distributed projects.
Results
We find that there are three common types of personality profiles among Apache developers, characterized in particular by their level of Agreeableness and Neuroticism. We also confirm that developers’ personality is stable over time. Moreover, personality traits do not vary with their role, membership, and extent of contribution to the projects. We also find evidence that more open developers are more likely to make contributors to Apache projects.
Conclusion
Overall, our findings reinforce the need for future studies on human factors in software engineering to use psychometric tools to control for differences in developers’ personalities.",https://doi.org/10.1016/j.infsof.2019.05.012,https://www.sciencedirect.com/science/article/pii/S0950584918301216,,,,2019,"A large-scale, in-depth analysis of developers’ personalities in the Apache ecosystem",Fabio Calefato and Filippo Lanubile and Bogdan Vasilescu,article,CALEFATO20191,Information and Software Technology,,114,0950-5849,,,
,"Empirical software engineering, Code review, Sentiment analysis, Opinion mining, Affective analysis, Propensity score matching",37-54,,"Context
Modern code reviews are supported by tools to enhance developers’ interactions allowing contributors to submit their opinions for each committed change in form of comments. Although the comments are aimed at discussing potential technical issues, the text might enclose harmful sentiments that could erode the benefits of suggested changes.
Objective
In this paper, we study empirically the impact of sentiment embodied within developers’ comments on the time and outcome of the code review process.
Method
Based on historical data of four long-lived Open Source Software (OSS) projects from a code review system we investigate whether perceived sentiments have any impact on the interval time of code changes acceptance.
Results
We found that (1) contributors frequently express positive and negative sentiments during code review activities; (2) the expressed sentiments differ among the contributors depending on their position within the social network of the reviewers (e.g., core vs peripheral contributors); (3) the sentiments expressed by contributors tend to be neutral as they progress from the status of newcomer in an OSS project to the status of core team contributors; (4) the reviews with negative comments on average took more time to complete than the reviews with positive/neutral comments, and (5) the reviews with controversial comments took significantly longer time in one project.
Conclusion
Through this work, we provide evidences that text-based sentiments have an impact on the duration of the code review process as well as the acceptance or rejection of the suggested changes.",https://doi.org/10.1016/j.infsof.2019.06.005,https://www.sciencedirect.com/science/article/pii/S0950584919301387,,,,2019,An empirical study of sentiments in code reviews,Ikram El Asri and Noureddine Kerzazi and Gias Uddin and Foutse Khomh and M.A. {Janati Idrissi},article,ASRI201937,Information and Software Technology,,114,0950-5849,,,
,"Chemotherapy, cancer, IVF, embryo quality, cryopreservation",897-901,,"Objective
To evaluate if in vitro fertilization (IVF) with embryo cryopreservation can be proposed to patients immediately after one or two regimens of chemotherapy.
Design
Retrospective study.
Setting
Academic research center and IVF unit.
Patient(s)
Eleven young patients diagnosed with cancer between September 1999 and April 2003 who wanted to preserve their fertility via IVF.
Intervention(s)
Stimulation and IVF before or soon after chemotherapy treatment.
Main outcome measure(s)
The number and quality of embryos obtained after stimulation in cancer patients undergoing IVF before or soon after chemotherapeutic treatment.
Result(s)
Four patients underwent IVF in the interval between two regimens of chemotherapy. Two of them had no follicular development; one underwent follicular puncture but no oocytes were retrieved; and, in one, six oocytes were harvested but only one good quality embryo was obtained. In the seven patients who underwent IVF before starting chemotherapy, between 4 and 11 embryos were obtained per patient, the majority being good quality embryos.
Conclusion(s)
Because the efficacy of IVF is dramatically reduced after even one round of chemotherapy, IVF should be performed before chemotherapy. For those who require immediate chemotherapy, ovarian tissue cryopreservation and/or oocyte cryopreservation could be used before treatment.",https://doi.org/10.1016/j.fertnstert.2004.08.035,https://www.sciencedirect.com/science/article/pii/S001502820403170X,,,,2005,Efficacy of in vitro fertilization after chemotherapy,Marie-Madeleine Dolmans and Dominique Demylle and Belen Martinez-Madrid and Jacques Donnez,article,DOLMANS2005897,Fertility and Sterility,4,83,0015-0282,,,
,,S2210-S2211,,,https://doi.org/10.1016/j.jtho.2017.09.1468,https://www.sciencedirect.com/science/article/pii/S1556086417322037,,,,2017,P3.01-027 TET2 Mutation as a Novel Mechanism of Acquired Resistance to EGFR TKIs Identified by a Mutational Profiling Using NGS,Y. Jin and X. Hu and M. Chen and X. Yu,article,JIN2017S2210,Journal of Thoracic Oncology,"11, Supplement 2",12,1556-0864,IASLC 18th World Conference on Lung Cancer,,
,,125,,,https://doi.org/10.1016/S1569-9056(08)60217-1,https://www.sciencedirect.com/science/article/pii/S1569905608602171,,,,2008,AGE AS ONLY PREDICTIVE FACTOR FOR SUCCESSFUL SPERM RECOVERY IN PATIENTS WITH KLINEFELTER'S SYNDROME,K. Ferhi and R. Avakian and J.F. Griveau and D. Lelannou and J.J. Patard,article,FERHI2008125,European Urology Supplements,3,7,1569-9056,23rd Annual Congress of the European Association of Urology,,
,"Developer discussions, Gitter, Issue reports",110852,,"Informal communication channels like mailing lists, IRC and instant messaging play a vital role in open source software development by facilitating communication within geographically diverse project teams e.g., to discuss issue reports to facilitate the bug-fixing process. More recently, chat systems like Slack and Gitter have gained a lot of popularity and developers are rapidly adopting them. Gitter is a chat system that is specifically designed to address the needs of GitHub users. Gitter hosts project-based asynchronous chats which foster frequent project discussions among participants. Developer discussions contain a wealth of information such as the rationale behind decisions made during the evolution of a project. In this study, we explore 24 open source project chat rooms that are hosted on Gitter, containing a total of 3,133,106 messages and 14,096 issue references. We manually analyze the contents of chat room discussions around 457 issue reports. The results of our study show the prevalence of issue discussions on Gitter, and that the discussed issue reports have a longer resolution time than the issue reports that are never brought on Gitter.",https://doi.org/10.1016/j.jss.2020.110852,https://www.sciencedirect.com/science/article/pii/S0164121220302429,,,,2021,How are issue reports discussed in Gitter chat rooms?,Hareem Sahar and Abram Hindle and Cor-Paul Bezemer,article,SAHAR2021110852,Journal of Systems and Software,,172,0164-1212,,,
,,15-21,,"The influence of concentrations of oxygen and radiation-induced oxygen sensitive sites on their rates of reactions in barley seeds was investigated. Himalaya (C.I. 620) barley seeds were adjusted to 9.9% water content irradiated with 60Co gamma rays and soaked at 0°C in distilled water bubbled with oxygen and nitrogen gas mixtures containing 0.0, 12.5, 25, 50 and 100% oxygen. Treatment effects were measured as M1 seedling injury. In one experiment, irradiated seeds were initially soaked in oxygen-saturate water, then transferred to O2-free water (nitrogen soaking) at selected time intervals. An increase in oxygen enhancement (OE) as measured by seedling injury is obtained with increased O2-soaking duration. A measure of the reaction rate between O2 and O2-sensitive sites (OSS) is thus obtained. This reaction is radiation exposure dependent. A reverse experiment (initial nitrogen soaking with transfer to O2 soaking at selected intervals) gives a measure of the lifetime of the OSS in water (quenching reaction). The same experimental plan is followed in two other experiments where the oxygen concentration in the gas phase of the soaking solution (OC) is variable. These experiments provide a measure of the influence of OC on the OE and OSS quenching reactions. A single radiation exposure was used. These results are demonstrated in four figures and numerical results and “reaction rates” are in two tables. The quenching reactions were independent of radiation exposure and OC. At low to intermediate OC the quenching reactions terminated the O2-OSS reaction. At 100% OC the O2-OSS reaction was two to three times faster and started three times sooner than the quenching reaction.",https://doi.org/10.1016/0098-8472(82)90004-1,https://www.sciencedirect.com/science/article/pii/0098847282900041,,,,1982,Rate of oxygen effect reactions in irradiated barley seeds,E. Donaldson and R.A. Nilan and C.F. Konzak,article,DONALDSON198215,Environmental and Experimental Botany,1,22,0098-8472,,,
,"Controlled volatile release, Phytosterols, Crystallization, Structured emulsion, -sitosterol, OSA starch",170-179,,"Flavor is one of the most important criteria for consumer acceptance of food products, especially for low-fat food emulsions. In this study, we prepared structured flavoring oil-in-water (O/W) emulsions based on the crystallization behavior of β-sitosterol (Sito), a functional phytosterol, in the presence of emulsifier (sodium caseinate, SC and octenylsuccinate starch, OSS), These structured emulsions improved colloidal stability during long-term storage and delayed volatiles release under real time dynamic condition. However, the equilibrium static headspace analysis did not show significant differences in the affinities of hydrophobic volatile compounds with pure constitutes of unstructured and structured emulsions. This highlighted the importance of structural properties of the O/W interface in volatile release modulation. A modified gel trapping technology (GTT) combined with polarized light microscopy (PLM) and confocal laser scanning microscope (CLSM) were applied to characterize the microstructure at the oil-water interface, and it clearly showed the formation of a novel Sito crystal/OSA starch complex interface for OSS stabilized structured emulsion. This unique interfacial microstructure might contribute to the strong retention of volatile compounds due to steric barrier and enhanced affinity to those lipophilic volatiles. The formulated flavor emulsion with controlled volatile release profile was successfully prepared by simply blending the unstructured and structured flavoring emulsions. This work provides indications for potential applications of the formulation design in flavor emulsions and phytosterols structured emulsion as novel aroma delivery systems to improve flavor perception.",https://doi.org/10.1016/j.foodhyd.2015.11.035,https://www.sciencedirect.com/science/article/pii/S0268005X15301673,,,,2016,Controlled volatile release of structured emulsions based on phytosterols crystallization,Xiao-Wei Chen and Jian Guo and Jin-Mei Wang and Shou-Wei Yin and Xiao-Quan Yang,article,CHEN2016170,Food Hydrocolloids,,56,0268-005X,,,
,,217-228,Firewalls,"Publisher Summary
This chapter focuses on traffic problem and data security. Being “aware” of the precautions that need to be taken does not serve anyone; security is less about understanding and all about taking action. Access lists should be treated with the same level of security as government threat codes. They should change frequently (daily), should be token driven, and the storage of critical information (including and especially e-mail addresses) should be encrypted at the data level. Merely protecting these items from access is not enough. Special encryption algorithms are required for even simple examination of the data. Only the full gamut of security measures can ensure the protection of critical data―data that, if compromised and released to the public, may cause the annihilation of public trust when the data fall into the wrong hands. Such flagrant heists as the AOL breach give spammers and hackers a veritable gold mine of information. AOL users are, typically, novice users and are the most likely to fall prey to spam scams, or “scam mail.” By carefully and thoroughly monitoring traffic and engaging the full capabilities of access control lists (ACLs), application firewalls, and inherent database security, much of the problematic traffic present on the Internet today can have been avoided.",https://doi.org/10.1016/B978-155558297-5/50015-3,https://www.sciencedirect.com/science/article/pii/B9781555582975500153,Burlington,Digital Press,978-1-55558-297-5,2005,13 - External Servers Protection,John R. Vacca and Scott R. Ellis,incollection,VACCA2005217,,,,,,John R. Vacca and Scott R. Ellis,
,"Financial linkage, SACCOS, Sustainability, Tanzania",65-71,,"The developing economies are experiencing a growing trend of financial Linkage between formal and less-formal financial institutions. Normally, less-formal financial institutions receive loanable funds from formal financial institutions as an approach to meet their financing deficit, while formal financial institutions engage in linkage as a mean to expand business. The main concern of stakeholders regarding this practice is how such linkage can affect the performance of the less-formal financial institutions. In Tanzania, the Savings and Credit Co-operative Societies (SACCOS) are the most used less-formal financial institutions which are also highly involved in financial linkage. In this study therefore, we used Tanzania SACCOS’ financial statement data, for the period of 2004–2011, and panel data regression model to examine the relationship between financial linkage (measured as financial dependency ratio) and sustainability (measured as Operational Self Sufficiency) of less-formal financial institutions. The findings suggest that the higher the level of financial linkage the more the SACCOS become unsustainable. Implying that, to be sustainable institutions, the SACCOS should try keep away from the use of external funds in their loan portfolio.",https://doi.org/10.1016/j.jcom.2014.10.003,https://www.sciencedirect.com/science/article/pii/S2213297X14000263,,,,2014,The impacts of financial linkage on sustainability of less-formal financial institutions: Experience of savings and credit co-operative societies in Tanzania,Benson Otieno Ndiege and Xuezhi Qin and Isaac Kazungu and John Moshi,article,NDIEGE201465,Journal of Co-operative Organization and Management,2,2,2213-297X,,,
,,125,,,https://doi.org/10.1016/S1569-9056(08)60216-X,https://www.sciencedirect.com/science/article/pii/S156990560860216X,,,,2008,EFFICACY AND SAFETY OF ETONOGESTREL AND TESTOSTERONE UNDECANOATE FOR MALE HORMONAL CONTRACEPTION,E. Mommers and W.M. Kersemaekers and J. Elliesen and E.J.H. Meuleman and M. Kepers and D. Apter and H.M. Behre and J. Beynon and P.M. Bouloux and A. Costantino and H.P. Gerbershagen and L. Grønlund and D. Heger-Mahn and I. Huhtaniemi and E. Koldewijn and C. Lange and S. Lindenberg and C. Meriggiola and P. Mulders and E. Nieschlag and A. Perheentupa and A. Solomon and L. Väisälä and F. Wu and M. Zitzmann,article,MOMMERS2008125,European Urology Supplements,3,7,1569-9056,23rd Annual Congress of the European Association of Urology,,
,"Network Functions Virtualization, Software Defined Networking, 5G, Self-Organizing Networks, Autonomic management",229-246,,"The 5G infrastructure initiative in Europe115G Infrastructure Public Private Partnership, [Online]. Available here: https://5g-ppp.eu/ has agreed a number of challenging key performance indicators (KPIs) to significantly enhance the user experience and support a number of use cases with very demanding requirements on the network infrastructure. At the same time there is high pressure on the reduction of the operational expenditure (OPEX). A contribution to meeting the KPIs and to reduce OPEX is to evolve the management of the network into a fully autonomic and intelligent framework. Based on advanced technologies, such as Software-Defined Networking (SDN) and Network Function Virtualization (NFV), the EU H2020 project SELFNET (https://selfnet-5g.eu/) is proposing an advanced network management framework to achieve these objectives.",https://doi.org/10.1016/j.csi.2016.12.008,https://www.sciencedirect.com/science/article/pii/S0920548916302434,,,,2017,Future mode of operations for 5G – The SELFNET approach enabled by SDN/NFV,Pedro Neves and Rui Calé and Mário Costa and Gonçalo Gaspar and Jose Alcaraz-Calero and Qi Wang and James Nightingale and Giacomo Bernini and Gino Carrozzo and Ángel Valdivieso and Luis Javier {García Villalba} and Maria Barros and Anastasius Gravas and José Santos and Ricardo Maia and Ricardo Preto,article,NEVES2017229,Computer Standards & Interfaces,,54,0920-5489,SI: Standardization SDN&NFV,,
,"Meta-model, Assembly tolerance types, Semantic interoperability, Description logics",1-16,,"There is a critical requirement for semantic interoperability among heterogeneous computer-aided tolerancing (CAT) systems with the sustainable growing demand of collaborative product design. But current data exchange standard for exchanging tolerance information among these systems can only exchange syntaxes and cannot exchange semantics. Semantic interoperability among heterogeneous CAT systems is difficult to be implemented only with this standard. To address this problem, some meta-models of tolerance information supporting semantic interoperability and an interoperability platform based on these meta-models should be constructed and developed, respectively. This paper mainly focuses on the construction of a meta-model for assembly tolerance types with a description logic ALC(D) based approach. Description logics, a family of knowledge representation languages for authoring ontologies, are well-known for having rigorous logic-based semantics which supports semantic interoperability. ALC(D) can provide a formal method to describe the research objects and the relations among them. In this formal method, constraint relations among parts, assembly feature surfaces and geometrical features are defined with some ALC(D) assertional axioms, and the meta-model of assembly tolerance types is constructed through describing the spatial relations between geometrical features with some ALC(D) terminological axioms. Besides, ALC(D) can also provide a highly efficient reasoning algorithm to automatically detect the inconsistency of the knowledge base, a finite set of assertional and terminological axioms. With this reasoning algorithm, assembly tolerance types for each pair of geometrical features are generated automatically through detecting the inconsistencies of the knowledge base. An application example is provided to illustrate the process of generating assembly tolerance types.",https://doi.org/10.1016/j.cad.2013.10.009,https://www.sciencedirect.com/science/article/pii/S0010448513002078,,,,2014,Constructing a meta-model for assembly tolerance types with a description logic based approach,Yanru Zhong and Yuchu Qin and Meifa Huang and Wenlong Lu and Liang Chang,article,ZHONG20141,Computer-Aided Design,,48,0010-4485,,,
,"Data science, Cyber forensics, Internet-of-things, IoT Security, Internet measurements",101707,,"The insecurity of the Internet-of-Things (IoT) paradigm continues to wreak havoc in consumer and critical infrastructures. The highly heterogeneous nature of IoT devices and their widespread deployments has led to the rise of several key security and measurement-based challenges, significantly crippling the process of collecting, analyzing and correlating IoT-centric data. To this end, this paper explores macroscopic, passive empirical data to shed light on this evolving threat phenomena. The proposed work aims to classify and infer Internet-scale compromised IoT devices by solely observing one-way network traffic, while also uncovering, reporting and thoroughly analyzing “in the wild” IoT botnets. To prepare a relevant dataset, a novel probabilistic model is developed to cleanse unrelated traffic by removing noise samples (i.e., misconfigured network traffic). Subsequently, several shallow and deep learning models are evaluated in an effort to train an effective multi-window convolutional neural network. By leveraging active and passing measurements when generating the training dataset, the neural network aims to accurately identify compromised IoT devices. Consequently, to infer orchestrated and unsolicited activities that have been generated by well-coordinated IoT botnets, hierarchical agglomerative clustering is employed by scrutinizing a set of innovative and efficient network feature sets. Analyzing 3.6 TB of recently captured darknet traffic revealed a momentous 440,000 compromised IoT devices and generated evidence-based artifacts related to 350 IoT botnets. Moreover, by conducting thorough analysis of such inferred campaigns, we reveal their scanning behaviors, packet inter-arrival times, employed rates and geo-distributions. Although several campaigns exhibit significant differences in these aspects, some are more distinguishable; by being limited to specific geo-locations or by executing scans on random ports besides their core targets. While many of the inferred botnets belong to previously documented campaigns such as Hide and Seek, Hajime and Fbot, newly discovered events portray the evolving nature of such IoT threat phenomena by demonstrating growing cryptojacking capabilities or by targeting industrial control services. To motivate empirical (and operational) IoT cyber security initiatives as well as aid in reproducibility of the obtained results, we make the source codes of all the developed methods and techniques available to the research community at large.",https://doi.org/10.1016/j.cose.2019.101707,https://www.sciencedirect.com/science/article/pii/S0167404819302445,,,,2020,"On data-driven curation, learning, and analysis for inferring evolving internet-of-Things (IoT) botnets in the wild",Morteza {Safaei Pour} and Antonio Mangino and Kurt Friday and Matthias Rathbun and Elias Bou-Harb and Farkhund Iqbal and Sagar Samtani and Jorge Crichigno and Nasir Ghani,article,SAFAEIPOUR2020101707,Computers & Security,,91,0167-4048,,,
,"Person re-identification, Loss, Deep metric learning",108949,,"The training loss function that enforces certain training sample distribution patterns plays a critical role in building a re-identification (ReID) system. Besides the basic requirement of discrimination, i.e., the features corresponding to different identities should not be mixed, additional intra-class distribution constraints, such as features from the same identities should be close to their centers, have been adopted to construct losses. Despite the advances of various new loss functions, it is still challenging to strike the balance between the need of reducing the intra-class variation and allowing certain distribution freedom. Traditional intra-class losses try to shrink samples of the same class into one point in the feature space and may easily drop their intra-class similarity structure. In this paper, we propose a new loss based on center predictivity, that is, a sample must be positioned in a location of the feature space such that from it we can roughly predict the location of the center of same-class samples. The prediction error is then regarded as a loss called Center Prediction Loss (CPL). Unlike most existing metric learning loss functions, CPL involves learnable parameters, i.e., the center predictor, which brings a remarkable change in the properties of the loss. In particular, it allows higher freedom in intra-class distributions. And the parameters in CPL will be discarded after training. Extensive experiments on various real-world ReID datasets show that the proposed loss can achieve superior performance and can also be complementary to existing losses.",https://doi.org/10.1016/j.patcog.2022.108949,https://www.sciencedirect.com/science/article/pii/S0031320322004290,,,,2022,Center Prediction Loss for Re-identification,Lu Yang and Yunlong Wang and Lingqiao Liu and Peng Wang and Yanning Zhang,article,YANG2022108949,Pattern Recognition,,132,0031-3203,,,
,"Molecular diffusion, Ternary mixture, Sliding Symmetric Tubes, Fitting procedure",356-364,,"The objective of this work is the determination of diagonal and cross-diagonal molecular diffusion coefficients in a ternary mixture, using the ‘Sliding Symmetric Tubes’ (SST) technique. The analyzed mixture consists of two aromatics and one normal alkane (tetrahydronaphthalene–dodecane–isobutylbenzene) with an equal mass fraction for all components (1:1:1) at 25 °C. The analytical solution corresponding to the SST technique has been successfully derived. The different fitting procedures were utilized by two scientific teams to subtract diffusion coefficients from the experimentally measured time-dependent concentration field. None of the attempts provided reliable results for the data from a single experiment. The “simplex”-based methods display reasonable results assuming that cross-diagonal coefficients are close to zero, i.e. quasi-binary and diluted mixtures. The results obtained by “trust region method” are satisfactory if the initial guess is good. To achieve better results, it is necessary to increase the number of experimental data.",https://doi.org/10.1016/j.crme.2013.01.008,https://www.sciencedirect.com/science/article/pii/S1631072113000247,,,,2013,Remarks on the analysis method for determining diffusion coefficient in ternary mixtures,Miren Larrañaga and M. Mounir Bou-Ali and Daniel Soler and Manex Martinez-Agirre and Aliaksandr Mialdun and Valentina Shevtsova,article,LARRANAGA2013356,Comptes Rendus Mécanique,4,341,1631-0721,10th International Meeting on Thermodiffusion,,
,"Big data, Cloud computing, Deep learning, Intrusion Detection System, IDS, IoT, Machine learning, Network Intrusion Detection, NIDS, SWOT, TOWS",227-247,,"Introduction:
The growth of ubiquitous networked devices and the proliferation of geographically dispersed ‘Internet of Thing’ devices have exponentially increased network traffic. The socio-economical society is highly dependent on modern devices, and unavailability may lead to catastrophic results for even a short time. The less secure and heterogeneous devices in the public domain have shaped a cyber-attack surface in the cloud environment. Traditional approaches for Network Intrusion Detection Systems have proven ineffective and insufficient in defending against zero-day attacks.
Methods:
This article visited the advancements in the intrusion detection realm in the last five years and conducted a comprehensive retrospection of modern network intrusion detection systems. The authors have performed a comprehensive SWOT (Strength, Weakness, Opportunities, Threats) analysis of contemporary Network Intrusion Detection Systems in multiple technology dimensions, including big-data processing of high volume network traffic, machine learning, deep learning for self-learning machines, readiness for zero-day attacks, distributed processing, cost-effective solution, and ability to perform autonomous operations.
Results:
The paper turns SWOT analysis into TOWS inferences from the retrospective study for strategy formulation and features the attributes of a futuristic NIDS solution.
Discussion:
The article concludes with the discussion and future scope as the pinnacle of security solution development against zero-day attacks.",https://doi.org/10.1016/j.comcom.2022.08.022,https://www.sciencedirect.com/science/article/pii/S0140366422003371,,,,2022,iNIDS: SWOT Analysis and TOWS Inferences of State-of-the-Art NIDS solutions for the development of Intelligent Network Intrusion Detection System,Jyoti Verma and Abhinav Bhandari and Gurpreet Singh,article,VERMA2022227,Computer Communications,,195,0140-3664,,,
,"Bötzinger complex, Pons, Intracellular labeling, Neurobiotin, VRG, Axonal projection",41-51,,"There are two types of expiratory neurons with augmenting firing patterns (E-AUG neurons), those in the Bötzinger complex (BOT) and those in the caudal ventral respiratory group (cVRG). We studied their axonal projections morphologically using intracellular labeling of single E-AUG neurons with Neurobiotin, in anesthetized, paralyzed and artificially-ventilated rats. BOT E-AUG neurons (n=11) had extensive axonal projections to the brainstem, but E-AUG neurons (n=5) of the cVRG sent axons that descended the contralateral spinal cord without medullary collaterals. In addition to these somewhat expected characteristics, the present study revealed a number of new projection patterns of the BOT E-AUG neurons. First, as compared with the dense projections to the ipsilateral brainstem, those to the contralateral side were sparse. Second, several BOT E-AUG neurons sent long ascending collaterals to the pons, which included an axon that reached the ipsilateral parabrachial and Kölliker–Fuse nuclei and distributed boutons. Third, conspicuous projections from branches of these ascending collaterals to the area dorsolateral to the facial nucleus were found. Thus, the present study has shown an anatomical substrate for the extensive inhibitory projections of single BOT E-AUG neurons to the areas spanning the bilateral medulla and the pons.",https://doi.org/10.1016/S0168-0102(02)00197-9,https://www.sciencedirect.com/science/article/pii/S0168010202001979,,,,2003,Brainstem and spinal projections of augmenting expiratory neurons in the rat,Kazuhisa Ezure and Ikuko Tanaka and Yoshiaki Saito,article,EZURE200341,Neuroscience Research,1,45,0168-0102,,,
,"Networks security, Attack modelling, Distributed Denial of Service (DDoS), Software Defined Networks (SDN), Virtual networks, Traditional networks",101065,,"Denial of Service and Distributed Denial of Service (DoS/DDoS) attacks have been one of the biggest threats against communication networks and applications throughout the years. Modelling DoS/DDoS attacks is necessary to get a better understanding of their behaviour at each step of the attack process, from the Botnet recruitment up to the dynamics of the attack. A deeper understanding of DoS/DDoS attacks would lead to the development of more efficient solutions and countermeasures to mitigate their impact. In this survey, we present a classification approach for existing DoS/DDoS models in different kinds of networks; traditional networks, Software Defined Networks (SDN) and virtual networks. In addition, this article provides a thorough review and comparison of the existing attack models, in particular we explain, analyze and simulate different aspects of three prominent models; congestion window, queuing, and epidemic models (same model used for corona virus spread analysis). Furthermore, we quantify the damage of DoS/DDoS attacks at three different levels; protocol (Transmission Control Protocol-TCP), device’s resources (bandwidth, CPU, memory), and network (infection and recovery speed).",https://doi.org/10.1016/j.jestch.2021.09.011,https://www.sciencedirect.com/science/article/pii/S2215098621001944,,,,2022,"A survey on DoS/DDoS attacks mathematical modelling for traditional, SDN and virtual networks",Juan Fernando Balarezo and Song Wang and Karina Gomez Chavez and Akram Al-Hourani and Sithamparanathan Kandeepan,article,BALAREZO2022101065,"Engineering Science and Technology, an International Journal",,31,2215-0986,,,
,"Internet-of-things (IoT), IoT ethical hacking, IoT penetration testing, Internet of ethical hacking things (IoEHT), IoT cyber-security",280-308,,"In recent years, attacks against various Internet-of-Things systems, networks, servers, devices, and applications witnessed a sharp increase, especially with the presence of 35.82 billion IoT devices since 2021; a number that could reach up to 75.44 billion by 2025. As a result, security-related attacks against the IoT domain are expected to increase further and their impact risks to seriously affect the underlying IoT systems, networks, devices, and applications. The adoption of standard security (counter) measures is not always effective, especially with the presence of resource-constrained IoT devices. Hence, there is a need to conduct penetration testing at the level of IoT systems. However, the main issue is the fact that IoT consists of a large variety of IoT devices, firmware, hardware, software, application/web-servers, networks, and communication protocols. Therefore, to reduce the effect of these attacks on IoT systems, periodic penetration testing and ethical hacking simulations are highly recommended at different levels (end-devices, infrastructure, and users) for IoT, and can be considered as a suitable solution. Therefore, the focus of this paper is to explain, analyze and assess both technical and non-technical aspects of security vulnerabilities within IoT systems via ethical hacking methods and tools. This would offer practical security solutions that can be adopted based on the assessed risks. This process can be considered as a simulated attack(s) with the goal of identifying any exploitable vulnerability or/and a security gap in any IoT entity (end devices, gateway, or servers) or firmware.",https://doi.org/10.1016/j.iotcps.2023.04.002,https://www.sciencedirect.com/science/article/pii/S2667345223000238,,,,2023,"Ethical hacking for IoT: Security issues, challenges, solutions and recommendations",Jean-Paul A. Yaacoub and Hassan N. Noura and Ola Salman and Ali Chehab,article,YAACOUB2023280,Internet of Things and Cyber-Physical Systems,,3,2667-3452,,,
,"Operator support system, production control, expert systems, chemical industry, estimation, pollution, diagnosis",263-268,,"Norsk Hydro a.s. is designing an operator support system to be implemented in a compound fertilizer plant by the summer of 1992. The goal of the system is to help operators keep process upsets to a minimum, thus reducing the total pollution from the plant as well as ensuring more stable product quality. This will be done by giving early warnings of process conditions that may lead to undesirable effects at a later time and by assisting the operators in tracing process upsets to their root cause. A combination of qualitative (rule-based) and quantitative (model-based) methods are used. The diagnosis is performed by a topological search from the detection point to the probable cause. The search is directed by automatic checking of process streams for unacceptable deviations. With few exceptions, rules are independent of the specific configuration, thus minimising the work needed after process modifications.",https://doi.org/10.1016/S1474-6670(17)50252-9,https://www.sciencedirect.com/science/article/pii/S1474667017502529,,,,1992,Operator Support System for Fertilizer Plant,A. Mjaavatten and S. Saelid,article,MJAAVATTEN1992263,IFAC Proceedings Volumes,4,25,1474-6670,"IFAC Symposium on On-line Fault Detection and Supervision in the Chemical Process Industries, Newark, Delaware, 22-24 April",,
,"Build-operate-transfer, Configuration management, Equipment vendor, Lifecycle, Network documentation, Operations team, Production engineering, Technical support, Troubleshooting",347-376,FTTx Networks,"This chapter provides information for operating the production network in steady-state production with a focus on the lifecycle of the network and the role of the Operations team in maintaining and optimizing the network. Several models for building the network are detailed, and key processes used to operate the network are enumerated and discussed.",https://doi.org/10.1016/B978-0-12-420137-8.00015-9,https://www.sciencedirect.com/science/article/pii/B9780124201378000159,Boston,Morgan Kaufmann,978-0-12-420137-8,2017,Chapter 15 - Production Operations,James Farmer and Brian Lane and Kevin Bourg and Weyl Wang,incollection,FARMER2017347,,,,,,James Farmer and Brian Lane and Kevin Bourg and Weyl Wang,
,"Suggesting reviewers, Reviewer recommendation, Graph mining, Software traceability, Pull-request review, Modern code review",106455,,"Context:
Various types of artifacts (requirements, source code, test cases, documents, etc.) are produced throughout the lifecycle of a software. These artifacts are connected with each other via traceability links that are stored in modern application lifecycle management repositories. Throughout the lifecycle of a software, various types of changes can arise in any one of these artifacts. It is important to review such changes to minimize their potential negative impacts. To make sure the review is conducted properly, the reviewer(s) should be chosen appropriately.
Objective:
We previously introduced a novel approach, named RSTrace, to automatically recommend reviewers that are best suited based on their familiarity with a given artifact. In this study, we introduce an advanced version of RSTrace, named RSTrace+ that accounts for recency information of traceability links including practical tool support for GitHub.
Methods:
In this study, we conducted a series of experiments on finding the appropriate code reviewer(s) using RSTrace+ and provided a comparison with the other code reviewer recommendation approaches.
Results:
We had initially tested RSTrace+ on an open source project (Qt 3D Studio) and achieved a top-3 accuracy of 0.89 with an MRR (mean reciprocal ranking) of 0.81. In a further empirical evaluation of 40 open source projects, we compared RSTrace+ with Naive-Bayes, RevFinder and Profile based approach, and observed higher accuracies on the average.
Conclusion:
We confirmed that the proposed reviewer recommendation approach yields promising top-k and MRR scores on the average compared to the existing reviewer recommendation approaches. Unlike other code reviewer recommendation approaches, RSTrace+ is not limited to recommending reviewers for source code artifacts and can potentially be used for recommending reviewers for other types of artifacts. Our approach can also visualize the affected artifacts and help the developer to make assessments of the potential impacts of change to the reviewed artifact.",https://doi.org/10.1016/j.infsof.2020.106455,https://www.sciencedirect.com/science/article/pii/S0950584920300021,,,,2021,RSTrace+: Reviewer suggestion using software artifact traceability graphs,Emre Sülün and Eray Tüzün and Uğur Doğrusöz,article,SULUN2021106455,Information and Software Technology,,130,0950-5849,,,
,,503-510,,"Modern equine anthelmintics can be divided into at least seven principal groups based on mode of action, i.e., benzimidazoles, pro-benzimidazoles, imidothiazoles, tetrahydropyrimidines, organophosphates, piperazines, and avermectins. The spectrum of activity of these drugs varies and resistance of cyathostomes to benzimidazole and pro-benzimidazole drugs has been observed in many areas. Cross resistance with other groups has not been reported in equines, however. Control is dependent upon understanding the capabilities of anthelmintics and the epizootiology of the important parasites, e.g., large strongyles, cyathostomes, ascarids and bots. Development of effective programs in a given region should be based on routine fecal analysis to ensure that treatment schedule and products selected are adequate for local climatic conditions and management methods.",https://doi.org/10.1016/0020-7519(87)90126-3,https://www.sciencedirect.com/science/article/pii/0020751987901263,,,,1987,Anthelmintics for horses,Richard B. Wescott,article,WESCOTT1987503,International Journal for Parasitology,2,17,0020-7519,,,
,"Game theory, Social dilemma, Public goods game, Trust management, Unwanted traffic control, Equilibrium",3-25,,"The Internet has witnessed an incredible growth in its pervasive use and brought unprecedented convenience to its users. However, an increasing amount of unwanted traffic, such as spam and malware, severely burdens both users and Internet service providers (ISPs), which arouses wide public concern. A Global Trust Management (GTM) system was proposed and demonstrated to be accurate, robust and effective on unwanted traffic control in our previous work (Yan et al., 2011, Yan et al., 2013). But its acceptance by network entities (ISPs and hosts) is crucial to its practical deployment and final success. In this paper, we investigate the acceptance conditions of the GTM system using game theory. Considering the selfish nature of network entities, we address our problem as a social dilemma. To enhance cooperation among network entities, a public-goods-based GTM game is formulated with a trust-based punishment mechanism that can provide the incentives of behaving cooperatively for network entities. Meanwhile, the conditions of the adoption of GTM system are figured out. We also carry out a number of simulations to illustrate the acceptance conditions of the GTM system in practical deployment, and show the effectiveness of the trust-based punishment mechanism. Furthermore, suggestions for ISPs cooperating with antivirus vendors are put forward.",https://doi.org/10.1016/j.cose.2014.03.010,https://www.sciencedirect.com/science/article/pii/S0167404814000492,,,,2014,Analysis on the acceptance of Global Trust Management for unwanted traffic control based on game theory,Yue Shen and Zheng Yan and Raimo Kantola,article,SHEN20143,Computers & Security,,47,0167-4048,"Trust in Cyber, Physical and Social Computing",,
,"Public private partnership, Co-treatment, Developing countries, Cost recovery, Waste stabilization ponds",114125,,"Globally, collection of tipping fees is being promoted as a solution to sustain the operation of fecal sludge treatment plants (FSTPs). Currently, there are six large-scale FSTPs in Ghana, of which five were in operation in June 2017. In Kumasi, Sekondi-Takoradi and Tamale, fecal sludge (FS) is co-treated with landfill leachate using waste stabilization ponds (WSPs). In Tema and Accra, FS is treated using WSPs and a mechanical dewatering system coupled with an upflow anaerobic sludge blanket (UASB). The focus of this study is FSTPs and to assess how, and if, the tipping fees set by the municipalities could enable cost recovery to sustain their long-term operation. Using a questionnaire survey to interview plant managers from the public and private sectors, and directors of waste management departments, we found that the overall average operation, maintenance and management (OM&M) costs per 1000 m3 of treated waste (FS or FS + leachate) in 2017 were USD89 in Kumasi, USD150 in Tamale, USD179 in Tema, USD244 in Sekondi-Takoradi and USD1,743 in Accra. There were important disparities between FSTPs due to their scale, age, and level of treatment and monitoring. Currently, most FSTPs charge tipping fees that range between USD310 and USD530/1000 m3 of FS, averaging USD421 ± 98/1000 m3 of FS discharged at FSTPs. Our study also showed that the OM&M costs of large-scale intensive FSTPs cannot be sustained by relying solely on tipping fees. However, there could be potential to cover the routine expenditures associated with operating smaller FSTPs that relying on WSP technologies.",https://doi.org/10.1016/j.jenvman.2021.114125,https://www.sciencedirect.com/science/article/pii/S0301479721021873,,,,2022,"The contribution of tipping fees to the operation, maintenance, and management of fecal sludge treatment plants: The case of Ghana",Rebecca Tanoh and Josiane Nikiema and Zipporah Asiedu and Nilanthi Jayathilake and Olufunke Cofie,article,TANOH2022114125,Journal of Environmental Management,,303,0301-4797,,,
,"Continuous integration, Refactoring, Exploratory study, Mining software repositories, Multiple Regression Analysis",106618,,"Context:
The ultimate goal of Continuous Integration (CI) is to support developers in integrating changes into production constantly and quickly through automated build process. While CI provides developers with prompt feedback on several quality dimensions after each change, such frequent and quick changes may in turn compromise software quality without Refactoring. Indeed, recent work emphasized the potential of CI in changing the way developers perceive and apply refactoring. However, we still lack empirical evidence to confirm or refute this assumption.
Objective:
We aim to explore and understand the evolution of refactoring practices, in terms of frequency, size and involved developers, after the switch to CI in order to emphasize the role of this process in changing the way Refactoring is applied.
Method:
We collect a corpus of 99,545 commits and 89,926 refactoring operations extracted from 39 open-source GitHub projects that adopt Travis CI and analyze the changes using Multiple Regression Analysis (MRA).
Results:
Our study delivers several important findings. We found that the adoption of CI is associated with a drop in the refactoring size as recommended, while refactoring frequency as well as the number (and its related rate) of developers that perform refactoring are estimated to decrease after the shift to CI, indicating that refactoring is less likely to be applied in CI context.
Conclusion:
Our study uncovers insights about CI theory and practice and adds evidence to existing knowledge about CI practices related especially to quality assurance. Software developers need more customized refactoring tool support in the context of CI to better maintain and evolve their software systems.",https://doi.org/10.1016/j.infsof.2021.106618,https://www.sciencedirect.com/science/article/pii/S0950584921000914,,,,2021,On the impact of Continuous Integration on refactoring practice: An exploratory study on TravisTorrent,Islem Saidani and Ali Ouni and Mohamed Wiem Mkaouer and Fabio Palomba,article,SAIDANI2021106618,Information and Software Technology,,138,0950-5849,,,
,"Health and medical informatics, Open source software (OSS), Sponsorship, License type",457-472,,"Purpose
Little has been published about the application profiles and development patterns of open source software (OSS) in health and medical informatics. This study explores these issues with an analysis of health and medical informatics related OSS projects on SourceForge, a large repository of open source projects.
Methodology
A search was conducted on the SourceForge website during the period from May 1 to 15, 2007, to identify health and medical informatics OSS projects. This search resulted in a sample of 174 projects. A Java-based parser was written to extract data for several of the key variables of each project. Several visually descriptive statistics were generated to analyze the profiles of the OSS projects.
Results
Many of the projects have sponsors, implying a growing interest in OSS among organizations. Sponsorship, we discovered, has a significant impact on project success metrics. Nearly two-thirds of the projects have a restrictive license type. Restrictive licensing may indicate tighter control over the development process. Our sample includes a wide range of projects that are at various stages of development (status). Projects targeted towards the advanced end user are primarily focused on bio-informatics, data formats, database and medical science applications.
Conclusion
We conclude that there exists an active and thriving OSS development community that is focusing on health and medical informatics. A wide range of OSS applications are in development, from bio-informatics to hospital information systems. A profile of OSS in health and medical informatics emerges that is distinct and unique to the health care field. Future research can focus on OSS acceptance and diffusion and impact on cost, efficiency and quality of health care.",https://doi.org/10.1016/j.ijmedinf.2009.02.006,https://www.sciencedirect.com/science/article/pii/S1386505609000318,,,,2009,The State and Profile of Open Source Software Projects in health and medical informatics,Balaji Janamanchi and Evangelos Katsamakas and Wullianallur Raghupathi and Wei Gao,article,JANAMANCHI2009457,International Journal of Medical Informatics,7,78,1386-5056,,,
,"Citizen participation, Crowdsourcing platform, Digitalization, Rapid flood spreading model (RFSM), 3D inundation mapping, Volunteered geographic information (VGI)",105496,,"The recent advancement in digital twin technology, which creates virtual replicas of real-world processes, offers an interactive testbed for understanding and predicting environmental changes. As pluvial flood damage escalates globally in urban areas, there remains a gap in understanding the most effective collaboration between governments and local residents for sustainable flood risk management. To address this gap, we develop a participatory framework for urban pluvial flood modeling, incorporating open source software, virtual reality, minimum viable product, and gamification components. This framework engages citizens in every phase of the participatory modeling process, from input data preparation, through hydrological model construction, to model verification, and experiments. We present a case study on the recurring pluvial flood damages in South Korea's Gangnam region, demonstrating the practical implications of an interactive, web-based crowdsourcing platform to leverage community engagement and local knowledge. The results underscore the evidence of a proactive role for citizens, not merely as recipients of disaster information but as key contributors collaborating with a range of stakeholders in stormwater management and modeling. Combining digital twin technology with citizen participation can empower informed decision-making and collective actions in the evolving digital era, leading to a disaster-resilient community.",https://doi.org/10.1016/j.scs.2024.105496,https://www.sciencedirect.com/science/article/pii/S2210670724003238,,,,2024,Participatory Framework for Urban Pluvial Flood Modeling in the Digital Twin Era,Samuel Park and Jaekyoung Kim and Yejin Kim and Junsuk Kang,article,PARK2024105496,Sustainable Cities and Society,,108,2210-6707,,,
,,247-254,Cybercrime and Espionage,,https://doi.org/10.1016/B978-1-59749-613-1.00019-4,https://www.sciencedirect.com/science/article/pii/B9781597496131000194,Boston,Syngress,978-1-59749-613-1,2011,,,incollection,2011247,,,,,,Will Gragido and John Pirc,
,"Open source software (OSS), Development process performance, Issue closure rate, Work centralization, Issue workflow, Surgical team",32-46,,"Context: Better methods of evaluating process performance of OSS projects can benefit decision makers who consider adoption of OSS software in a company. This article studies the closure of issues (bugs and features) in GitHub projects, which is an important measure of OSS development process performance and quality of support that project users receive from the developer team. Objective: The goal of this article is a better understanding of the factors that affect issue closure rates in OSS projects. Methodology: The GHTorrent repository is used to select a large sample of mature, active OSS projects. Using survival analysis, we calculate short-term, and long-term issue closure rates. We formulate several hypotheses regarding the impact of OSS project and team characteristics, such as measures of work centralization, measures that reflect internal project workflows, and developer social networks measures on issue closure rates. Based on the proposed features and several control features, a model is built that can predict issue closure rate. The model allows to test our hypotheses. Results: We find that large teams that have many project members have lower issue closure rates than smaller teams. Similarly, increased work centralization increases issue closure rates. While desirable social network characteristics have a positive impact on the amount of commits in a project, they do not have significant influence on issue closure. Conclusion: Overall, findings from empirical analysis support the classic notion of Brook’s – the “surgical team” – in the context of OSS project development process performance on GitHub. The model of issue closure rates proposed in this article is a first step towards an improved understanding and prediction of this important measure of OSS development process performance.",https://doi.org/10.1016/j.infsof.2018.03.010,https://www.sciencedirect.com/science/article/pii/S095058491730304X,,,,2018,Surgical teams on GitHub: Modeling performance of GitHub project development processes,Oskar Jarczyk and Szymon Jaroszewicz and Adam Wierzbicki and Kamil Pawlak and Michal Jankowski-Lorek,article,JARCZYK201832,Information and Software Technology,,100,0950-5849,,,
,"Mining software repositories, Deep learning, Encoder–decoder neural network, Third-party libraries upgrade",117267,,"To keep their code up-to-date with the newest functionalities as well as bug fixes offered by third-party libraries, developers often need to replace an old version of third-party libraries (TPLs) with a newer one. However, choosing a suitable version for a library to be upgraded is complex and susceptible to error. So far, Dependabot is the only tool that supports library upgrades; however, it targets only security fixes and singularly analyzes libraries without considering the whole set of related libraries. In this work, we propose DeepLib as a practical approach to learn upgrades for third-party libraries that have been performed by similar clients. Such upgrades are considered safe, i.e., they do not trigger any conflict, since, in the training clients, the libraries already co-exist without causing any compatibility or dependency issues. In this way, the upgrades provided by DeepLib allow developers to maintain a harmonious relationship with other libraries. By mining the development history of projects, we build migration matrices to train deep neural networks. Once being trained, the networks are then used to forecast the subsequent versions of the related libraries, exploiting the well-founded background related to the machine translation domain. As input, DeepLib accepts a set of library versions and returns a set of future versions to which developers should upgrade the libraries. The framework has been evaluated on two real-world datasets curated from the Maven Central Repository. The results show promising outcomes: DeepLib can recommend the next version for a library as well as a set of libraries under investigation. At its best performance, DeepLib gains a perfect match for several libraries, earning an accuracy of 1.0.",https://doi.org/10.1016/j.eswa.2022.117267,https://www.sciencedirect.com/science/article/pii/S0957417422006388,,,,2022,DeepLib: Machine translation techniques to recommend upgrades for third-party libraries,Phuong T. Nguyen and Juri {Di Rocco} and Riccardo Rubei and Claudio {Di Sipio} and Davide {Di Ruscio},article,NGUYEN2022117267,Expert Systems with Applications,,202,0957-4174,,,
,"Soil-water retention, Interfacial area, Unsaturated clay, Adsorption, Machine learning",105678,,"In this article, we investigate the nanoscale soil-water retention mechanism of unsaturated clay through molecular dynamics and machine learning. Pyrophyllite was chosen due to its stable structure and as the precursor of other 2:1 clay minerals. A series of molecular dynamics simulations of clay at low degrees of saturation were conducted. Soil water was represented by a point cloud through the center-of-mass method. Water-air interface area was measured numerically by the alpha-shape method. The soil-water retention mechanism at the nanoscale was analyzed by distinguishing adsorptive pressure and capillary pressure at different mass water contents and considering the apparent capillary interface area (i.e., water-air interface area per unit water volume). The water number density profile was used to quantify the adsorption effect. A neural-network based machine learning technique was utilized to construct functional relationships among matric suction, the mass water content, and the apparent water-air interface area. Our numerical results have demonstrated from a nanoscale perspective that the adsorption effect is dominated by the van der Waals force and hydroxyl hydration between the clay surface and water. As the mass water content increases, the adsorption pressure decreases, and capillarity plays a prominent role in the soil-water retention mechanism at the nanoscale.",https://doi.org/10.1016/j.compgeo.2023.105678,https://www.sciencedirect.com/science/article/pii/S0266352X23004354,,,,2023,Nanoscale soil-water retention mechanism of unsaturated clay via MD and machine learning,Zhe Zhang and Xiaoyu Song,article,ZHANG2023105678,Computers and Geotechnics,,163,0266-352X,,,
,"Shoulder, Fracture, Trauma, Outcome instrument, Psychometric, Validity, Reliability, Responsiveness",248-252,,"The increasing shift towards patient-centred healthcare has lead to an emergence of patient-reported outcome instruments to quantify functional outcomes in orthopaedic patients. Unfortunately, selecting an instrument for use in a shoulder trauma population is often problematic because most shoulder instruments were initially designed for use with chronic shoulder pathology patients. To ensure an instrument is valid, reliable, and sensitive to clinical changes, it is important to obtain psychometric evidence of its use in the target population. Four commonly used shoulder outcome instruments are reviewed in this paper: American Shoulder and Elbow Surgeons Standardized Shoulder Assessment Form (ASES); Constant–Murley shoulder score (CMS); Disabilities of Arm, Shoulder, and Hand (DASH); Oxford Shoulder Score (OSS). Each instrument was reviewed for floor or ceiling effects, validity, reliability, responsiveness, and interpretability. Additionally, evidence of each instrument's psychometric properties was sought in shoulder fracture populations. Based on the current literature, each instrument has limited amounts of evidence to support their use in shoulder trauma populations. Overall, psychometric evaluations in isolated shoulder fracture populations remain scarce, and clinicians must remember that an instrument's properties are defined for the population tested and not the instrument. Therefore, caution must always be exercised when using an instrument that has not been fully evaluated in trauma populations.",https://doi.org/10.1016/j.injury.2010.11.046,https://www.sciencedirect.com/science/article/pii/S0020138310007813,,,,2011,Measuring shoulder injury function: Common scales and checklists,G.P. Slobogean and B.L. Slobogean,article,SLOBOGEAN2011248,Injury,3,42,0020-1383,Assessing Patient Outcomes,,
,"Chatbot, IoT, Deep learning, BERT, NLP, AI",100419,,"The advent of modern technologies like Artificial Intelligence(AI), Internet of Things(IoT) and Deep Learning(DL) has ushered in a transformative era in healthcare, offering innovative solutions towards personalized healthcare by enhancing the quality of various medical services. Our proposed methodology involves the development of a BERT-based medical chatbot, leveraging cutting-edge deep learning technology to significantly enhance healthcare communication and accessibility. The traditional challenges faced by medical chatbots, such as imprecise understanding of medical conversations, inaccurate responses to jargon, and the inability to offer personalized feedback, are addressed through the utilization of Bidirectional Encoder Representations from Transformers (BERT). The performance metrics of our chatbot underscore its effectiveness. With an accuracy of 98%, the chatbot ensures a high level of precision in handling medical queries. The precision score of 97% attests to the accuracy and reliability of its responses. The AUC-ROC score of 97% indicates the chatbot's exceptional ability to predict specific diseases based on user queries and symptoms, showcasing its robust predictive power. Furthermore, a recall of 96% demonstrates the chatbot's capability to avoid missing cases in medical diagnoses, ensuring comprehensive coverage of potential conditions. The F1 score of 98% showcases the chatbot's proficiency in delivering accurate and personalized healthcare information, striking a harmonious balance between precision and recall. Our BERT-based medical chatbot not only addresses the limitations of traditional approaches but also achieves a remarkable performance with high accuracy, precision, predictive power, and comprehensive coverage, making it a valuable tool for advancing the quality of healthcare services.",https://doi.org/10.1016/j.rcsop.2024.100419,https://www.sciencedirect.com/science/article/pii/S2667276624000143,,,,2024,BERT-Based Medical Chatbot: Enhancing Healthcare Communication through Natural Language Understanding,Arun Babu and Sekhar Babu Boddu,article,BABU2024100419,Exploratory Research in Clinical and Social Pharmacy,,13,2667-2766,,,
,"Bitumen modification, Castor oil, Waste tires recycling, Reclaimed rubber, Rheological properties, Epoxy resin",141524,,"The bitumen industry in the European Union is facing several difficulties, including rising demand, unstable oil supply, rising prices for synthetic polymer modifiers, and a focus on lowering carbon footprint. Bitumen modification with crumb rubber (CR) is one of the most promising solution to these challenges. However, CR-modified bitumen have poor processability and low storage stability. To overcome these flaws we are introducing a sustainable approach for ecological modification of bitumen taking advantage of renewable resources. For this reason, unmodified castor oil was selected as a green modifier of reclaimed rubber dust. The ecologically modified bitumen underwent visco-elastic behavior analysis based on rheological tests varying the temperature. The modification with rubber-oil improved the longevity of typical pavement, featured by an exceptional deformation resistance at elevated temperatures (well above 70 °C, the maximum pavement temperature reported in the region). The Cole-Cole graphs and black space diagrams unraveled the enhanced elasticity of bitumen. Technically, in comparison to plain bitumen, the compatibility ratio of modified bitumen to aggregates showed an uplift by 258%. The environmentally friendly bitumen modified ecologically herein revealed potential for performance window enlargement. Nevertheless, future investigations should focus on optimization of the bitumen formulation, along with examination of other sustainable moieties for the sake of commercialization of the developed binders in pavement construction.",https://doi.org/10.1016/j.jclepro.2024.141524,https://www.sciencedirect.com/science/article/pii/S0959652624009727,,,,2024,"Eco-friendly modification of bitumen: The effects of rubber wastes and castor oil on the microstructure, processability and properties",Maciej Sienkiewicz and Przemysław Gnatowski and Mateusz Malus and Anna Grzegórska and Hossein Ipakchi and Maryam Jouyandeh and Justyna Kucińska-Lipka and Francisco Javier Navarro and Mohammad Reza Saeb,article,SIENKIEWICZ2024141524,Journal of Cleaner Production,,447,0959-6526,,,
,"Modern code review, Software quality, Code reviewers recommendation, Search-based software engineering",106908,,"Contemporary software development is distributed and characterized by high dynamics with continuous and frequent changes to fix defects, add new user requirements or adapt to other environmental changes. To manage such changes and ensure software quality, modern code review is broadly adopted as a common and effective practice. Yet several open-source as well as commercial software projects have adopted peer code review as a crucial practice to ensure the quality of their software products using modern tool-based code review. Nevertheless, the selection of peer reviewers is still merely a manual and hard task especially with the growing size of distributed development teams. Indeed, it has been proven that inappropriate peer reviewers selection can consume more time and effort from both developers and reviewers and increase the development costs and time to market. To address this problem, we introduce a multi-objective search-based approach, named WhoReview, to find the optimal set of peer reviewers for code changes. We use the Indicator-Based Evolutionary Algorithm (IBEA) to find the best set of code reviewers that are (1) most experienced with the code change to be reviewed, while (2) considering their current workload, i.e., the number of open code reviews they are working on. We conduct an empirical study on 4 long-lived open source software projects to evaluate our approach. The obtained results show that WhoReview outperforms state-of-the-art approach by an average precision of 68% and recall of 77%. Moreover, we deployed our approach in an industrial context and evaluated it qualitatively from developers perspective. Results show the effectiveness of our approach with a high acceptance ratio in identifying relevant reviewers.",https://doi.org/10.1016/j.asoc.2020.106908,https://www.sciencedirect.com/science/article/pii/S1568494620308462,,,,2021,WhoReview: A multi-objective search-based approach for code reviewers recommendation in modern code review,Moataz Chouchen and Ali Ouni and Mohamed Wiem Mkaouer and Raula Gaikovina Kula and Katsuro Inoue,article,CHOUCHEN2021106908,Applied Soft Computing,,100,1568-4946,,,
,,333-343,,,https://doi.org/10.1016/j.jse.2010.10.028,https://www.sciencedirect.com/science/article/pii/S1058274610004441,,,,2011,Outcome measures in the management of proximal humeral fractures: a systematic review of their use and psychometric properties,Alexander T.M. {van de Water} and Nora Shields and Nicholas F. Taylor,article,VANDEWATER2011333,Journal of Shoulder and Elbow Surgery,2,20,1058-2746,,,
,"Internet of things (IoT) security, Attack detection, Network traffic predictability, Multi-Criteria decision making, Analytical hierarchical process (AHP)",103073,,"IoT devices are known to be vulnerable to various cyber-attacks, such as data exfiltration and the execution of flooding attacks as part of a DDoS attack. When it comes to detecting such attacks using network traffic analysis, it has been shown that some attack scenarios are not always equally easy to detect if they involve different IoT models. That is, when targeted at some IoT models, a given attack can be detected rather accurately, while when targeted at others the same attack may result in too many false alarms. In this research, we attempt to explain this variability of IoT attack detectability and devise a risk assessment method capable of addressing a key question: how easy is it for an anomaly-based network intrusion detection system to detect a given cyber-attack involving a specific IoT model? In the process of addressing this question we (a) investigate the predictability of IoT network traffic, (b) present a novel taxonomy for IoT attack detection which also encapsulates traffic predictability aspects, (c) propose an expert-based attack detectability estimation method which uses this taxonomy to derive a detectability score (termed ‘D-Score’) for a given combination of IoT model and attack scenario, and (d) empirically evaluate our method while comparing it with a data-driven method.",https://doi.org/10.1016/j.cose.2022.103073,https://www.sciencedirect.com/science/article/pii/S0167404822004655,,,,2023,D-Score: An expert-based method for assessing the detectability of IoT-related cyber-attacks,Yair Meidan and Daniel Benatar and Ron Bitton and Dan Avraham and Asaf Shabtai,article,MEIDAN2023103073,Computers & Security,,126,0167-4048,,,
,"Network intrusion detection system, Triple layered hybrid approach, Weighted deep neural network, CNN+LSTM and XGBoost",469-482,,"Anomaly-based intrusion detection system have been consistently used in business organizations and military to detect a breach in network by identifying any activity that deviates from the baseline pattern. In this paper, we propose an effective intrusion detection technique to identify and predict the minority attacks with three layers. Here, the first layer utilizes a Weighted Deep Neural Network (WDNN) for identifying the suspicious traffic samples in network and it is passed to the second layer. Layer 2 classifies the traffic samples as normal or majority and minority attacks using Convolutional Neural Network (CNN) and Long-Short Term Memory (LSTM). Any traffic sample classified as minority attack is sent to Layer 3 that utilizes XGBoost algorithm. Layer 3 classifies the samples into their respective minority attack classes. To boost the detection rate of minority attacks, system employs a One-Sided Selection under-sampling algorithm to remove noisy samples from the majority attack classes. An Adaptive Synthetic (ADASYN) oversampling algorithm generates synthetic samples of minority attack classes. To evaluate the system, the datasets namely NSL KDD, CICIDS-2017 and CIDDS 001 dataset are used. The system attained an overall accuracy of 97.94% on NSL KDD dataset, 98.3% on CICIDS-2017 dataset and 97.9% on CIDDS 001 dataset.",https://doi.org/10.1016/j.aej.2023.07.063,https://www.sciencedirect.com/science/article/pii/S1110016823006531,,,,2023,An effective technique for detecting minority attacks in NIDS using deep learning and sampling approach,R. Harini and N. Maheswari and Sannasi Ganapathy and M. Sivagami,article,HARINI2023469,Alexandria Engineering Journal,,78,1110-0168,,,
,"Borderline ovarian tumor, ex-vivo oocyte retrieval, fertility preservation",1787.e15-1787.e17,,"Objective
To report a novel fertility preservation strategy in a woman with recurrent serous borderline ovarian tumor in the conserved ovary involving ex-vivo retrieval of in vivo matured oocytes and subsequent embryo cryopreservation.
Design
Case report.
Setting
Tertiary infertility care unit.
Patient(s)
A 27-year-old woman presented for follow-up visit with a history of borderline serous adenocarcinoma treated conservatively with left oophorectomy and fertility-sparing laparoscopic staging. Ultrasound scan revealed a recurrent disease in the right ovary.
Intervention(s)
Ex-vivo retrieval of mature oocytes after ovarian stimulation.
Main Outcome Measure(s)
Fertility preservation.
Result(s)
The patient underwent ovarian stimulation followed by a laparotomy and oophorectomy on the day of oocyte retrieval. A puncture of the follicles was performed in the operating theatre with a maximum ischemia time of 14 minutes. Eleven mature oocytes were aspirating, resulting in seven zygotes for cryopreservation.
Conclusion(s)
Mature oocytes can be successfully retrieved ex-vivo from the oophorectomy specimen after a controlled ovarian hyperstimulation (COH) protocol. This method provides a possible strategy for fertility preservation in patients with recurrent ovarian cancer without the risk of cancer cells spillage associated with the standard transvaginal oocyte retrieval.",https://doi.org/10.1016/j.fertnstert.2010.11.023,https://www.sciencedirect.com/science/article/pii/S0015028210028098,,,,2011,Ex-vivo oocyte retrieval for fertility preservation,Human M. Fatemi and Dimitra Kyrou and Majedah Al-Azemi and Dominique Stoop and Philippe {De Sutter} and Claire Bourgain and Paul Devroey,article,FATEMI20111787.e15,Fertility and Sterility,5,95,0015-0282,,,
,"Cloud security, Cloud computing, Denial-of-service, Security threats, Intrusion detection systems",11-29,,"High quality computing services with reduced cost and improved performance have made cloud computing a popular paradigm. Due to its flexible infrastructure, net centric approach and ease of access, the cloud computing has become prevalent. Its widespread usage is however being diminished by the fact that the cloud computing paradigm is yet unable to address security issues which may in turn aggravate the quality of service as well as the privacy of customers' data. In this paper, we present a survey of security issues in terms of security threats and their remediations. The contribution aims at the analysis and categorization of working mechanisms of the main security issues and the possible solutions that exist in the literature. We perform a parametric comparison of the threats being faced by cloud platforms. Moreover, we compare various intrusion detection and prevention frameworks being used to address security issues. The trusted cloud computing and mechanisms for regulating security compliance among cloud service providers are also analyzed. Since the security mechanisms continue to evolve, we also present the future orientation of cloud security issues and their possible countermeasures.",https://doi.org/10.1016/j.jnca.2016.05.010,https://www.sciencedirect.com/science/article/pii/S1084804516301060,,,,2016,A survey of security issues for cloud computing,Minhaj Ahmad Khan,article,KHAN201611,Journal of Network and Computer Applications,,71,1084-8045,,,
,"Service placement, Internet of Things, Single objective, Multi-objective, Optimization, Meta-heuristic",100379,,"The fog computing paradigm is promising for deploying various delay-sensitive Internet of Things (IoT) applications. The resource-constrained fog devices restrict the number of application deployments due to a lack of efficient resource estimation and discovery mechanisms for various emergent heterogeneous IoT applications. An efficient resource allocation strategy is one of the best choices to meet these application’s Quality of Service (QoS) requirements and improve system performance. However, finding the best allocation strategy for IoT applications with more than one QoS parameter is a challenge, and it has been proved as a non-deterministic polynomial time (NP)-complete problem. This article formulates a classical weighted multi-objective IoT service placement to optimize three parameters, i.e., makespan, cost, and energy. The non-convexity nature of the solution space motivates us to focus on the population-based meta-heuristic algorithm, i.e. Genetic Algorithm (GA), Simulated Annealing (SA) and Particle Swarm Optimization (PSO), along with their combination GA-SA, and GA-PSO. It implements the algorithm and compares it with the greedy-based random placement approach, varying the number of IoT applications with different parameters. The final results reveal that the hybrid method GA-SA outperforms other state-of-the-art algorithms.",https://doi.org/10.1016/j.dajour.2023.100379,https://www.sciencedirect.com/science/article/pii/S2772662223002199,,,,2024,A hybrid meta-heuristic algorithm for multi-objective IoT service placement in fog computing environments,Hemant Kumar Apat and Bibhudutta Sahoo and Veena Goswami and Rabindra K. Barik,article,APAT2024100379,Decision Analytics Journal,,10,2772-6622,,,
,"Bot, Botnet, Command and control or C2, Cyberattack, Internet relay chat (IRC), Malware, Trojan horse, Zombie",265-274,Computer and Information Security Handbook (Third Edition),"Automated programs that covertly infect vulnerable computers and turn them into hosts for unauthorized networks are called bots. These infected hosts are configured to report back to a central system(s) run by an attacker, or bot-herder, and collectively form a botnet. Botnets may contain thousands of hosts and can be used to execute a variety of cyber-based attacks, in particular flooding target's networks and devices with too much traffic and stealing data from hosts infected with the bots. Accordingly, the aim of attackers who deploy botnets is usually to interrupt a target's operations or achieve financial gain. This problem is compounded by the spread of new technologies that connect a variety of devices to the Internet, making them susceptible to being an unwitting bot host or else a target of the botnet's massive disruption campaign. Given the global implications of so many potential hosts, preventing the spread of botnets and tracing the malicious cyber activity are key challenges to overcome when addressing the botnet problem.",https://doi.org/10.1016/B978-0-12-803843-7.00014-4,https://www.sciencedirect.com/science/article/pii/B9780128038437000144,Boston,Morgan Kaufmann,978-0-12-803843-7,2017,Chapter 14 - The Botnet Problem,Nailah Mims,incollection,MIMS2017265,,,,,,John R. Vacca,Third Edition
,,247-269,The Economics of Open Source Software Development,"Publisher Summary
This chapter constructs four social networks for the Open Source Software (OSS) development community at Source Forge. Social network analysis has been used in many research areas to discover the intrinsic mechanisms of social communities by examining the topological properties of the social network formed by relationships between the actors and the groups in those communities. For each social network, number of people are expanded in the network by including the next set of peripheral users as defined by their role in the community, moving from the core project leaders, to the core developers, to the co-developers, and finally out to active users. All the social networks have scale-free properties, and the inclusion of the co-developers and active users triggers the emergence of the small world phenomenon for the social network. The chapter examines how these topological network properties potentially explain the success and efficiency of OSS development practices.",https://doi.org/10.1016/B978-044452769-1/50012-3,https://www.sciencedirect.com/science/article/pii/B9780444527691500123,Amsterdam,Elsevier,978-0-444-52769-1,2006,12 - Application of Social Network Analysis to the Study of Open Source Software,Jin Xu and Scott Christley and Gregory Madey,incollection,XU2006247,,,,,,Jürgen Bitzer and Philipp J.H. Schröder,
,"Commenter recommendation, Reviewer recommendation, Attribute selection, Pull-based software development",48-62,,"Context: The pull-based software development helps developers make contributions flexibly and efficiently. Commenters freely discuss code changes and provide suggestions. Core members make decision of pull requests. Both commenters and core members are reviewers in the evaluation of pull requests. Since some popular projects receive many pull requests, commenters may not notice new pull requests in time, and even ignore appropriate pull requests. Objective: Our objective in this paper is to analyze attributes that affect the precision and recall of commenter prediction, and choose appropriate attributes to build commenter recommendation approach. Method: We collect 19,543 pull requests, 206,664 comments and 4817 commenters from 8 popular projects in GitHub. We build approaches based on different attributes, including activeness, text similarity, file similarity and social relation. We also build composite approaches, including time-based text similarity, time-based file similarity and time-based social relation. The time-based social relation approach is the state-of-the-art approach proposed by Yu et al. Then we compare precision and recall of different approaches. Results: We find that for 8 projects, the activeness based approach achieves the top-3 precision of 0.276, 0.386, 0.389, 0.516, 0.322, 0.572, 0.428, 0.402, and achieves the top-3 recall of 0.475, 0.593, 0.613, 0.66, 0.644, 0.791, 0.714, 0.65, which outperforms approaches based on text similarity, file similarity or social relation by a substantial margin. Moreover, the activeness based approach achieves better precision and recall than composite approaches. In comparison with the state-of-the-art approach, the activeness based approach improves the top-3 precision by 178.788%, 30.41%, 25.08%, 41.76%, 49.07%, 32.71%, 25.15%, 78.67%, and improves the top-3 recall by 196.875%, 36.32%, 29.05%, 46.02%, 43.43%, 27.79%, 25.483%, 79.06% for 8 projects. Conclusion: The activeness is the most important attribute in the commenter prediction. The activeness based approach can be used to improve the commenter recommendation in code review.",https://doi.org/10.1016/j.infsof.2016.10.006,https://www.sciencedirect.com/science/article/pii/S095058491630283X,,,,2017,Who should comment on this pull request? Analyzing attributes for more accurate commenter recommendation in pull-based development,Jing Jiang and Yun Yang and Jiahuan He and Xavier Blanc and Li Zhang,article,JIANG201748,Information and Software Technology,,84,0950-5849,,,
,"Oropharyngeal carcinoma, Transoral robotic surgery, TORS, Radiotherapy, Quality of life",108434,,"Background
Transoral Robotic Surgery (TORS) and radiotherapy are considered oncologically equivalent primary treatment options for early-stage HPV-positive oropharyngeal squamous cell carcinoma (OPSCC). Quality of Life (QoL) and Patient Reported Outcome Measures (PROMs) are therefore imperative in supporting clinical decision-making and optimising patient-centred care. The aim of this article is to evaluate how these primary treatment modalities compare in terms of QoL.
Materials and methods
Systematic review and meta-analysis of studies comparing primary TORS and primary radiotherapy for OPSCC using validated QoL tools. Swallowing and global QoL were the primary endpoints with secondary endpoints including all other QoL domains. An inverse variance random-effects model was employed to calculate the weighted estimate of the treatment effects across trials.
Results
A total of six studies collectively reporting on 555 patients were included (n = 236 TORS and n = 319 radiotherapy). Meta-analysis showed no significant difference for swallowing (mean difference = −0.24, p = 0.89) and global QoL (mean difference = 4.55, p = 0.14). For the remaining QoL domains (neck/shoulder impairment, neurotoxicity, voice, xerostomia, speech, and distress), the scarcity of data did not permit meta-analysis. However, the existing data showed no significant difference for any except for xerostomia where TORS appears favourable in the sole study reporting on this.
Conclusions
TORS and radiotherapy appear to be comparable primary treatment options for early stage OPSCC when it comes to QoL. However, a substantial proportion of patients in the TORS group received adjuvant (chemo)radiotherapy rendering it difficult to establish the ‘true’ QoL outcomes following surgery alone. There are also minimal studies reporting QoL outcomes beyond swallowing and global QoL. Further research is therefore needed, including more randomised trials adequately powered to detect differences in QoL outcomes.",https://doi.org/10.1016/j.ejso.2024.108434,https://www.sciencedirect.com/science/article/pii/S0748798324004864,,,,2024,Quality of life outcomes comparing primary Transoral Robotic Surgery (TORS) with primary radiotherapy for early-stage oropharyngeal squamous cell carcinoma: A systematic review and meta-analysis,Keshav Kumar Gupta and Mriganka De and Thanos Athanasiou and Christos Georgalas and George Garas,article,GUPTA2024108434,European Journal of Surgical Oncology,7,50,0748-7983,,,
,"Borderline tumor, conservative treatment, infertility, in vitro fertilization, pregnancy, recurrence",591-596,,"Objective
To evaluate safety and fertility outcome after the use of infertility drugs in patients who were treated conservatively for a borderline ovarian tumor (BOT).
Design
A retrospective multicenter study.
Setting
Centers participating in the French National Register on In Vitro Fertilization registry.
Patient(s)
Thirty patients who were treated for BOT who underwent ovarian induction (OI).
Intervention(s)
Ovarian induction was performed in 25 patients for infertility after conservative surgery and before surgery for recurrent disease in 5 patients with a single ovary (emergency cases).
Main Outcomes Measure(s)
Fertility and recurrences rates.
Result(s)
The mean number of cycles of OI per patient was 2.6 (range, 1–10 cycles). The median follow-up time after treatment of the BOT was 93 months (range, 26–276 months). After a median follow-up time of 42 months after OI, 4 recurrences were observed (initial management was simple cystectomy in 3 of them). All recurrences were borderline tumors on a remaining ovary that had been treated by surgery alone. All patients are currently disease-free. Thirteen pregnancies were observed (10 pregnancies (40%) in the group of 25 patients who were treated for infertility).
Conclusion(s)
These results suggest that infertility drugs could be used safely in patients who experience infertility after conservative management of an early-stage BOT.",https://doi.org/10.1016/j.fertnstert.2006.07.1503,https://www.sciencedirect.com/science/article/pii/S001502820604009X,,,,2007,Impact of infertility drugs after treatment of borderline ovarian tumors: results of a retrospective multicenter study,Anne Fortin and Philippe Morice and Anne Thoury and Sophie Camatte and Caroline Dhainaut and Patrick Madelenat,article,FORTIN2007591,Fertility and Sterility,3,87,0015-0282,,,
,"IT Security, Common vulnerability scoring system, Classification, National vulnerability database, Security management, Deep learning",103286,,"The number of newly published vulnerabilities is constantly increasing. Until now, the information available when a new vulnerability is published is manually assessed by experts using a Common Vulnerability Scoring System (CVSS) vector and score. This assessment is time consuming and requires expertise. Various works already try to predict CVSS vectors or scores using machine learning based on the textual descriptions of the vulnerability to enable faster assessment. However, for this purpose, previous works only use the texts available in databases such as National Vulnerability Database. With this work, the publicly available web pages referenced in the National Vulnerability Database are analyzed and made available as sources of texts through web scraping. A Deep Learning based method for predicting the CVSS vector is implemented and evaluated. The present work provides a classification of the National Vulnerability Database’s reference texts based on the suitability and crawlability of their texts. While we identified the overall influence of the additional texts is negligible, we outperformed the state-of-the-art with our Deep Learning prediction models.",https://doi.org/10.1016/j.cose.2023.103286,https://www.sciencedirect.com/science/article/pii/S0167404823001967,,,,2023,Common vulnerability scoring system prediction based on open source intelligence information sources,Philipp Kühn and David N. Relke and Christian Reuter,article,KUHN2023103286,Computers & Security,,131,0167-4048,,,
,"Systematic mapping study, Technical debt, Technical debt management, Tools, Automation",107375,,"Context:
Technical debt (TD) refers to non-optimal decisions made in software projects that may lead to short-term benefits, but potentially harm the system’s maintenance in the long-term. Technical debt management (TDM) refers to a set of activities that are performed to handle TD, e.g., identification or measurement of TD. These activities typically entail tasks such as code and architectural analysis, which can be time-consuming if done manually. Thus, substantial research work has focused on automating TDM tasks (e.g., automatic identification of code smells). However, there is a lack of studies that summarize current approaches in TDM automation. This can hinder practitioners in selecting optimal automation strategies to efficiently manage TD. It can also prevent researchers from understanding the research landscape and addressing the research problems that matter the most.
Objectives:
The main objective of this study is to provide an overview of the state of the art in TDM automation, analyzing the available tools, their use, and the challenges in automating TDM.
Methods:
We conducted a systematic mapping study (SMS), following the guidelines proposed by Kitchenham et al. From an initial set of 1086 primary studies, 178 were selected to answer three research questions covering different facets of TDM automation.
Results:
We found 121 automation artifacts that can be used to automate TDM activities. The artifacts were classified in 4 different types (i.e., tools, plugins, scripts, and bots); the inputs/outputs and interfaces were also collected and reported. Finally, a conceptual model is proposed that synthesizes the results and allows to discuss the current state of TDM automation and related challenges.
Conclusion:
The research community has investigated to a large extent how to perform various TDM activities automatically, considering the number of studies and automation artifacts we identified. Nonetheless, more research is needed towards fully automated TDM, specially concerning the integration of the automation artifacts.",https://doi.org/10.1016/j.infsof.2023.107375,https://www.sciencedirect.com/science/article/pii/S0950584923002306,,,,2024,Technical debt management automation: State of the art and future perspectives,João Paulo Biazotto and Daniel Feitosa and Paris Avgeriou and Elisa Yumi Nakagawa,article,BIAZOTTO2024107375,Information and Software Technology,,167,0950-5849,,,
,"Bug priority change, Open source software, Empirical study",112019,,"In issue tracking systems, each bug is assigned a priority level (e.g., Blocker, Critical, Major, Minor, or Trivial in JIRA from highest to lowest), which indicates the urgency level of the bug. In this sense, understanding bug priority changes helps to arrange the work schedule of participants reasonably, and facilitates a better analysis and resolution of bugs. According to the data extracted from JIRA deployed by Apache, a proportion of bugs in each project underwent priority changes after such bugs were reported, which brings uncertainty to the bug fixing process. However, there is a lack of in-depth investigation on the phenomenon of bug priority changes, which may negatively impact the bug fixing process. Thus, we conducted a quantitative empirical study on bugs with priority changes through analyzing 32 non-trivial Apache open source software projects. The results show that: (1) 8.3% of the bugs in the selected projects underwent priority changes; (2) the median priority change time interval is merely a few days for most (28 out of 32) projects, and half (50. 7%) of bug priority changes occurred before bugs were handled; (3) for all selected projects, 87.9% of the bugs with priority changes underwent only one priority change, most priority changes tend to shift the priority to its adjacent priority, and a higher priority has a greater probability to undergo priority change; (4) bugs that require bug-fixing changes of higher complexity or that have more comments are likely to undergo priority changes; and (5) priorities of bugs reported or allocated by a few specific participants are more likely to be modified, and maximally only one participant in each project tends to modify priorities.",https://doi.org/10.1016/j.jss.2024.112019,https://www.sciencedirect.com/science/article/pii/S0164121224000621,,,,2024,Bug priority change: An empirical study on Apache projects,Zengyang Li and Guangzong Cai and Qinyi Yu and Peng Liang and Ran Mo and Hui Liu,article,LI2024112019,Journal of Systems and Software,,212,0164-1212,,,
,"Live streaming, Developer communities, Gaming communities, Live coding, Online education, Collaborative learning",111630,,"People use the Internet to learn new skills, stay connected with friends, and find new communities to engage with. Live streaming platforms like Twitch.tv, YouTube Live, and Facebook Gaming provide a place where all three of these activities intersect and enable users to live-stream themselves playing a video game or live-coding software and game development, as well as the ability to participate in chat while watching someone else engage in an activity. Through fifteen interviews with software and game development streamers, we investigate why people choose to stream themselves programming and if they perceive themselves improving their programming skills by live streaming. We found that the motivations to stream included accountability, self-education, community, and visibility of the streamers’ work, and streamers perceived a positive influence on their ability to write source code. Our findings implicate that alternative learning methods like live streaming programming are a beneficial tool in the age of the virtual classroom. This work also contributes to and extends research efforts surrounding educational live streaming and collaboration in developer communities.",https://doi.org/10.1016/j.jss.2023.111630,https://www.sciencedirect.com/science/article/pii/S0164121223000250,,,,2023,"Streaming software development: Accountability, community, and learning",Ella Kokinda and Paige Rodeghero,article,KOKINDA2023111630,Journal of Systems and Software,,199,0164-1212,,,
,,S75,,,https://doi.org/10.1016/j.clim.2006.04.110,https://www.sciencedirect.com/science/article/pii/S1521661606002324,,,,2006,F.70. Melanoma Inhibitory Activity (MIA) Reflects Chondrocyte Anabolism in Chronic Inflammatory Arthritis: Suppression By Proinflammatory Cytokines Is Reversed By Targeted Therapy,Bernard Vandooren and Marie-Jose {van Lierop} and Tineke Cantaert and Leen {De Rycke} and Elli Kruithof and Eric Veys and Ebo Bos and Annemieke Boots and Dominique Baeten,article,VANDOOREN2006S75,Clinical Immunology,,119,1521-6616,FOCIS 2006 Abstract Supplement,,
,"Socio-smells, Socio-technical smells, Mining-software-repositories, Gitlog, Mailing-list, Issue-tracker, Identity-matching, Networks, Tools",111967,,"Context:
An extensive body of work has examined socio-technical activities in software development; however, the availability of tools to enable these studies is limited.
Aim:
We extend Kaiaulu, a software package for Mining Software Repositories to enable a broad spectrum analysis of Social Smells and Motifs.
Methods:
We perform a literature review to identify what tools are available which implement graph construction methods and social smell metrics, contextualizing the contributions of our tool.
Results:
The few tools identified in the literature either leverage fewer parts of the software ecosystem, have been archived, or depend on components no longer maintained.
Conclusion:
The socio-technical features in Kaiaulu complement existing tools and related literature, while providing a simple architecture to facilitate ease or use, and ease of learning, benefitting reproducibility.
Tool Repository:
github.com/sailuh/kaiaulu",https://doi.org/10.1016/j.jss.2024.111967,https://www.sciencedirect.com/science/article/pii/S0164121224000104,,,,2024,Analyzing the Tower of Babel with Kaiaulu,Carlos Paradis and Rick Kazman and Damian Tamburri,article,PARADIS2024111967,Journal of Systems and Software,,210,0164-1212,,,
,"Dot blot assay, Aptamer, SELEX, Diagnostics",122436,,"Dot blot assays have always been associated with antibodies as the main molecular recognition element, which are widely employed in a myriad of diagnostic applications. With the rising of aptamers as the equivalent molecular recognition elements of antibodies, dot blot assays are also one of the diagnostic avenues that should be scrutinized for their amenability with aptamers as the potential surrogates of antibodies. In this review, the stepwise procedures of an aptamer-based dot blot assays are underscored before reviewing the existing aptamer-based dot blot assays developed so far. Most of the applications center on monitoring the progress of SELEX and as the validatory assays to assess the potency of aptamer candidates. For the purpose of diagnostics, the current effort is still languid and as such possible suggestions to galvanize the move to spur the aptamer-based dot blot assays to a point-of-care arena are discussed.",https://doi.org/10.1016/j.talanta.2021.122436,https://www.sciencedirect.com/science/article/pii/S003991402100357X,,,,2021,Aptamers as the powerhouse of dot blot assays,Marimuthu Citartan,article,CITARTAN2021122436,Talanta,,232,0039-9140,,,
,,429-436,FTTx Networks,,https://doi.org/10.1016/B978-0-12-420137-8.18001-1,https://www.sciencedirect.com/science/article/pii/B9780124201378180011,Boston,Morgan Kaufmann,978-0-12-420137-8,2017,Index,,incollection,2017429,,,,,,James Farmer and Brian Lane and Kevin Bourg and Weyl Wang,
,"Adsorption, Floatability, Flotation, Frother, Low-energy surface, Plastic",2623-2631,,"Flotation tests of 35 polymer materials were carried out to investigate their floatability modulated by frothers. Results of flotation tests demonstrated that polymer resins and soft PVC showed high floatability, floatability of hard PVC plastics was relatively low and was related to the frothers, and there exists significant difference in the floatability of different post-consumer plastics. Flotation rate of post-consumer plastics varies from 0% to 100%. Furthermore, three-category low-energy surface (LES) was defined based on the hydrophile index of the materials involved in this paper, and an adsorption model was proposed to explain the results of flotation and to discuss the floatability of polymer materials modulated by frothers. Frother molecules are prone to adsorb on the surface of bubble rather than LES at relatively low concentration, bubble adsorbed by frother molecules is prone to approach first-category LES rather than third-category LES, and the structure of liquid film is formed on the first-category LES at large concentration. Floatability of polymer materials modulated by frothers is further discussed: frothers increase the floatability of the first-category LES but decrease the floatability of the third-category LES, while the floatability of the second-category LES is related to the type of frothers.",https://doi.org/10.1016/j.wasman.2013.09.003,https://www.sciencedirect.com/science/article/pii/S0956053X13004066,,,,2013,Floatability of polymer materials modulated by frothers,Hui Wang and Chong-qing Wang and Jian-gang Fu,article,WANG20132623,Waste Management,12,33,0956-053X,,,
,"Regional climate, central northern Sahara, NAO, Warming, Ouargla",852-862,,"Climate change shows itself in various scales in the Mediterranean and Sahara region. The study aims at characterizing climate of the Sahara in a bigger scale otherwise-said, precision as for the current climate reigning (evolution), at the level of the region of Ouargla. For that purpose, we adopted a complementary, dynamic and static approach. The dynamic approach was approached by compilations of the previous works. Followed by a static analysis, leaning on climatological data, spread over a period going from 1978 till 2015. It emerges from it that the dynamic character is characterized by the frequency of the regime NAO + with regard to that of the NAO-. This regime expresses himself daily, in terms, of temperature and haste, explaining the importing lived reheating these last decades. So, the results show that the region is characterized by a ""hot"" thermoclimate, expressed by all the energy parameters (rise of the fraction of sunstroke and the temperature) and a ""dry""ombroclimate.",https://doi.org/10.1016/j.egypro.2017.07.138,https://www.sciencedirect.com/science/article/pii/S1876610217326954,,,,2017,Did the global warming confirm in central northern Sahara (case of the Ouargla region )?,Fatiha Hadjaidji-Benseghier and Talbi Nadjib and et Derridj Arrezki,article,HADJAIDJIBENSEGHIER2017852,Energy Procedia,,119,1876-6102,"International Conference on Technologies and Materials for Renewable Energy, Environment and Sustainability, TMREES17, 21-24 April 2017, Beirut Lebanon",,
,,81-83,,,https://doi.org/10.1016/j.wpi.2013.10.003,https://www.sciencedirect.com/science/article/pii/S0172219013001221,,,,2014,Our referees – An appreciation,Michael Blackman and David Newton,article,BLACKMAN201481,World Patent Information,,36,0172-2190,,,
,"icroalgae, physicochemical approaches, surface interactions, magnetite, XDLVO theory, harvesting",1778-1787,,"Expensive cell concentration procedures represent one of the bottlenecks of large-scale microalgal biotechnological processes as many industrially attractive species have a small cell size and sustain in suspension. An economically effective solution is to alter the process conditions for the cells to form aggregates, which sediment faster. The use of magnetic agents binding to the cell surface and forming larger complexes, that sediment very fast upon application of an external magnetic field, is a rarely explored possibility in this area. We used commercially available, finely pulverized magnetite (Sigma Aldrich) as a potential harvesting agent and studied its surface interactions with an industrially important microalgal strain (Chlorella vulgaris). Firstly, we characterized the interacting surfaces in model environments by zeta potential and contact angle measurements, which were followed by particle size determination. Secondly, we applied the XDLVO theory to predict favorable experimental conditions for a successful magnetic cell modification, which would lead to an effective biomass separation. The hypotheses were then tested by using various ratios of magnetic agent and microalgal biomass under different environmental conditions. Obtained results were in good accordance with the predictions and we achieved an excellent separation efficiency of over 90% within a few minutes at a ratio of microalgae to magnetite 1:26 (w/w). We can conclude that magnetite successfully modifies the microalgal surface under certain conditions and is a promising agent for harvesting C. vulgaris, enabling high separation efficiencies in a very short period of time, but further research is necessary to optimize the process.",https://doi.org/10.1016/j.proeng.2012.07.572,https://www.sciencedirect.com/science/article/pii/S1877705812029797,,,,2012,Surface Modification of Chlorella Vulgaris Cells Using Magnetite Particles,G. Procházková and I. Šafařík and T. Brányik,article,PROCHAZKOVA20121778,Procedia Engineering,,42,1877-7058,CHISA 2012,,
,,1228.e1-1228.e7,,"Background
To determine the effect of oral testosterone supplementation on systemic low-grade inflammation measured by high-sensitive C-reactive protein (hs-CRP) in aging men with low testosterone levels.
Methods
Two hundred thirty-seven men aged 60 to 80 years with a testosterone level of <13.7 nmol/L (below the 50th percentile of the population distribution) were recruited into a double-blind randomized placebo-controlled trial. Participants were randomized to either 4 capsules of 40 mg testosterone undecanoate (Andriol Testocaps, NV Organon, Oss, The Netherlands) or placebo daily for 26 weeks. Serum levels of hs-CRP were measured at baseline and at 26 weeks using a near-infrared particle immunoassay of the Synchron LX System (Beckman Coulter, Fullteron, CA).
Results
The median baseline hs-CRP level was 1.95 mg/L (0.30-6.43) in the testosterone group compared with 1.90 mg/L (0.40-5.91) in the placebo group. After 26 weeks of testosterone supplementation therapy, the 2 intervention groups were not statistically significantly different (median hs-CRP 2.20 vs 2.00 mg/L, interquartile range 0.40-6.54 vs 0.50-5.70, P = .36). In subgroup analysis, neither baseline testosterone level, nor age, nor baseline CRP-level modified the effect of testosterone supplementation on CRP levels.
Conclusion
Oral testosterone undecanoate supplementation, in dosage of 160 mg daily for 26 weeks, does not increase hs-CRP levels in elderly men.",https://doi.org/10.1016/j.ahj.2007.09.001,https://www.sciencedirect.com/science/article/pii/S0002870307007594,,,,2007,"Oral testosterone supplementation and chronic low-grade inflammation in elderly men: A 26-week randomized, placebo-controlled trial",Hamid Reza Nakhai-Pour and Diederick E. Grobbee and Marielle H. Emmelot-Vonk and Michiel L. Bots and Harald J.J. Verhaar and Yvonne T. {van der Schouw},article,NAKHAIPOUR20071228.e1,American Heart Journal,6,154,0002-8703,,,
,"Company, energy, costs, hierarchy, control, stochastic, learning, mechanism",366-371,,"The paper examines the model of energy cost management in a four-level control system of company, includes its boss with the advisor on top level, administrator on the middle level, and managing director of the plant at the bottom level. Neither the boss nor the advisor knows minimal administrator and plant stochastic energy costs, and need to learn to control them. The administrator knows minimal stochastic costs better than the boss and the advisor. So the administrator can manipulate costs in order to influence the results of learning the advisor and the boss in own favor. But the administrator itself does not know the minimum stochastic costs in plant. This can be used by its director to achieve own goal. So the administrator also needs to learn to control the managing director. All of the interests of such active elements are reflected in the model by introducing goal functions. On the basis of this model, sufficient conditions have been found for the synthesis of a hierarchy of mechanisms for managing energy costs, ensuring the use of stochastic possibilities of reducing these costs. In these conditions, the boss needs training with the help of a self-learning consultant. Through this training, the boss can rate the administrator's costs. This mechanism encourages the administrator, firstly, to minimize overhead energy costs and, secondly, to implement an adaptive cost savings mechanism on the plant. Such an adaptive mechanism includes standardization and stimulation procedures that encourage the managing director to minimize the energy costs of the plant. The application of this approach is illustrated by the example of managing energy costs in a wagon repair company.",https://doi.org/10.1016/j.ifacol.2022.07.064,https://www.sciencedirect.com/science/article/pii/S2405896322004499,,,,2022,Comprehensive Mechanism for Four-Level Energy Cost Control,Vladimir V. Tsyganov,article,TSYGANOV2022366,IFAC-PapersOnLine,9,55,2405-8963,11th IFAC Symposium on Control of Power and Energy Systems CPES 2022,,
,"Ovarian sparing surgery, Ovariectomy, Oophorectomy, Ovarian tumors, Pediatrics, Fertility, Long term outcomes",106923,,"Introduction
An increased number of children and adolescents with ovarian tumors have been managed with ovarian-sparing surgery in the last few years. However, comprehensive data on fertility outcomes and local relapse are scarce. In this study, we systematically describe the contemporary outcomes of ovarian-sparing surgery, as reported in the literature.
Materials and methods
Using PRISMA guidelines, we analyzed studies reporting ovarian-sparing techniques for ovarian tumors in children and adolescents. from 1980 to 2022. Reports with fewer than three patients, narrative reviews, and opinion articles were excluded. Statistical analysis was performed for dichotomous and continuous variables.
Results
Of 283 articles screened, 16 papers (3057 patients) met inclusion criteria (15 retrospective/1 prospective) and were analyzed. The vast majority of studies had no long-term fertility follow-up data and direct comparison between ovarian-sparing surgery vs oophorectomy was reported in only a few studies. Ovarian sparing surgery was not associated with worse oncologic outcomes in terms of (i) tumour spillage or (ii) recurrence rates, and of key importance allowed a higher ovarian reserve at long term follow-up.
Conclusions
Ovarian-sparing surgery is a safe and feasible technique for benign tumors. Long-term outcome studies are needed to show efficacy and fertility preservation.",https://doi.org/10.1016/j.ejso.2023.04.022,https://www.sciencedirect.com/science/article/pii/S0748798323004821,,,,2023,Ovarian-sparing surgery for ovarian tumors in children: A systematic review and meta-analysis,Luca Pio and Ahmed Abu-Zaid and Tarek Zaghloul and Huma F. Halepota and Andrew M. Davidoff and Paul D. Losty and Hafeez H. Abdelhafeez,article,PIO2023106923,European Journal of Surgical Oncology,10,49,0748-7983,,,
,"Smart cities, Network datasets, Cybersecurity applications, Machine learning, Edge, Software-Defined Network (SDN), Network Function Virtualization (NFV), Service Orchestration (SO)",102994,,"While there has been a significant interest in understanding the cyber threat landscape of Internet of Things (IoT) networks, and the design of Artificial Intelligence (AI)-based security approaches, there is a lack of distributed architecture led to generating heterogeneous datasets that contain the actual behaviors of real-world IoT networks and complex cyber threat scenarios to evaluate the credibility of the new systems. This paper presents a novel testbed architecture of IoT network which can be used to evaluate Artificial Intelligence (AI)-based security applications. The platform NSX vCloud NFV was employed to facilitate the execution of Software-Defined Network (SDN), Network Function Virtualization (NFV) and Service Orchestration (SO) to offer dynamic testbed networks, which allow the interaction of edge, fog and cloud tiers. While deploying the architecture, real-world normal and attack scenarios are executed to collect labeled datasets. The generated datasets are named ‘TON_IoT’, as they comprise heterogeneous data sources collected from telemetry datasets of IoT services, Windows and Linux-based datasets, and datasets of network traffic. The TON_IoT network dataset is validated using four machine learning-based intrusion detection algorithms of Gradient Boosting Machine, Random Forest, Naive Bayes, and Deep Neural Networks, revealing a high performance of detection accuracy using the set of training and testing. A comparative summary of the TON_IoT network dataset and other competing network datasets demonstrates its diverse legitimate and anomalous patterns that can be used to better validate new AI-based security solutions. The architecture and datasets can be publicly accessed from TON_IOT Datasets (2020).",https://doi.org/10.1016/j.scs.2021.102994,https://www.sciencedirect.com/science/article/pii/S2210670721002808,,,,2021,A new distributed architecture for evaluating AI-based security systems at the edge: Network TON_IoT datasets,Nour Moustafa,article,MOUSTAFA2021102994,Sustainable Cities and Society,,72,2210-6707,,,
,"Access control, Ransomware, Malware, File systems, Software defects, Attacks, Cybersecurity",568-582,,"Traditional non-semantic file systems are not sufficient in protecting file systems against attacks, either caused by ransomware attacks or software-related defects. Furthermore, outbreaks of new malware often cannot provide a large quantity of training samples for machine-learning-based approaches to counter malware campaigns. The malware defense system should aim to achieve the best balance between early detection and detection accuracy. In this paper, we present a situation-aware access control framework to work with existing file systems as a stackable add-on. Our framework enables the access control decision making to be deferred when required, to observe the consequence of such an access request to the file system and to roll back changes if required. As an application against ransomware attacks, it can be applied to preserve file content integrity, by enforcing that all binary files written to the file system have consistent internal file structures with the declared file types, and rolling back changes that violate such constraints. We envision our access control framework to complement existing operating system access control frameworks, to significantly reduce the dimension of data required for machine learning, and to build extra resilience into the operating systems against damages caused by either malware or software defects. We demonstrate the practicality of our framework through a prototype testing, capturing relevant ransomware situations. The experimental results along with a large ransomware dataset show that our framework can be effectively applied in practice.",https://doi.org/10.1016/j.future.2020.09.035,https://www.sciencedirect.com/science/article/pii/S0167739X20305641,,,,2021,Enforcing situation-aware access control to build malware-resilient file systems,Timothy McIntosh and Paul Watters and A.S.M. Kayes and Alex Ng and Yi-Ping Phoebe Chen,article,MCINTOSH2021568,Future Generation Computer Systems,,115,0167-739X,,,
,"Honeypot, Honeypot framework, Cybersecurity, Threat intelligence",103737,,"Automated attacks allow adversaries to exploit vulnerabilities in enterprise IT systems at short notice. To identify such attacks as well as new cybersecurity threats, defenders use honeypot systems; these monitored decoy resources mimic legitimate devices to entice adversaries. The domain of enterprise IT honeypots has been an active area of development and research, especially in the open-source community. In this work, we survey open-source honeypots, honeypot frameworks, and tools that help to develop or discover honeypot deployments. In contrast to existing surveys, our work provides a detailed discussion of the honeypots’ system architecture, software architecture, and cloud-native deployment options. In addition, we cover the most recent academic research in honeypot detection and evasion techniques, and discuss how these advances impact current open-source honeypots. This work helps the reader to make an educated choice when selecting a honeypot for deployment or further development.",https://doi.org/10.1016/j.jnca.2023.103737,https://www.sciencedirect.com/science/article/pii/S108480452300156X,,,,2023,"A survey of contemporary open-source honeypots, frameworks, and tools",Niclas Ilg and Paul Duplys and Dominik Sisejkovic and Michael Menth,article,ILG2023103737,Journal of Network and Computer Applications,,220,1084-8045,,,
,"Change intent analysis, Review effort, Machine learning",106408,,"Context: Code changes to software occur due to various reasons such as bug fixing, new feature addition, and code refactoring. Change intents have been studied for years to help developers understand the rationale behind code commits. However, in most existing studies, the intent of the change is rarely leveraged to provide more specific, context aware analysis. Objective: In this paper, we present the first study to leverage change intent to characterize and identify Large-Review-Effort (LRE) changes—changes with large review effort. Method: Specifically, we first propose a feedback-driven and heuristics-based approach to identify change intents of code changes. We then characterize the changes regarding review effort by using various features extracted from change metadata and the change intents. We further explore the feasibility of automatically classifying LRE changes. We conduct our study on four large-scale projects, one from Microsoft and three are open source projects, i.e., Qt, Android, and OpenStack. Results: Our results show that, (i) code changes with some intents (i.e., Feature and Refactor) are more likely to be LRE changes, (ii) machine learning based prediction models are applicable for identifying LRE changes, and (iii) prediction models built for code changes with some intents achieve better performance than prediction models without considering the change intent, the improvement in AUC can be up to 19 percentage points and is 7.4 percentage points on average. Conclusion: The change intent analysis and its application on LRE identification proposed in this study has already been used in Microsoft to provide the review effort and intent information of changes for reviewers to accelerate the review process. To show how to deploy our approaches in real-world practice, we report a case study of developing and deploying the intent analysis system in Microsoft. Moreover, we also evaluate the usefulness of our approaches by using a questionnaire survey. The feedback from developers demonstrate its practical value.",https://doi.org/10.1016/j.infsof.2020.106408,https://www.sciencedirect.com/science/article/pii/S0950584920300033,,,,2021,Large-scale intent analysis for identifying large-review-effort code changes,Song Wang and Chetan Bansal and Nachiappan Nagappan,article,WANG2021106408,Information and Software Technology,,130,0950-5849,,,
,"Network theory, Open source software, Private-collective innovation, Propensity score matching",114406,,"Much research on open source software development has highlighted the best-of-both-worlds benefits generated by private and collective contributions from a broad base of developers. However, these studies have tended to overlook the heterogeneous nature of various developer groups including firm-sponsored developers. To unveil the behavioural differences between developer groups, we expand upon the private-collective innovation model using a networking approach, linking network closure and positional embeddedness with technical contribution. We tested our predictions using a lagged analysis based on communication and networking behaviours on the Linux kernel mailing-list in the production of the Linux operation system over a three-year period. Our findings support our predictions, showing that network closure has an adverse impact on technical contribution. Additionally, the relationship between positional embeddedness and technical contribution follows an inverted U-shape. In addition, high positional embeddedness counteracts the negative influence of extensive network closure on technical contribution. These effects are partly moderated by respective developer groups. Our model and results offer important theoretical and practical implications for community management within the framework of private-collective innovation.",https://doi.org/10.1016/j.jbusres.2023.114406,https://www.sciencedirect.com/science/article/pii/S0148296323007658,,,,2024,All of the same breed? A networking perspective of private-collective innovation,George Kuk and Mario Schaarschmidt and Dirk Homscheid,article,KUK2024114406,Journal of Business Research,,172,0148-2963,,,
,"Experimental economics, Web-based, Software, Online experiments, Web-based experiments, Economic experiments",138-160,,"Web-based experiments that cut across the lab vs. field distinction are increasingly popular with economists. However, non-standardized software features and services hinder comparability and replication. This study reviews a wide selection of experimental economics software packages and evaluates them against criteria based on the logistics and operational requirements of economic experiments. We find that oTree and SoPHIE rank highest across criteria, but Veconlab and classEx might be suitable for those with a dominant need for a large library of ready-made experiments. We find a portability gap: no presently available software allows portability of experiments across platforms because of technical complexity and the challenging coordination needs of experimental economists. As a result, experiments may be replicated only on the same platform or with the same software, but general replicability is slow and costly. This constrains the development of experimental economics as a replicable science.",https://doi.org/10.1016/j.jbef.2019.04.007,https://www.sciencedirect.com/science/article/pii/S221463501830090X,,,,2019,Web-based experimental economics software: How do they compare to desirable features?,Shu Wing Chan and Steven Schilizzi and Md Sayed Iftekhar and Raymond {Da Silva Rosa},article,CHAN2019138,Journal of Behavioral and Experimental Finance,,23,2214-6350,,,
,,87-89,,,https://doi.org/10.1016/S0927-7765(01)00295-8,https://www.sciencedirect.com/science/article/pii/S0927776501002958,,,,2002,Hans Visser 1936–2001,Carel Jan {van Oss},article,VANOSS200287,Colloids and Surfaces B: Biointerfaces,2,24,0927-7765,,,
,"Software documentation, Open science, Open access, Traceability",111117,,"Traceability between published scientific breakthroughs and their implementation is essential, especially in the case of open-source scientific software which implements bleeding-edge science in its code. However, aligning the link between GitHub repositories and academic papers can prove difficult, and the current practice of establishing and maintaining such links remains unknown. This paper investigates the role of academic paper references contained in these repositories. We conduct a large-scale study of 20 thousand GitHub repositories that make references to academic papers. We use a mixed-methods approach to identify public access, traceability and evolutionary aspects of the links. Although referencing a paper is not typical, we find that a vast majority of referenced academic papers are public access. These repositories tend to be affiliated with academic communities. More than half of the papers do not link back to any repository. We find that academic papers from top-tier SE venues are not likely to reference a repository, but when they do, they usually link to a GitHub software repository. In a network of arXiv papers and referenced repositories, we find that the most referenced papers are (i) highly-cited in academia and (ii) are referenced by repositories written in different programming languages.",https://doi.org/10.1016/j.jss.2021.111117,https://www.sciencedirect.com/science/article/pii/S0164121221002144,,,,2022,"GitHub repositories with links to academic papers: Public access, traceability, and evolution",Supatsara Wattanakriengkrai and Bodin Chinthanet and Hideaki Hata and Raula Gaikovina Kula and Christoph Treude and Jin Guo and Kenichi Matsumoto,article,WATTANAKRIENGKRAI2022111117,Journal of Systems and Software,,183,0164-1212,,,
,,96-98,,,https://doi.org/10.1016/j.wpi.2011.11.006,https://www.sciencedirect.com/science/article/pii/S0172219011001876,,,,2012,Our Referees – An Appreciation,Michael Blackman and David Newton,article,BLACKMAN201296,World Patent Information,1,34,0172-2190,,,
,"Deep brain stimulation, Parkinson's disease, Animal models, Rat, Rodent, Neuroimaging, Open-source, Research software",113978,,"Deep Brain Stimulation (DBS) is an efficacious treatment option for an increasing range of brain disorders. To enhance our knowledge about the mechanisms of action of DBS and to probe novel targets, basic research in animal models with DBS is an essential research base. Beyond nonhuman primate, pig, and mouse models, the rat is a widely used animal model for probing DBS effects in basic research. Reconstructing DBS electrode placement after surgery is crucial to associate observed effects with modulating a specific target structure. Post-mortem histology is a commonly used method for reconstructing the electrode location. In humans, however, neuroimaging-based electrode localizations have become established. For this reason, we adapt the open-source software pipeline Lead-DBS for DBS electrode localizations from humans to the rat model. We validate our localization results by inter-rater concordance and a comparison with the conventional histological method. Finally, using the open-source software pipeline OSS-DBS, we demonstrate the subject-specific simulation of the VTA and the activation of axon models aligned to pathways representing neuronal fibers, also known as the pathway activation model. Both activation models yield a characterization of the impact of DBS on the target area. Our results suggest that the proposed neuroimaging-based method can precisely localize DBS electrode placements that are essentially rater-independent and yield results comparable to the histological gold standard. The advantages of neuroimaging-based electrode localizations are the possibility of acquiring them in vivo and combining electrode reconstructions with advanced imaging metrics, such as those obtained from diffusion or functional magnetic resonance imaging (MRI). This paper introduces a freely available open-source pipeline for DBS electrode reconstructions in rats. The presented initial validation results are promising.",https://doi.org/10.1016/j.expneurol.2022.113978,https://www.sciencedirect.com/science/article/pii/S0014488622000036,,,,2022,Deep brain stimulation electrode modeling in rats,Andrea Andree and Ningfei Li and Konstantin Butenko and Maria Kober and Jia Zhi Chen and Takahiro Higuchi and Mareike Fauser and Alexander Storch and Chi Wang Ip and Andrea A. Kühn and Andreas Horn and Ursula {van Rienen},article,ANDREE2022113978,Experimental Neurology,,350,0014-4886,,,
,"Open Source Software community, Distributed and asynchronous design, Online discussions, Quoting, Role",141-165,,"This paper is an analysis of online discussions in an Open Source Software (OSS) design community, the Python project. Developers of Python are geographically distributed and work online asynchronously. The objective of our study is to understand and to model the dynamics of the OSS design process that takes place in mailing list exchanges. We develop a method to study distant and asynchronous collaborative design activity based on an analysis of quoting practices. We analyze and visualize three aspects of the online dynamics: social, thematic temporal, and design. We show that roles emerge during discussions according to the involvement and the position of the participants in the discussions and how they influence participation in the design discussions. In our analysis of the thematic temporal dynamics of discussion, we examine how themes of discussion emerge, diverge, and are refined over time. To understand the design dynamics, we perform a content analysis of messages exchanged between developers to reveal how the online discussions reflect the “work flow” of the project: it provides us with a picture of the collaborative design process in the OSS community. These combined results clarify how knowledge and artefacts are elaborated in this epistemic, exploration-oriented, OSS community. Finally, we outline the need to automate of our method to extend our results. The proposed automation could have implications for both researchers and participants in OSS communities.",https://doi.org/10.1016/j.intcom.2007.10.004,https://www.sciencedirect.com/science/article/pii/S0953543807000793,,,,2008,A socio-cognitive analysis of online design discussions in an Open Source Software community,Flore Barcellini and Françoise Détienne and Jean-Marie Burkhardt and Warren Sack,article,BARCELLINI2008141,Interacting with Computers,1,20,0953-5438,,,
,"Modern code review, Software verification, Software quality, Systematic literature review",110951,,"Context:
Modern Code Review (MCR) is a widely known practice of software quality assurance. However, the existing body of knowledge of MCR is currently not understood as a whole.
Objective:
Our goal is to identify the state of the art on MCR, providing a structured overview and an in-depth analysis of the research done in this field.
Methods:
We performed a systematic literature review, selecting publications from four digital libraries.
Results:
A total of 139 papers were selected and analyzed in three main categories. Foundational studies are those that analyze existing or collected data from the adoption of MCR. Proposals consist of techniques and tools to support MCR, while evaluations are studies to assess an approach or compare a set of them.
Conclusion:
The most represented category is foundational studies, mainly aiming to understand the motivations for adopting MCR, its challenges and benefits, and which influence factors lead to which MCR outcomes. The most common types of proposals are code reviewer recommender and support to code checking. Evaluations of MCR-supporting approaches have been done mostly offline, without involving human subjects. Five main research gaps have been identified, which point out directions for future work in the area.",https://doi.org/10.1016/j.jss.2021.110951,https://www.sciencedirect.com/science/article/pii/S0164121221000480,,,,2021,A systematic literature review and taxonomy of modern code review,Nicole Davila and Ingrid Nunes,article,DAVILA2021110951,Journal of Systems and Software,,177,0164-1212,,,
,"Event data behavioral analytics, Collaboration behavior, Mining resource behavior, Project mining, RFM, Social network analysis",106765,,"Organizations increasingly rely on teamwork to achieve their goals. Therefore they continuously strive to improve their teams as their performance is interwoven with that of the organization. To implement beneficial changes, accurate insights into the working of the team are necessary. However, team leaders tend to have an understanding of the team’s collaboration that is subjective and seldom completely accurate. Recently there has been an increase in the adoption of digital support systems for collaborative work that capture objective data on how the work took place in reality. This creates the opportunity for data-driven extraction of insights into the collaboration behavior of a team. This data however, does not explicitly record the collaboration relationships, which many existing techniques expect as input. Therefore, these relationships first have to be discovered. Existing techniques that apply discovery are not generally applicable because their notion of collaboration is tailored to the application domain. Moreover, the information that these techniques extract from the data about the nature of the relationships is often limited to the network level. Therefore, this research proposes a generic algorithm that can discover collaboration relationships between resources from event data on any collaborative project. The algorithm adopts an established framework to provide insights into collaboration on a fine-grained level. To this end, three properties are calculated for both the resources and their collaboration relationships: a recency, frequency, and monetary value. The technique’s ability to provide valuable insights into the team structure and characteristics is empirically validated on two use cases.",https://doi.org/10.1016/j.engappai.2023.106765,https://www.sciencedirect.com/science/article/pii/S0952197623009491,,,,2023,Mining Recency–Frequency–Monetary enriched insights into resources’ collaboration behavior from event data,Leen Jooken and Benoît Depaire and Mieke Jans,article,JOOKEN2023106765,Engineering Applications of Artificial Intelligence,,126,0952-1976,,,
,"Computer network, Cyber-attacks, Honeypot, Intrusion detection system, Rootkit, Security",103606,,"Honeypot is one of the existing technologies in the area of computer network security. The goal of Honeypot is to create a tempting target for the attacker. The system that is considered as a Honeypot in the network includes the services and functions of a real system that the attacker sees as a normal system and enters for exploitation. In this way, Honeypot can monitor the behaviors, patterns, and tools used in various attacks. Certainly, if the intelligent attacker realizes the existence of this trap in the target network, he can design ways to bypass it. In this case, Honeypot practically loses its effectiveness. Therefore, the issue of hiding Honeypot is one of the primary challenges in this field. In this paper, a solution to this problem is presented. In the present paper, Honeypot is concealed using the concealment techniques used in Rootkits. We use application examples and theoretical analysis results to show that the proposed Honeypots concealment approach is strong against existing kernel-based Honeypots detection methods. Sebek, VMScope, and Qebek are three Honeypots that we choose for comparison purposes. The proposed Honeypot has been compared with them in virtualization, memory usage, and kernel modification. The experimental results show that the proposed hidden Honeypot in addition to low kernel modification has no track in the memory. Also, the proposed Honeypot does not use virtualization. It can successfully be concealed in the kernel of the target system without any effect on the target system. We also implemented the proposed algorithm on the example network and test all Sebek’s detection methods on it. The experimental results show that the proposed kernel-based approach can bypass these detection methods.",https://doi.org/10.1016/j.jnca.2023.103606,https://www.sciencedirect.com/science/article/pii/S1084804523000255,,,,2023,Using rootkits hiding techniques to conceal honeypot functionality,Maryam Mohammadzad and Jaber Karimpour,article,MOHAMMADZAD2023103606,Journal of Network and Computer Applications,,214,1084-8045,,,
,"Hyperspectral, Radiative transfer, Clouds, Adding–doubling, Remote sensing, Fast model",243-263,,"A fast infrared radiative transfer (RT) model is developed on the basis of the adding–doubling principle, hereafter referred to as FIRTM-AD, to facilitate the forward RT simulations involved in hyperspectral remote-sensing applications under cloudy-sky conditions. A pre-computed look-up table (LUT) of the bidirectional reflection and transmission functions and emissivities of ice clouds in conjunction with efficient interpolation schemes is used in FIRTM-AD to alleviate the computational burden of the doubling process. FIRTM-AD is applicable to a variety of cloud conditions, including vertically inhomogeneous or multilayered clouds. In particular, this RT model is suitable for the computation of high-spectral-resolution radiance and brightness temperature (BT) spectra at both the top-of-atmosphere and surface, and thus is useful for satellite and ground-based hyperspectral sensors. In terms of computer CPU time, FIRTM-AD is approximately 100–250 times faster than the well-known discrete-ordinate (DISORT) RT model for the same conditions. The errors of FIRTM-AD, specified as root-mean-square (RMS) BT differences with respect to their DISORT counterparts, are generally smaller than 0.1K.",https://doi.org/10.1016/j.jqsrt.2007.01.009,https://www.sciencedirect.com/science/article/pii/S002240730700009X,,,,2007,A fast infrared radiative transfer model based on the adding–doubling method for hyperspectral remote-sensing applications,Zhibo Zhang and Ping Yang and George Kattawar and Hung-Lung {(Allen) Huang} and Thomas Greenwald and Jun Li and Bryan A. Baum and Daniel K. Zhou and Yongxiang Hu,article,ZHANG2007243,Journal of Quantitative Spectroscopy and Radiative Transfer,2,105,0022-4073,,,
,"Architecture erosion symptom, Architecture violation, Code review, Code commit",107319,,"Context:
As a software system evolves, its architecture tends to degrade, and gradually impedes software maintenance and evolution activities and negatively impacts the quality attributes of the system. The main root cause behind architecture erosion phenomenon derives from violation symptoms (i.e., various architecturally-relevant violations, such as violations of architecture pattern). Previous studies focus on detecting violations in software systems using architecture conformance checking approaches. However, code review comments are also rich sources that may contain extensive discussions regarding architecture violations, while there is a limited understanding of violation symptoms from the viewpoint of developers.
Objective:
In this work, we investigated the characteristics of architecture violation symptoms in code review comments from the developers’ perspective.
Methods:
We employed a set of keywords Related to violation symptoms to collect 606 (out of 21,583) code review comments from four popular OSS projects in the openStack and qt communities. We manually analyzed the collected 606 review comments to provide the categories and linguistic patterns of violation symptoms, as well as the reactions how developers addressed them.
Results:
Our findings show that: (1) three main categories of violation symptoms are discussed by developers during the code review process; (2) The frequently-used terms of expressing violation symptoms are “inconsistent” and “violate”, and the most common linguistic pattern is Problem Discovery; (3) Refactoring and removing code are the major measures (90%) to tackle violation symptoms, while a few violation symptoms were ignored by developers.
Conclusions:
Our findings suggest that the investigation of violation symptoms can help researchers better understand the characteristics of architecture erosion and facilitate the development and maintenance activities, and developers should explicitly manage violation symptoms, not only for addressing the existing architecture violations but also preventing future violations.",https://doi.org/10.1016/j.infsof.2023.107319,https://www.sciencedirect.com/science/article/pii/S095058492300174X,,,,2023,Warnings: Violation symptoms indicating architecture erosion,Ruiyin Li and Peng Liang and Paris Avgeriou,article,LI2023107319,Information and Software Technology,,164,0950-5849,,,
,,125,,,https://doi.org/10.1016/S1569-9056(08)60219-5,https://www.sciencedirect.com/science/article/pii/S1569905608602195,,,,2008,ULTRASONOGRAPHIC EVALUATION OF THE EPIDIDYMIS IN 139 SUB FERTILE MALES AND COMPARISON WITH CLINICAL FINDINGS,J.H. {Van Roijen} and R.S.G.M. Bots and M.C. Schoemaker,article,VANROIJEN2008125,European Urology Supplements,3,7,1569-9056,23rd Annual Congress of the European Association of Urology,,
,"Aerosol nonsphericity, Inversion, Aspect ratio, Radiative forcing, Dry deposition velocity",281-291,,"Aerosol nonsphericity causes great uncertainty in radiative forcing assessments and climate simulations. Although considerable studies have attempted to quantify this uncertainty, the relationship between aerosol nonsphericity and particle size is usually not considered, thus reducing the accuracy of the results. In this study, a coupled inversion algorithm combining an improved stochastic particle swarm optimization algorithm and angular light scattering is used for the nonparametric estimation of aerosol nonsphericity variation with particle size, and the optimal sample selection method is employed to screen the data. Based on the verification of inversion accuracy, the variation of aerosol aspect ratio with particle size based on the ellipsoidal model in global regions has been obtained from Aerosol Robotic Network (AERONET) data, and the effect of nonsphericity on radiative forcing and dry deposition has been studied. The results show that the aspect ratio increases with particle size in all regions, with the maximum ranging from 1.4 to 1.8 in the desert, reflecting the differences in aerosol composition at different particle sizes. In radiation calculations, considering aerosol nonsphericity makes the aerosol cooling effect weaker and surface radiative fluxes increase, but hardly changes the aerosol absorption, with maximum differences of 9.22% and 22.12% at the bottom and top of the atmosphere, respectively. Meanwhile, the differences in radiative forcing between aspect ratios as a function of particle size and not varying with particle size are not significant, averaging less than 2%. Besides, the aspect ratio not varying with particle size underestimates the deposition velocity of small particles and overestimates that of large particles compared to that as a function of particle size, with maximum differences of 7% and 4%, respectively.",https://doi.org/10.1016/j.partic.2023.12.013,https://www.sciencedirect.com/science/article/pii/S1674200124000014,,,,2024,Simulation and evaluation study of atmospheric aerosol nonsphericity as a function of particle size,Qianjun Mao and Xin Nie,article,MAO2024281,Particuology,,90,1674-2001,,,
,,289-304,,"Three methods for the GC determination of oxysterols (OSs) in spray-dried egg, which combine different steps of purification, are compared. In addition, the efficiency of silica cartridges in the purification of OSs using four different systems of elution with increasing polarities is studied. The absence of cholesterol oxidation during the application of the analytical procedures is checked, and the linearity of the response and the chromatographic limits of detection and quantification are established. The methods are characterized by the calculation of precision and recovery for the different OSs. The method based on saponification alone is rejected, since it shows much lower precision. The method that includes saponification and silica cartridge purification offers higher reliability than the method based on cartridge purification alone, because it shows a higher precision and larger samples can be processed, which improves the limits of detection and quantification.",https://doi.org/10.1016/0021-9673(95)00034-K,https://www.sciencedirect.com/science/article/pii/002196739500034K,,,,1995,Comparison of three methods for the determination of oxysterols in spray-dried egg,Francesc Guardiola and Rafael Codony and Magda Rafecas and Josep Boatella,article,GUARDIOLA1995289,Journal of Chromatography A,2,705,0021-9673,,,
,"Git, Commit activity, Developer abandonment, Distributed software development, Prediction model",110573,,"Abandonment of active developers poses a significant risk for many open source software projects. This risk can be reduced by forecasting the future activity of contributors involved in such projects. Focusing on the commit activity of individuals involved in git repositories, this paper proposes a practicable probabilistic forecasting model based on the statistical technique of survival analysis. The model is empirically validated on a wide variety of projects accounting for 7528 git repositories and 5947 active contributors. We found that a model based on the last 20 observed days of commit activity per contributor provides the best concordance. We also found that the predictions provided by the model are generally close to actual observations, with slight underestimations for low probability predictions and slight overestimations for higher probability predictions. This model is implemented as part of an open source tool, called GAP, that predicts future commit activity.",https://doi.org/10.1016/j.jss.2020.110573,https://www.sciencedirect.com/science/article/pii/S0164121220300546,,,,2020,GAP: Forecasting commit activity in git projects,Alexandre Decan and Eleni Constantinou and Tom Mens and Henrique Rocha,article,DECAN2020110573,Journal of Systems and Software,,165,0164-1212,,,
,"Triage, Software, Update, Release Notes, Classifier, Evaluation",618-622,,"In the rapidly evolving domain of Industry 4.0, effective management of software updates is crucial for maintaining system continuity and security. This paper presents a novel machine learning-based approach for a prompt and effective triage of software updates, leveraging an evaluation of six release note classifiers to categorize updates by component type, release type, and security risk. Our methodology, tested on a dataset of 1,000 release notes commonly encountered in Industry 4.0 ecosystems, demonstrates Logistic Regression as the most accurate classifier. The findings not only highlight the practical applicability of our approach in real-world data but also set the foundation for future enhancements to streamline the machine learning triage process further.",https://doi.org/10.1016/j.procs.2024.06.069,https://www.sciencedirect.com/science/article/pii/S187705092401305X,,,,2024,Triage Software Update Impact via Release Notes Classification,Solomon Berhe and Vanessa Kan and Omhier Khan and Nathan Pader and Ali Zain Farooqui and Marc Maynard and Foutse Khomh,article,BERHE2024618,Procedia Computer Science,,238,1877-0509,"The 15th International Conference on Ambient Systems, Networks and Technologies Networks (ANT) / The 7th International Conference on Emerging Data and Industry 4.0 (EDI40), April 23-25, 2024, Hasselt University, Belgium",,
,,75-76,,,https://doi.org/10.1016/j.fldmyc.2011.06.002,https://www.sciencedirect.com/science/article/pii/S1468164111000168,,,,2011,"Fungal Portraits: No. 47: Volvariella aethiops, the first British collection",Geoffrey Kibby,article,KIBBY201175,Field Mycology,3,12,1468-1641,,,
,"Cybersecurity, Deep learning, Adversarial machine learning, Cyber threats, Adversarial examples",122223,,"Over the last few years, the adoption of machine learning in a wide range of domains has been remarkable. Deep learning, in particular, has been extensively used to drive applications and services in specializations such as computer vision, natural language processing, machine translation, and cybersecurity, producing results that are comparable to or even surpass the performance of human experts. Nevertheless, machine learning systems are vulnerable to adversarial attacks, especially in nonstationary environments where actual adversaries exist, such as the cybersecurity domain. In this work, we comprehensively survey and present the latest research on attacks based on adversarial examples against deep learning-based cybersecurity systems, highlighting the risks they pose and promoting efficient countermeasures. To that end, adversarial attack methods are first categorized according to where they occur and the attacker’s goals and capabilities. Then, specific attacks based on adversarial examples and the respective defensive methods are reviewed in detail within the framework of eight principal cybersecurity application categories. Finally, the main trends in recent research are outlined, and the impact of recent advancements in adversarial machine learning is explored to provide guidelines and directions for future research in cybersecurity. In summary, this work is the first to systematically analyze adversarial example-based attacks in the cybersecurity field, discuss possible defenses, and highlight promising directions for future research.",https://doi.org/10.1016/j.eswa.2023.122223,https://www.sciencedirect.com/science/article/pii/S0957417423027252,,,,2024,Adversarial examples: A survey of attacks and defenses in deep learning-enabled cybersecurity systems,Mayra Macas and Chunming Wu and Walter Fuertes,article,MACAS2024122223,Expert Systems with Applications,,238,0957-4174,,,
,"Moving Target Defense (MTD), MTD as a Service (MTDaaS), Network Functions Virtualization (NFV), Cloud security, Security as a Service (SECaaS), Zero-day vulnerabilities",100916,,"The Internet of Things (IoT) paradigm has been one of the main contributors, in recent years, to the growth in the number of connected equipment. This fact has predominantly contributed to IoT being constrained by the 5th Generation Mobile Network (5G) progress and the promises this technology brings. However, this can be a double-edged sword. On the one hand, it will benefit from those progresses, but on the other, it will also be impacted by any security risk associated with 5G. One of the more serious security problems associated with it is the new wave of virtualization and softwarization of networks and analogous appliances, brought to light by paradigms such as Network Functions Virtualization (NFV) and Multi-access Edge Computing (MEC). Considering these predicaments, we propose a state-of-the-art Moving Target Defense (MTD) approach that defends Cloud-based Network Functions (CNFs) launched within MEC and NFV environments. Furthermore, our mechanism follows the famous Everything as a Service (XaaS) ideology, allowing any CNF provider to use this protection system, working agonistically. In the end, we created a Proof of Concept (PoC) of our proposed methodology, which we then used to conduct an extensive practical security analysis against the multiple phases of the Intrusion Kill Chain. Our final results have proven that our MTD as a Service (MTDaaS) approach can effectively delay and, in some cases, stop an attacker from achieving its objectives when trying to attack a CNF, even if the related vulnerability is a zero-day.",https://doi.org/10.1016/j.iot.2023.100916,https://www.sciencedirect.com/science/article/pii/S2542660523002391,,,,2023,Moving Target Defense for the cloud/edge Telco environments,Pedro Escaleira and Vitor A. Cunha and Diogo Gomes and João P. Barraca and Rui L. Aguiar,article,ESCALEIRA2023100916,Internet of Things,,24,2542-6605,,,
,"Object-oriented metrics, Fluctuation, Case study, Software evolution",110-124,,"Context
Software quality attributes are assessed by employing appropriate metrics. However, the choice of such metrics is not always obvious and is further complicated by the multitude of available metrics. To assist metrics selection, several properties have been proposed. However, although metrics are often used to assess successive software versions, there is no property that assesses their ability to capture structural changes along evolution.
Objective
We introduce a property, Software Metric Fluctuation (SMF), which quantifies the degree to which a metric score varies, due to changes occurring between successive system's versions. Regarding SMF, metrics can be characterized as sensitive (changes induce high variation on the metric score) or stable (changes induce low variation on the metric score).
Method
SMF property has been evaluated by: (a) a case study on 20 OSS projects to assess the ability of SMF to differently characterize different metrics, and (b) a case study on 10 software engineers to assess SMF's usefulness in the metric selection process.
Results
The results of the first case study suggest that different metrics that quantify the same quality attributes present differences in their fluctuation. We also provide evidence that an additional factor that is related to metrics’ fluctuation is the function that is used for aggregating metric from the micro to the macro level. In addition, the outcome of the second case study suggested that SMF is capable of helping practitioners in metric selection, since: (a) different practitioners have different perception of metric fluctuation, and (b) this perception is less accurate than the systematic approach that SMF offers.
Conclusions
SMF is a useful metric property that can improve the accuracy of metrics selection. Based on SMF, we can differentiate metrics, based on their degree of fluctuation. Such results can provide input to researchers and practitioners in their metric selection processes.",https://doi.org/10.1016/j.infsof.2015.12.010,https://www.sciencedirect.com/science/article/pii/S0950584915002190,,,,2016,Software metrics fluctuation: a property for assisting the metric selection process,Elvira-Maria Arvanitou and Apostolos Ampatzoglou and Alexander Chatzigeorgiou and Paris Avgeriou,article,ARVANITOU2016110,Information and Software Technology,,72,0950-5849,,,
,,8-11,,"Bricks-and-mortar retail sales are rapidly being replaced by online shopping. And where money is spent, bad actors will follow. Data breaches involving e-commerce have now surpassed breaches at the point of sale and they're becoming very expensive. In spite of this, there remains an alarming lack of corporate self-awareness when it comes to cyber security. Where money is spent, bad actors will follow. Data breaches involving e-commerce have now surpassed breaches at the point of sale and they're becoming very expensive. In spite of this, there remains an alarming lack of corporate self-awareness when it comes to cyber security. This has led to major incidents that could have been avoided. Steve Roberts of OSS Technology analyses some major breaches of the past few years and asks what went wrong, how could they have been prevented and what lessons can we learn?",https://doi.org/10.1016/S1353-4858(18)30111-9,https://www.sciencedirect.com/science/article/pii/S1353485818301119,,,,2018,Learning lessons from data breaches,Steve Roberts,article,ROBERTS20188,Network Security,11,2018,1353-4858,,,
,"northern area of Western Mahuang Mountain, sedimentary microfacies, law of evolution, Chang6–4+5 layer",277-286,,"Although there are widespread indications of oil and gas in the Chang 6–4+5 layer of western Mahuang Mountian, well test proves that there is more water and less oil with the distribution and continuity of sand being not yet clear. To understand the distribution and evolution of sedimentary microfacies in the area, six kinds of sedimentary microfacies and ten kinds of sedimentary structures were identified, and ten patterns of contact between microfacies and five kinds of sedimentary sequence model were summarized through detailed observation and description of the core of rock and logging data. Each model represents different sedimentary facies. Reversed cycle is dominant and normal short-term cycle also exists in the vertical direction; Mouth bar and subaqueous distributary channel developed alternately in the lateral direction. The lower channel sand is “large in quantity but small in size with the layer narrow and thin”, whereas the upper sand is “few in quantity but large in size with a wide and thick layer”. The “single-factor analysis and multifactor comprehensive” research method was used to divide this area into three phase belts—delta inner front, delta outer front, and predelta. Subaqueous distributary channel, distributary mouth bar, and interdistributary deposits are prevailing in the delta inner front. Distal bar and sand sheet are dominant in the delta outer front, and predelta mud is dominant in the predelta. According to modern sedimentary facies model, the area is a constructive braided river-lake delta. Three stages appeared in its evolution: the initial development period (Chang 63), in which the predelta and the delta outer front are the main facies belts; the early-middle development period (Chang 62–Chang 61), in which the inner delta front and the delta outer front dominates and each micro-facies is a single phase and is deposited alternately; the middle-late development period (Chang 4 +52–Chang 4 +51), in which the delta inner front dominates and subaqueous distributary channel shows multiphase stacking pattern.",https://doi.org/10.1016/S1872-5791(08)60100-1,https://www.sciencedirect.com/science/article/pii/S1872579108601001,,,,2009,Characteristics and Evolution of Sedimentary Microfacies of Chang 6–4+5 Layer in the Northern Area of Western Mahuang Mountain,Yumei LIU and Xinghe YU and Shengli LI and Weiwei DU and Mei LI and Shunli LI,article,LIU2009277,Earth Science Frontiers,4,16,1872-5791,,,
,"Systematic literature review, Code reviewer recommendation, Reviewer recommendation, Modern code review, Pull request",102652,,"Code review is the process of inspecting code changes by a developer who is not involved in the development of the changeset. One of the initial and important steps of code review process is selecting code reviewer(s) for a given code change. To maximize the benefits of the code review process, the appropriate selection of the reviewer is essential. Code reviewer recommendation has been an active research area over the last few years, and many recommendation models have been proposed in the literature. In this study, we conduct a systematic literature review by inspecting 29 primary studies published from 2009 to 2020. Based on the outcomes of our review: (1) most preferred approaches are heuristic approaches closely followed by machine learning approaches, (2) the majority of the studies use open source projects to evaluate their models, (3) the majority of the studies prefer incremental training set validation techniques, (4) most studies suffer from reproducibility problems, (5) model generalizability and dataset integrity are the most common validity threats for the models and (6) refining models and conducting additional experiments are the most common future work discussions in the studies.",https://doi.org/10.1016/j.scico.2021.102652,https://www.sciencedirect.com/science/article/pii/S0167642321000459,,,,2021,A review of code reviewer recommendation studies: Challenges and future directions,H. Alperen Çetin and Emre Doğan and Eray Tüzün,article,CETIN2021102652,Science of Computer Programming,,208,0167-6423,,,
,"3D sonography, 3D Sonographie",84-89,,"A method of 3-dimensional (3D) sonography (US) is described in this paper. Special emphasis is laid upon the basic problem of generating well-orientated 3D visualizations on the basis of different evaluation techniques. Furthermore, some problems of data acquisition and data processing using US are presented. Alternative solutions thereto are briefly discussed.
Es wird eine Methode zur Erzeugung 3-dimensionaler (3D) Sonogramme (US) dargelegt. Neben der prinzipiellen Problematik der Erzeugung einer räumlichen Orientierung und der Generierung von 3D Bildern auf der Basis unterschiedlicher Untersuchungsmethoden werden einige spezielle Schwierigkeiten der US Datengewinnung und-weiterverarbeitung aufgezeigt. Alternative Lösungsansätze zur 3D US werden diskutiert.",https://doi.org/10.1016/S0901-5027(05)80867-7,https://www.sciencedirect.com/science/article/pii/S0901502705808677,,,,1995,3D Sonography,Berthold Hell,article,HELL199584,International Journal of Oral and Maxillofacial Surgery,"1, Part 2",24,0901-5027,,,
,"Online communities, Governance, Dropouts, Network-analysis, Reputation, Controversies",404-413,,"Summary
This paper contributes to our understanding of an increasingly prevalent work system, web-based internet communities (WebICs). We are particularly interested in how WebICs are governed given the fact how different they are compared to more classical forms of organization. We study the governance of a WebIC by studying the structure and dynamics of their edit network. Given the fact that the edit network is a relational structure, social network analysis is key to understanding these work systems. We demonstrate that characteristics of the edit network contribute to predicting the dropout hazard of valuable WebIC members. Since WebICs exist only thanks to the activity of their contributors, predicting drop-outs becomes crucial. The results show that reputation and controversy have different effects for different types of Wikipedians; i.e., an actor’s reputation decreases the dropout hazard of active Wikipedians, while participation on controversial pages decreases the dropout hazard of highly active Wikipedians.",https://doi.org/10.1016/j.emj.2011.02.003,https://www.sciencedirect.com/science/article/pii/S0263237311000053,,,,2011,Will they stay or will they go? How network properties of WebICs predict dropout rates of valuable Wikipedians,Jürgen Lerner and Patrick Kenis and Denise van Raaij and Ulrik Brandes,article,LERNER2011404,European Management Journal,5,29,0263-2373,Management & Social Networks: Stretching Boundaries,,
,"Network-based intrusion detection system, Deep learning, Feature augmentation",119-132,,"Machine Learning (ML) techniques are increasingly adopted to tackle ever-evolving high-profile network attacks, including Distributed Denial of Service (DDoS), botnet, and ransomware, due to their unique ability to extract complex patterns hidden in data streams. These approaches are however routinely validated with data collected in the same environment, and their performance degrades when deployed in different network topologies and/or applied on previously unseen traffic, as we uncover. This suggests malicious/benign behaviors are largely learned superficially and ML-based Network Intrusion Detection Systems (NIDS) need revisiting, to be effective in practice. In this paper we dive into the mechanics of large-scale network attacks, with a view to understanding how to use ML for Network Intrusion Detection (NID) in a principled way. We reveal that, although cyberattacks vary significantly in terms of payloads, vectors and targets, their early stages, which are critical to successful attack outcomes, share many similarities and exhibit important temporal correlations. Therefore, we treat NID as a time-sensitive task and propose NetSentry, perhaps the first of its kind NIDS that builds on Bidirectional Asymmetric LSTM (Bi-ALSTM), an original ensemble of sequential neural models, to detect network threats before they spread. We cross-evaluate NetSentry using two practical datasets, training on one and testing on the other, and demonstrate F1 score gains above 33% over the state-of-the-art, as well as up to 3× higher rates of detecting attacks such as Cross-Site Scripting (XSS) and web bruteforce. Further, we put forward a novel data augmentation technique that boosts the generalization abilities of a broad range of supervised deep learning algorithms, leading to average F1 score gains above 35%. Lastly, we shed light on the feasibility of deploying NetSentry in operational networks, demonstrating affordable computational overhead and robustness to evasion attacks.",https://doi.org/10.1016/j.comcom.2022.04.020,https://www.sciencedirect.com/science/article/pii/S0140366422001335,,,,2022,NetSentry: A deep learning approach to detecting incipient large-scale network attacks,Haoyu Liu and Paul Patras,article,LIU2022119,Computer Communications,,191,0140-3664,,,
,,137-147,,"The extent to which Spartina alterniflora Loisel. fixes lacunar CO2 and utilizes dissolved inorganic carbon in the interstitial water of sediment was investigated, and the contribution of these two processes to total primary productivity was estimated and compared with photosynthesis in the leaf blades. Atmospheric CO2 is primarily fixed in the leaf blades, and the resultant assimilates are rapidly translocated through the leaf sheaths to the below ground tissues and growing points above ground. Lacunar CO2 is primarily fixed in the leaf sheaths and stem. The fact that these assimilates remain in the tissues around the lacunar spaces indicates that lacunar CO2 does not diffuse freely into the leaf blades but is recycled in the lacunar spaces. Dissolved inorganic carbon taken up by the plant from the sediment is primarily fixed by a dark reaction in the root tissues. Some dissolved inorganic carbon in the interstitial water may collect as gaseous CO2 in the lacunae and be fixed in the leaf sheaths and stem. In addition, dissolved inorganic carbon may be taken up in the transpiration stream and be fixed in the leaf blades by photosynthesis. However, internal CO2 fixation and dissolved inorganic carbon utilization together are only about 10% of the rate of fixation of atmospheric CO2 by leaves.",https://doi.org/10.1016/0304-3770(92)90039-L,https://www.sciencedirect.com/science/article/pii/030437709290039L,,,,1992,Fixation of inorganic carbon from different sources and its translocation in Spartina alterniflora Loisel,Yuan-Hsun Hwang and James T. Morris,article,HWANG1992137,Aquatic Botany,2,43,0304-3770,,,
,"Engineering Applications of Artificial Intelligence, Holonic Manufacturing Systems, Product Driven Control",1087-1092,,"Multi agent systems represent an elegant approach for the control architecture of manufacturing systems. Distributed control architectures have the potential to achieve greater flexibility by being capable of local decision making based on real time reasoning. One of the main challenges of these distributed architectures is represented by the capability to synchronize the production data across all execution points in a reliable and consistent fashion. In this context, this paper aims to resolve the problems associated with real time production data synchronization in distributed multi-agent control systems by proposing a common dataset synchronized across all agent entities using multicast network communication. On top of this common dataset approach, an agent negotiation mechanism is proposed that addresses the operation sequencing and resource allocation in decentralized operation model. The pilot implementation is using JADE multi agent platform and JGroups for real time data synchronization and NetLogo for abstract representation of the simulation system. Experimental results gathered from the pilot implementation are discussed.",https://doi.org/10.1016/j.ifacol.2015.06.228,https://www.sciencedirect.com/science/article/pii/S240589631500467X,,,,2015,Multicast dataset synchronization and agent negotiation in distributed manufacturing control systems,Octavian Morariu and Cristina Morariu and Theodor Borangiu and Silviu Raileanu,article,MORARIU20151087,IFAC-PapersOnLine,3,48,2405-8963,15th IFAC Symposium onInformation Control Problems inManufacturing,,
,"Responsible software engineering, Infrastructure, Social connection model of responsibility, Installed base, Deepfake technology",100087,,"In recent years, we have seen many examples of software products unintentionally causing demonstrable harm. Many guidelines for ethical and responsible computing have been developed in response. Dominant approaches typically attribute liability and blame to individual companies or actors, rather than understanding how the working practices, norms, and cultural understandings in the software industry contribute to such outcomes. In this paper, we propose an understanding of responsibility that is infrastructural, relational, and cultural; thus, providing a foundation to better enable responsible software engineering into the future. Our approach draws on Young's (2006) social connection model of responsibility and Star and Ruhleder's (1994) concept of infrastructure. By bringing these theories together we introduce a concept called infrastructural injustice, which offers a new way for software engineers to consider their opportunities for responsible action with respect to society and the planet. We illustrate the utility of this approach by applying it to an Open-Source software communities’ development of Deepfake technology, to find key leverage points of responsibility that are relevant to both Deepfake technology and software engineering more broadly.",https://doi.org/10.1016/j.jrt.2024.100087,https://www.sciencedirect.com/science/article/pii/S2666659624000131,,,,2024,"Infrastructural justice for responsible software engineering,",Sarah Robinson and Jim Buckley and Luigina Ciolfi and Conor Linehan and Clare McInerney and Bashar Nuseibeh and John Twomey and Irum Rauf and John McCarthy,article,ROBINSON2024100087,Journal of Responsible Technology,,19,2666-6596,,,
,"Public-private partnership, public schools, value creation, user, owner",398-406,,"The purpose of this paper is to assess if and to what extent PPPs contribute to value creation for user and owner, by highlighting how PPP contribute to value creation in public schools in a Norwegian context. Little research has been found concerning PPPs contribution to value creation for user and owner. The analysis and document studies in this paper show that PPP compels to consideration of the life cycle, incentivises project owners to focus on output-based specifications and indicates commitment for the contractors to deliver. In sum, this indicates that PPP is suited for public schools in Norway.",https://doi.org/10.1016/j.sbspro.2016.06.204,https://www.sciencedirect.com/science/article/pii/S1877042816308904,,,,2016,PPP in Public Schools as Means for Value Creation for User and Owner,Ole Andreas Aarseth and Vegar Mong Urdal and Svein Bjørberg and Marit Støre-Valen and Jardar Lohne,article,AARSETH2016398,Procedia - Social and Behavioral Sciences,,226,1877-0428,"Proceedings of the 29th IPMA World Congress WC2015 (28-30 September – 1 October, Panama)",,
,"Coastal wetlands, environmental index, water quality, macrophyte, Great Lakes, wetland macrophyte index",172-197,,"Indices have been developed with invertebrates, fish, and water quality parameters to detect the impact of human disturbance on coastal wetlands, but a macrophyte index of fish habitat for the Great Lakes does not currently exist. Because wetland macrophytes are directly influenced by water quality, any impairment in wetland quality should be reflected by taxonomic composition of the aquatic plant community. We developed a wetland macrophyte index (WMI) with plant presence/absence data for 127 coastal wetlands (154 wetland-years) from all five Great Lakes, using results of a canonical correspondence analysis (CCA) to ordinate plant species along a water quality gradient (CCA axis 1). We validated the WMI with data collected before and after the implementation of remedial actions plans (RAPs) in Sturgeon Bay (Severn Sound) and Cootes Paradise Marsh. Consistent with predictions, WMI scores for Sturgeon Bay were significantly higher after the implementation of the RAP. Historical data from Cootes Paradise Marsh were used to track the declining condition of the plant community from the 1940s to 1990s. Subsequently, when remedial actions had been implemented in 1997, the calculated WMI scores showed improvement, but when the presence of exotic species (WMIadj) was accounted for, improvements in ecological integrity of the aquatic-plant community were no longer evident. We show how WMI scores can be used by environmental agencies to assess the historic, current, and future ecological status of wetland ecosystems in two Canadian national parks, Point Pelee National Park (PPNP) and Fathom Five National Marine Park (FFNMP).",https://doi.org/10.3394/0380-1330(2007)33[172:UADOTW]2.0.CO;2,https://www.sciencedirect.com/science/article/pii/S0380133007701491,,,,2007,Use and Development of the Wetland Macrophyte Index to Detect Water Quality Impairment in Fish Habitat of Great Lakes Coastal Marshes,Melanie V. Croft and Patricia Chow-Fraser,article,CROFT2007172,Journal of Great Lakes Research,,33,0380-1330,Coastal Indicators,,
,"intrusion prevention systems, network intrusions, physical attacks, TCP/IP, malware, phishing, social engineering, rootkit, intrusion detection systems, tunneling",57-82,Network and System Security (Second Edition),"Guarding against network intrusions requires the monitoring of network traffic for particular network segments or devices and analysis of network, transport, and application protocols to identify suspicious activity. This chapter provides a detailed discussion of network-based intrusion protection technologies. It contains a brief overview of the major components of network-based intrusion protection systems and explains the architectures typically used for deploying the components. It also examines the security capabilities of the technologies in depth, including the methodologies they use to identify suspicious activity. The rest of the chapter discusses the management capabilities of the technologies and provides recommendations for implementation and operation.",https://doi.org/10.1016/B978-0-12-416689-9.00003-4,https://www.sciencedirect.com/science/article/pii/B9780124166899000034,Boston,Syngress,978-0-12-416689-9,2014,Chapter 3 - Guarding Against Network Intrusions,Thomas M. Chen and Patrick J. Walsh,incollection,CHEN201457,,,,,,John R. Vacca,Second Edition
,,65-67,,,https://doi.org/10.1016/j.wpi.2015.01.005,https://www.sciencedirect.com/science/article/pii/S017221901500006X,,,,2015,Our reviewers – An appreciation,Susanne Hantos and Jane List,article,HANTOS201565,World Patent Information,,40,0172-2190,,,
,,I-LXXXI,,,https://doi.org/10.1016/S2452-302X(23)00486-2,https://www.sciencedirect.com/science/article/pii/S2452302X23004862,,,,2023,Full Issue PDF,,article,2023I,JACC: Basic to Translational Science,11,8,2452-302X,,,
,"Climate, Shrubland ecosystems",113-129,,"The paper summarizes the bush ecosystem model developed for assessing the effects of climatic change on the behaviour of mediterranean bushes assuming that temperature, humidity and rain-fall are the basic dimensions of the niche occupied by shrub species. In this context, changes in the monthly weather pattern serve only to outline the growth conditions due to the nonlinearity of response of shrubs to climatic factors. The plant-soil-atmosphere system is described by means of ordinary non-linear differential equations for the state variables: green biomass, woody biomass, the residues of green and woody biomasses, faecal detritus of mammals on the soil, and the total organic matter of the soil. The behaviour of the flow variables is described by means of equations obtained from non-linear multiple regressions from the state variables and the input variables. The model has been applied with success to the behaviour of Cistus albidus in two zones of the Province of Alicante (Spain). The data base for the parametrical locations (zone 1) and validation (zone 2) is based upon measurements taken weekly over a 2-year period. The model is used to simulate the response of this shrub to a decreasing tendency in precipitation combined with a simultaneous rise in temperature. A period of 10 years is simulated and it is observed that plants with woody biomass smaller than 85 g die between the first and the third month and other plants' biomass decreases during this period, and strongly thereafter.",https://doi.org/10.1016/0304-3800(94)00052-J,https://www.sciencedirect.com/science/article/pii/030438009400052J,,,,1995,MARIOLA: a model for calculating the response of mediterranean bush ecosystem to climatic variations,J.L. Usó-Domenech and Y. Villacampa-Esteve and G. Stübing-Martinez and T. Karjalainen and M.P. Ramo,article,USODOMENECH1995113,Ecological Modelling,2,80,0304-3800,,,
,"Rosaceae, tannins, polyphenols, hydrolysable tannins, oligomeric hydrolysable tannins, agrimoniin, gemin A, rugosin D, sanguiin, chemotaxonomy.",3091-3096,,"A HPLC survey of leaves of 80 plants (62 species, 15 hybrids, one variety and two cytotypes) from 18 genera of four subfamilies of Rosaceae, using five oligomeric hydrolysable tannins, five monomeric hydrolysable tannins, and chlorogenic acid as reference compounds, showed that the oligomers can be used as chemotaxonomic markers for the family, viz., sanguiin H-6 and H-11 in the genera Sanguisorba and Rubus, gemin A in Geum, agrimoniin in Agrimonia, Fragaria and Potentilla, and rugosin D in Filipendula. The hydrolysable tannin monomers were widely distributed in the herbaceous and frutescent Rosoideae species, but not in the arborous species of the other subfamilies. Chlorogenic acid was found in almost all of the plants examined.",https://doi.org/10.1016/0031-9422(92)83451-4,https://www.sciencedirect.com/science/article/pii/0031942292834514,,,,1992,Hydrolysable tannins as chemotaxonomic markers in the rosaceae,Takuo Okuda and Takashi Yoshida and Tsutomu Hatano and Mayumi Iwasaki and Makiko Kubo and Teruyo Orime and Masao Yoshizaki and Naohiro Naruhashi,article,OKUDA19923091,Phytochemistry,9,31,0031-9422,The International Journal of Plant Biochemistry,,
,", Compositae, new thymol derivatives.",1850-1851,,,https://doi.org/10.1016/S0031-9422(00)83829-7,https://www.sciencedirect.com/science/article/pii/S0031942200838297,,,,1980,Thymol derivatives from Doronicum hungaricum,Ferdinand Bohlmann and Autar Krishen Dhar and Maniruddin Ahmed,article,BOHLMANN19801850,Phytochemistry,8,19,0031-9422,,,
,"Online community, Participant contribution, Forms of participation, Interactive role, Conflict, Argumentation",11-31,,"This research focuses on analysing collective activity in Wikipedia, conceptualised as an Online Epistemic Community (“OEC”). Previous research on Wikipedia has shown that widespread participation, coupled with the principle of neutrality of viewpoint, has led to ‘editing wars’ and associated high coordination costs. The question that we address is therefore that of how to analyse the interactive dynamics of conflictual OEC discussions. To address this issue, we performed a longitudinal analysis of a specific case-study within the French-speaking “astronomy” Wikipedia OEC, revolving around the renaming of the article on the celestial body “Pluto”, given the ‘descent’ of its scientific status from that of a planet to an asteroid. Our choice was to focus on the analysis of dialogic and epistemic roles, as an appropriate meso-level unit of analysis. We present a qualitative-quantitative method for analysis of roles, based on filtering major participants and analysing the dialogic functions and epistemic contents of their communicative acts. Our analyses showed that online epistemic communities can be communities in the true sense of their involving cooperation, in that roles become gradually specialised and reciprocal over sequences of the discussion: when one participant changes role from one sequence to another, other participants ‘fill in’ for the vacant role. Secondly, we show that OECs, in the case of Wikipedia, do not function purely on a knowledge-level, but also involve, crucially, negotiation of images of participants’ competences with respect to the knowledge domain. In that sense, OECs can be seen as socio-cognitive communities. The originality of our research resides in the qualitative-quantitative method for analysing interactive roles, and the results of its application to an extended longitudinal case study.",https://doi.org/10.1016/j.ijhcs.2015.09.002,https://www.sciencedirect.com/science/article/pii/S1071581915001469,,,,2016,"The Descent of Pluto: Interactive dynamics, specialisation and reciprocity of roles in a Wikipedia debate",Françoise Détienne and Michael Baker and Dominique Fréard and Flore Barcellini and Alexandre Denis and Matthieu Quignard,article,DETIENNE201611,International Journal of Human-Computer Studies,,86,1071-5819,,,
,,147-158,,"The fine structure of in situ Rhabdosporites langii miospores is described. The trilete spores are characterized by an irregular pseudosaccus that is conspicuous on the distal surface of the grain; ornamentation consists of narrow coni. The central body of the spore is constructed of superimposed lamellae, each up to 50 nm thick. Pseudosaccus formation occurs as a result of a separation of the outer one third of the sporoderm of the central body. As development continues small perforations are formed in the pseudosaccus wall where lamellae separate. The development of the saccus, protosaccus and pseudosaccus is compared, and the biological significance of camerate grains discussed.",https://doi.org/10.1016/0034-6667(95)00124-7,https://www.sciencedirect.com/science/article/pii/0034666795001247,,,,1996,Devonian spore ultrastructure: Rhabdosporites,Thomas N. Taylor and Stephen E. Scheckler,article,TAYLOR1996147,Review of Palaeobotany and Palynology,1,93,0034-6667,Maurice Streel,,
,,147-150,Ecomaterials,"Addition of alloying elements and optimization of chemical composition are common and important means of material development to satisfy a demanded performance. On the other hand, a large amounts and many types of alloying elements and, therefore, complicated chemical composition is detrimental for recycling of materials and saving of scarce material resources. Modern design concept of heat resistant materials to minimize the contents of alloying elements and to simplify the chemical composition without loss of long-term creep strength has been devised from a viewpoint of “Inherent Creep Strength”. The materials designed from the new concept, which minimize environmental load, have been named as “Shaped Up Materials”, and proposed as one of the candidate for “ECOMATERIALS”.",https://doi.org/10.1016/B978-1-4832-8381-4.50040-8,https://www.sciencedirect.com/science/article/pii/B9781483283814500408,,Elsevier,978-1-4832-8381-4,1994,Shaped up materials: A new design concept of environmental conscious heat resistant steels,K. Kimura and H. Kushima and K. Yagi and C. Tanaka,incollection,KIMURA1994147,,,,,,R. Yamamoto and E. Furubayashi and Y. Doi and R. Fang and B. Liu and K. Otsuka and C.T. Liu and K. Shimizu and Y. Suzuki and J. {Van Humbeeck} and Y. Fukai and S. Ono and S. Suda,
Focal Press Media Technology Professional Series,,53-91,Technology and Workflows for Multiple Channel Content Distribution,,https://doi.org/10.1016/B978-0-240-81172-7.00004-8,https://www.sciencedirect.com/science/article/pii/B9780240811727000048,Boston,Focal Press,978-0-240-81172-7,2009,Chapter 4 - Broadcast operation centers in transition,Philip J. Cianci,incollection,CIANCI200953,,,,,,Philip J. Cianci,
,"Security, Privacy, Streaming, Malware, IoT",78-89,,"Streaming media are currently conquering traditional multimedia by means of services like Netflix, Amazon Prime and Hulu which provide to millions of users worldwide with paid subscriptions in order to watch the desired content on-demand. Simultaneously, numerous applications and services infringing this content by sharing it for free have emerged. The latter has given ground to a new market based on illegal downloads which monetizes from ads and custom hardware, often aggregating peers to maximize multimedia content sharing. Regardless of the ethical and legal issues involved, the users of such streaming services are millions and they are severely exposed to various threats, mainly due to poor hardware and software configurations. Recent attacks have also shown that they may, in turn, endanger others as well. This work details these threats and presents new attacks on these systems as well as forensic evidence that can be collected in specific cases.",https://doi.org/10.1016/j.diin.2018.03.004,https://www.sciencedirect.com/science/article/pii/S1742287618300069,,,,2018,I know what you streamed last night: On the security and privacy of streaming,Alexios Nikas and Efthimios Alepis and Constantinos Patsakis,article,NIKAS201878,Digital Investigation,,25,1742-2876,,,
," sp SIN-1, rRNA, , Ultrastructure",19-25,,"Rhizobium sp. SIN-1, isolated in India from root nodules on the tropical legume Sesbania aculeata, also induces nitrogen-fixing nodules on roots of S. macrocarpa, S. speciosa, S. procumbens, S. punicea, S. rostrata, and Vigna unguiculata. Unlike Azorhizobium caulinodans, SIN-1 does not induce stem nodules on S. rostrata. The nodules induced by SIN-1 develop exclusively at the bases of secondary roots. Electron microscopic studies of mature nodule sections revealed rhizobia within intercellular spaces, indicating a ‘crack entry’ mechanism of root infection. SIN-1 is a fast-growing, acid-producing, salt-tolerant Rhizobium that utilizes a wide variety of carbon sources. The nodulation (nod) genes of this strain are located on a 300-MDa symbiosis (sym) plasmid. Fatty acid profile and sequence comparison of a 260-bp conserved region of the 16S rRNA gene demonstrated that SIN-1 is phylogenetically closely related to R. galegae, a species that nodulates temperate legumes.",https://doi.org/10.1016/0378-1097(95)00373-D,https://www.sciencedirect.com/science/article/pii/037810979500373D,,,,1995,"A new root-nodulating symbiont of the tropical legume Sesbania, Rhizobium sp SIN-1, is closely related to R. galegae, a species that nodulates temperate legumes",Debashis Rana and Hari B. Krishnan,article,RANA199519,FEMS Microbiology Letters,1,134,0378-1097,,,
,"Code review, Patch, Early prediction, Merged, Abandoned",106756,,"Context:
The modern code review process is an integral part of the current software development practice. Considerable effort is given here to inspect code changes, find defects, suggest an improvement, and address the suggestions of the reviewers. In a code review process, several iterations usually take place where an author submits code changes and a reviewer gives feedback until is happy to accept the change. In around 12% cases, the changes are abandoned, eventually wasting all the efforts.
Objective:
In this research, our objective is to design a tool that can predict whether a code change would be merged or abandoned at an early stage to reduce the waste of efforts of all stakeholders (e.g., program author, reviewer, project management, etc.) involved. The real-world demand for such a tool was formally identified by a study by Fan et al. (2018).
Method:
We have mined 146,612 code changes from the code reviews of three large and popular open-source software and trained and tested a suite of supervised machine learning classifiers, both shallow and deep learning-based. We consider a total of 25 features in each code change during the training and testing of the models. The features are divided into five dimensions: reviewer, author, project, text, and code.
Results:
The best performing model named PredCR (Predicting Code Review), a LightGBM-based classifier achieves around 85% AUC score on average and relatively improves the state-of-the-art (Fan et al., 2018) by 14%–23%. In our extensive empirical study involving PredCR on the 146,612 code changes from the three software projects, we find that (1) The new features like reviewer dimensions that are introduced in PredCR are the most informative. (2) Compared to the baseline, PredCR is more effective towards reducing bias against new developers. (3) PredCR uses historical data in the code review repository and as such the performance of PredCR improves as a software system evolves with new and more data.
Conclusion:
PredCR can help save time and effort by helping developers/code reviewers to prioritize the code changes that they are asked to review. Project management can use PredCR to determine how code changes can be assigned to the code reviewers (e.g., select code changes that are more likely to be merged for review before the changes that might be abandoned).",https://doi.org/10.1016/j.infsof.2021.106756,https://www.sciencedirect.com/science/article/pii/S0950584921002032,,,,2022,Early prediction for merged vs abandoned code changes in modern code reviews,Khairul Islam and Toufique Ahmed and Rifat Shahriyar and Anindya Iqbal and Gias Uddin,article,ISLAM2022106756,Information and Software Technology,,142,0950-5849,,,
,"antioxidants, chlorophyll fluorescence, gas exchange, photoinhibition, xanthophyll cycle",110-119,,"Summary
The Canarian laurel forest ecosystem is composed of several co-dominant evergreen tree species including Ilex perado, I. canariensis, Myrica faya, Laurus azorica, and Persea indica. With leaves of these trees the diurnal course of stress parameters (chlorophyll fluorescence Fv/Fm, pigments, ascorbate, glutathione, gas exchange, water relations) was investigated during a mildly stressful summer day. Sun leaves generally had lower photochemical efficiencies (morning Fv/Fm in sun leaves were below 0.80 and above 0.80 in shade leaves), less chlorophyll, a larger xanthophyll cycle pool per unit chlorophyll, and more glutathione and ascorbate. Minimal relative water contents of more than 85% indicated that dehydration was not a stress factor. Stomatal conductances decreased from 150 to 200 mmol H2O m−2 s−1 in the morning to about 50 mmol H2O m−2 s−1 during the day in all species, but this did not limit CO2 uptake. De-epoxidation of xanthophylls only occurred in sun leaves of I. canariensis (to more than 50%) and M. faya (more than 60%). Decrea Fv/Fm were only found in sun leaves of P. indica (from ca. 0.80 in the morning to a minimum of 0.70) and, as a trend, also in L. azorica (from ca. 0.75 to ca. 0.65). I. perado showed neither of those responses. P. indica and L. azorica exhibited the highest photosynthesis rates of about 10 μmol CO2 m−2 s−1 compared to 8 in the other species. The photoprotection strategy of P. indica and L. azorica admitted slow recovery from photoinhibition, did not activate protective energy dissipation through xanthophylls, and allowed highest production under these typical conditions.",https://doi.org/10.1078/0367-2530-00140,https://www.sciencedirect.com/science/article/pii/S0367253004701048,,,,2004,"Photostress, photoprotection, and water soluble antioxidants in the canopies of five Canarian laurel forest tree species during a diurnal course in the field",Michael Tausz and Águeda María González-Rodríguez and Astrid Wonisch and Juliane Peters and Dieter Grill and Domingo Morales and María Soledad Jiménez,article,TAUSZ2004110,"Flora - Morphology, Distribution, Functional Ecology of Plants",2,199,0367-2530,,,
,,153-164,,"The roles of oxygen concentration, seed water content, and their interaction in the γ-ray-induced damage to dry barley seeds were investigated. Himalaya (C.I. 620) barley seeds were adjusted to water contents ranging from 2 to 10%, irradiated with 60Co γ-rays, and soaked at 0°C in distilled water bubbled with oxygen-nitrogen gas mixtures containing 0.0, 3.1, 6.25, 12.5, 25, 50 and 100% oxygen. Biological effects of the treatments were recorded as M1 seedling injury. Essentially no oxygen enhancement of biological damage was obtained with an oxygen concentration of 3.1% in the gas phase of the soaking solution. The minimum OCHG needed to cause an oxygen enhancement of biological damage (3.1% OCHG) increased with increasing seed water content between 1.8 and 10.0%, and decreased as the radiation dose increased, suggesting a triple factor interaction. For moderate levels of injury (between 20 and 60%), a nearly linear increase in seedling injury was obtained when the OCHG was increased in an exponential fashion. For greater seedling injury, the response tended toward a sigmoid shaped curve, probably due to limitations of the biological parameter. The same types of response were obtained when the results were analyzed in terms of oxygen enhancement ratios (OER) obtained from seedling injury data. Decreases in oxygen-independent radiosensitivity, determined by the increase in radiation exposure required to induce 40% injury with anaerobic soakings, were obtained as the seed water content was increased from 2.0 to 9.9%. The same pattern of radiosensitivity was observed with aerobic soakings and was more pronounced at intermediate levels of OCHG. The change in radiosensitivity of seeds between seed water contents of 2.0 and 7.7% was consistent with published EPR data. The increase in response at intermediate OCHG was in part a reflection of the influence of seed water content on the level of OCHG needed to produce an oxygen enhancement of damage. Cooling seeds of 6.1% water content to dry ice temperatures immediately after irradiation at 0°C decreased both oxygen-dependent and oxygen-independent damage. The decreases in damage were greater at 20 krad than at 10 krad and tended to be greater at the higher OCHG.",https://doi.org/10.1016/0098-8472(79)90044-3,https://www.sciencedirect.com/science/article/pii/0098847279900443,,,,1979,"The interaction of oxygen, radiation exposure and seed water content on γ-irradiated barley seeds",E. Donaldson and R.A. Nilan and C.F. Konzak,article,DONALDSON1979153,Environmental and Experimental Botany,3,19,0098-8472,,,
,", , Erythroxylaceae, tropane alkaloids, 3α-benzoyloxytropan-6β-ol, 3α-benzoyloxynortropane, 3α-benzoyloxynortropan-6β-ol, chemotaxonomy.",851-853,,"Erythroxylum macrocarpum and E. sideroxyloides, two closely related species indigenous to Mauritius, contain a similar range of alkaloids consisting mainly of benzoyl esters of tropan-3α-ol, tropan-3β-ol, and tropan-3α,6β-diol together with their nor-derivatives. 3α-Benzoyloxytropan-6β-ol (E. sideroxyloides) and 3α-benzoyloxynortropane and 3β-benzoyloxynortropan-6β-ol (both species) are reported for the first time.",https://doi.org/10.1016/0031-9422(86)80015-2,https://www.sciencedirect.com/science/article/pii/0031942286800152,,,,1986,Alkaloids of erythroxylum macrocarpum and E. sideroxyloides,Mansour S. Al-said and William C. Evans and Raymond J. Grout,article,ALSAID1986851,Phytochemistry,4,25,0031-9422,,,
,,1-3,,,https://doi.org/10.1016/j.compmedimag.2012.12.001,https://www.sciencedirect.com/science/article/pii/S0895611112001760,,,,2013,Atherosclerosis: The evolving role of vascular image analysis,,article,20131,Computerized Medical Imaging and Graphics,1,37,0895-6111,,,
,"Preforming, manufacturing, autmatization, thermoplastic hybrid yarns",57-61,,"Due to their outstanding mechanical properties, fiber reinforced composites are particularly suitable for lightweight applications. Especially hollow structures made of braided hybrid yarn hoses offer a high application potential as the unconsolidated hoses provide a good drapability and thus allow the fabrication of complex shaped torsion- and bend-resistant structures. At present, the shaping and preforming of braided hoses is usually performed manually. To enable a high volume production of lightweight hollow structures, automated preforming technologies are required. This article discusses a new technical approach which allows a fully automated preforming of braided hybrid yarn hoses. Starting with pre-fabricated and rolled up quasi-endless braided hoses, the conceived automation system has to cut several segments from the hose and subsequently pull them above each other to produce a multi-ply preform. For an automated process, a reproducible and damage-free manipulation of the hoses has to be ensured during preforming. Therefore, the process is analyzed and concepts for unrolling and cutting of the endless hoses as well as stacking and fixation of the obtained segments are developed and evaluated experimentally. As a result of the investigation, a fully automated preforming station is built up.",https://doi.org/10.1016/j.procir.2017.03.299,https://www.sciencedirect.com/science/article/pii/S2212827117304870,,,,2017,Automated Preforming of Braided Hoses Made of Thermoplast-glass Fiber Hybrid Yarns,A. Liebsch and R. Kupfer and A. Defranceski and B. Rösler and J. Janik and M. Gude,article,LIEBSCH201757,Procedia CIRP,,66,2212-8271,1st CIRP Conference on Composite Materials Parts Manufacturing (CIRP CCMPM 2017),,
,"Intrusion detection system, Internet of Things, Cybersecurity",25-37,,"Internet of Things (IoT) is a new paradigm that integrates the Internet and physical objects belonging to different domains such as home automation, industrial process, human health and environmental monitoring. It deepens the presence of Internet-connected devices in our daily activities, bringing, in addition to many benefits, challenges related to security issues. For more than two decades, Intrusion Detection Systems (IDS) have been an important tool for the protection of networks and information systems. However, applying traditional IDS techniques to IoT is difficult due to its particular characteristics such as constrained-resource devices, specific protocol stacks, and standards. In this paper, we present a survey of IDS research efforts for IoT. Our objective is to identify leading trends, open issues, and future research possibilities. We classified the IDSs proposed in the literature according to the following attributes: detection method, IDS placement strategy, security threat and validation strategy. We also discussed the different possibilities for each attribute, detailing aspects of works that either propose specific IDS schemes for IoT or develop attack detection strategies for IoT threats that might be embedded in IDSs.",https://doi.org/10.1016/j.jnca.2017.02.009,https://www.sciencedirect.com/science/article/pii/S1084804517300802,,,,2017,A survey of intrusion detection in Internet of Things,Bruno Bogaz Zarpelão and Rodrigo Sanches Miani and Cláudio Toshio Kawakani and Sean Carlisto {de Alvarenga},article,ZARPELAO201725,Journal of Network and Computer Applications,,84,1084-8045,,,
,"Chlorophyll fluorescence, leaf hairs, , UV-B radiation",341-345,,"The photochemical efficiency of photosystem II, as measured by chlorophyll fluorescence induction, was not affected in de-haired olive leaves kept in the dark or intact leaves irradiated with a moderate (3.75 W m−2) ultraviolet-B (UV-B) intensity. In de-haired, UV-B-irradiated leaves, however, the ratio of variable to maximum (Fv/Fm) chlorophyll fluorescence declined significantly and irreversibly. Reduction in Fv/Fm was associated with an increase in instantaneous (F0) and a decrease in maximum (Fm) fluorescence, indicating perturbation by the UV-B exposure of more than one photosynthetic site. Extensive epidermal browning in dehaired, UV-B irradiated leaves was also observed, indicating possible damage to cell membranes. The results strengthen the hypothesis that leaf hairs protect the underlying tissues against UV-B radiation damage.",https://doi.org/10.1016/0098-8472(93)90035-E,https://www.sciencedirect.com/science/article/pii/009884729390035E,,,,1993,Leaf hairs of Olea europeae protect underlying tissues against ultraviolet-B radiation damage,George Karabourniotis and Aris Kyparissis and Yiannis Manetas,article,KARABOURNIOTIS1993341,Environmental and Experimental Botany,3,33,0098-8472,,,
,,465-482,Firewall Policies and VPN Configurations,,https://doi.org/10.1016/B978-159749088-7/50012-8,https://www.sciencedirect.com/science/article/pii/B9781597490887500128,Burlington,Syngress,978-1-59749-088-7,2006,Index,,incollection,2006465,,,,,,Anne Henmi,
,,113-120,,"The ability to control the transition from vegetative to reproductive growth could potentially increase wheat yields, particularly in regions subject to midseason drought stress. Little is known about the factors that regulate or affect this transition in wheat and other graminae. Because ethephon is known to accelerate this transition in other plants, the effect of seed treatment on spring wheat growth and development was investigated. Seedlings derived from seeds imbibed in ethephon underwent the transition from vegetative to reproductive growth earlier than seeds imbibed in water. The percentage of 17-day-old plants with four fully-emerged leaves (i.e., plants in which meristem development had proceeded from vegetative apex to double-ridge formation) showed a positive correlation with ethephon concentration. Subsequent yield components were unaffected with the exception of a small increase in the number of kernels/spike in plants derived from seeds imbibed in ethephon solutions for 24 h. Neither root nor shoot dry weights of 21-day-old plants were affected by the treatments. Germination percentages were unaffected by the treatments but 8-day-old plants derived from seeds imbibed for 24 h had reduced height with increasing ethephon concentrations. These results will be useful in further studies of the biochemical basis of the transition to reproductive growth.",https://doi.org/10.1016/0378-4290(93)90115-4,https://www.sciencedirect.com/science/article/pii/0378429093901154,,,,1993,The effect of ethephon seed treatment on leaf development and head initiation of wheat,Gary M. Banowetz,article,BANOWETZ1993113,Field Crops Research,1,34,0378-4290,,,
,,11-19,,"The influence of high pressure oxygen (HOP) before, during and after irradiation on seedling injury (percent reduction in seedling height relative to the non-irradiated controls) was investigated using Himalaya (C.I. 620) barley seeds. Seeds were adjusted to water contents of 2–14% by storage in vacuum desiccators over calcium oxide or mixtures of glycerol and water and then irradiated in vacuo or under various oxygen tensions with 60Co gamma rays. After irradiation, the seeds were soaked at approximately 0°C in oxygen or nitrogen bubbled water. Treatment effects were recorded as M1 seedling injury. Seeds exposed to HPO before, during or after irradiation followed by soaking in oxygen or nitrogen expressed two or three times more damage than irradiation in vacuo followed by soaking in oxygenated water. That a reaction between oxygen and radiation-induced sites probably occurs before the seeds are soaked was demonstrated by the failure to remove completely the effect of HPO by vacuum between HPO treatment and irradiation. The results indicate that placing the seeds under HPO may increase the rate and extent of reactions which occur during post-radiation storage of seeds in the presence of oxygen. The increase in damage associated with oxygen soaking (oxygen-dependent damage) is partially lost during aerobic storage and is largely pre-empted when seeds are placed under HPO. This decrease in oxygen-dependent damage is accompanied by an increase in damage occurring with nitrogen soaking, suggesting that the reaction which leads to damage was initiated before soaking and to the same oxygen sensitive sites.",https://doi.org/10.1016/0098-8472(80)90214-2,https://www.sciencedirect.com/science/article/pii/0098847280902142,,,,1980,Influence of oxygen at high pressure on the induction of damage in barley seeds by gamma radiation,E. Donaldson and R.A. Nilan and C.F. Konzak,article,DONALDSON198011,Environmental and Experimental Botany,1,20,0098-8472,,,
,,361-372,Network Security Assessment,,https://doi.org/10.1016/B978-159749101-3/50018-5,https://www.sciencedirect.com/science/article/pii/B9781597491013500185,Burlington,Syngress,978-1-59749-101-3,2006,Index,,incollection,2006361,,,,,,Steve Manzuik and André Gold and Chris Gatford,
,"MCP-1, RANTES, Estradiol, Conjugated equine estrogens (CEE), Testosterone, Postmenopausal, Atherosclerosis, Tibolone, Raloxifene",142-150,,"Background
The cardinal role of chronic inflammation in the development of atherosclerosis is increasingly being recognized. Estrogens may prevent the evolution of atherosclerosis by suppressing immune response. Furthermore, the conflicting reports on the cardiovascular effects of hormone therapy between observational and clinical trials have triggered interest on the effect of alternative therapies on the cardiovascular system.
Objective
The aim of this study was to assess the effect of estrogen, estrogen–progestin, tibolone and raloxifene therapy on circulating markers of chemotaxis in healthy postmenopausal women.
Methods
Eighty-eight postmenopausal women aged 44–62 years were randomly allocated to daily: (1) conjugated equine estrogens 0.625mg (CEE), (2) 17β-estradiol 1mg plus norethisterone acetate 0.5mg (E2/NETA), (3) tibolone 2.5mg, (4) raloxifene HCl 60mg or (5) no treatment. Serum monocyte chemoattractant protein-1 (MCP-1) and regulated upon activation, normal T-cell expressed and secreted (RANTES) were measured at baseline and at 3 months.
Results
Endogenous testosterone and free androgen index (FAI) correlated negatively, while SHBG correlated positively with serum RANTES (testosterone: r=−0.27, p=0.033; FAI: r=−0.43, p=0.004: SHBG: r=0.34, p=0.026). Serum MCP-1 decreased significantly in the CEE group (baseline 125.3±51pg/ml, 3 months 84.5±36.1pg/ml, p=0.043), while no difference was detected between baseline and post-treatment levels in the other groups. Furthermore, a significant decrease in serum RANTES was observed at the end of 3 months only in the E2/NETA and the raloxifene group (E2/NETA baseline 8690.6±3880.0pg/ml, 3 months 6894.0±1720.0pg/ml, p=0.007; raloxifene baseline 9042.4±3765.6pg/ml, 3 months 6718.1±2366.2pg/ml, p=0.011).
Conclusion
Endogenous androgens may suppress chemotactic response. Postmenopausal hormone therapy and raloxifene may inhibit the expression of chemoattractant molecules and thus attenuate inflammation. The relevance of these findings in terms of clinically established caridoprotection remains to be clarified.",https://doi.org/10.1016/j.atherosclerosis.2006.05.045,https://www.sciencedirect.com/science/article/pii/S0021915006003303,,,,2007,"Circulating chemoattractants RANTES, negatively related to endogenous androgens, and MCP-1 are differentially suppressed by hormone therapy and raloxifene",George E. Christodoulakos and Irene V. Lambrinoudaki and Emmanuel V. Economou and Constantinos Papadias and Nikolaos Vitoratos and Constantinos P. Panoulis and Evangelia E. Kouskouni and Sofia A. Vlachou and George C. Creatsas,article,CHRISTODOULAKOS2007142,Atherosclerosis,1,193,0021-9150,,,
Advances in Parallel Computing,,695-704,Parallel Computing,"Publisher Summary
A cellular automaton is viewed as simple models of spatially extended decentralized systems made up of a number of individual components (e.g. biological cells). The communication between constituent cells is limited to local interaction. Each individual cell is in a specific state, which changes over time depending on the states of its local neighbors. In particular, cellular automaton models have been proposed for biological applications, including ecological, epidemiological, ethological (game theoretical), evolutionary, immunobiological and morphogenetic aspects. The chapter discusses an overview of cellular automaton models of spatio-temporal pattern formation in interacting cell systems. Various automaton rules mimicking general pattern forming principles have been suggested, and may lead to models of (intracellular) cytoskeleton and membrane dynamics, tissue formation, tumor growth, life cycles of micro-organisms or animal coat markings. Automaton models of cellular pattern formation can be roughly classified according to the prevalent type of interaction. Cell-medium interactions dominate (nutrient-dependent) growth models, while one can further distinguish direct cell-cell and indirect cell-medium-cell interactions. Finally, the chapter focuses on a specific example—tippling pattern formation in myxobacteria and introduce a cellular automaton model for this phenomenon, which is able to lead to testable biological hypotheses.",https://doi.org/10.1016/S0927-5452(04)80086-8,https://www.sciencedirect.com/science/article/pii/S0927545204800868,,North-Holland,,2004,Cellular automaton modeling of pattern formation in interacting cell systems,Andreas Deutsch and Uwe Börner and M. Bär,incollection,DEUTSCH2004695,,,13,0927-5452,,G.R. Joubert and W.E. Nagel and F.J. Peters and W.V. Walter,
,"Web-based experiments, Online recruitment, Data quality, Online research, Remote testing, Cognitive psychology, Crowdsourcing",104472,,"The past 10 years have seen rapid growth of online (web-based) data collection across the behavioural sciences. Despite the many important contributions of such studies, some researchers have concerns about the reduction in experimental control when research moves outside of laboratory conditions. This paper provides an accessible overview of the issues that can adversely affect data quality in online experiments, with particular focus on cognitive studies of memory and language. I provide checklists for researchers setting up such experiments to help improve data quality. These recommendations focus on three key aspects of experimental design: the technology choices made by researchers and participants, participant recruitment methods, and the performance of participants during experiments. I argue that ensuring high data quality for online experiments requires significant effort prior to data collection to maintain the credibility of our rapidly expanding evidence base. With such safeguards in place, online experiments will continue to provide important, paradigm-changing opportunities across the behavioural sciences.",https://doi.org/10.1016/j.jml.2023.104472,https://www.sciencedirect.com/science/article/pii/S0749596X23000712,,,,2024,Moving experimental psychology online: How to obtain high quality data when we can’t see our participants,Jennifer M. Rodd,article,RODD2024104472,Journal of Memory and Language,,134,0749-596X,,,
,"rye proteins, wheat proteins, barley proteins, purification, polyacrylamide gel electrophoresis, PAGE: , , ",31-43,,"Summary
Rye secalins have been separated using preparative Polyacrylamide gel electrophoresis (PAGE) in gradient gels. Fractionated secalin was recovered by solvent extraction. Based on the recovery of unfractionated secalin from the entire gel, nearly quantitative recovery of cereal prolamins is possible. However, the yield of purified secalin constituents was typically about 75 %. The procedure has been used to prepare milligram quantities of individual secalin bands or fractions. The method and equipment described are simple and can be applied for the fractionation of prolamins from other cereal grains. To demonstrate the general usefulness of the method, wheat gliadins and barley hordeins have been fractionated. Experimental conditions can readily be modified to enhance prolamin resolution. The procedure can probably be adapted to provide purified components equivalent to most of the prolamin bands visible in one- or two-dimensional PAGE patterns.",https://doi.org/10.1016/S0015-3796(84)80062-1,https://www.sciencedirect.com/science/article/pii/S0015379684800621,,,,1984,Purification of cereal prolamins by means of preparative PAGE at acid pH,Kathryn A. Caldwell,article,CALDWELL198431,Biochemie und Physiologie der Pflanzen,1,179,0015-3796,,,
,"embryo transfer, cervical mucus, aspiration, catheter, clinical trial",308-313,,"The removal of cervical mucus during embryo transfer has been postulated to increase the pregnancy and implantation rates by not interfering with embryo implantation. Even so, this is a time-consuming procedure that may increase the incidence of difficult transfers by removing the naturally lubricant mucus. In addition, any cervical manipulations at the time of embryo transfer may cause unwarranted uterine contractions. In this prospective, controlled study, 286 women undergoing embryo transfer between January and May 2006 were divided into two groups according to whether the cervical mucus was scheduled to be aspirated (group A) or not (group B). The two groups were similar with regards to the demographics, cause of infertility, characteristics of ovarian stimulation and embryos transferred. Even so, the clinical pregnancy rate was significantly higher in group (A) than group (B) (OR = 2.18, 95% CI = 1.32–3.58), although there were easier transfers in group (B) than group (A) (OR = 3.00, 95% CI = 1.05–8.55). This demonstrates that even though embryo transfers were easier to perform when the cervical mucus was left in place, aspiration resulted in an increased chance of clinical pregnancy.",https://doi.org/10.1016/S1472-6483(10)60872-3,https://www.sciencedirect.com/science/article/pii/S1472648310608723,,,,2007,Removal of cervical mucus prior to embryo transfer improves pregnancy rates in women undergoing assisted reproduction,Mamdoh A Eskandar and Ahmed M Abou-Setta and Mohamed El-Amin and Mona A Almushait and Adekunle A Sobande,article,ESKANDAR2007308,Reproductive BioMedicine Online,3,14,1472-6483,,,
,,67-73,,"A visual census technique for estimating seagrass biomass has been adapted from a comparative pasture yield method. The above-ground biomass of seagrass within sampling quadrats was ranked with respect to a set of reference quadrats which were preselected to provide a scale of standing crop dry weights. At the end of each sampling period, sufficient quadrats were harvested to calibrate the scale. Using the method, monthly mean standing crops were estimated from May 1987 to April 1988 for a multispecific seagrass bed on Green Island, North Queensland. Values obtained ranged between 61.52 and 113.08 g dry weight m−2. The precision (SE/x) of each monthly estimate ranged from 0.05 to 0.13, a satisfactory level for field programs. This method is more precise and time efficient, and is less destructive than some traditional harvesting methods.",https://doi.org/10.1016/0304-3770(91)90106-F,https://www.sciencedirect.com/science/article/pii/030437709190106F,,,,1991,An evaluation of a rapid visual technique for estimating seagrass biomass,Jane E. Mellors,article,MELLORS199167,Aquatic Botany,1,42,0304-3770,,,
,,83-86,,"The pyroantimonate method was used to study the localization of free and weakly bound calcium in cells of moss protonema of Funaria hygrometrica Hedw. cultivated on a clinostat (2 rev/min). Electroncytochemical study of control cells cultivated at 1 g revealed that granular precipitate marked chloroplasts, mitochondria, Golgi apparatus, lipid drops, nucleoplasma, nucleolus, nucleus membranes, cell walls and endoplasmic reticulum. In mitochondria the precipitate was revealed in stroma, in chloroplast it was found on thylakoids and envelope membranes. The cultivation of protonema on clinostat led to the intensification in cytochemical reaction product deposit. A considerable intensification of the reaction was noted in endomembranes, vacuoles, periplasmic space and cell walls. At the same time analysis of pectinase localization was made using the electroncytochemical method. A high reaction intensity in walls in comparison to that in control was found out to be a distinctive pecularity of the cells cultivated on clinostat. It testifies to the fact that increasing of freee calcium concentrations under conditions of clinostation is connected with pectinic substances hydrolysis and breaking of methoxy groups of pectins. Data obtained are discussed in relation to problems of possible mechanisms of disturbance in calcium balance of plant cells and the role of cell walls in gomeostasis of cell grown under conditions of simulated weighlessness.",https://doi.org/10.1016/0273-1177(89)90060-4,https://www.sciencedirect.com/science/article/pii/0273117789900604,,,,1989,Long clinostation influence on the localization of free and weakly bound calcium in cell walls of Funaria hygrometrica moss protonema cells,E.M. Nedukha,article,NEDUKHA198983,Advances in Space Research,11,9,0273-1177,,,
,,407-413,,"Agrocybe pusilla, A. vervacti, Crinipellis tomentosa, Marasmius anomalus and Psilocybe calongei sp.nov. are reported from xerophytic grasslands in central Spain.",https://doi.org/10.1016/S0007-1536(88)80149-9,https://www.sciencedirect.com/science/article/pii/S0007153688801499,,,,1988,Agarics from xerophytic grasslands in Central Spain,G. Moreno and F. Esteve-Raventós,article,MORENO1988407,Transactions of the British Mycological Society,3,90,0007-1536,,,
,"Critical point, Phase diagram, Second virial coefficient",105546,,"The prediction of phase separation is essential to understand and control the properties of food systems. In this work, an existing theoretical model for describing phase separation between binary mixtures of hydrocolloids, using a virial approach up to second order, is extended with several new analytical expressions. These new expressions allow one to determine the three virial coefficients directly from three characteristics of the phase diagram, where the critical point plays a pivotal role and allows one to predict the complete phase diagram. The advantage of this approach is that experimental techniques, like membrane osmometry or static light scattering, to directly measure virial coefficients can be, in principle, avoided. It was found that just the location of the critical point is sufficient to determine two of the three virial coefficients, when one of the virial coefficients is known. When, in addition to the critical point, one other characteristic of the phase diagram is known with sufficient accuracy, like the slope of the tie-lines near or far away from the critical point, all three virial coefficients can be determined from the phase diagram. Using this approach, three virial coefficients for aqueous mixtures of dextran and polyethylene oxide were determined and compared to the ones obtained from membrane osmometry.",https://doi.org/10.1016/j.foodhyd.2019.105546,https://www.sciencedirect.com/science/article/pii/S0268005X19323252,,,,2020,Second order virial coefficients from phase diagrams,Belinda P.C. Dewi and Erik {van der Linden} and Arjen Bot and Paul Venema,article,DEWI2020105546,Food Hydrocolloids,,101,0268-005X,,,
,"Lipoprotein (a), Endothelial function, Postmenopausal women, Nitric oxide",249-254,,"Background. Lipoprotein (a) (Lp(a)) is an independent risk factor for atherosclerotic cardiovascular disease. The atherogenic potential of Lp(a) may be by impairment of endothelial function. Objectives. We investigated the relation of Lp(a) plasma levels to endothelium dependent and independent dilatation of the brachial artery in healthy postmenopausal women. Methods. One hundred and five healthy postmenopausal women aged 52–67 years were included in the study. Endothelial function was assessed non-invasively by measuring percent lumen diameter change in the brachial artery after reactive hyperemia and sublingual nitroglycerine spray. Results. Flow mediated dilatation was inversely related to the plasma logLp(a) level. Mean change per unit logLp(a) increase:−2.83% (95% CI: −5.22–−0.43). Elevated Lp(a) (>239 mg/l) (upper quartile) was associated with an impaired flow mediated vasodilatation (2.4%±1.2) compared to Lp(a) ≤239 mg/l (5.2%±0.7). Adjustment for other cardiovascular risk factors did not change the magnitude of the association. Nitroglycerine-induced vasodilatation was not significantly lower in the high Lp(a) level group, compared to the group with normal levels of Lp(a) (≤239 mg/l) (8.0±1.2 vs 11.4%±0.8). Conclusion. Elevated lipoprotein (a) levels are associated with an impaired endothelial function in healthy postmenopausal women, independent of conventional risk factors for cardiovascular disease. Since Lp(a) may be pathogenetically important for early vascular damage, elevated Lp(a) levels might contribute to the increased cardiovascular risk seen in postmenopausal women.",https://doi.org/10.1016/S0021-9150(00)00411-1,https://www.sciencedirect.com/science/article/pii/S0021915000004111,,,,2000,Lipoprotein (a) is associated with endothelial function in healthy postmenopausal women,Hanneke W. Wilmink and Miriam J.J. {de Kleijn} and Michiel L. Bots and Annette A.A. Bak and Yvonne T. {van der Schouw} and Sylvia Engelen and Jose Planellas and Jan-Dirk Banga and Diederick E. Grobbee,article,WILMINK2000249,Atherosclerosis,1,153,0021-9150,,,
,"network forensics, admissible, authentic, complete, reliable, believable, cyber attacks, traceback, itrace, packet marketing, log-based traceback",649-660,Computer and Information Security Handbook (Second Edition),"Today’s cyber criminal investigator faces a formidable challenge: tracing network-based cyber criminals. The possibility of becoming a victim of cyber crime is the number-one fear of billions of people. This concern is well founded. The findings in the annual CSI/FBI Computer Crime and Security Surveys confirm that cyber crime is real and continues to be a significant threat. Traceback and attribution are performed during or after cyber violations and attacks, to identify where an attack originated, how it propagated, and what computer(s) and person(s) are responsible and should be held accountable. The goal of network forensics capabilities is to determine the path from a victimized network or system through any intermediate systems and communication pathways, back to the point of attack origination or the person who is accountable. In some cases, the computers launching an attack may themselves be compromised hosts or be controlled remotely. Attribution is the process of determining the identity of the source of a cyber attack. Types of attribution can include both digital identity (computer, user account, IP address, or enabling software) and physical identity (the actual person using the computer from which an attack originated). Cyber crime has become a painful side effect of the innovations of computer and Internet technologies. With the growth of the Internet, cyber attacks and crimes are happening every day and everywhere. It is very important to build the capability to trace and attribute attacks to the real cyber criminals and terrorists, especially in this large-scale human-built networked environment. In this chapter, we discuss the current network forensic techniques in cyber attack traceback. We focus on the current schemes in IP spoofing traceback and stepping-stone attack attribution. Furthermore, we introduce the traceback issues in Voice over IP, Botmaster, and online fraudsters.",https://doi.org/10.1016/B978-0-12-394397-2.00036-2,https://www.sciencedirect.com/science/article/pii/B9780123943972000362,Boston,Morgan Kaufmann,978-0-12-394397-2,2013,Chapter 36 - Network Forensics,Yong Guan,incollection,GUAN2013649,,,,,,John R. Vacca,Second Edition
,,146-151,,,https://doi.org/10.1016/S0144-8617(05)00617-X,https://www.sciencedirect.com/science/article/pii/S014486170500617X,,,,2006,Bibliography,,article,2006146,Carbohydrate Polymers,1,63,0144-8617,,,
,"Cloud security, Cloud computing, Denial-of-service, Security threats, Intrusion detection systems",11-29,,"High quality computing services with reduced cost and improved performance have made cloud computing a popular paradigm. Due to its flexible infrastructure, net centric approach and ease of access, the cloud computing has become prevalent. Its widespread usage is however being diminished by the fact that the cloud computing paradigm is yet unable to address security issues which may in turn aggravate the quality of service as well as the privacy of customers' data. In this paper, we present a survey of security issues in terms of security threats and their remediations. The contribution aims at the analysis and categorization of working mechanisms of the main security issues and the possible solutions that exist in the literature. We perform a parametric comparison of the threats being faced by cloud platforms. Moreover, we compare various intrusion detection and prevention frameworks being used to address security issues. The trusted cloud computing and mechanisms for regulating security compliance among cloud service providers are also analyzed. Since the security mechanisms continue to evolve, we also present the future orientation of cloud security issues and their possible countermeasures.",https://doi.org/10.1016/j.jnca.2016.05.010,https://www.sciencedirect.com/science/article/pii/S1084804516301060,,,,2016,A survey of security issues for cloud computing,Minhaj Ahmad Khan,article,KHAN201611,Journal of Network and Computer Applications,,71,1084-8045,,,
,"Biosurfaces, Hydrophobicity, Interaction energies",91-110,,"It is shown that the “hydrophobic” attraction energy between two apolar moieties (as well as between one polar and one apolar moiety) immersed in water is the sole consequence of the hydrogen-bonding energy of cohesion of the water molecules surrounding these moieties. It is also shown that “hydrophobic” surfaces do not repel, but on the contrary attract water. The theory is given of hydrophobic interactions at a macroscopic level, as well as various methods for their quantitative measurement. The properties of hydrophobic, partly hydrophobic and hydrophilic compounds and surfaces are described, including those of amino acids, proteins (incorporating protein solubility), proteins at the air-water interface, carbohydrates, phospholipids, phospholipid layers, and nucleic acids. Finally, some effects and applications of hydrophobic interactions are discussed, including protein adsorption, protein precipitation, cell adhesion, cell fusion, and liquid chromatography approaches such as reversed-phase and hydrophobic interaction chromatography. Finally, the influence of hydrophobic forces is treated in antigen-antibody and other ligand-receptor interactions.",https://doi.org/10.1016/0927-7765(95)01217-7,https://www.sciencedirect.com/science/article/pii/0927776595012177,,,,1995,"Hydrophobicity of biosurfaces — Origin, quantitative determination and interaction energies",C.J. {van Oss},article,VANOSS199591,Colloids and Surfaces B: Biointerfaces,3,5,0927-7765,Hydrophobicity,,
,"sausage, casing, , adhesion, proteins",249-257,,"The adhesion of a meat Lactobacillus sp. to sausage collagen casing was substantially reduced (by 1–2 log CPU cm−2) in the presence of bovine serum albumin, casein, and a yeast cell wall mannoprotein. These proteins affected the [bacterium-medium-casing]system in several ways. They interacted with the cell wall surface, making it more positively charged, they lowered the surface tension of the adhesion medium, and they decreased the hydrophobicity of the casing. Reduction of bacterial adhesion appeared to be mostly related to the decrease in casing hydrophobicity and, indeed, the proteins which did not reduce adhesion (gelatin or casamino acids) had no effect on casing hydrophobicity. The fact that collagen reduced adhesion without affecting the casing surface free energy is consistent with the previous report that some lactobacilli can specifically bind to collagen through a receptor-adhesion site interaction.",https://doi.org/10.1016/0963-9969(96)00031-2,https://www.sciencedirect.com/science/article/pii/0963996996000312,,,,1996,Reduction of adhesion of a Lactobacillus sp. to collagen sausage casing by proteins,M.I. Barriga and J.P.G. Piette,article,BARRIGA1996249,Food Research International,3,29,0963-9969,,,
,"Phishing hostname, Fast flux service network, Machine learning, Deep learning, Flat classification, Hierarchical classification",103125,,"Attackers are increasingly using Fast Flux Service Networks (FFSNs), networks of compromised machines, to host phishing websites. In FFSNs, the machines rapidly change such that blacklisting them does not entirely stop the networks from operating the websites. This increases the longevity of the websites thus becoming more harmful. Existing solutions for detecting the websites are limited with relatively low or moderate prediction performances, high prediction time and use of less diversified features which increases their susceptibility to detection evasions. This paper proposes a Machine Learning (ML) based approach for detecting phishing websites hosted in FFSNs using a novel set of 56 features. Compared with previous works, the approach achieves high accuracy, a low detection time and uses highly diversified features to enhance resilience to detection evasion. The effectiveness of the features for prediction was evaluated in the context of binary and multi-class classification tasks using multiple traditional and deep learning ML algorithms. The proposed approach achieves an accuracy of 98.42% and 97.81% for binary and multi-class classification tasks respectively. Our results showed that temporal and DNS based features are the strongest predictors while network and host related features are the weakest. Our approach is a significant step towards tracking of core components of FFSNs with an aim of shutting down the entire phishing ecosystem.",https://doi.org/10.1016/j.jisa.2022.103125,https://www.sciencedirect.com/science/article/pii/S2214212622000175,,,,2022,A machine learning approach for detecting fast flux phishing hostnames,Thomas Nagunwa and Paul Kearney and Shereen Fouad,article,NAGUNWA2022103125,Journal of Information Security and Applications,,65,2214-2126,,,
,"Mobile health (mHealth), Smartphones, Community health workers, Persuasive technology, Sensors, Smart/connected health",277-294,Fundamentals of Telemedicine and Telehealth,"Mobile health (mHealth), the use of mobile devices such as cell phones to support health, is poised to greatly impact healthcare in many ways. Smartphones are ubiquitous in developed countries and are rapidly being adopted in developing countries. Since they are highly portable and very powerful computing and communication devices with large storage and excellent graphic capabilities, they have the capability to provide clinical decision support, deliver media-rich medical advice, and support documentation of care even when there is no connectivity. The emerging discipline of persuasive technology provides a conceptual framework for developing effective smartphone systems for healthcare. In developing countries, smartphones can serve as powerful support tools for healthcare professionals including community health workers. Google, Apple, and other third parties provide systems for the development of smartphone systems. There are many new mobile technologies for the health including activity sensors and smartwatches.",https://doi.org/10.1016/B978-0-12-814309-4.00012-4,https://www.sciencedirect.com/science/article/pii/B9780128143094000124,,Academic Press,978-0-12-814309-4,2020,Chapter 12 - Mobile health (mHealth),Sriram Iyengar,incollection,IYENGAR2020277,,,,,,Shashi Gogia,
,"resident training, evaluation, competencies, resident evaluation, communications competency, professionalism, halo effect, global evaluations, Patient Care, Medical Knowledge, Professionalism, Interpersonal and Communication Skills, Practice Based Learning and Improvement",351-356,,"Background
The ACGME requires the assessment of resident competency in 6 domains. Global evaluations covering all 6 competencies are routinely used. Evaluators may be overly influenced by resident affability and availability, thereby resulting in a halo effect. We hypothesized that the Interpersonal Skills and Communications (ICS) and Professionalism (PR) competencies would unduly influence other competency scores.
Methods
General surgery resident evaluations are performed by staff and peers on a rotational basis using competency-based questions. Each question is scored using a 5-point Likert scale. Mean individual composite scores for each competency were calculated and then correlated with other mean composite competency scores. Data from patient evaluations were similarly analyzed. A final correlation of competency scores to ABSITE scores, as an objective, standardized measure of a specific competency, Medical knowledge (MK) was also performed.
Results
Results were available for 37 residents (PGY 1-5). There was a significant association between ICS scores and higher scores in MK (r = 0.52, p = 0.004), PR (r = 0.826, p < 0.0001) and patient care (PC) (r = 0.619, p < 0.0001). No correlation, however, was found between patient evaluations of residents and their faculty/peer-based ICS scores. We found no association between ICS scores and improved patient evaluations. Lastly, we found no association between ICS or MK scores and ABSITE scores.
Conclusions
It was difficult to ascertain whether residents with better ICS scores had higher PR, PC, and MK scores because of the halo effect, improper completion of evaluations, or whether those residents were truly performing better clinically. External measures of resident performance did not correlate with faculty/peer evaluations of ICS and PR. Residency programs should consider adopting a more standardized way to objectively evaluate residents.",https://doi.org/10.1016/j.jsurg.2007.06.012,https://www.sciencedirect.com/science/article/pii/S1931720407001663,,,,2007,Are the Communication and Professionalism Competencies the New Critical Values in a Resident’s Global Evaluation Process?,Mounir J. Haurani and I. Rubinfeld and S. Rao and J. Beaubien and J.L. Musial and A. Parker and C. Reickert and A. Raafat and A. Shepard,article,HAURANI2007351,Journal of Surgical Education,6,64,1931-7204,,,
,"cervical mucus, embryo transfer, randomized controlled trial",310-315,,"Cervical mucus may cover the embryo transfer catheter during passage of the cervical canal, interfering with the correct placement of the embryo(s) into the uterine cavity. The effect of removal of cervical mucus prior to embryo transfer in IVF/intracytoplasmic sperm injection (ICSI) on live birth rate was studied. The study was set up as a single blind randomized controlled trial. Couples undergoing IVF/ICSI were randomly allocated to either removal of cervical mucus prior to embryo transfer, or a mock procedure. Randomization was done with stratification for age, cycle number and method of treatment. Primary outcome was live birth rate. A total of 317 couples were included and underwent 428 cycles, of which the outcome of 3 cycles was unknown. Baseline characteristics of both groups were comparable. Live birth occurred in 52 of 220 (24%) cycles in the treatment group and 42 of 205 (21%) cycles in the control group (risk difference 3%, 95% confidence interval −5–11%). It is unlikely that removal of cervical mucus prior to embryo transfer has a significant effect on live birth rate. A small effect, however, cannot be excluded.",https://doi.org/10.1016/S1472-6483(10)60344-6,https://www.sciencedirect.com/science/article/pii/S1472648310603446,,,,2007,Removal of cervical mucus: effect on pregnancy rates in IVF/ICSI,BAJT Visschers and RSGM Bots and MF Peeters and BWJ Mol and HJHM {van Dessel},article,VISSCHERS2007310,Reproductive BioMedicine Online,3,15,1472-6483,,,
,,321-332,,"Photosynthetic carbon uptake of Callitriche cophocarpa Sendt. was examined in plants collected from six Danish streams and in plants grown under variable inorganic carbon conditions in the laboratory. Both field and laboratory plants showed a low affinity for inorganic carbon (CO2 compensation points ranging from 0.7 to 22 μM, and K0.5(CO2) from 51 to 121 μM), consistent with C-3 photosynthesis and use of CO2 alone. Variation in inorganic carbon uptake characteristics was low in both groups of plants. Only in laboratory-grown plants was a coupling found between carbon uptake and the inorganic carbon regime of the medium. The carbon extraction capacity, expressed as a percentage of the initial amount of dissolved inorganic carbon (DIC) assimilated in PH-drift experiments, increased from −1.4 to 11.8% with declining external carbon availability, and the initial slope of the CO2 response curve increased from 6.4 to 15.3 g−1 h−1 dm3. The plasticity of the inorganic carbon uptake system of C. cophocarpa was very low compared to the plasticity observed for submerged macrophytes with accessory carbon uptake systems (i.e. HCO3− use or C-4 photosynthesis), suggesting that the plasticity of the C-3 photosynthetic apparatus as such is restricted. The low carbon affinity of C. cophocarpa indicates that this species depends on CO2 oversaturation for a sufficient supply of CO2 for photosynthesis and growth.",https://doi.org/10.1016/0304-3770(91)90078-J,https://www.sciencedirect.com/science/article/pii/030437709190078J,,,,1991,Inorganic carbon uptake kinetics of the stream macrophyte Callitriche cophocarpa Sendt.,Tom Vindbæk Madsen,article,MADSEN1991321,Aquatic Botany,4,40,0304-3770,,,
,,551-563,,"Since the ban on the use of trichloroacetic acid (TCAA) as a herbicide in several countries, TCAA is still found ubiquitously in the environment. The presence of TCAA nowadays is suggested to originate mainly from the atmospheric degradation of tetrachloroethene. Our mass balance calculations indicate that this may be true for the presence of TCAA in the atmosphere. However, our mass balance calculations also provide tentative evidence for the formation of TCAA in soil. If our calculated production fluxes are realistic estimates, a very large source of TCAA in soil has been identified.",https://doi.org/10.1016/S0045-6535(98)00206-9,https://www.sciencedirect.com/science/article/pii/S0045653598002069,,,,1999,Mass balance of trichloroacetic acid in the soil top layer,Eddo J. Hoekstra and Ed W.B. {de Leer} and Udo A.Th. Brinkman,article,HOEKSTRA1999551,Chemosphere,3,38,0045-6535,,,
,"intrusion prevention systems, network intrusions, physical attacks, TCP/IP, malware, phishing, social engineering, rootkit, intrusion detection systems, tunneling",81-95,Computer and Information Security Handbook (Second Edition),"Guarding against network intrusions requires the monitoring of network traffic for particular network segments or devices and analysis of network, transport, and application protocols to identify suspicious activity. This chapter provides a detailed discussion of network-based intrusion protection technologies. It contains a brief overview of the major components of network-based intrusion protection systems and explains the architectures typically used for deploying the components. It also examines the security capabilities of the technologies in depth, including the methodologies they use to identify suspicious activity. The rest of the chapter discusses the management capabilities of the technologies and provides recommendations for implementation and operation.",https://doi.org/10.1016/B978-0-12-394397-2.00005-2,https://www.sciencedirect.com/science/article/pii/B9780123943972000052,Boston,Morgan Kaufmann,978-0-12-394397-2,2013,Chapter 5 - Guarding Against Network Intrusions,Thomas M. Chen and Patrick J. Walsh,incollection,CHEN201381,,,,,,John R. Vacca,Second Edition
,"Cardiovascular disease, Prevention, Therapy, Estrogen",357-365,,"Objective: To compare the effects of 3 months treatment with tibolone (a single entity synthetic steroid hormone with estrogenic, progestanic and androgenic activities), or continuous combined conjugated equine estrogens (CEE) plus medroxyprogesterone acetate (MPA), with placebo, on endothelial function. Design: A single center, randomized, double-blind, placebo-controlled study. Setting: Research center as part of the University Medical Center Utrecht. Subjects: One hundred and five healthy postmenopausal women, sampled from the general population. Interventions: Three months treatment with tibolone or CEE+MPA or placebo. Main outcome measure: At baseline and after 3 months, endothelial function was assessed non-invasively by measuring percent lumen diameter change in the brachial artery after reactive hyperemia and sublingual nitroglycerine spray. Results: Results are presented as mean differences between treatment groups of endothelium dependent flow mediated dilatation (fmd) and endothelium independent nitroglycerine induced dilatation with 95% confidence intervals (95% CI). After treatment, there was a significant difference in mean fmd between the CEE+MPA group and the placebo group of 2.5% (95% CI: 0.3–4.6) while the tibolone group and the placebo group did not differ significantly (0.6%; 95% CI: 1.6–2.8). Nitroglycerine induced dilatation did not differ significantly between the groups. Conclusions: Hormone replacement therapy with CEE+MPA for 3 months increases endothelium dependent fmd of the brachial artery in healthy postmenopausal women. Tibolone did not alter fmd. The clinical significance of this improvement in fmd for cardiovascular disease risk needs to be established.",https://doi.org/10.1016/S0021-9150(01)00507-X,https://www.sciencedirect.com/science/article/pii/S002191500100507X,,,,2001,Hormone replacement therapy and endothelial function: Results of a randomized controlled trial in healthy postmenopausal women,Miriam J.J {de Kleijn} and Hanneke W Wilmink and Michiel L Bots and Annette A.A Bak and Yvonne T {van der Schouw} and Juan Planellas and Sylvia Engelen and Jan-Dirk Banga and Diederick E Grobbee,article,DEKLEIJN2001357,Atherosclerosis,2,159,0021-9150,,,
,,269-298,,"Taxonomic decisions presented in this study of Vallisneria are founded on the consistency of comparable staminate and pistillate floral structures considering the geography and dioecious nature of the genus. Field studies, realized in southern Europe, eastern North America, Central America, northern South America and the Greater Antilles, formed the basis for the development of the present knowledge of characteris. Umbel and spike-like inflorescences were discovered from three localities in the Americas. Staminodia were encountered in the female flowers of Vallisneria spiralis. Two species including four varieties are recognized, mapped and illustrated. Infraspecific taxa are V. spiralis L. var. spiralis, V. spiralis var. denseserrulata Makino, V. americana Michaux var. americana and V. americana var. biwaensis (Miki) Lowden, comb. nov. These taxa are delineated according to the degree of connation of fertile filaments in the staminate flower and adnation of staminodia to stigma—style surfaces in the pistillate flower. Both species converge along what appears to be a continuous gradient in floral variation.",https://doi.org/10.1016/0304-3770(82)90064-X,https://www.sciencedirect.com/science/article/pii/030437708290064X,,,,1982,An approach to the taxonomy of Vallisneria L. (Hydrocharitaceae),Richard M. Lowden,article,LOWDEN1982269,Aquatic Botany,,13,0304-3770,Growth Regulators in Aquatic Plants,,
," Perr, Supercritical fluid chromatography-mass spectrometry, , Lipids, 1,2-Dioleoylglycerol, Glycerols",139-146,,"On-line coupling of supercritical fluid chromatography to atmospheric pressure chemical ionisation mass spectrometry was used to analyse a complex mixture of tri- and di-acylglycerols extracted from the tree Commiphora guillaumini Perr. (Burseraceae). The single components, including the ant attractant 1,2-dioleoylglycerol, were identified by mass spectrometry using skimmer-fragmentation in both the positive and the negative mode.",https://doi.org/10.1016/0021-9673(95)01118-8,https://www.sciencedirect.com/science/article/pii/0021967395011188,,,,1996,"Identification of the lipids and the ant attractant 1,2-dioleoylglycerol in the arils of Commiphora guillaumini Perr. (Burseraceae) by supercritical fluid chromatography-atmospheric pressure chemical ionisation mass spectrometry",Karl Schmeer and Graeme Nicholson and Shigang Zhang and Ernst Bayer and Katrin Bohning-Gaese,article,SCHMEER1996139,Journal of Chromatography A,1,727,0021-9673,,,
,"Functional food, Conjugated linoleic acid, CLA, Lactic acid bacteria, , Probiotics",403-411,,"Lactic acid bacteria isolated from a traditional Azorean cheese were screened for their ability to convert free linoleic acid to conjugated linoleic acid (CLA). Two strains of Lactobacillus plantarum were recognized as potential CLA producers. GC analysis identified cis-9, trans-11 C18:2 as the predominant isomer (10–14 μg/mL), followed by trans-9, trans-11 C18:2 (4–6 μg/mL). The CLA producing strains demonstrated strong biofilm capacity, high cell surface hydrophobicity and good auto-aggregation ability. These strains were capable of surviving in the presence of bile salts (0.3%) and pancreatin (0.1%), but only the highest CLA producer (L3C1E8) was able to resist low pH (2.5). Moreover, the CLA-producers showed good adhesion capacity to intestinal human cells (Caco-2 and HT-29) and were able to prevent colonization of Escherichia coli. Of the two strains, Lactobacillus plantarum L3C1E8 revealed superior probiotic properties and great potential for producing food products enriched in the two CLA isomers, cis-9, trans-11 C18:2 (60%) and trans-9, trans-11 C18:2 (25%).",https://doi.org/10.1016/j.lwt.2017.12.065,https://www.sciencedirect.com/science/article/pii/S0023643817309593,,,,2018,Conjugated linoleic acid production and probiotic assessment of Lactobacillus plantarum isolated from Pico cheese,Susana C. Ribeiro and Catherine Stanton and Bo Yang and R. Paul Ross and Célia C.G. Silva,article,RIBEIRO2018403,LWT,,90,0023-6438,,,
,"Admissible, Authentic, Believable, Complete, Cyber-attacks, Itrace, Network forensics, Packet marketing and log-based trace-back, Reliable, Trace-back",e71-e82,Computer and Information Security Handbook (Third Edition),"Today's cyber-criminal investigator faces a formidable challenge: tracing network-based cyber criminals. The possibility of becoming a victim of cyber-crime is the number-one fear of billions of people. This concern is well founded. The findings in the annual Computer Security Institute/Federal Bureau of Investigation Computer Crime and Security Surveys confirm that cyber-crime is real and continues to be a significant threat. Trace-back and attribution are performed during or after cyber violations and attacks to identify where an attack originated, how it propagated, and what computer(s) and person(s) are responsible and should be held accountable. The goal of network forensics capabilities is to determine the path from a victimized network or system through any intermediate systems and communication pathways, back to the point of attack origination or the person who is accountable. In some cases, the computers launching an attack may themselves be compromised hosts or be controlled remotely. Attribution is the process of determining the identity of the source of a cyber-attack. Types of attribution can include both digital identity [computer, user account, Internet Protocol (IP) address, or enabling software] and physical identity (the actual person using the computer from which an attack originated). Cyber-crime has become a painful side effect of the innovations of computer and Internet technologies. With the growth of the Internet, cyber-attacks and crimes are happening every day and everywhere. It is very important to build the capability to trace and attribute attacks to the real cyber criminals and terrorists, especially in this large-scale human-built networked environment. In this chapter, we discuss the current network forensic techniques in cyber-attack trace-back. We focus on the current schemes in IP spoofing trace-back and stepping-stone attack attribution. Furthermore, we introduce the trace-back issues in Voice over Internet Protocol, botmaster, and online fraudsters.",https://doi.org/10.1016/B978-0-12-803843-7.00043-0,https://www.sciencedirect.com/science/article/pii/B9780128038437000430,Boston,Morgan Kaufmann,978-0-12-803843-7,2013,Chapter e43 - Network Forensics,Yong Guan,incollection,GUAN2013e71,,,,,,John R. Vacca,Third Edition
,"Digital forensic tools, Published software, Literature review, Open source software, Availability",300999,,"Publications in the digital forensics domain frequently come with tools – a small piece of functional software. These tools are often released to the public for others to reproduce results or use them for their own purposes. However, there has been no study on the tools to understand better what is available and what is missing. For this paper we analyzed almost 800 articles from pertinent venues from 2014 to 2019 to answer the following three questions (1) what tools (i.e., in which domains of digital forensics): have been released; (2) are they still available, maintained, and documented; and (3) are there possibilities to enhance the status quo? We found 62 different tools which we categorized according to digital forensics subfields. Only 33 of these tools were found to be publicly available, the majority of these were not maintained after development. In order to enhance the status quo, one recommendation is a centralized repository specifically for tested tools. This will require tool researchers (developers) to spend more time on code documentation and preferably develop plugins instead of stand-alone tools.",https://doi.org/10.1016/j.fsidi.2020.300999,https://www.sciencedirect.com/science/article/pii/S2666281720301864,,,,2020,Digital forensic tools: Recent advances and enhancing the status quo,Tina Wu and Frank Breitinger and Stephen O'Shaughnessy,article,WU2020300999,Forensic Science International: Digital Investigation,,34,2666-2817,,,
,"Hormone replacement therapy, Endothelial function, Lipids, Blood pressure",47-54,,"Objectives: To determine whether improvement in endothelial function of the brachial artery observed in women treated with hormone replacement therapy (HRT) may be explained by changes in lipid profile or blood pressure, information was used obtained in a single-centre, randomised, double blind, placebo-controlled trial. Methods: Hundred-and-five healthy postmenopausal women, aged 50–65 years, were treated with 0.625 mg conjugated equine estrogens (CEE) combined with 2.5 mg medroxyprogesterone acetate (MPA) (CEE+MPA), 2.5 mg tibolone or placebo for 3 months. At baseline and after 3 months, endothelial function was assessed using flow-mediated dilatation (FMD) and nitro glycerine-mediated dilatation (NMD). Furthermore, lipids were measured. Multivariate linear regression analysis was applied to address the research question. Results: Treatment with CEE+MPA resulted in an improvement in FMD of 2.0% (95% CI: −0.1; 4.1). CEE/MPA reduced total cholesterol with 13% (95% CI: −18%; −7%), LDL-cholesterol with 23% (95% CI: −30%; −15%) and lipoprotein(a) (Lp(a)) with 14% (95% CI: −26%; −2%). The magnitude of the relation of CEE/MPA with endothelial function was attenuated to from 2.0 to 1.6% when change in Lp(a) was taken into account. Adjustments for other lipids or blood pressure did not attenuate the association. Conclusions: The improvement in endothelial function in postmenopausal women treated with CEE+MPA appears to be partially mediated by change in Lp(a), and apparently not by changes in other lipids.",https://doi.org/10.1016/S0378-5122(03)00085-9,https://www.sciencedirect.com/science/article/pii/S0378512203000859,,,,2003,Does the beneficial effect of HRT on endothelial function depend on lipid changes,Marlies E. Ossewaarde and Michiel L. Bots and Yvonne T. {van der Schouw} and Miriam J.J. {de Kleijn} and Hanneke W. Wilmink and Annette A.A. Bak and Juan Planellas and Jan-Dirk Banga and Diederick E. Grobbee,article,OSSEWAARDE200347,Maturitas,1,45,0378-5122,,,
,,139-158,,"Measurements of the following parameters were made over a 4 year period in 10- to 14-year-old stands of Pinus radiata subjected to markedly different degrees of water and nitrogen (N) stress: needle length, weight and specific leaf area (every 2 weeks), foliage biomass production (annually), pre-dawn needle water potential (every 2 weeks) and needle litter N concentration (monthly). Increments in needle length were a useful estimate of increments in needle weight for any given forest treatment and year because there was no consistent variation in weight per unit length of needles as they developed during the growing season. However, for well-illuminated needles, the ratio of weight per unit of needle length showed a large (approximately two-fold) variation attributable to treatment and year of foliage elongation. The ratio was loosely positively correlated with needle length (or the favourability of growing conditions) on non-irrigated plots, and appeared to result largely from increases in needle thickness rather than density. Final needle length, ranging between 40 and 160 mm, depended mainly on the amount of water and N stress experienced by trees during the growing season. The majority (greater than 90%) of needle extension occurred during a 4 month period (October–January) in spring and summer and the pattern of needle growth was affected only by water availability. Needle extension rates were negatively linearly correlated with the water stress integral (Sψ, a temporal integration of the effects of both water and N availability on needle water potentials) for monthly periods during the growing season. Needle extension, was most sensitive to the Sψ in mid-spring (October/November) when needles were elongating rapidly and still less than one-half grown. About 80% of the variation in annual foliage production (3.2–8.5 t ha−1) could be explained in terms of both (a) Sψ during the previous summer (when primordia were initiated), and (b) the water and N status of trees concurrent with needle extension. Final needle length and total foliage biomass production in the same year were poorly correlated. The specific leaf area (SLA, all sides) ranged from 10 to 17 m2 kg−1 and was greater for needles formed under low light. Irrigation or fertilisation had only an indirect effect on SLA by hastening canopy closure.",https://doi.org/10.1016/0378-1127(92)90499-Y,https://www.sciencedirect.com/science/article/pii/037811279290499Y,,,,1992,Dynamics of Pinus radiata foliage in relation to water and nitrogen stress: I. Needle production and properties,R.J. Raison and B.J. Myers and M.L. Benson,article,RAISON1992139,Forest Ecology and Management,1,52,0378-1127,The Biology of Forest Growth Experiment,,
,"KL1, PIM, PIMOS",119-125,,"The paper first briefly describes the KL1 language and its implementation on the Parallel Inference Machine (PIM). KL1 is a successor of Flat GHC and adds features intended for writing efficient, production-quality programs that exploit physical parallelism. KL1 has been used for writing the PIMOS operating system. An implementation of KL1 on the PIM must solve several problems, such as: the representation of KL1's flat global name space on PIM's hierarchical memory; memory management; distributed unification; goals scheduling; and meta-control. The language and its implementation are evaluated and compared with related systems.",https://doi.org/10.1016/0167-739X(93)90004-9,https://www.sciencedirect.com/science/article/pii/0167739X93900049,,,,1993,Evaluation of KL1 and the inference machine,Henri E Bal,article,BAL1993119,Future Generation Computer Systems,2,9,0167-739X,FGCS Conference,,
,"Electric furnace, continuous-type, heat systems, optimization, multiobjective, nonlinear programming, thermal variables, computer-aided design",247-252,,"A thermal designing problem was considered for an electric resistance vacuum furnace of continuous-type used for high temperature sintering processes of new ceramic materials. The objective furnace has 12 small cells, and the static heat balance relations were formulated mathematically at each cells by investigating heat transfer relationships among heater, insulator, dividing board and heated material. Then, the thermal designing problem of the furnace was formulated as a multiobjective nonlinear optimization problem by investigating two objective functions; that is, (a) minimization of the! sum of the insulator's thickness, and (b) minimization of the total heat loss from the furnace. By adopting both the weighting method and the generalized reduced gradient algorithm, the set of Pare to optimal solutions was derived by determining the thickness of the heat insulator at each cell. The numerical results obtained suggest us the benefit to increase the thickness of the insulator at each cell according to the temperature rise of the corresponding heater.",https://doi.org/10.1016/S1474-6670(17)59100-4,https://www.sciencedirect.com/science/article/pii/S1474667017591004,,,,1987,A Multiobjective Optimization Approach to a Thermal Designing Problem of a Continuous-Type Electric Furnace,K. Ito and T. Mukai and H. Yokohata and Y. Sato,article,ITO1987247,IFAC Proceedings Volumes,8,20,1474-6670,"5th IFAC Symposium on Automation and Mining, Mineral and Metal Processing 1986, Tokyo, Japan, 24-29 August, 1986",,
,"assessment, health-related quality of life, patient-reported outcomes, psychometric properties",700-708,,"Objective
This study was aimed to develop a tool for the standardized assessment of patient-reported outcomes (PROs) to assist the choice of instruments.
Methods
An expert panel adapted the eight attributes proposed by the Medical Outcomes Trust as evaluation review criteria, created items to evaluate them, and included a response scale for each item. A pilot test was designed to test the new tool's feasibility and to obtain preliminary information concerning its psychometric properties. The Spanish versions of five measures were selected for assessment: the SF-36 Health Survey, the Nottingham Health Profile, the COOP-WONCA charts, the EuroQol-5D, and the Quality of Life Questionnaire EORTC-QLQ-C30. We assessed the new tool's reliability (Cronbach's alpha and intraclass correlation coefficient [ICC]) and construct validity.
Results
The new EMPRO (Evaluating the Measurement of Patient-Reported Outcomes) tool has 39 items covering eight key attributes: conceptual and measurement model, reliability, validity, responsiveness, interpretability, burden, alternative modes of administration, and cross-cultural and linguistic adaptations. Internal consistency was high (α = 0.95) as was interrater concordance (ICC: 0.87–0.94). Positive associations consistent with a priori hypotheses were observed between EMPRO attribute scores and the number of articles identified for the measures, the years elapsed since the publication of the first article, and the number of citations.
Conclusion
A new tool for the standardized assessment of PRO measures is available. It has shown good preliminary reliability and validity and should be a useful aid to investigators who need to choose between alternative measures. Further assessment of the tool is necessary.",https://doi.org/10.1111/j.1524-4733.2007.00309.x,https://www.sciencedirect.com/science/article/pii/S1098301510605475,,,,2008,Development of EMPRO: A Tool for the Standardized Assessment of Patient-Reported Outcome Measures,Jose M. Valderas and Montse Ferrer and Joan Mendívil and Olatz Garin and Luis Rajmil and Michael Herdman and Jordi Alonso,article,VALDERAS2008700,Value in Health,4,11,1098-3015,,,
,"Internet of Things, IoT attacks, Taxonomy, Vulnerabilities, Detection methods, Challenges",,,"The Internet of Things (IoT) has set the way for the continuing digitalization of society in various manners during the past decade. The IoT is a vast network of intelligent devices exchanging data online. The security component of IoT is crucial given its rapid expansion as a new technology paradigm since it may entail safety-critical procedures and the online storage of sensitive data. Unfortunately, security is the primary challenge when adopting Internet of Things (IoT) technologies. As a result, manufacturers’ and academics’ top priority now is improving the security of IoT devices. A substantial body of literature on the subject encompasses several issues and potential remedies. However, most existing research fails to offer a comprehensive perspective on attacks inside the IoT. Hence, this survey aims to establish a structure to guide researchers by categorizing attacks in the taxonomy according to various factors such as attack domains, attack threat type, attack executions, software surfaces, IoT protocols, attacks based on device property, attacks based on adversary location and attacks based on information damage level. This is followed by a comprehensive analysis of the countermeasures offered in academic literature. In this discourse, the countermeasures proposed for the most significant security attacks in the IoT are investigated. Following this, a comprehensive classification system for the various domains of security research in the IoT and Industrial Internet of Things (IIoT) is developed, accompanied by their respective remedies. In conclusion, the study has revealed several open research areas pertinent to the subject matter.",https://doi.org/10.1016/j.jiixd.2023.12.001,https://www.sciencedirect.com/science/article/pii/S2949715923000793,,,,2023,"A comprehensive survey on IoT attacks: Taxonomy, detection mechanisms and challenges",Tinshu Sasi and Arash Habibi Lashkari and Rongxing Lu and Pulei Xiong and Shahrear Iqbal,article,SASI2023,Journal of Information and Intelligence,,,2949-7159,,,
,,77-88,,"Specimens from the Lower Devonian (possibly Pragian) Posongchong Formation of Wenshan, southeastern Yunnan Province, China, originally described as Zosterophyllum contiguum Li et Cai are reinterpreted and placed in the new combination Demersatheca contigua Li et Edwards, comb. nov. They consist of strobili in which sporangia, inserted decussately, form four vertical rows. The sporangia themselves have two valves, splitting around the convex margin, and are sunk into the strobilar axis such that only the abaxial valves, circular to elliptical in outline, are visible. Their contours are continuous with the surface of the strobilus producing a cylindrical structure. The strobili morphologically most closely resemble those of Zosterophyllum, but more detailed comparison is impossible because of the absence of anatomical information on the Chinese specimens.",https://doi.org/10.1016/0034-6667(95)00120-4,https://www.sciencedirect.com/science/article/pii/0034666795001204,,,,1996,"Demersatheca Li et Edwards, gen. nov., a new genus of early land plants from the Lower Devonian, Yunnan Province, China",Cheng-Sen Li and Dianne Edwards,article,LI199677,Review of Palaeobotany and Palynology,1,93,0034-6667,Maurice Streel,,
,"Anabaena doliolum, different factors, sporulation",123-134,,"Summary
The effect of various physical and chemical factors on spore formation of Anabaena doliolum [AdS strain*)] was investigated under laboratory conditions. Among the three inorganic nitrogen sources, nitrate and nitrite (0.5 mM) were slightly stimulatory to sporulation, however, the specific growth rate was reduced in comparison to N-free grown culture. Ammonium (all concentrations) was inhibitory to growth as well as to sporulation. Dilution of phosphate in the medium was stimulatory whereas dilution of the medium was inhibitory to sporulation. Temporal relationship between spore differentiation, depletion of phosphate from the medium, and development of alkaline phosphatase activity suggest that induction of this enzyme may be considered as one of the important events preceeding sporulation. Metabolic inhibitors like sodium azide, sodium fluoride, and sodium arsenate were stimulatory either in terms of the time required for sporulation or the spore frequency. Growth rate as well as sporulation of A. doliolum was more enhanced at 32 ±2 °C than at 25 ±1 °C. Increasing light intensities (from 500lx to 3,000lx) increased the sporulation frequency with a gradual decrease in the time required for spore initiation. pH 8.0 of the medium was most suitable for sporulation.",https://doi.org/10.1016/S0176-1617(87)80046-9,https://www.sciencedirect.com/science/article/pii/S0176161787800469,,,,1987,Factors Affecting Formation of Spores (Akinetes) in Cyanobacterium Anabaena doliolum (AdS strain),K.D. Pandey and A.K. Kashyap,article,PANDEY1987123,Journal of Plant Physiology,1,127,0176-1617,,,
,,397-431,Configuring Exchange Server 2000,"Publisher Summary
Application Service Providers (ASPs) have an increasing impact on how small- and medium-sized companies handle their messaging infrastructure. An ASP can help companies by outsourcing the implementation, configuration, and maintenance of a variety of services, including messaging. Although companies may derive financial benefits from reduced cost of ownership, they will also reap the benefits of allowing their overutilized staff to concentrate on more important projects than commodity messaging. This chapter explores the basic architecture of hosting Exchange 2000 and then discusses configuring Active Directory and Exchange 2000. ASPs provide access to applications (including the entire infrastructure for supporting that application) to customers who pay for access to the application in the form of a subscription. Customers access the application over the Internet or via a private leased line to the ASP's data center. There are many possibilities beyond messaging to provide services to subscribers. These include real-time conferencing, instant messaging, custom applications, and third-party add-ons. Security considerations for an ASP hosting Exchange 2000 are similar to a corporate implementation that offers messaging capabilities to users from the Internet.",https://doi.org/10.1016/B978-192899425-1/50013-8,https://www.sciencedirect.com/science/article/pii/B9781928994251500138,Burlington,Syngress,978-1-928994-25-1,2001,Chapter 9 - Application Service Providers,,incollection,2001397,,,,,,Liz Mason and William Lefkovics and Melissa Craft and Brian Barber and Neil Hobson and Steve Schwartz and Keith Boesel and William C. Wade,
,,I-IV,,,https://doi.org/10.1016/S0939-3889(15)70536-2,https://www.sciencedirect.com/science/article/pii/S0939388915705362,,,,2002,MITTEILUNGEN DER DEUTSCHEN GESELLSCHAFT FÜR MEDIZINISCHE PHYSIK E.V.,,article,2002I,Zeitschrift für Medizinische Physik,1,12,0939-3889,,,
,"Defense in depth, Exploits, Filtering, Intrusion detection, Malware, Reconnaissance, Vulnerability, Web",149-163,Computer and Information Security Handbook (Third Edition),"The Internet exposes computer users to risks from a wide variety of possible threats, including direct intrusions by exploits or social engineering, malware, and web-based attacks. Perfect network security is generally believed to be infeasible. Instead, a defense-in-depth strategy is to hinder the attacker as much as possible with multiple layers of defense, even though each layer might be surmountable. The combination of multiple layers increases the cost for the attacker to be successful, and the cost is proportional to the value of the protected assets. The cost for the attacker could be in terms of additional time, effort, or equipment. A variety of technological measures are used for layers of protection. Preventive measures aim to reduce the likelihood or potential impact of intrusions by eliminating vulnerabilities or exposure to threats. Prevention includes vulnerability assessments, software patching, system hardening, antivirus software, firewalls, and access controls. However, it is practically impossible to deter or prevent all attacks. Reactive measures are necessary to detect malicious activities and take defensive actions by blocking attacks, isolating valuable resources, or tracing the intruder. Host-based and network-based intrusion detection is an essential reactive measure that operates by a combination of misuse (signature-based) detection and anomaly (behavior-based) detection. The central issue is detection accuracy in terms of false positives and false negatives in the face of evolving, intelligent threats.",https://doi.org/10.1016/B978-0-12-803843-7.00008-9,https://www.sciencedirect.com/science/article/pii/B9780128038437000089,Boston,Morgan Kaufmann,978-0-12-803843-7,2013,Chapter 8 - Guarding Against Network Intrusions,Thomas M. Chen,incollection,CHEN2013149,,,,,,John R. Vacca,Third Edition
,"Weak hydrophilic substances (WHS), Adsorption, Low-energy surface (LES), Contact angle, Surface energy",7959-7967,,"Through the methods such as measurements of contact angle and surface tension, calculations of surface energy and interfacial interaction free energy, and four weak hydrophilic substances (WHS) were taken as research objects, some interesting conclusions were obtained as follow. In aqueous medium, the WHS give priority to adsorb on low-energy surface that is low polar or particularly non-polar. There is a clear corresponding relationship between the free energy and Lewis base component γ− or the hydrophile index of low-energy surface, and the specific relationship is obtained. Finally, we find hydrophobic attractive force of the Lewis acid–base interaction is mainly responsible for the absorption of WHS on low-energy surface. In short, an initial insight into adsorption behavior of WHS on low-energy surface is demonstrated in this paper.",https://doi.org/10.1016/j.apsusc.2011.03.158,https://www.sciencedirect.com/science/article/pii/S016943321100540X,,,,2011,Adsorption behavior of weak hydrophilic substances on low-energy surface in aqueous medium,Wang Hui and Guo Chao and Fu Jiangang and He Zhangxing and Liang Wei and Chen Xiaolei and Zhuang Caihong,article,HUI20117959,Applied Surface Science,18,257,0169-4332,,,
,,86-88,,,https://doi.org/10.1016/j.wpi.2012.09.007,https://www.sciencedirect.com/science/article/pii/S017221901200155X,,,,2013,Our Referees – An Appreciation,Michael Blackman and David Newton,article,BLACKMAN201386,World Patent Information,1,35,0172-2190,,,
,,339-359,,"Various hypotheses that seek to explain the rich species diversity of angiosperms relative to other seed plants are briefly mentioned or reviewed. Of these, the subset that relates angiosperm diversity in some way to the relationship between angiosperms and insects, particularly anthophilous insects, is here the object of attention. Specifically, I address and reject the possibility that the relationship between angiosperm diversification and insects, particularly those demonstrating a preference for flowers with derived floral characteristics associated with insect pollination, may be ruled out because of asynchronous patterns of diversification in the fossil record. New data on floral structure from the Turonian of the Atlantic Coastal Plain reveal a surprising diversity of floral characters in taxa bearing tricolpate and tricolporate-derived pollen. The characters and taxa that appear in these Turonian sediments suggest that rather specific modes of insect pollination, perhaps involving highly derived insect pollinators, already existed at 90 Ma. Given the observed rate of diversification of angiosperms during that time and the pattern of evolution in insects, including what can be inferred about the history of the Apidae, these new floral data suggest that hypotheses relating angiosperm diversity to highly specific pollinators are still valid in the context of fossil evidence. Even so, consistency with fossil evidence is not necessarily proof of these relationships. In any case, there may well be multiple causes of relatively high angiosperm species diversity and understanding the relative importance of each of these requires neontological as well as paleontological investigations. One promising approach is to work within the context of phylogenetic patterns with more fossil data.",https://doi.org/10.1016/0034-6667(95)00091-7,https://www.sciencedirect.com/science/article/pii/0034666795000917,,,,1996,Timing in the evolution of derived floral characters: upper cretaceous (turonian) taxa with tricolpate and tricolpate-derived pollen,William L. Crepet,article,CREPET1996339,Review of Palaeobotany and Palynology,3,90,0034-6667,,,
,,233-235,,,https://doi.org/10.1016/S0378-5122(96)90027-4,https://www.sciencedirect.com/science/article/pii/S0378512296900274,,,,1996,Editors' acknowledgement,,article,1996233,Maturitas,3,25,0378-5122,,,
,"Authentication, confidentiality, cryptography, cyber security, cyber space, encryption, privileges, threat actor, threat vector, vulnerability",33-62,Research Methods for Cyber Security,"This chapter aims to introduce and define cyber space and cyber security, describing what constitutes cyber space and what it means to secure that space. It describes the foundational concepts of cyber security and discusses the philosophy of cyber security science. The chapter provides an overview and discussion on the fundamental concepts of cyber security, introducing the concepts of attackers, such as vulnerability, exploit, threat, malware etc., and then exploring security by design and the principles that it is based upon. Host security, network security, and risk are all considered, along with the many challenges involved in achieving security in cyber space. The chapter also provides an introductory overview of the cyber security research field and some of the many subfields.",https://doi.org/10.1016/B978-0-12-805349-2.00002-9,https://www.sciencedirect.com/science/article/pii/B9780128053492000029,,Syngress,978-0-12-805349-2,2017,Chapter 2 - Science and Cyber Security,Thomas W. Edgar and David O. Manz,incollection,EDGAR201733,,,,,,Thomas W. Edgar and David O. Manz,
,"Tibolone, Soy, Menopause, Monkeys, Lipids, Cardiovascular",216-222,,"Objectives
To determine whether co-administration of soy during tibolone treatment would prevent tibolone-induced dyslipoproteinemia in postmenopausal monkeys and women.
Methods
Surgically postmenopausal cynomolgus monkeys (n=18) were assigned randomly to one of four dietary regimens in a Latin Square crossover design, such that all animals received all diets for 14 weeks with a 4-week washout period: (1) casein/lactalbumin (CL); (2) tibolone (Tib, 1.25mg/day women's equivalent); (3) soy (138mg isoflavones/day women's equivalent); (4) Soy+Tib. Postmenopausal women on tibolone treatment were randomized to receive soy powder (52g of soy protein containing 112mg isoflavones) or placebo (containing 52g of milk protein) daily in a crossover trial for 8 weeks with a 4-week washout period.
Results
Monkeys given Tib alone had ∼14% increase in plasma LDL+VLDL-C; whereas those given soy combined with tibolone had significant (∼22%) reductions. Tib treated monkeys had reductions in plasma HDL-C of about 48% vs. no reductions in Soy+Tib. In postmenopausal women using tibolone, soy reduced plasma LDL-C concentrations by ∼10% from baseline without a change in HDL-C.
Conclusions
Co-administration of soy during tibolone treatment improved the lipoprotein profile in both monkeys and women; however, the effects were more robust in monkeys.",https://doi.org/10.1016/j.maturitas.2008.06.003,https://www.sciencedirect.com/science/article/pii/S0378512208001953,,,,2008,Soy–tibolone combination—Effect on lipids in postmenopausal monkeys and women,Susan E. Appt and Riina Törmälä and Adrian A. Franke and Tomi S. Mikkola and Matti J. Tikkanen and Olavi Ylikorkala and Thomas B. Clarkson,article,APPT2008216,Maturitas,3,60,0378-5122,,,
,,375,,,https://doi.org/10.1016/0165-5728(82)90039-X,https://www.sciencedirect.com/science/article/pii/016557288290039X,,,,1982,"Myasthenia gravis: Major problems in neurology, vol. 11γ by R.P. Lisak and R.L. Barchi (Eds.), 244 pages, W.B. Saunders Comp., Philadelphia, PA, London, 1982. US$ 23.00",J.A. Aarli,article,AARLI1982375,Journal of Neuroimmunology,4,3,0165-5728,,,
,"Fracture healing, Acceleration, Osteoporosis, Mesenchymal stem cells, Growth factors",S90-S99,,"Summary
Osteoporosis is a major health problem characterized by compromised bone strength that predisposes patients to an increased risk of fracture. Osteoporotic patients differ from normal subjects in bone mineral composition, bone mineral content, and crystallinity. Poor bone quality in patients with osteoporosis presents the surgeon with difficult treatment decisions. Much effort has been expended on improving therapies that are expected to preserve bone mass and thus decrease fracture risk. Manipulation of both the local fracture environment in terms of application of growth factors, scaffolds and mesenchymal cells, and systemic administration of agents promoting bone formation and bone strength has been considered as a treatment option from which promising results have recently been reported. Surprisingly, less importance has been given to investigating fracture healing in osteoporosis. Fracture healing is a complex process of bone regeneration, involving a well-orchestrated series of biological events that follow a definable temporal and spatial sequence that may be affected by both biological factors, such as age and osteoporosis, and mechanical factors such as stability of the osteosynthesis. Current studies mainly focus on preventing osteoporotic fractures. In recent years, the literature has provided evidence of altered fracture healing in osteoporotic bone, which may have important implications in evaluating the effects of new osteoporosis treatments on fracture healing. However, the mechanics of this influence of osteoporosis on fracture healing have not yet been clarified and clinical evidence is still lacking.",https://doi.org/10.1016/j.injury.2007.02.014,https://www.sciencedirect.com/science/article/pii/S0020138307000630,,,,2007,Fracture healing in osteoporotic fractures: Is it really different?: A basic science perspective,Peter Giannoudis and Christopher Tzioupis and Talal Almalki and Richard Buckley,article,GIANNOUDIS2007S90,Injury,"1, Supplement ",38,0020-1383,Scientific basis of fracture healing: an update,,
,"Heavy ion, 4 π-geometry technique, computer programs, ‘TRANSCORD’ & ‘HIFISS’, fusion-fission, U, Bi",609-612,,Fusion-Fission of 238U and 209Bi in different SSNTDs has been studied using 4 π-geometry technique. Results indicate that the projectile ions on interaction with the atoms of the detector media form compound nuclei and subsequently scission of the compound nuclei takes place in the forward hemisphere. Intricacies involved in the analysis of such kind of events have been discussed.,https://doi.org/10.1016/0969-8078(93)90139-U,https://www.sciencedirect.com/science/article/pii/096980789390139U,,,,1993,Fusion-fission of 238U and 209Bi in different SSNTDs,Jolly Raju and K.K. Dwivedi,article,RAJU1993609,Nuclear Tracks and Radiation Measurements,1,22,0969-8078,,,
,"Computer-aided design, Computer-aided manufacture, computer software, manufacturing processes, columns",393-397,,"This paper considers the problem of specifying special purpose CAD/CAM systems by presenting a case study which discusses the requirements for software that will be used to aid the design and manufacture of liqhting colmns. whilst many of the details of the programs will be unique to this particular set of problems, much of what is described may have wider applicability particularly, perhaps, for the smaller company or for an organisation with limited knowledge and experience of this technology.",https://doi.org/10.1016/S1474-6670(17)60402-6,https://www.sciencedirect.com/science/article/pii/S1474667017604026,,,,1985,The Specification of a Computer Aided System for the Design and Manufacture of Lighting Columns,P.F. McGoldrick and C. O'Brien and N.A. Rusby and J.B. Lightbody,article,MCGOLDRICK1985393,IFAC Proceedings Volumes,8,18,1474-6670,"3rd IFAC/IFIP Symposium on Computer Aided Design in Control and Engineering Systems: Advanced Tools for Modern Technology, Lyngby, Denmark, 31 July-2 August 1985",,
,,189-196,,"Accumulation of fluoride was determined in the thalli of Xanthoria parietina growing within a 30 km radius of the bedfordshire brickfields. Internal fluoride concentrations ranged from 158 ppm within 3 km of the brickfields to 1 ppm, 22 km distant from the source of emissions. The fluoride content was linked to the prevailing winds in the area. Visible damage to the lichen thalli was observed when internal fluoride concentrations exceeded 68 ppm and internal damage when fluoride concentrations exceeded 90 ppm. This damage was attributed to high fluoride concentrations rather than any other pollutant.",https://doi.org/10.1016/0143-1471(82)90163-5,https://www.sciencedirect.com/science/article/pii/0143147182901635,,,,1982,Accumulation of fluoride by Xanthoria parietina growing in the vicinity of the bedfordshire brickfields,Frances B.M. Davies,article,DAVIES1982189,"Environmental Pollution Series A, Ecological and Biological",3,29,0143-1471,,,
,"In-memory Computing, In-memory Data Grid, Object-oriented Modeling, Online Power Grid Analysis",132-137,,"To address the hard disk and network data I/O bottleneck issue in the large-scale online power grid analysis, an in-memory computing based power grid analysis approach is proposed in this paper. Typical in-memory computing application scenarios in the online power grid analysis are discussed. Using a large-scale online analysis network model as a sample case, in-memory computing simulations corresponding to the scenarios were performed, and the simulation results and analysis of the performance of the simulation are presented.",https://doi.org/10.1016/j.ifacol.2018.11.690,https://www.sciencedirect.com/science/article/pii/S2405896318334098,,,,2018,Application of In-Memory Computing to Online Power Grid Analysis,Mike Zhou and Donghao Feng,article,ZHOU2018132,IFAC-PapersOnLine,28,51,2405-8963,10th IFAC Symposium on Control of Power and Energy Systems CPES 2018,,
,"Manufacturing, Sustainable development, Value Stream Mapping",289-294,,"In production research, sustainability is discussed in various forms and often combined with Value Stream Mapping (VSM), a highly accepted method in practice for improving production systems using lean principles. In scientific literature, most authors present frameworks for scoring production processes (e.g. ratios, benchmarks). These approaches aim to reduce (material) input for producing a specific amount of goods. Hence, improved target-conditions of value streams can be designed to increase ecological efficiency and therefore decrease costs. However, the main aim of this contribution is to present an approach to combine generally accepted parameters and indicators of sustainability and VSM. This approach is based on process-oriented accounting of resource consumption along buffers, transports and processes along value streams. This model of integrating sustainability into VSM goes conform with international accepted guidelines to prevent disposals of input resources by reuse, recycle and recovery. On the one hand, following international guidelines and frameworks, this approach can be used for sustainability reporting; e.g. calculating emitted solvents per produced part, kilogram carbon dioxide equivalents per produced part (with units [kgCDE] or [kgCO2eq]), kilogram disposals per produced part, etc. On the other hand, companies will be able to calculate costs and revenues of sustainable value streams; i.e. to quantify their efforts and benefits monetary. Hence, it is necessary to immerse into material flows in value stream, material consumptions at processes, energy consumption of transports, buffers and processes in value stream, linkage of processes with scrap rates, creation of waste, etc. New data lines in VSM need to be created to represent the parameters and indicators of sustainability. The research findings will be presented by an use case from automotive industry.",https://doi.org/10.1016/j.procir.2015.08.037,https://www.sciencedirect.com/science/article/pii/S2212827115008884,,,,2016,An Approach to Integrate Parameters and Indicators of Sustainability Management into Value Stream Mapping,Thomas Edtmayr and Alexander Sunk and Wilfried Sihn,article,EDTMAYR2016289,Procedia CIRP,,41,2212-8271,Research and Innovation in Manufacturing: Key Enabling Technologies for the Factories of the Future - Proceedings of the 48th CIRP Conference on Manufacturing Systems,,
,,234-242,,"The shape of the spectra of ocean bottom noise and earthquakes recorded in the course of seismological observations in the ocean is analysed. The generalized spectra of bottom seismic noise are suggested as reference curves for comparison with new data. The comparison showed a similarity in the shape and level of the generalized spectra to the noise spectra obtained recently both on the bottom and under the bottom by seismographs placed in holes drilled by the Deep-sea Drilling Project. The spectral analysis of the earthquakes recorded on the bottom of the North-west Pacific basin has shown clear maxima at frequencies of 7–17 Hz formed both by site effects and by absorption of seismic energy in the lithosphere. The frequency of spectral maxima decrease with increasing epicentral distance. Comparison of the earthquake spectra with generalized spectra of bottom noise revealed (probably) incidental coincidence in the frequencies of the minimum for noise spectra (10 Hz) and the average maximum of earthquake record spectra. The sharp mechanical impacts on a bottom seismograph, usually induced by bottom displacements under the instrument, are suggested as rough analogues of the impulses for the bottom instrument system transient calibration. Test measurements have shown that in many cases this method makes it possible to distinguish spectral peaks characterising earthquakes and seismic noise wave trains from those which are caused by coupling resonances of the OBS-sediment interface.",https://doi.org/10.1016/0031-9201(90)90024-R,https://www.sciencedirect.com/science/article/pii/003192019090024R,,,,1990,On the spectra shape of seismic noise and earthquakes recorded in the ocean,A.A. Ostrovsky,article,OSTROVSKY1990234,Physics of the Earth and Planetary Interiors,3,63,0031-9201,,,
,"Google directives, Information gathering, Reconnaissance, Social engineering",19-51,The Basics of Hacking and Penetration Testing (Second Edition),"This chapter reviews the first step in any penetration test. Reconnaissance (also known as information gathering) plays a vital role in the success or failure of the overall PT or hack. Of each of the steps covered in this book, reconnaissance is the least understood and most underutilized by new penetration testers. This phase can be seen as the “preparation” and forerunner to the penetration test itself. This chapter follows a methodology that can be used by new ethical hackers so that they can better understand the process and importance of reconnaissance.",https://doi.org/10.1016/B978-0-12-411644-3.00002-9,https://www.sciencedirect.com/science/article/pii/B9780124116443000029,Boston,Syngress,978-0-12-411644-3,2013,Chapter 2 - Reconnaissance,Patrick Engebretson,incollection,ENGEBRETSON201319,,,,,,Patrick Engebretson,Second Edition
,"network forensics, admissible, authentic, complete, reliable, believable, cyber attacks, traceback, itrace, packet marketing, log-based traceback",313-334,Managing Information Security (Second Edition),"Today’s cyber criminal investigator faces a formidable challenge: tracing network-based cyber criminals. The possibility of becoming a victim of cyber crime is the number-one fear of billions of people. This concern is well founded. The findings in the annual CSI/FBI Computer Crime and Security Surveys confirm that cyber crime is real and continues to be a significant threat. Traceback and attribution are performed during or after cyber violations and attacks, to identify where an attack originated, how it propagated, and what computer(s) and person(s) are responsible and should be held accountable. The goal of network forensics capabilities is to determine the path from a victimized network or system through any intermediate systems and communication pathways, back to the point of attack origination or the person who is accountable. In some cases, the computers launching an attack may themselves be compromised hosts or be controlled remotely. Attribution is the process of determining the identity of the source of a cyber attack. Types of attribution can include both digital identity (computer, user account, IP address, or enabling software) and physical identity (the actual person using the computer from which an attack originated). Cyber crime has become a painful side effect of the innovations of computer and Internet technologies. With the growth of the Internet, cyber attacks and crimes are happening every day and everywhere. It is very important to build the capability to trace and attribute attacks to the real cyber criminals and terrorists, especially in this large-scale human-built networked environment. In this chapter, we discuss the current network forensic techniques in cyber attack traceback. We focus on the current schemes in IP spoofing traceback and stepping-stone attack attribution. Furthermore, we introduce the traceback issues in Voice over IP, Botmaster, and online fraudsters.",https://doi.org/10.1016/B978-0-12-416688-2.00011-8,https://www.sciencedirect.com/science/article/pii/B9780124166882000118,Boston,Syngress,978-0-12-416688-2,2014,Chapter 11 - Network Forensics,Yong Guan,incollection,GUAN2014313,,,,,,John R. Vacca,Second Edition
,,99-113,,"Radium-226 concentrations in water, sediment and Nymphaea violacea (Lehm) root and rhizome samples were strongly correlated over 2 years between three sample sites from Magela Creek, Northern Territory, Australia. The uptake by roots and rhizomes was due primarily to surface accumulation. Radium-226 concentrations in foliage were not correlated with media concentrations. However, foliar tissue senescence was shown to increase radium accumulation across a range of aquatic plant species including N. violacea (P < 0·05). Principal coordinate analysis showed that the distribution of radium and calcium concentrations in the foliar organs of N. violacea were strongly correlated (r = 0·522; P < 0·001). This result supported the hypothesis that radium was accumulated and/or distributed by the mechanisms involved in uptake of the nutrient divalent cation. However, subsequent analyses comparing the ratio of extractable radium and calcium in the supporting media to their ratio in the plant showed no correlation, which suggested that different uptake mechanisms were involved.",https://doi.org/10.1016/0265-931X(89)90009-X,https://www.sciencedirect.com/science/article/pii/0265931X8990009X,,,,1989,"Principal coordinate analysis of the distribution of radium-226 between water, sediment and the waterlily, Nymphaea violacea (Lehm), in the vicinity of a uranium mine in the Northern Territory, Australia",John R. Twining,article,TWINING198999,Journal of Environmental Radioactivity,2,10,0265-931X,,,
,"Combined 17β-estradiol and desogestrel, Common carotid intima-media thickness, Desogestrel, Equine estrogens, Norgestrel",195-204,,"Objectives: To assess the 2-year effects of a combined regimen of oral 17β-estradiol and desogestrel (17βE-D) and a sequential combination of conjugated equine estrogens and norgestrel (CEE-N) on common carotid intima-media thickness and end-diastolic lumen diameter in comparison to placebo in perimenopausal women. Methods: The study was a single center, randomized, group-comparative, double-blind study with respect to the 17βE-D and placebo groups and open with respect to CEE-N. After cycle 6, the blind was broken and the trial was continued as an open trial for another 18 months for the active study arms. The study included 121 perimenopausal women recruited from the general population. Common carotid intima-media thickness and end-diastolic lumen diameter were measured at baseline and cycle 24 with B-mode ultrasonography. Results: At cycle 24 small changes in intima-media thickness and lumen diameter were observed. Relative to placebo, changes in intima-media thickness were −0.009 mm [95% CI −0.045; 0.027] for 17βE-D and −0.016 mm [95% CI −0.055; 0.024] for CEE-N. For end-diastolic lumen diameter the changes were −0.091 mm [95% CI −0.236; 0.055] and −0.125 mm [95% CI −0.820; 0.032] for 17βE-D and CEE-N, respectively. Conclusions: In this study among perimenopausal women a significant effect of 17βE-D and CEE-N on common carotid intima-media thickness and lumen diameter could not be demonstrated. Although the sample size of the present trial is too limited to provide definite conclusions, the direction of the effect is in agreement with evidence from earlier studies on the effects of hormone replacement therapy in postmenopausal women.",https://doi.org/10.1016/S0378-5122(99)00035-3,https://www.sciencedirect.com/science/article/pii/S0378512299000353,,,,1999,Hormone replacement therapy in perimenopausal women and 2-year change of carotid intima-media thickness,Miriam J.J. {de Kleijn} and Michiel L. Bots and Annette A.A. Bak and Iris C.D. Westendorp and Juan Planellas and Herjan J.T. {Coelingh Bennink} and Jacqueline C.M. Witteman and Diederick E. Grobbee,article,DEKLEIJN1999195,Maturitas,3,32,0378-5122,,,
,,73-122,Firewall Policies and VPN Configurations,,https://doi.org/10.1016/B978-159749088-7/50005-0,https://www.sciencedirect.com/science/article/pii/B9781597490887500050,Burlington,Syngress,978-1-59749-088-7,2006,Chapter 3 - Defining a Firewall,,incollection,200673,,,,,,Anne Henmi,
,"Mass storage, Network, Data storage & data access, Processor farms, Physics data processing",12-17,,"Since the HERA experiments H1 and ZEUS started data taking in '92, the computing environment at DESY has changed dramatically. Running a mainframe centred computing for more than 20 years, DESY switched to a heterogeneous, fully distributed computing environment within only about two years in almost every corner where computing has its applications. The computing strategy was highly influenced by the needs of the user community. The collaborations are usually limited by current technology and their ever increasing demands is the driving force for central computing to always move close to the technology edge. While DESY's central computing has a multidecade experience in running Central Data Recording/Central Data Processing for HEP experiments, the most challenging task today is to provide for clear and homogeneous concepts in the desktop area. Given that lowest level commodity hardware draws more and more attention, combined with the financial constraints we are facing already today, we quickly need concepts for integrated support of a versatile device which has the potential to move into basically any computing area in HEP. Though commercial solutions, especially addressing the PC management/support issues, are expected to come to market in the next 2–3 years, we need to provide for suitable solutions now. Buying PC's at DESY currently at a rate of about 30/month will otherwise absorb any available manpower in central computing and still will leave hundreds of unhappy people alone. Though certainly not the only region, the desktop issue is one of the most important one where we need HEP-wide collaboration to a large extent, and right now. Taking into account that there is traditionally no room for R&D at DESY, collaboration, meaning sharing experience and development resources within the HEP community, is a predominant factor for us.",https://doi.org/10.1016/S0010-4655(97)00146-X,https://www.sciencedirect.com/science/article/pii/S001046559700146X,,,,1998,"Computing at DESY — current setup, trends and strategic directions",Michael Ernst,article,ERNST199812,Computer Physics Communications,1,110,0010-4655,,,
,,I-III,,,https://doi.org/10.1016/S0172-2190(16)00016-8,https://www.sciencedirect.com/science/article/pii/S0172219016000168,,,,2016,Our reviewers – An appreciation,Susanne Hantos and Jane List,article,HANTOS2016I,World Patent Information,,44,0172-2190,,,
,,S32-S35,,"There are many examples of organisms which, by new genetic construction or by finding themselves in new habitats, have established large populations. Some have changed ecosystems drastically, some slightly, some apparently scarcely at all as a result. In the light of these natural and unintentional experiments, protocols for the examination of proposals for genetic release can be derived. The risk of damage will be small, but the damage that could be caused is large. Because of the variety and subtlety of ecological interactions, some dangerous organisms will be passed as safe. Methods of control need to be considered at the time of release.",https://doi.org/10.1016/0167-7799(88)90013-3,https://www.sciencedirect.com/science/article/pii/0167779988900133,,,,1988,Potential effects of recombinant DNA organisms on ecosystems and their components,Mark Williamson,article,WILLIAMSON1988S32,Trends in Biotechnology,4,6,0167-7799,,,
,"DNS, DNSSEC, Security, Availability, Internet abuse",100469,,"The Domain Name System (DNS) plays a crucial role in connecting services and users on the Internet. Since its first specification, DNS has been extended in numerous documents to keep it fit for today’s challenges and demands. And these challenges are many. Revelations of snooping on DNS traffic led to changes to guarantee confidentiality of DNS queries. Attacks to forge DNS traffic led to changes to shore up the integrity of the DNS. Finally, denial-of-service attack on DNS operations have led to new DNS operations architectures. All of these developments make DNS a highly interesting, but also highly challenging research topic. This tutorial – aimed at graduate students and early-career researchers – provides a overview of the modern DNS, its ongoing development and its open challenges. This tutorial has four major contributions. We first provide a comprehensive overview of the DNS protocol. Then, we explain how DNS is deployed in practice. This lays the foundation for the third contribution: a review of the biggest challenges the modern DNS faces today and how they can be addressed. These challenges are (i) protecting the confidentiality and (ii) guaranteeing the integrity of the information provided in the DNS, (iii) ensuring the availability of the DNS infrastructure, and (iv) detecting and preventing attacks that make use of the DNS. Last, we discuss which challenges remain open, pointing the reader towards new research areas.",https://doi.org/10.1016/j.cosrev.2022.100469,https://www.sciencedirect.com/science/article/pii/S1574013722000132,,,,2022,Addressing the challenges of modern DNS a comprehensive tutorial,Olivier {van der Toorn} and Moritz Müller and Sara Dickinson and Cristian Hesselman and Anna Sperotto and Roland {van Rijswijk-Deij},article,VANDERTOORN2022100469,Computer Science Review,,45,1574-0137,,,
,,235-248,,,https://doi.org/10.1016/0014-2999(95)90016-0,https://www.sciencedirect.com/science/article/pii/0014299995900160,,,,1995,Acknowledgement to reviewers,,article,1995235,European Journal of Pharmacology,1,274,0014-2999,,,
,,223-236,,"The transplasmalemmal electrical gradient recorded in laticiferous cells at steady state was −113 ± 21 mV. Sucrose and glucose depolarize the plasmalemma of laticiferous cells by about 15 to 25 mV. Our results show that with depolarization due to sucrose (1 mM) or glucose (1 mM) a slight alkalinization (0.1 to 0.2 pH units) can be detected on the outer surface of the cell. Fructose and 3-O-methyl-glucose have no such effect. The extent of depolarization due to the addition of sugars is lower than the electrogenic component of the membrane potential produced by the functioning of the H+-excretion pump (vanadate sensitive-ATPase). Furthermore, in the presence of vanadate or DNP, with glucose or sucrose no shift in pH value was observed. The effect of phlorizin has been tested on the shift of the membrane potential due to sugar uptake across the plasmalemma: neither sucrose nor glucose demonstrate any further depolarization and alkalinization in the presence of phlorizin. Stimulation of the H+-pump by ethylene hyperpolarizes cells by approximately −40 mV and increases the extent of the depolarization induced by sugar transport. These results suggest an active transport of the sugars from the apoplasm towards the cytosol. Evidence for the existence of H+ cotransport with sucrose and/or glucose at the plasmalemma is discussed hereafter.",https://doi.org/10.1016/0022-0728(91)85598-J,https://www.sciencedirect.com/science/article/pii/002207289185598J,,,,1991,Electrogenic active proton pump in Hevea brasiliensis laticiferous cells: Its role in activating sucrose/H+ and glucose/H+ symports at the plasma membrane,F. Bouteau and R. Lacrotte and D. Cornel and M. Monestiez and U. Bousquet and A.M. Pennarun and J.P. Rona,article,BOUTEAU1991223,Journal of Electroanalytical Chemistry and Interfacial Electrochemistry,2,321,0022-0728,,,
,"Hormone replacement therapy, Lipids, Menopause, Randomized controlled trial",209-216,,"Objective: To determine the effects of oral sequential hormone replacement therapy (HRT) on lipid-profile in perimenopausal and early postmenopausal women. Methods: We performed a single-center, randomized, placebo-controlled trial. The trial was double blind with respect to 17β-estradiol/desogestrel (17β-E-D) and placebo and open with respect to conjugated estrogens/norgestrel (CEE-N). A total of 125 healthy perimenopausal and early postmenopausal women, aged 43–58 years, were recruited from the general population in Zoetermeer, the Netherlands. The intervention consisted of 6 months treatment with 1.5 mg 17β-estradiol/0.15 mg desogestrel (n=53), 0.625 mg conjugated estrogens/0.15 mg norgestrel (n=36) or placebo (n=36). At baseline, cycle 1, 3 and 6, overnight fasting blood samples were obtained in which lipids were determined. We used linear regression analysis to calculate differences in mean change from baseline in lipids in the active treatment groups compared to placebo. Results: In both treatment groups significant (P<0.05) falls in low-density-lipoprotein (LDL)-cholesterol (17β-E-D: −7.8% and CEE-N: −8.4%) and lipoprotein(a) (17β-E-D: −11.7% and CEE-N: −28.3%) were found compared to placebo. Apolipoprotein A1 (17β-E-D: 6.8% and CEE-N: 7.3%) and HDL-cholesterol (17β-E-D: 6.4% and CEE-N: 8.0%) significantly increased compared to placebo. No significant changes were found in the other lipids. Mean changes from baseline in total cholesterol, LDL-cholesterol and apolipoprotein B were significantly more pronounced in postmenopausal women compared to perimenopausal women, adjustment for age-differences did not change the results. Conclusion: Treatment of perimenopausal and early postmenopausal women with 17β-E-D or CEE-N changes their lipid-profile in a potentially anti-atherogenic direction. Changes appear to be more pronounced in postmenopausal women compared to perimenopausal women.",https://doi.org/10.1016/S0378-5122(01)00224-9,https://www.sciencedirect.com/science/article/pii/S0378512201002249,,,,2001,Effect of hormone replacement therapy on lipids in perimenopausal and early postmenopausal women,Marlies E Ossewaarde and Michiel L Bots and Annette A.A Bak and Yvonne T {Van Der Schouw} and Jacqueline C.M Witteman and Juan Planellas and Herjan J.T.Coelingh Bennink and Diederick E Grobbee,article,OSSEWAARDE2001209,Maturitas,3,39,0378-5122,,,
,"Artifact lifecycle models, Patch lifecycles, Software development artifacts, Knowledge discovery, Decision-making",73-84,The Art and Science of Analyzing Software Data,"When software practitioners make day-to-day design decisions about their projects, they are guided by not only their intuition and experience, but also by the variety of software artifacts that are available to them. This chapter describes how lifecycle models can be used to build a useful and intuitive model of these development artifacts. Lifecycle models capture the dynamic nature of how such artifacts change over time in a graphical form that can be easily understood and communicated. We show how lifecycle models can be generated, and we present two industrial case studies where we applied lifecycle models to assess a project’s code review process.",https://doi.org/10.1016/B978-0-12-411519-4.00004-5,https://www.sciencedirect.com/science/article/pii/B9780124115194000045,Boston,Morgan Kaufmann,978-0-12-411519-4,2015,Chapter 4 - Synthesizing Knowledge from Software Development Artifacts,Olga Baysal and Oleksii Kononenko and Reid Holmes and Michael W. Godfrey,incollection,BAYSAL201573,,,,,,Christian Bird and Tim Menzies and Thomas Zimmermann,
,", Pinaceae, foliar flavonoids, infraspecific variation, chemotypes, genetic and ecological differentiation",659-664,,"A total of 120 individual trees representative of Pinus uncinata were analysed for their foliar flavonoid content. The ratio of two extracted anthocyanidins, prodelphinidin and procyanidin, is a constant. Among the flavonols quercetin, kaempfrerol and isorhamnetin, the percentage of quercetin discriminates the five studied populations. Its distribution conforms to the Hardy-Weinberg law, but the ratio of the two implicit alleles proves the originality of each population, and leads to the recognition of distinct chemotypes.",https://doi.org/10.1016/0305-1978(91)90082-B,https://www.sciencedirect.com/science/article/pii/030519789190082B,,,,1991,Flavonoid variability within and between natural populations of Pinus uncinata,Josiane Lauranson and Philippe Lebreton,article,LAURANSON1991659,Biochemical Systematics and Ecology,8,19,0305-1978,,,
,"Text mining, Natural language processing, Information extraction, Text complexity measures, Business analytics, Accounting",100456,,"Text mining on a large corpus of data has gained utility and popularity over recent years owing to advancements in information retrieval and machine learning methods. However, popular text mining software packages mainly focus on either sentiment analysis or semantic meaning extraction, requiring pretraining on a large corpus of text data. In comparison, MoreThanSentiments provides computation of newer text attribution measures, including boiler score, specificity, redundancy, and hard info, which have been proposed in accounting analytics literature. Our software package, available in Python, is flexible in terms of parameter setting and is adaptable to different applications. Through this package, we seek to simplify the process of deploying nontrivial information extraction techniques published in domain-specific text analysis research into domain-agnostic analytics applications.",https://doi.org/10.1016/j.simpa.2022.100456,https://www.sciencedirect.com/science/article/pii/S2665963822001403,,,,2023,MoreThanSentiments: A text analysis package,Jinhang Jiang and Karthik Srinivasan,article,JIANG2023100456,Software Impacts,,15,2665-9638,,,
,"e‐cigarette, vaping, nicotine, Australia, attitudes, regulation, policy",543-545,,"Objective
In June 2020, the Australian Government announced that personal importation of nicotine vaping products (NVP) would be prohibited, pending a 12‐month classification and regulation review by the Therapeutic Goods Administration. This brief report examines the themes of responses on Twitter to this announcement.
Methods
Simple random sampling was used to retrieve tweets containing keywords from 19 to 26 June 2020. Tweets were manually coded and descriptive statistics calculated for themes and policy position.
Results
The vast majority of the 1,168 tweets were anti‐policy. Themes included: criticism towards government (59.8%), activism against NVP restriction (38%), potential adverse consequences (30.8%) and support for NVP restriction (1.4%). Tweets that identified potential adverse consequences of NVP restriction cited: smoking relapse for individuals currently using NVPs (75.6%); the impact of policy enforcement (8.6%); illicit market (8.3%); panic buying (3.6%); difficulty obtaining prescriptions (2.8%); and impacts on NVP businesses (2.8%).
Conclusion
Tweets predominately objected to the policy announcement. Approximately three‐quarters of tweets that cited potential adverse consequences of the policy mentioned smoking relapse as their primary concern.
Implications for public health
User‐generated content on Twitter was primarily used to lobby against the proposed policy, which was subsequently amended.",https://doi.org/10.1111/1753-6405.13143,https://www.sciencedirect.com/science/article/pii/S1326020023003710,,,,2021,Reactions on Twitter towards Australia's proposed import restriction on nicotine vaping products: a thematic analysis,Tianze Sun and Carmen C.W. Lim and Coral Gartner and Jason P. Connor and Wayne D. Hall and Janni Leung and Daniel Stjepanović and Gary C.K. Chan,article,SUN2021543,Australian and New Zealand Journal of Public Health,6,45,1326-0200,,,
,"Hate speech, Text classification, Multiple classifiers system, Natural language processing, Machine learning",100194,,"Hate speech is a major issue in social networks due to the high volume of data generated daily. Recent works demonstrate the usefulness of machine learning (ML) in dealing with the nuances required to distinguish between hateful posts from just sarcasm or offensive language. Many ML solutions for hate speech detection have been proposed by either changing how features are extracted from the text or the classification algorithm employed. However, most works consider only one type of feature extraction and classification algorithm. This work argues that a combination of multiple feature extraction techniques and different classification models is needed. We propose a framework to analyze the relationship between multiple feature extraction and classification techniques to understand how they complement each other. The framework is used to select a subset of complementary techniques to compose a robust multiple classifiers system (MCS) for hate speech detection. The experimental study considering four hate speech classification datasets demonstrates that the proposed framework is a promising methodology for analyzing and designing high-performing MCS for this task. MCS system obtained using the proposed framework significantly outperforms the combination of all models and the homogeneous and heterogeneous selection heuristics, demonstrating the importance of having a proper selection scheme. Source code, figures and dataset splits can be found in the GitHub repository: https://github.com/Menelau/Hate-Speech-MCS.",https://doi.org/10.1016/j.osnem.2021.100194,https://www.sciencedirect.com/science/article/pii/S2468696421000719,,,,2022,Selecting and combining complementary feature representations and classifiers for hate speech detection,Rafael M.O. Cruz and Woshington V. {de Sousa} and George D.C. Cavalcanti,article,CRUZ2022100194,Online Social Networks and Media,,28,2468-6964,,,
,"Modern code review, Bad practices, Conformance checking, Code review smell, Process smell, Process debt",106737,,"Context:
Code review is a crucial step of the software development life cycle in order to detect possible problems in source code before merging the changeset to the codebase. Although there is no consensus on a formally defined life cycle of the code review process, many companies and open source software (OSS) communities converge on common rules and best practices. In spite of minor differences in different platforms, the primary purpose of all these rules and practices leads to a faster and more effective code review process. Non-conformance of developers to this process does not only reduce the advantages of the code review but can also introduce waste in later stages of the software development.
Objectives:
The aim of this study is to provide an empirical understanding of the bad practices followed in the code review process, that are code review (CR) smells.
Methods:
We first conduct a multivocal literature review in order to gather code review bad practices discussed in white and gray literature. Then, we conduct a targeted survey with 32 experienced software practitioners and perform follow-up interviews in order to get their expert opinion. Based on this process, a taxonomy of code review smells is introduced. To quantitatively demonstrate the existence of these smells, we analyze 226,292 code reviews collected from eight OSS projects.
Results:
We observe that a considerable number of code review smells exist in all projects with varying degrees of ratios. The empirical results illustrate that 72.2% of the code reviews among eight projects are affected by at least one code review smell.
Conclusion:
The empirical analysis shows that the OSS projects are substantially affected by the code review smells. The provided taxonomy could provide a foundation for best practices and tool support to detect and avoid code review smells in practice.",https://doi.org/10.1016/j.infsof.2021.106737,https://www.sciencedirect.com/science/article/pii/S0950584921001877,,,,2022,Towards a taxonomy of code review smells,Emre Doğan and Eray Tüzün,article,DOGAN2022106737,Information and Software Technology,,142,0950-5849,,,
,"Software architecture, Robotics, ROS",110969,,"Context:
The Robot Operating System (ROS) is the de-facto standard for robotics software. However, ROS-based systems are getting larger and more complex and could benefit from good software architecture practices.
Goal:
We aim at (i) unveiling the state-of-the-practice in terms of targeted quality attributes and architecture documentation in ROS-based systems, and (ii) providing empirically-grounded guidance to roboticists about how to properly architect ROS-based systems.
Methods:
We designed and conducted an observational study where we (i) built a dataset of 335 GitHub repositories containing real open-source ROS-based systems, and (ii) mined the repositories to extract and synthesize quantitative and qualitative findings about how roboticists are architecting ROS-based systems.
Results:
First, we extracted an empirically-grounded overview of the state of the practice for architecting and documenting ROS-based systems. Second, we synthesized a catalog of 47 architecting guidelines for ROS-based systems. Third, the extracted guidelines were validated by 119 roboticists working on real-world open-source ROS-based systems.
Conclusion:
Roboticists can use our architecting guidelines for applying good design principles to develop robots that meet quality requirements, and researchers can use our results as evidence-based indications about how real-world ROS systems are architected today, thus inspiring future research contributions.",https://doi.org/10.1016/j.jss.2021.110969,https://www.sciencedirect.com/science/article/pii/S0164121221000662,,,,2021,Mining guidelines for architecting robotics software,Ivano Malavolta and Grace A. Lewis and Bradley Schmerl and Patricia Lago and David Garlan,article,MALAVOLTA2021110969,Journal of Systems and Software,,178,0164-1212,,,
,"Android malware, Hook, MaaS, RAT, Accessibility permission",301769,,"This publication presents a thorough forensic investigation of the banking malware known as Hook, shedding light on its intricate functionalities and providing valuable insights into the broader realm of banking malware. Given the persistent evolution of Android malware, particularly in the context of banking threats, this research explores the ongoing development of these malicious entities. In particular, it emphasizes the prevalent “malware as a service” (MaaS) model, which engenders a competitive environment where malware developers continually strive to enhance their capabilities. Consequently, this investigation serves as a vital benchmark for evaluating the current state of banking MaaS capabilities in July 2023, enabling researchers and practitioners to gauge the advancements and trends within the field.",https://doi.org/10.1016/j.fsidi.2024.301769,https://www.sciencedirect.com/science/article/pii/S266628172400088X,,,,2024,Forensic analysis of hook Android malware,Dominic Schmutz and Robin Rapp and Benjamin Fehrensen,article,SCHMUTZ2024301769,Forensic Science International: Digital Investigation,,49,2666-2817,,,
,"Internet of Things, Software-defined networks, Distributed denial of service, Network security",100543,,"The Internet of Things (IoT) has transformed our lives by introducing new services and enhancing productivity. However, the widespread adoption of IoT devices and communication units has posed challenges in network management. In response, there is a growing necessity to rethink and redesign IoT network control. Software-defined networking (SDN) has emerged as a promising solution, leveraging its programmability and centralized management capabilities. SDN can simplify network management, offer network abstraction, facilitate development, and efficiently handle the complexities of IoT networks. Despite these advantages, security concerns, particularly the threat of Distributed Denial of Service (DDoS) attacks, persist in the IoT landscape. This survey focuses on exploring the collaboration between SDN and IoT. It investigates various types of DDoS attacks and highlights different types of defense, detection, and mitigation methods employed to address DDoS threats in SDN-based IoT (SDN-IoT) networks.",https://doi.org/10.1016/j.prime.2024.100543,https://www.sciencedirect.com/science/article/pii/S2772671124001256,,,,2024,A comprehensive survey on DDoS attacks detection & mitigation in SDN-IoT network,Chandrapal Singh and Ankit Kumar Jain,article,SINGH2024100543,"e-Prime - Advances in Electrical Engineering, Electronics and Energy",,8,2772-6711,,,
,"Collaborative knowledge engineering, Knowledge graph, Discussion analysis, Wikidata",100799,,"We study discussions in Wikidata, the world’s largest open-source collaborative knowledge graph (KG). This is important because it helps KG community managers understand how discussions are used and inform the design of collaborative practices and support tools. We follow a mixed-methods approach with descriptive statistics, thematic analysis, and statistical tests to investigate how much discussions in Wikidata are used, what they are used for, and how they support knowledge engineering (KE) activities. The study covers three core sources of discussion, the talk pages that accompany Wikidata items and properties, and a general-purpose communication page. Our findings show low use of discussion capabilities and a power-law distribution similar to other KE projects such as Schema.org. When discussions are used, they are mostly about KE activities, including activities that span across the entire KE lifecycle from conceptualisation and implementation to maintenance and taxonomy building. We hope that the findings will help Wikidata devise improved practices and capabilities to encourage the use of discussions as a tool to collaborate, improve editor engagement, and engineer better KGs.",https://doi.org/10.1016/j.websem.2023.100799,https://www.sciencedirect.com/science/article/pii/S1570826823000288,,,,2023,An analysis of discussions in collaborative knowledge engineering through the lens of Wikidata,Elisavet Koutsiana and Gabriel Maia Rocha Amaral and Neal Reeves and Albert Meroño-Peñuela and Elena Simperl,article,KOUTSIANA2023100799,Journal of Web Semantics,,78,1570-8268,,,
,"Meta-Collaborative Workstations, Smart Manufacturing, Human-Machine Interaction, Industry 4.0, Deep Learning",102085,,"This paper presents the Meta-Collaborative Workstation concept and a gesture-based robot program builder software named MEGURU. The software is ROS-based, and it is publicly available on GitHub. A hand-gestures language has been developed to create a fast and easy to use communication method, where single-hand gestures are combined to create composed Commands, allowing the user to create a customized, powerful, and flexible Gestures Dictionary. Gestures are recognized using an R-FCN Object Detector model fine-tuned on a custom dataset developed for this work. The system has been tested in two experiments. The first one was aimed at evaluating the user experience of people of different age, sex, and professional background concerning the proposed communication method. The second one was aimed at comparing the traditional teach pendant programming method and MEGURU in the task of assembling a small Moka coffee maker. The results of both experiments highlight that MEGURU is a promising robot programming method, especially for non-expert users.",https://doi.org/10.1016/j.rcim.2020.102085,https://www.sciencedirect.com/science/article/pii/S0736584520302957,,,,2021,MEGURU: a gesture-based robot program builder for Meta-Collaborative workstations,Cristina Nuzzi and Simone Pasinetti and Roberto Pagani and Stefano Ghidini and Manuel Beschi and Gabriele Coffetti and Giovanna Sansoni,article,NUZZI2021102085,Robotics and Computer-Integrated Manufacturing,,68,0736-5845,,,
,"IoT security, Evolution of IoT malware, IoT botnet, VPNFilter, IoTReaper, Hide’n Seek, Echobot",102143,,"The past decade has seen a rapidly growing interest in IoT-connected devices. But as is usually the case with computer systems and networks, malicious individuals soon realized that these objects could be exploited for criminal purposes. The problem is particularly salient since the firmware used in many Internet connected devices was developed without taking into consideration the expertise and best security practices gained over the past several years by programmers in other areas. Consequently, multiple attacks on IoT devices took place over the last decade, culminating in the largest ever recorded DDoS attack, the Mirai botnet, which took advantage of weaknesses in the security of the IoT. In this survey, we seek to shed light on the evolution of the IoT malware. We compare the characteristic features of 28 of the most widespread IoT malware programs of the last decade and propose a novel methodology for classifying malware based on its behavioral features. Our study also highlights the common practice of feature reuse across multiple malware programs.",https://doi.org/10.1016/j.sysarc.2021.102143,https://www.sciencedirect.com/science/article/pii/S1383762121001053,,,,2021,"The evolution of IoT Malwares, from 2008 to 2019: Survey, taxonomy, process simulator and perspectives",Benjamin Vignau and Raphaël Khoury and Sylvain Hallé and Abdelwahab Hamou-Lhadj,article,VIGNAU2021102143,Journal of Systems Architecture,,116,1383-7621,,,
,"Responsible software engineering, Infrastructure, Social connection model of responsibility, Installed base, Deepfake technology",100087,,"In recent years, we have seen many examples of software products unintentionally causing demonstrable harm. Many guidelines for ethical and responsible computing have been developed in response. Dominant approaches typically attribute liability and blame to individual companies or actors, rather than understanding how the working practices, norms, and cultural understandings in the software industry contribute to such outcomes. In this paper, we propose an understanding of responsibility that is infrastructural, relational, and cultural; thus, providing a foundation to better enable responsible software engineering into the future. Our approach draws on Young's (2006) social connection model of responsibility and Star and Ruhleder's (1994) concept of infrastructure. By bringing these theories together we introduce a concept called infrastructural injustice, which offers a new way for software engineers to consider their opportunities for responsible action with respect to society and the planet. We illustrate the utility of this approach by applying it to an Open-Source software communities’ development of Deepfake technology, to find key leverage points of responsibility that are relevant to both Deepfake technology and software engineering more broadly.",https://doi.org/10.1016/j.jrt.2024.100087,https://www.sciencedirect.com/science/article/pii/S2666659624000131,,,,2024,"Infrastructural justice for responsible software engineering,",Sarah Robinson and Jim Buckley and Luigina Ciolfi and Conor Linehan and Clare McInerney and Bashar Nuseibeh and John Twomey and Irum Rauf and John McCarthy,article,ROBINSON2024100087,Journal of Responsible Technology,,19,2666-6596,,,
,"CAPTCHA, Bot detection, Behavior, Biometrics, Mouse, Neuromotor",108643,,"We first study the suitability of behavioral biometrics to distinguish between computers and humans, commonly named as bot detection. We then present BeCAPTCHA-Mouse, a bot detector based on: i) a neuromotor model of mouse dynamics to obtain a novel feature set for the classification of human and bot samples; and ii) a learning framework involving real and synthetically generated mouse trajectories. We propose two new mouse trajectory synthesis methods for generating realistic data: a) a function-based method based on heuristic functions, and b) a data-driven method based on Generative Adversarial Networks (GANs) in which a Generator synthesizes human-like trajectories from a Gaussian noise input. Experiments are conducted on a new testbed also introduced here and available in GitHub: BeCAPTCHA-Mouse Benchmark; useful for research in bot detection and other mouse-based HCI applications. Our benchmark data consists of 15,000 mouse trajectories including real data from 58 users and bot data with various levels of realism. Our experiments show that BeCAPTCHA-Mouse is able to detect bot trajectories of high realism with 93% of accuracy in average using only one mouse trajectory. When our approach is fused with state-of-the-art mouse dynamic features, the bot detection accuracy increases relatively by more than 36%, proving that mouse-based bot detection is a fast, easy, and reliable tool to complement traditional CAPTCHA systems.",https://doi.org/10.1016/j.patcog.2022.108643,https://www.sciencedirect.com/science/article/pii/S0031320322001248,,,,2022,BeCAPTCHA-Mouse: Synthetic mouse trajectories and improved bot detection,Alejandro Acien and Aythami Morales and Julian Fierrez and Ruben Vera-Rodriguez,article,ACIEN2022108643,Pattern Recognition,,127,0031-3203,,,
,"Image Recognition, SME, Object Detection, Synthetic Training Data, Chroma Keying, Low-Effort",434-439,,"Training datasets for image recognition are poorly available for small and medium-sized manufacturing companies, due to the specialized products they work with, and the disproportionate investment to generate their own ones. Thus, we investigate a new approach: The Image-Bot consists of a physical apparatus and a processing pipeline to generate training datasets from real-world objects easily. It takes pictures of the objects in front of a green screen and blends them with random backgrounds. The approach was tested with 23 objects and a YOLOv5 algorithm. It creates a state-of-the-art training dataset with about 2,000 images per object in under 45 min.",https://doi.org/10.1016/j.procir.2022.05.004,https://www.sciencedirect.com/science/article/pii/S2212827122002876,,,,2022,Image-Bot: Generating Synthetic Object Detection Datasets for Small and Medium-Sized Manufacturing Companies,Lukas Block and Adrian Raiser and Lena Schön and Franziska Braun and Oliver Riedel,article,BLOCK2022434,Procedia CIRP,,107,2212-8271,Leading manufacturing systems transformation – Proceedings of the 55th CIRP Conference on Manufacturing Systems 2022,,
,"Intrusion detection, Internet of Things, Graph neural networks, Artificial intelligence",110966,,"With recent advances in the Internet of Things (IoT) technology, more people can have instant and easy access to the IoT network of vast and diverse interconnected devices (e.g., surveillance cameras, motion sensors, or smart watches). This trend leads to a significant increase in the frequency and complexity of cyber attacks in the IoT network. Further, these attacks inflict severe financial and privacy damages to individuals and evince the need to develop a more effective and robust network intrusion detection system (NIDS). Network Intrusion Detection (NID) aims to identify the attacks in the networked devices, which is an essential task to protect and maintain Cyber Security. Although recent Machine Learning-based methods have developed and provided more efficient non-human intervention solutions to this problem, these methods still have some unsolved issues. One of the main limitations of existing solutions is that most focus on extracting the features at the flow level independently and ignore their interactions in the network, which impacts the detection performance. To address this problem, in this paper, we propose a Traffic-aware Self-supervised learning for IoT Network Intrusion Detection System, namely TS-IDS, which aims to capture the flow relationships between the network entities. Our approach leverages both node and edge features for improved performance. Additionally, we incorporate auxiliary property-based self-supervised learning (SSL) to enhance the graph representation, even in the absence of labelled data. We conducted experiments on two real-world datasets, NF-ToN-IoT and NF-BoT-IoT. We compared the proposed model with state-of-the-art baseline models to demonstrate the potential of our proposed framework.",https://doi.org/10.1016/j.knosys.2023.110966,https://www.sciencedirect.com/science/article/pii/S0950705123007165,,,,2023,TS-IDS: Traffic-aware self-supervised learning for IoT Network Intrusion Detection,Hoang Nguyen and Rasha Kashef,article,NGUYEN2023110966,Knowledge-Based Systems,,279,0950-7051,,,
,"Software testing, Blockchain, Smart contracts",110647,,"Smart contracts are a new type of software that allows its users to perform irreversible transactions on a distributed persistent data storage called the blockchain. The nature of such contracts and the technical details of the blockchain architecture give raise to new kinds of faults, which require specific test behaviours to be exposed. In this paper we present SoCRATES, a generic and extensible framework to test smart contracts running in a blockchain. The key properties of SoCRATES are: (1) it comprises bots that interact with the blockchain according to a set of composable behaviours; (2) it can instantiate a society of bots, which can trigger faults due to multi-user interactions that are impossible to expose with a single bot. Our experimental results show that SoCRATES can expose known faults and detect previously unknown faults in contracts currently published in the Ethereum blockchain. They also show that a society of bots is often more effective than a single bot in fault exposure.",https://doi.org/10.1016/j.jss.2020.110647,https://www.sciencedirect.com/science/article/pii/S0164121220301163,,,,2020,A federated society of bots for smart contract testing,Emanuele Viglianisi and Mariano Ceccato and Paolo Tonella,article,VIGLIANISI2020110647,Journal of Systems and Software,,168,0164-1212,,,
,"Distributed social coding, Developer social network, Github, Github social influence analysis, User influence, Following-Star-Fork-Activity",108-118,,"Github, one of the largest social coding platforms, offers software developers the opportunity to engage in social activities relating to software development and to store or share their codes/projects with the wider community using the repositories. Analysis of data representing the social interactions of Github users can reveal a number of interesting features. In this paper, we analyze the data to understand user social influence on the platform. Specifically, we propose a Following-Star-Fork-Activity based approach to measure user influence in the Github developer social network. We first preprocess the Github data, and construct the social network. Then, we analyze user influence in the social network, in terms of popularity, centrality, content value, contribution and activity. Finally, we analyze the correlation of different user influence measures, and use Borda Count to comprehensively quantify user influence and verify the results.",https://doi.org/10.1016/j.eswa.2018.05.002,https://www.sciencedirect.com/science/article/pii/S0957417418302793,,,,2018,User influence analysis for Github developer social networks,Yan Hu and Shanshan Wang and Yizhi Ren and Kim-Kwang Raymond Choo,article,HU2018108,Expert Systems with Applications,,108,0957-4174,,,
,"Conversational agents, Chatbots, Personal assistants, Conversational AI, Natural Language Processing",8852-8866,,"Conversational AI intends for machine-human interactions to appear and feel more natural and inclined to communicate in a near-human context. Chatbots, also known as conversational agents, are typically divided into two use-cases: task-oriented bots and social friend-bots. Task-oriented bots are often used to do activities such as answering questions or solving basic queries. Furthermore, social-friend-bots are designed to communicate like humans, where the user can speak freely and the bot answers organically while maintaining the conversation’s ambience. This paper analyses recent works in the conversational AI domain examining the exclusive methodologies, existing frameworks or tools, evaluation metrics, and available datasets for building robust conversational agents. Finally, a mind-map encompassing all the stated elements and qualities of chatbots is created.",https://doi.org/10.1016/j.jksuci.2021.10.013,https://www.sciencedirect.com/science/article/pii/S1319157821003001,,,,2022,A survey on near-human conversational agents,Satwinder Singh and Himanshu Beniwal,article,SINGH20228852,Journal of King Saud University - Computer and Information Sciences,"10, Part A",34,1319-1578,,,
,"Bot, Botnet traffic, Network analysis, Feature analysis, Network-based detection",1-15,,"Botnet use is on the rise, with a growing number of botmasters now switching to the HTTP-based C&C infrastructure. This offers them more stealth by allowing them to blend in with benign web traffic. Several works have been carried out aimed at characterising or detecting HTTP-based bots, many of which use network communication features as identifiers of botnet behaviour. In this paper, we present a survey of these approaches and the network features they use in order to highlight how botnet traffic is currently differentiated from normal traffic. We classify papers by traffic types, and provide a breakdown of features by protocol. In doing so, we hope to highlight the relationships between features at the application, transport and network layers.",https://doi.org/10.1016/j.jnca.2016.10.007,https://www.sciencedirect.com/science/article/pii/S1084804516302363,,,,2016,Survey of approaches and features for the identification of HTTP-based botnet traffic,Dilara Acarali and Muttukrishnan Rajarajan and Nikos Komninos and Ian Herwono,article,ACARALI20161,Journal of Network and Computer Applications,,76,1084-8045,,,
,"Data science applications in education, Architectures for educational technology system, Teaching/learning strategies",100042,,"The tech sector has been growing at a rapid speed, demanding a higher level of expertise from its labor force. New skills and programming languages are introduced and required by the industry every day, while the university courses are not updated adequately. Finding the high-demand skills and relevant courses to study has become essential to both students and faculty members at tech universities, which leads to a growing research interest in building an intelligence system to support decision making. Leveraging recent development in Natural Language Processing, we built an NLP-based course recommendation system specifically for the computer science (CS) and information technology (IT) fields. In particular, we built (1) a Named Entity Recognition (CSIT-NER) model to extract tech-related skills and entities, then used these skills to build (2) a personalized multi-level course recommendation system using a hybrid model (hybrid CSIT-CRS). Our CSIT-NER model, trained and fine-tuned on a large corpus of text extracted from StackOverflow and GitHub, can accurately extract the relevant skills and entities, outperforming state-of-the-art models across all evaluation metrics. Our hybrid CSIT-CRS can provide recommendations on multiple individualized levels of university courses, career paths with job listings, and industry-required with suitable online courses. The whole system received good ratings and feedback from users from our survey with 201 volunteers who are students and faculty members of tech universities in Australia and Vietnam. This research is beneficial to students, faculty members, universities in CS/IT higher education sector, and stakeholders in tech-related industries.",https://doi.org/10.1016/j.caeai.2021.100042,https://www.sciencedirect.com/science/article/pii/S2666920X21000369,,,,2022,Domain-specific NLP system to support learning path and curriculum design at tech universities,Nhi N.Y. Vo and Quang T. Vu and Nam H. Vu and Tu A. Vu and Bang D. Mach and Guandong Xu,article,VO2022100042,Computers and Education: Artificial Intelligence,,3,2666-920X,,,
,"Developer discussions, Gitter, Issue reports",110852,,"Informal communication channels like mailing lists, IRC and instant messaging play a vital role in open source software development by facilitating communication within geographically diverse project teams e.g., to discuss issue reports to facilitate the bug-fixing process. More recently, chat systems like Slack and Gitter have gained a lot of popularity and developers are rapidly adopting them. Gitter is a chat system that is specifically designed to address the needs of GitHub users. Gitter hosts project-based asynchronous chats which foster frequent project discussions among participants. Developer discussions contain a wealth of information such as the rationale behind decisions made during the evolution of a project. In this study, we explore 24 open source project chat rooms that are hosted on Gitter, containing a total of 3,133,106 messages and 14,096 issue references. We manually analyze the contents of chat room discussions around 457 issue reports. The results of our study show the prevalence of issue discussions on Gitter, and that the discussed issue reports have a longer resolution time than the issue reports that are never brought on Gitter.",https://doi.org/10.1016/j.jss.2020.110852,https://www.sciencedirect.com/science/article/pii/S0164121220302429,,,,2021,How are issue reports discussed in Gitter chat rooms?,Hareem Sahar and Abram Hindle and Cor-Paul Bezemer,article,SAHAR2021110852,Journal of Systems and Software,,172,0164-1212,,,
,"Mirai, IoT malware, Forensics, Botnet server",300926,,"Internet of Things (IoT) bot malware is relatively new and not yet well understood forensically, despite its potential role in a broad range of malicious cyber activities. For example, it was abused to facilitate the distributed denial of service (DDoS) attack that took down a significant portion of the Internet on October 21, 2016, keeping millions of people from accessing over 1200 websites, including Twitter and NetFlix for nearly an entire day. The widespread adoption of an estimated 50 billion IoT devices, as well as the increasing interconnectivity of those devices to traditional networks, not to mention to one another with the advent of fifth generation (5G) networks, underscore the need for IoT botnet forensics. This study is the first published, comprehensive digital forensic case study on one of the most well known families of IoT bot malware - Mirai. Past research has largely studied the botnet architecture and analyzed the Mirai source code (and that of its variants) through traditional static and dynamic malware analysis means, but has not fully and forensically analyzed infected devices or Mirai network devices. In this paper, we set up a fully functioning Mirai botnet network architecture and conduct a comprehensive forensic analysis on the Mirai botnet server. We discuss forensic artifacts left on the attacker's terminal, command and control (CNC) server, database server, scan receiver and loader, as well as the network packets therefrom. We discuss how a forensic investigator might acquire some of these artifacts remotely, without direct physical access to the botnet server itself. This research provides findings tactically useful to forensic investigators, not only from the perspective of what data can be obtained (e.g., IP addresses of bot members), but also important information about which device they should target for acquisition and investigation to obtain the most investigatively useful information.",https://doi.org/10.1016/j.fsidi.2020.300926,https://www.sciencedirect.com/science/article/pii/S2666281720300214,,,,2020,IoT Botnet Forensics: A Comprehensive Digital Forensic Case Study on Mirai Botnet Servers,Xiaolu Zhang and Oren Upton and Nicole Lang Beebe and Kim-Kwang Raymond Choo,article,ZHANG2020300926,Forensic Science International: Digital Investigation,,32,2666-2817,,,
,"Transparency reports, Transparency, Online platforms, Santa Clara Principles, Compliance, Comparative analysis, Regulation, Digital Services Act",102477,,"Over the last decade, transparency reports have been adopted by most large information technology companies. These reports provide important information on the requests tech companies receive from state actors around the world and the ways they respond to these requests, including what content the companies remove from platforms they own. In theory, such reports shall make inner workings of companies more transparent, in particular with respect to their collaboration with state actors. They shall also allow users and external entities (e.g., researchers or watchdogs) to assess to what extent companies adhere to their own policies on user privacy and content moderation as well as to the principles formulated by global entities that advocate for the freedom of expression and privacy online such as the Global Network Initiative or Santa Clara Principles. However, whether the current state of transparency reports actually is conducive to meaningful transparency remains an open question. In this paper, we aim to address this through a critical comparative analysis of transparency reports using Santa Clara Principles 2.0 (SCP 2.0) as the main analytical framework. Specifically, we aim to make three contributions: first, we conduct a comparative analysis of the types of data disclosed by major tech companies and social media platforms in their transparency reports. The companies and platforms analyzed include Google (incl. YouTube), Microsoft (incl. its subsidiaries Github and LinkedIn), Apple, Meta (prev. Facebook), TikTok, Twitter, Snapchat, Pinterest, Reddit and Amazon (incl. subsidiary Twitch). Second, we evaluate to what degree the released information complies with SCP 2.0 and how it aligns with different purposes of transparency. Finally, we outline recommendations that could improve the level of transparency within the reports and beyond, and contextualize our recommendations with regard to the Digital Services Act (DSA) that received the final approval of the European Council in October 2022.",https://doi.org/10.1016/j.telpol.2022.102477,https://www.sciencedirect.com/science/article/pii/S0308596122001793,,,,2023,How transparent are transparency reports? Comparative analysis of transparency reporting across online platforms,Aleksandra Urman and Mykola Makhortykh,article,URMAN2023102477,Telecommunications Policy,3,47,0308-5961,,,
,"Pull-request, Reviewer recommendation, Social network analysis",204-218,,"Context: The pull-based model, widely used in distributed software development, offers an extremely low barrier to entry for potential contributors (anyone can submit of contributions to any project, through pull-requests). Meanwhile, the project’s core team must act as guardians of code quality, ensuring that pull-requests are carefully inspected before being merged into the main development line. However, with pull-requests becoming increasingly popular, the need for qualified reviewers also increases. GitHub facilitates this, by enabling the crowd-sourcing of pull-request reviews to a larger community of coders than just the project’s core team, as a part of their social coding philosophy. However, having access to more potential reviewers does not necessarily mean that it’s easier to find the right ones (the “needle in a haystack” problem). If left unsupervised, this process may result in communication overhead and delayed pull-request processing. Objective: This study aims to investigate whether and how previous approaches used in bug triaging and code review can be adapted to recommending reviewers for pull-requests, and how to improve the recommendation performance. Method: First, we extend three typical approaches used in bug triaging and code review for the new challenge of assigning reviewers to pull-requests. Second, we analyze social relations between contributors and reviewers, and propose a novel approach by mining each project’s comment networks (CNs). Finally, we combine the CNs with traditional approaches, and evaluate the effectiveness of all these methods on 84 GitHub projects through both quantitative and qualitative analysis. Results: We find that CN-based recommendation can achieve, by itself, similar performance as the traditional approaches. However, the mixed approaches can achieve significant improvements compared to using either of them independently. Conclusion: Our study confirms that traditional approaches to bug triaging and code review are feasible for pull-request reviewer recommendations on GitHub. Furthermore, their performance can be improved significantly by combining them with information extracted from prior social interactions between developers on GitHub. These results prompt for novel tools to support process automation in social coding platforms, that combine social (e.g., common interests among developers) and technical factors (e.g., developers’ expertise).",https://doi.org/10.1016/j.infsof.2016.01.004,https://www.sciencedirect.com/science/article/pii/S0950584916000069,,,,2016,Reviewer recommendation for pull-requests in GitHub: What can we learn from code review and bug assignment?,Yue Yu and Huaimin Wang and Gang Yin and Tao Wang,article,YU2016204,Information and Software Technology,,74,0950-5849,,,
,"Domain generation algorithm, Malicious domain name, Classification, Variational autoencoder, Deep learning",102948,,"Domain generation algorithm (DGA) is used by botnets to build a stealthy command and control (C&C) communication channel between the C&C server and the bots. A DGA can periodically produce a large number of pseudo-random algorithmically generated domains (AGDs), a few of which direct the bots to the C&C server. AGD detection algorithms provide a lightweight, promising solution in response to the existing DGA techniques. In the constantly evolving attacker–defender game, attackers may seek more advanced DGA techniques to gain a better chance of evading detection by defenders. In this paper, we propose a new DGA, namely a neural networks-based domain name generation (NDG) architecture. NDG is based on a variational autoencoder (VAE), where the encoder and decoder networks use stacked gated convolutional neural networks (GCNNs) to learn the contextual structure hierarchically. NDG is experimentally validated using a set of state-of-the-art AGD detection algorithms. The existing DGAs of different classes following a DGA taxonomy are used to benchmark NDG. NDG shows the best overall anti-detection performance among all tested DGAs. We also demonstrate that NDG is effective in benchmarking AGD detection algorithms.",https://doi.org/10.1016/j.jisa.2021.102948,https://www.sciencedirect.com/science/article/pii/S2214212621001629,,,,2021,Neural networks based domain name generation,Zheng Wang and Yang Guo,article,WANG2021102948,Journal of Information Security and Applications,,61,2214-2126,,,
,"DDoS, Moving target defense, SDN, Machine learning, Cyber security",103462,,"The Distributed Denial of Service (DDoS) coordinates synchronized attacks on systems on the Internet using a set of infected hosts (bots). Bots are programmed to attack a determined target by firing a lot of synchronized requests, causing slowness or unavailability of the service. This type of attack has recently grown in magnitude, diversity, and economic cost. Thus, this paper presents a DDoS detection and mitigation architecture based on Software Defined Networking (SDN). It considers the Moving Target Defense (MTD) approach, redirecting malicious floods to expendable low-capacity servers to protect the main server while discouraging the attacker. The redirecting decision is based on a sensor, that employs Machine Learning (ML) algorithms for flow classification. When malicious flows are detected, the sensor notifies the SDN controller to include them in the malicious hosts lists and to realize the redirection. The validation and evaluation of the proposed architecture are conducted by simulation. Results considering different classification models (probabilistic, linear model, neural networks, and trees) and attack types indicate that the proposed architecture is efficient in detecting and mitigating DDoS attacks in approximately 3 seconds.",https://doi.org/10.1016/j.cose.2023.103462,https://www.sciencedirect.com/science/article/pii/S0167404823003723,,,,2023,Detecting and mitigating DDoS attacks with moving target defense approach based on automated flow classification in SDN networks,Marcos Aurélio Ribeiro and Mauro Sergio {Pereira Fonseca} and Juliana {de Santi},article,RIBEIRO2023103462,Computers & Security,,134,0167-4048,,,
,"Ontology engineering, Ontology evaluation, Ontology documentation, Ontology publication",100472,,"Due to the increasing uptake of semantic technologies, ontologies are now part of a good number of information systems. As a result, software development teams that have to combine ontology engineering activities with software development practices are facing several challenges, since these two areas have evolved, in general, separately. In this paper we present OnToology, an approach to manage ontology engineering support activities (i.e., documentation, evaluation, releasing and versioning). OnToology is a web-based application that builds on top of Git-based environments and integrates existing semantic web technologies. We have validated OnToology against a set of representative requirements for ontology development support activities in distributed environments, and report on a survey of the system to assess its usefulness and usability.",https://doi.org/10.1016/j.websem.2018.09.003,https://www.sciencedirect.com/science/article/pii/S1570826818300465,,,,2019,Automating ontology engineering support activities with OnToology,Ahmad Alobaid and Daniel Garijo and María Poveda-Villalón and Idafen Santana-Perez and Alba Fernández-Izquierdo and Oscar Corcho,article,ALOBAID2019100472,Journal of Web Semantics,,57,1570-8268,,,
,,12,,"Elon Musk and Reddit are leading a new wave of objections to the long-accepted practice of scraping content from websites, discovers Matthew Sparkes",https://doi.org/10.1016/S0262-4079(23)00836-9,https://www.sciencedirect.com/science/article/pii/S0262407923008369,,,,2023,The war against AI web scraping,Matthew Sparkes,article,SPARKES202312,New Scientist,3438,258,0262-4079,,,
,"Natural language generation, Saliency, Dialogue Systems, End-to-End generation",124283,,"Challenges persist in dialogue scenarios, particularly in multi-turn dialogues where response generation often disregards contextual information beyond the last user utterance, resulting in fluent yet inadequate responses. This paper addresses these issues by identifying and resolving common shortcomings in base model responses during response generation and proposes methods to enhance response quality in unannotated dialogue settings. Our approach involves augmenting information from multiple sources, including keywords, salient features, and knowledge graph triples. We compare the effectiveness of these methods against both the base model and human annotation, which includes dialogue acts and entities. Our findings demonstrate that appending extracted tokens significantly enhances response quality compared to annotated information. In task-oriented dialogue, models perform best when infused with saliency and knowledge graph triples, as shown in the MultiWOZ dataset. Conversely, focusing solely on saliency yields better results for open-domain dialogue, as demonstrated with the DailyDialog dataset. For contextual relevance, the information infusion could also approach the performance of the LLama2 model with only a tenth of the available parameters.",https://doi.org/10.1016/j.eswa.2024.124283,https://www.sciencedirect.com/science/article/pii/S0957417424011497,,,,2024,Saliency infused dialogue response generation: Improving task oriented text generation using feature attribution,Ratnesh Kumar Joshi and Arindam Chatterjee and Asif Ekbal,article,JOSHI2024124283,Expert Systems with Applications,,255,0957-4174,,,
,,8-10,,"Digital coin software could be infecting your desktops and servers with malware, opening the doors to hackers. They could be after your customer lists, your passwords, your databases. Or they could be looking to turn your computers and devices into bots. Jesse Sampson of Ziften explains the nature of the threat and what to do about it. Bitcoin? Monero? Ethereum? It doesn't matter. Coin mining and trading activities by employees – or by hackers – is a huge security problem that every organisation needs to address.",https://doi.org/10.1016/S1361-3723(18)30032-0,https://www.sciencedirect.com/science/article/pii/S1361372318300320,,,,2018,Secret digital coin mining and trading is a threat to your business,Jesse Sampson,article,SAMPSON20188,Computer Fraud & Security,4,2018,1361-3723,,,
,"Social bots, Misinformation, Fake news, Social influence, Agent-based model",100106,,"Some fear that social bots, automated accounts on online social networks, propagate falsehoods that can harm public opinion formation and democratic decision-making. Empirical research, however, resulted in puzzling findings. On the one hand, the content emitted by bots tends to spread very quickly in the networks. On the other hand, it turned out that bots’ ability to contact human users tends to be very limited. Here we analyze an agent-based model of social influence in networks explaining this inconsistency. We show that bots may be successful in spreading falsehoods not despite their limited direct impact on human users, but because of this limitation. Our model suggests that bots with limited direct impact on humans may be more and not less effective in spreading their views in the social network, because their direct contacts keep exerting influence on users that the bot does not reach directly. Highly active and well-connected bots, in contrast, may have a strong impact on their direct contacts, but these contacts grow too dissimilar from their network neighbors to further spread the bot’s content. To demonstrate this effect, we included bots in Axelrod’s seminal model of the dissemination of cultures and conducted simulation experiments demonstrating the strength of weak bots. A series of sensitivity analyses show that the finding is robust, in particular when the model is tailored to the context of online social networks. We discuss implications for future empirical research and developers of approaches to detect bots and misinformation.",https://doi.org/10.1016/j.osnem.2020.100106,https://www.sciencedirect.com/science/article/pii/S2468696420300471,,,,2021,The strength of weak bots,Marijn A. Keijzer and Michael Mäs,article,KEIJZER2021100106,Online Social Networks and Media,,21,2468-6964,,,
,"Mirai, Qbot, Generic IoT botnet detection, IoT botnet",301224,,"As the source code of various IoT botnet families including Mirai has been made publicly available, the adversaries are drastically introducing new variants of these IoT Botnet families. However, there is a lack of generic mechanism for the detection of these emerging variants. As a consequence, it is infeasible for security solution providers to effectively identify new variants of IoT botnets. In this paper, we have done static code analysis of 17 IoT botnet variants of family Mirai and Qbot in order to dig out the attacker's perspective, generic behavior, employed technologies and implemented techniques. With the help of this analysis, we have identified generic behavioral patterns of IoT botnets and have developed generic signatures for the identification of IoT botnets. These signatures includes identification on the basis of CPU architectures, Bot control commands, Bot scanning commands, obfuscation methods, botnet specific exploits and attacks. A comparative analysis of analyzed IoT-Botnet families has been presented. For the evaluation of identified signatures, we first tested them on unknown Mirai and Qbot variants and gained a detection rate of 100% for both the variants. Secondly, we tested those signatures on other IoT-Botnet families: IRC-Bot, Perl ShellBot, Trick-Bot and gained a detection rate of 98%, 96.79% and 98.2% respectively. Further, we have presented open research challenges in the field of IoT-Botnet detection. This research will enhance IoT botnets understanding and pave the way for generic detection and prevention methods of IoT botnets.",https://doi.org/10.1016/j.fsidi.2021.301224,https://www.sciencedirect.com/science/article/pii/S2666281721001323,,,,2021,Generic signature development for IoT Botnet families,Syed Ghazanfar Abbas and Fabiha Hashmat and Ghalib A. Shah and Kashif Zafar,article,ABBAS2021301224,Forensic Science International: Digital Investigation,,38,2666-2817,,,
,"Authentication, Botnet, Ddos, Brute force, Port scanning, Corda virtual machine, Mirai, Manufacturer usage description, Owasp, Vulnerability",104503,,"Internet of Things (IoT) networks has gained popularity due to their amazing and cost-effective services and one of the main areas in smart cities. The stability of these networks is based on stable and secure data transmission without any vulnerabilities present used devices. Distributed Denial of Services (DDoS) attacks have brought critical interruptions in IoT services and significantly damage the network. In DDoS attacks, attackers utilize botnets, with the capability of frequently exploiting the millions of IoT devices around the globe. After the source code of Mirai malware is loaded on GitHub, the threats are significantly increased. Manufacturer Usage Description (MUD) is an embedded software standard for IoT device makers to advertise device specifications, including the intended communication patterns when it connects to the network. Even though the MUD mechanism is promising exertion, still there is a need for evaluating its viability, recognize its limits, and upgrade its architecture to reduce shortcomings in its architecture as well as to increase its effectiveness. This standard neither identifies the vulnerability path before the creation of the MUD profile. Thus, it is possible to exploit an IoT device even after the MUD profile is issued to the device by manipulating the vulnerabilities in the device. By keeping in mind this situation, this paper discusses the limitations of MUD in detail and proposed a framework to identify the patch and default vulnerabilities by using blockchain method before the generation/creation of MUD profiles. The proposed framework can also mitigate open ports, DDoS attacks, and Brute force attacks. The experiment results show the identification, elimination, and sharing of vulnerability report with vendors and significantly minimized the risk of IoT device exploitation.",https://doi.org/10.1016/j.micpro.2022.104503,https://www.sciencedirect.com/science/article/pii/S0141933122000631,,,,2022,Security provision for protecting intelligent sensors and zero touch devices by using blockchain method for the smart cities,Khaleeq {Un Nisa} and Adi Alhudhaif and Kashif Naseer Qureshi and Hassan Jalil Hadi and Gwanggil Jeon,article,UNNISA2022104503,Microprocessors and Microsystems,,90,0141-9331,,,
,"Suggesting reviewers, Reviewer recommendation, Graph mining, Software traceability, Pull-request review, Modern code review",106455,,"Context:
Various types of artifacts (requirements, source code, test cases, documents, etc.) are produced throughout the lifecycle of a software. These artifacts are connected with each other via traceability links that are stored in modern application lifecycle management repositories. Throughout the lifecycle of a software, various types of changes can arise in any one of these artifacts. It is important to review such changes to minimize their potential negative impacts. To make sure the review is conducted properly, the reviewer(s) should be chosen appropriately.
Objective:
We previously introduced a novel approach, named RSTrace, to automatically recommend reviewers that are best suited based on their familiarity with a given artifact. In this study, we introduce an advanced version of RSTrace, named RSTrace+ that accounts for recency information of traceability links including practical tool support for GitHub.
Methods:
In this study, we conducted a series of experiments on finding the appropriate code reviewer(s) using RSTrace+ and provided a comparison with the other code reviewer recommendation approaches.
Results:
We had initially tested RSTrace+ on an open source project (Qt 3D Studio) and achieved a top-3 accuracy of 0.89 with an MRR (mean reciprocal ranking) of 0.81. In a further empirical evaluation of 40 open source projects, we compared RSTrace+ with Naive-Bayes, RevFinder and Profile based approach, and observed higher accuracies on the average.
Conclusion:
We confirmed that the proposed reviewer recommendation approach yields promising top-k and MRR scores on the average compared to the existing reviewer recommendation approaches. Unlike other code reviewer recommendation approaches, RSTrace+ is not limited to recommending reviewers for source code artifacts and can potentially be used for recommending reviewers for other types of artifacts. Our approach can also visualize the affected artifacts and help the developer to make assessments of the potential impacts of change to the reviewed artifact.",https://doi.org/10.1016/j.infsof.2020.106455,https://www.sciencedirect.com/science/article/pii/S0950584920300021,,,,2021,RSTrace+: Reviewer suggestion using software artifact traceability graphs,Emre Sülün and Eray Tüzün and Uğur Doğrusöz,article,SULUN2021106455,Information and Software Technology,,130,0950-5849,,,
,"Functions as a service, Serverless, Denial of wallet, Botnet",109921,,"Denial of Wallet (DoW) attacks refers to a type of cyberattack that aims to exploit and exhaust the financial resources of an organization by triggering excessive costs or charges within their cloud or serverless computing environment. These attacks are particularly relevant in the context of serverless architectures due to characteristics like pay-as-you-go model, auto-scaling, limited control and cost amplification. Serverless computing, often referred to as Function-as-a-Service (FaaS), is a cloud computing model that allows developers to build and run applications without the need to manage traditional server infrastructure. Serverless architectures have gained popularity in cloud computing due to their flexibility and ability to scale automatically based on demand. These architectures are based on executing functions without the need to manage the underlying infrastructure. However, the lack of realistic and representative datasets that simulate function invocations in serverless environments has been a challenge for research and development of solutions in this field. The aim is to create a dataset for simulating function invocations in serverless architectures, that is a valuable practice for ensuring the reliability, efficiency, and security of serverless applications. Furthermore, we propose a methodology for the generation of the dataset, which involves the generation of synthetic data from traffic generated on cloud platforms and the identification of the main characteristics of function invocations. These characteristics include SubmitTime, Invocation Delay, Response Delay, Function Duration, Active Functions at Request, Active Functions at Response. By generating this dataset, we expect to facilitate the detection of Denial of Wallet (DoW) attacks using machine learning techniques and neural networks. In this way, this dataset available in Mendeley data repository could provide other researchers and developers with a dataset to test and evaluate machine learning algorithms or use other techniques based on the detection of attacks and anomalies in serverless environments.",https://doi.org/10.1016/j.dib.2023.109921,https://www.sciencedirect.com/science/article/pii/S2352340923009605,,,,2024,Generation of a dataset for DoW attack detection in serverless architectures,José Manuel {Ortega Candel} and Francisco José {Mora Gimeno} and Higinio {Mora Mora},article,ORTEGACANDEL2024109921,Data in Brief,,52,2352-3409,,,
,"Linked Building Data, Temporary construction items, BIM",104258,,"For decades, the construction industry has experienced poor productivity due to challenges such as increasing project complexity and a fragmented project environment. Even though some technological innovations around Building Information Modeling (BIM) might have the potential to overcome these challenges, data integration across disciplines, companies and software solutions is yet to be solved entirely. Trending advancements try to enrich existing BIM data using Linked Data technologies to semantically describe the building information and facilitate data integration. By that, project data from different data sources is made available in an accessible format, so project participants can use it for their planning efforts. In this paper we explore the use of Linked Building Data (LBD) on a specific use case to answer the question of how the planning of Temporary Construction Items (TCIs) can be improved by integrating data and automating the demand calculation. A literature review concludes that TCIs only experience little attention in the current planning of construction projects but have a critical impact on the outcome of a project. Thus, the objective of this paper is to develop standard ontologies to provide a semantically rich terminology of the data and to propose a framework for TCI consideration within a BIM based project delivery system. A prototype solution is developed, taking formwork as a TCI representative. The result is a process for automatically creating a TCI utilization plan that quantifies the precise time- and location-based on-site TCI demand by integrating data from BIM, Location-Based Scheduling (LBS) and TCI information. Based on the results of prototyping and findings from expert interviews, this research integrates the solution into the process of construction and finally proposes two implementation scenarios for the solution – one being based on the current industry situation and one exploring the future vision of a more integrated and decentralized project delivery in the construction industry.",https://doi.org/10.1016/j.autcon.2022.104258,https://www.sciencedirect.com/science/article/pii/S0926580522001315,,,,2022,Using Linked Building Data for managing temporary construction items,Alexander Schlachter and Mads Holten Rasmussen and Jan Karlshøj,article,SCHLACHTER2022104258,Automation in Construction,,139,0926-5805,,,
,"ChatGPT, Large language models, Programming",100526,,"Artificial intelligence (AI) has made remarkable strides, giving rise to the development of large language models such as ChatGPT. The chatbot has garnered significant attention from academia, industry, and the general public, marking the beginning of a new era in AI applications. This work explores how well ChatGPT can write source code. To this end, we performed a series of experiments to assess the extent to which ChatGPT is capable of solving general programming problems. Our objective is to assess ChatGPT’s capabilities in two different programming languages, namely C++ and Java, by providing it with a set of programming problem, encompassing various types and difficulty levels. We focus on evaluating ChatGPT’s performance in terms of code correctness, run-time efficiency, and memory usage. The experimental results show that, while ChatGPT is good at solving easy and medium programming problems written in C++ and Java, it encounters some difficulties with more complicated tasks in the two languages. Compared to code written by humans, the one generated by ChatGPT is of lower quality, with respect to runtime and memory usage.",https://doi.org/10.1016/j.mlwa.2024.100526,https://www.sciencedirect.com/science/article/pii/S2666827024000021,,,,2024,Programming with ChatGPT: How far can we go?,Alessio Bucaioni and Hampus Ekedahl and Vilma Helander and Phuong T. Nguyen,article,BUCAIONI2024100526,Machine Learning with Applications,,15,2666-8270,,,
,"Mirai, Botnet, IoT malware, Command & control server, Mirai signature",103629,,"The proliferation of Internet of Things devices has resulted in an increase in security vulnerabilities and network attacks. The Mirai botnet is a well-known example of a network used for malicious activities, detected for the first time by the white-hat research group in August 2016. Since then, Mirai initiated massive DDoS attacks by scanning for and exploiting vulnerabilities in network devices. In this paper, we investigate the evolution of the Mirai botnet over a six-year period, analyzing the TCP SYN packets using Mirai signature, i.e. with TCP sequence number equal to the destination IP address. Our analysis stands out as we extensively investigate the evolution of Mirai scans over a prolonged six-year period (2016–2022). Our findings reveal that the Mirai signature is still implemented by malicious actors today, in contrast with previous works. Moreover, we observe that the number of hijacked devices and TCP SYN packets involved in the scanning phase have increased over time. We also confirm that cybercriminals generally target Telnet port 23, followed by fewer requests on Telnet port 2323. Conversely, the number of probes on the SSH ports decreases over time, followed by a subsequent increase in 2022. Lastly, we identify several ports that had not been contacted until 2018 but have since received a large number of TCP SYN packets that verify the Mirai’s signature. These ports are linked with the emergence of new variants of the Mirai botnet.",https://doi.org/10.1016/j.jisa.2023.103629,https://www.sciencedirect.com/science/article/pii/S2214212623002132,,,,2023,The evolution of Mirai botnet scans over a six-year period,Antonia Affinito and Stefania Zinno and Giovanni Stanco and Alessio Botta and Giorgio Ventre,article,AFFINITO2023103629,Journal of Information Security and Applications,,79,2214-2126,,,
,"Continuous integration, Refactoring, Exploratory study, Mining software repositories, Multiple Regression Analysis",106618,,"Context:
The ultimate goal of Continuous Integration (CI) is to support developers in integrating changes into production constantly and quickly through automated build process. While CI provides developers with prompt feedback on several quality dimensions after each change, such frequent and quick changes may in turn compromise software quality without Refactoring. Indeed, recent work emphasized the potential of CI in changing the way developers perceive and apply refactoring. However, we still lack empirical evidence to confirm or refute this assumption.
Objective:
We aim to explore and understand the evolution of refactoring practices, in terms of frequency, size and involved developers, after the switch to CI in order to emphasize the role of this process in changing the way Refactoring is applied.
Method:
We collect a corpus of 99,545 commits and 89,926 refactoring operations extracted from 39 open-source GitHub projects that adopt Travis CI and analyze the changes using Multiple Regression Analysis (MRA).
Results:
Our study delivers several important findings. We found that the adoption of CI is associated with a drop in the refactoring size as recommended, while refactoring frequency as well as the number (and its related rate) of developers that perform refactoring are estimated to decrease after the shift to CI, indicating that refactoring is less likely to be applied in CI context.
Conclusion:
Our study uncovers insights about CI theory and practice and adds evidence to existing knowledge about CI practices related especially to quality assurance. Software developers need more customized refactoring tool support in the context of CI to better maintain and evolve their software systems.",https://doi.org/10.1016/j.infsof.2021.106618,https://www.sciencedirect.com/science/article/pii/S0950584921000914,,,,2021,On the impact of Continuous Integration on refactoring practice: An exploratory study on TravisTorrent,Islem Saidani and Ali Ouni and Mohamed Wiem Mkaouer and Fabio Palomba,article,SAIDANI2021106618,Information and Software Technology,,138,0950-5849,,,
,,10893-10916,,"A reinforcement learning environment with adversary agents is proposed in this work for pursuit–evasion game in the presence of fog of war, which is of both scientific significance and practical importance in aerospace applications. One of the most popular learning environments, StarCraft, is adopted here and the associated mini-games are analyzed to identify its potential applications and limitations for training adversary agents. The key contribution includes the analysis of the best performance that an intelligent agent could be achieved by incorporating control and differential game theory into the specific reinforcement learning environment, and the development of a StarCraft adversary-agents challenge (SAAC) environment by extending the current StarCraft mini-games. The subsequent study showcases the use of this learning environment and the effectiveness of an adversary agent for evaders. Overall, along with rapidly-emerging reinforcement learning technologies, the proposed SAAC environment should benefit pursuit–evasion studies in particular and aerospace applications in general. Last but not least, the corresponding code is available at GitHub.",https://doi.org/10.1016/j.jfranklin.2023.08.032,https://www.sciencedirect.com/science/article/pii/S0016003223005203,,,,2023,StarCraft adversary-agent challenge for pursuit–evasion game,Xun Huang,article,HUANG202310893,Journal of the Franklin Institute,15,360,0016-0032,,,
,"Open source software (OSS), Development process performance, Issue closure rate, Work centralization, Issue workflow, Surgical team",32-46,,"Context: Better methods of evaluating process performance of OSS projects can benefit decision makers who consider adoption of OSS software in a company. This article studies the closure of issues (bugs and features) in GitHub projects, which is an important measure of OSS development process performance and quality of support that project users receive from the developer team. Objective: The goal of this article is a better understanding of the factors that affect issue closure rates in OSS projects. Methodology: The GHTorrent repository is used to select a large sample of mature, active OSS projects. Using survival analysis, we calculate short-term, and long-term issue closure rates. We formulate several hypotheses regarding the impact of OSS project and team characteristics, such as measures of work centralization, measures that reflect internal project workflows, and developer social networks measures on issue closure rates. Based on the proposed features and several control features, a model is built that can predict issue closure rate. The model allows to test our hypotheses. Results: We find that large teams that have many project members have lower issue closure rates than smaller teams. Similarly, increased work centralization increases issue closure rates. While desirable social network characteristics have a positive impact on the amount of commits in a project, they do not have significant influence on issue closure. Conclusion: Overall, findings from empirical analysis support the classic notion of Brook’s – the “surgical team” – in the context of OSS project development process performance on GitHub. The model of issue closure rates proposed in this article is a first step towards an improved understanding and prediction of this important measure of OSS development process performance.",https://doi.org/10.1016/j.infsof.2018.03.010,https://www.sciencedirect.com/science/article/pii/S095058491730304X,,,,2018,Surgical teams on GitHub: Modeling performance of GitHub project development processes,Oskar Jarczyk and Szymon Jaroszewicz and Adam Wierzbicki and Kamil Pawlak and Michal Jankowski-Lorek,article,JARCZYK201832,Information and Software Technology,,100,0950-5849,,,
,"Chatbot, Question answering, Artificial intelligence, First-order logic, Cognitive architectures, Meta-reasoning",64-79,,"This paper presents a framework based on natural language processing and first-order logic aiming at instantiating cognitive chatbots. The proposed framework leverages two types of knowledge bases interacting with each other in a meta-reasoning process. The first one is devoted to the reactive interactions within the environment, while the second one to conceptual reasoning. The latter exploits a combination of axioms represented with rich semantics and abduction as pre-stage of deduction, dealing also with some of the state-of-the-art issues in the natural language ontology domain. As a case study, a Telegram chatbot system has been implemented, supported by a module which automatically transforms polar and wh-questions into one or more likely assertions, so as to infer Boolean values or snippets with variable length as factoid answer. The conceptual knowledge base is organized in two layers, representing both long- and short-term memory. The knowledge transition between the two layers is achieved by leveraging both a greedy algorithm and the engine’s features of a NoSQL database, with promising timing performance if compared with the adoption of a single layer. Furthermore, the implemented chatbot only requires the knowledge base in natural language sentences, avoiding any script updates or code refactoring when new knowledge has to income. The framework has been also evaluated as cognitive system by taking into account the state-of-the art criteria: the results show that AD-Caspar is an interesting starting point for the design of psychologically inspired cognitive systems, endowed of functional features and integrating different types of perception.",https://doi.org/10.1016/j.cogsys.2023.05.002,https://www.sciencedirect.com/science/article/pii/S1389041723000359,,,,2023,A framework for cognitive chatbots based on abductive–deductive inference,Carmelo Fabio Longo and Paolo Marco Riela and Daniele Francesco Santamaria and Corrado Santoro and Antonio Lieto,article,LONGO202364,Cognitive Systems Research,,81,1389-0417,,,
,"Context utilization, Dialogue generation, Chit-chat-bots, Co-reference",109873,,"Dialogue is a process of information exchanging, where global background is stable while local focuses are transiting. Thus, at the ongoing dialogue turn, there are both relevant and irrelevant semantics existing in dialogue contexts. How to filter out noises and selectively utilize context can pave the way to successful dialogue generation. Current work on dialogue context utilization either processes contexts as vanilla monologue text ignoring dynamic conversation flows, or depends on weighted strategies to fuse all contexts where irrelevant utterances cannot be filter out even may overwhelm relevant ones. To deal with this, this paper proposes a Hard-style Selective Context Utilization method (HardSCU). We first define and measure the information density of the last utterance (query) of a dialogue, marking it as “strong” or “weak”. For a dialogue with strong query, HardSCU directly inputs the query into a RNN-based or T5-based encoder–decoder framework to generate a response; for a dialogue with weak query, HardSCU conducts a selective context utilization for dialogue generation, where a semantic interaction module introduces relevant semantics of context to enrich the query and the co-reference relations existing in dialogue are extracted to promote the learning process of response decoder. Extensive experiments on two benchmark conversation corpora verify that our HardSCU method can outperform competitive baselines on generating appropriate responses for chit-chat-bots with yielding strong robustness to the variations of dialogue lengths.",https://doi.org/10.1016/j.knosys.2022.109873,https://www.sciencedirect.com/science/article/pii/S0950705122009662,,,,2022,Hard-style Selective Context Utilization for dialogue generation based on what user just said,Yanxiang Ling and Zheng Liang and Tianqi Wang and Fei Cai and Honghui Chen,article,LING2022109873,Knowledge-Based Systems,,257,0950-7051,,,
,"Tag recommendation, Pull request, Open-source project, Github",106394,,"Context
In GitHub, contributors make code changes, then create and submit pull requests to projects. Tags are a simple and effective way to attach additional information to pull requests and facilitate their organization. However, little effort has been devoted to study pull requests’ tags in GitHub.
Objective
Our objective in this paper is to propose an approach which automatically recommends tags for pull requests in GitHub.
Method
We make a survey on the usage of tags in pull requests. Survey results show that tags are useful for developers to track, search or classify pull requests. But some respondents think that it is difficult to choose right tags and keep consistency of tags. 60.61% of respondents think that a tag recommendation tool is useful. In order to help developers choose tags, we propose a method FNNRec which uses feed-forward neural network to analyze titles, description, file paths and contributors.
Results
We evaluate the effectiveness of FNNRec on 10 projects containing 68,497 tagged pull requests. The experimental results show that on average, FNNRec outperforms approach TagDeepRec and TagMulRec by 62.985% and 24.953% in terms of F1−score@3, respectively.
Conclusion
FNNRec is useful to find appropriate tags and improve tag setting process in GitHub.",https://doi.org/10.1016/j.infsof.2020.106394,https://www.sciencedirect.com/science/article/pii/S0950584920301580,,,,2021,Recommending tags for pull requests in GitHub,Jing Jiang and Qiudi Wu and Jin Cao and Xin Xia and Li Zhang,article,JIANG2021106394,Information and Software Technology,,129,0950-5849,,,
,"OpenMP, ompTG, Parallel task graph, Control flow analysis",102470,,"Real-time systems are shifting them from single-core to multi-core processors. Software must be parallelized to fully utilize the computation power of multi-core architectures. OpenMP is a promising framework to develop parallel real-time software on multi-cores. OpenMP programs keep certain similarity to real-time task graph models, and this motivates much recent work done on real-time scheduling of OpenMP tasks. However, these studies conduct evaluations with randomly generated task graphs, which cannot well capture the structure features of realistic OpenMP programs. To fill the gap between theoretical real-time scheduling research and the OpenMP software reality, we develop an ompTG tool for transforming OpenMP programs into parallel task graphs. ompTG prepares a way to exhibit OpenMP such that the researchers in real-time community can easily understand: An OpenMP system consists of a set of tasks. There are interdependencies among tasks, and each task has an intra structure of the control-flow graph. Besides the topology of OpenMP tasks, we also provide a safe WCET for each vertex of OpenMP task graphs by using static WCET analysis techniques. Moreover, we derive the flow facts, e.g, infeasible path and loop bounds for the task graph, which is necessary information for real-time scheduling and analysis. As a case study, we collect 12 OpenMP programs from the BOTS benchmark, and transform them into task graphs, demonstrating the usage of ompTG.",https://doi.org/10.1016/j.sysarc.2022.102470,https://www.sciencedirect.com/science/article/pii/S138376212200056X,,,,2022,ompTG: From OpenMP Programs to Task Graphs,Jinghao Sun and Tao Jin and Yekai Xue and Liwei Zhang and Jinrong Liu and Nan Guan and Quan Zhou,article,SUN2022102470,Journal of Systems Architecture,,126,1383-7621,,,
,"Underwater organism detection, Deep learning, U-YOLOv7, Quantity estimation",102108,,"Detecting and monitoring underwater organisms is very important for sea aquaculture. The human eye struggles to quickly distinguish between aquatic species due to their variety and dense dispersion. In this paper, a deep learning object detection algorithm based on YOLOv7 is used to design a new network, called Underwater-YOLOv7 (U-YOLOv7), for underwater organism detection. This model satisfies the requirements with regards to both speed and accuracy. First, a network combining CrossConv and an efficient squeeze-excitation module is created. This network increases the extraction of channel information while reducing parameters and enhancing the feature fusion of the network. Second, a lightweight Content-Aware ReAssembly of FEatures (CARAFE) operator is used to obtain more semantic information about underwater images before feature fusion. A 3D attention mechanism is incorporated to improve the anti-interference ability of the model in underwater recognition. Finally, a decoupling head using hybrid convolution is designed to accelerate convergence and improve the accuracy of underwater detection. The results show that the network proposed in this paper obtains an improvement of 3.2% in accuracy, 2.3% in recall, and 2.8% in the mean average precision value and runs at up to 179 fps, far outperforming other advanced networks. Moreover, it has a higher estimation accuracy than the YOLOv7 network.",https://doi.org/10.1016/j.ecoinf.2023.102108,https://www.sciencedirect.com/science/article/pii/S1574954123001371,,,,2023,U-YOLOv7: A network for underwater organism detection,Guoyan Yu and Ruilin Cai and Jinping Su and Mingxin Hou and Ruoling Deng,article,YU2023102108,Ecological Informatics,,75,1574-9541,,,
,"Malware, Botnets, Domain Generation Algorithm, DNS, Covert communication",101614,,"There is a continuous increase in the sophistication that modern malware exercise in order to bypass the deployed security mechanisms. A typical approach to evade the identification and potential take down of a botnet command and control server is domain fluxing through the use of Domain Generation Algorithms (DGAs). These algorithms produce a vast amount of domain names that the infected device tries to communicate with to find the C&C server, yet only a small fragment of them is actually registered. This allows the botmaster to pivot the control and make the work of seizing the botnet control rather difficult. Current state of the art and practice considers that the DNS queries performed by a compromised device are transparent to the network administrator and therefore can be monitored, analysed, and blocked. In this work, we showcase that the latter is a strong assumption as malware could efficiently hide its DNS queries using covert and/or encrypted channels bypassing the detection mechanisms. To this end, we discuss possible mitigation measures based on traffic analysis to address the new challenges that arise from this approach.",https://doi.org/10.1016/j.cose.2019.101614,https://www.sciencedirect.com/science/article/pii/S016740481831321X,,,,2020,Encrypted and covert DNS queries for botnets: Challenges and countermeasures,Constantinos Patsakis and Fran Casino and Vasilios Katos,article,PATSAKIS2020101614,Computers & Security,,88,0167-4048,,,
,"Adaptive reasoning, Adversarial reasoning, Opponent modeling, Rock–paper–scissors",101654,,"How do people adapt to others in adversarial settings? Prior work has shown that people often violate rational models of adversarial decision-making in repeated interactions. In particular, in mixed strategy equilibrium (MSE) games, where optimal action selection entails choosing moves randomly, people often do not play randomly, but instead try to outwit their opponents. However, little is known about the adaptive reasoning that underlies these deviations from random behavior. Here, we examine strategic decision-making across repeated rounds of rock, paper, scissors, a well-known MSE game. In experiment 1, participants were paired with bot opponents that exhibited distinct stable move patterns, allowing us to identify the bounds of the complexity of opponent behavior that people can detect and adapt to. In experiment 2, bot opponents instead exploited stable patterns in the human participants’ moves, providing a symmetrical bound on the complexity of patterns people can revise in their own behavior. Across both experiments, people exhibited a robust and flexible attention to transition patterns from one move to the next, exploiting these patterns in opponents and modifying them strategically in their own moves. However, their adaptive reasoning showed strong limitations with respect to more sophisticated patterns. Together, results provide a precise and consistent account of the surprisingly limited scope of people’s adaptive decision-making in this setting.",https://doi.org/10.1016/j.cogpsych.2024.101654,https://www.sciencedirect.com/science/article/pii/S0010028524000252,,,,2024,"Repeated rock, paper, scissors play reveals limits in adaptive sequential behavior",Erik Brockbank and Edward Vul,article,BROCKBANK2024101654,Cognitive Psychology,,151,0010-0285,,,
,"Malicious content, Content propagation, Network intervention, Feed management, Agent-based model, Preferential attachment, Cognitive load",114235,,"Malicious content threatens the integrity and quality of content in social networks. Research and practice have experimented with network intervention strategies to curb malicious content propagation. These strategies lack efficiency, target malicious content propagators, and abridge freedom of speech. We draw upon the preferential attachment literature and cognitive load theory to employ the mechanisms of network formation, information sharing, and limited human cognitive capacities to propose an alternative feed management strategy—Preferentiality Dampened Feed Management. We compare and contrast this strategy against other established strategies using an agent-based model that utilizes empirical data from Twitter and findings from the prior literature. The results from our two experiments suggest that our proposed strategy is more effective in curbing malicious content propagation than other established strategies. Our work has important implications for the network interventions literature and practical implications for platform providers, social media users, and society.",https://doi.org/10.1016/j.dss.2024.114235,https://www.sciencedirect.com/science/article/pii/S016792362400068X,,,,2024,Freedom of speech or freedom of reach? Strategies for mitigating malicious content in social networks,Saurav Chakraborty and Sandeep Goyal and Annamina Rieder and Agnieszka Onuchowska and Donald J. Berndt,article,CHAKRABORTY2024114235,Decision Support Systems,,182,0167-9236,,,
,"Machine learning, Twitter bot detection, Model explainability",100333,,"This study introduces a novel, reproducible and reusable Twitter bot identification system. The system uses a machine learning (ML) pipeline, fed with hundreds of features extracted from a Twitter corpus. The main objective of the proposed ML pipeline is to train and validate different state-of-the-art machine learning models, where the eXtreme Gradient Boosting (XGBoost) model is selected since it achieves the highest detection performance. The Twitter dataset was collected during the 2020 US Presidential Elections, and additional experimental evaluation on distinct Twitter datasets demonstrates the superiority of our approach, in terms of high bot detection accuracy.",https://doi.org/10.1016/j.simpa.2022.100333,https://www.sciencedirect.com/science/article/pii/S2665963822000598,,,,2022,Explainable machine learning pipeline for Twitter bot detection during the 2020 US Presidential Elections,Alexander Shevtsov and Christos Tzagkarakis and Despoina Antonakaki and Sotiris Ioannidis,article,SHEVTSOV2022100333,Software Impacts,,13,2665-9638,,,
,"Unknown attack, Adversarial attack, Intrusion detection system, DoS/DDoS attack, Machine learning, Deep learning",100851,,"The fourth industrial revolution is marked by the rapid growth of Internet of Things (IoT) technology, leading to an increase in the number of IoT devices. Unfortunately, this also makes these devices more susceptible to cyber threats, especially DoS/DDoS attacks. While supervised learning models have been adopted to detect and mitigate these threats, they have limitations in detecting unknown attacks that can cause severe consequences. This research aims to address those limitations and provide better protection for IoT networks against DoS/DDoS attacks. We propose a new approach that combines a soft-ordering convolutional neural network (SOCNN) model with local outlier factor (LOF) and isolation-based anomaly detection using nearest-neighbor ensembles (iNNE) models that use both supervised and unsupervised learning methods. We evaluated our approach on three benchmark datasets with varying unknown attack scenarios, and our hybrid model achieved high accuracy in detecting unknown attacks with an average F1-score of 98.94%, 91.68%, and 96.07%, respectively, on BoT-IoT, CIC-IDS-2017, and CIC-IDS-2018 datasets, outperforming state-of-the-art competitors. Our model also showed resilience against adversarial attacks such as the fast gradient sign method (FGSM) and Carlini Wagner (CW) adversarial attacks, highlighting the potential of our approach to enhance IoT network security against DoS/DDoS attacks in unknown attack scenarios.",https://doi.org/10.1016/j.iot.2023.100851,https://www.sciencedirect.com/science/article/pii/S2542660523001749,,,,2023,Robust detection of unknown DoS/DDoS attacks in IoT networks using a hybrid learning model,Xuan-Ha Nguyen and Kim-Hung Le,article,NGUYEN2023100851,Internet of Things,,23,2542-6605,,,
,"Robotic Process Automation, Artificial Intelligence, Industry 4.0",51-58,,"Taking into account the technological evolution of the last decades and the proliferation of information systems in society, today we see the vast majority of services provided by companies and institutions as digital services. Industry 4.0 is the fourth industrial revolution where technologies and automation are asserting themselves as major changes. Robotic Process Automation (RPA) has numerous advantages in terms of automating organizational and business processes. Allied to these advantages, the complementary use of Artificial Intelligence (AI) algorithms and techniques allows to improve the accuracy and execution of RPA processes in the extraction of information, in the recognition, classification, forecasting and optimization of processes. In this context, this paper aims to present a study of the RPA tools associated with AI that can contribute to the improvement of the organizational processes associated with Industry 4.0. It appears that the RPA tools enhance their functionality with the objectives of AI being extended with the use of Artificial Neural Network algorithms, Text Mining techniques and Natural Language Processing techniques for the extraction of information and consequent process of optimization and of forecasting scenarios in improving the operational and business processes of organizations.",https://doi.org/10.1016/j.procs.2021.01.104,https://www.sciencedirect.com/science/article/pii/S1877050921001393,,,,2021,Robotic Process Automation and Artificial Intelligence in Industry 4.0 – A Literature review,Jorge Ribeiro and Rui Lima and Tiago Eckhardt and Sara Paiva,article,RIBEIRO202151,Procedia Computer Science,,181,1877-0509,"CENTERIS 2020 - International Conference on ENTERprise Information Systems / ProjMAN 2020 - International Conference on Project MANagement / HCist 2020 - International Conference on Health and Social Care Information Systems and Technologies 2020, CENTERIS/ProjMAN/HCist 2020",,
,"Commenter recommendation, Reviewer recommendation, Attribute selection, Pull-based software development",48-62,,"Context: The pull-based software development helps developers make contributions flexibly and efficiently. Commenters freely discuss code changes and provide suggestions. Core members make decision of pull requests. Both commenters and core members are reviewers in the evaluation of pull requests. Since some popular projects receive many pull requests, commenters may not notice new pull requests in time, and even ignore appropriate pull requests. Objective: Our objective in this paper is to analyze attributes that affect the precision and recall of commenter prediction, and choose appropriate attributes to build commenter recommendation approach. Method: We collect 19,543 pull requests, 206,664 comments and 4817 commenters from 8 popular projects in GitHub. We build approaches based on different attributes, including activeness, text similarity, file similarity and social relation. We also build composite approaches, including time-based text similarity, time-based file similarity and time-based social relation. The time-based social relation approach is the state-of-the-art approach proposed by Yu et al. Then we compare precision and recall of different approaches. Results: We find that for 8 projects, the activeness based approach achieves the top-3 precision of 0.276, 0.386, 0.389, 0.516, 0.322, 0.572, 0.428, 0.402, and achieves the top-3 recall of 0.475, 0.593, 0.613, 0.66, 0.644, 0.791, 0.714, 0.65, which outperforms approaches based on text similarity, file similarity or social relation by a substantial margin. Moreover, the activeness based approach achieves better precision and recall than composite approaches. In comparison with the state-of-the-art approach, the activeness based approach improves the top-3 precision by 178.788%, 30.41%, 25.08%, 41.76%, 49.07%, 32.71%, 25.15%, 78.67%, and improves the top-3 recall by 196.875%, 36.32%, 29.05%, 46.02%, 43.43%, 27.79%, 25.483%, 79.06% for 8 projects. Conclusion: The activeness is the most important attribute in the commenter prediction. The activeness based approach can be used to improve the commenter recommendation in code review.",https://doi.org/10.1016/j.infsof.2016.10.006,https://www.sciencedirect.com/science/article/pii/S095058491630283X,,,,2017,Who should comment on this pull request? Analyzing attributes for more accurate commenter recommendation in pull-based development,Jing Jiang and Yun Yang and Jiahuan He and Xavier Blanc and Li Zhang,article,JIANG201748,Information and Software Technology,,84,0950-5849,,,
,"CAPTCHA, Island Problem, Depth-first Search, Security, Convolutional Neural Network",107593,,"CAPTCHA stands for Completely Automated Public Turing Test to Tell Computers and Humans Apart. CAPTCHAs are used as security mechanism in web applications to differentiate between real users and automated users, also known as bots. Text-based CAPTCHAs are the popularly used CAPTCHA schemes due to their simplicity and thus, they are still being used despite the proposal of several attack mechanisms. In this work, the authors have proposed a novel approach to solve CAPTCHA schemes. In this approach, the authors have used Depth First Search algorithm for the extraction of characters from CAPTCHAs and Convolutional Neural Network for recognizing these extracted characters. The proposed approach was validated on 3000+ CAPTCHA schemes and proved to be efficient by providing an average accuracy of more than 92.0% in detecting CAPTCHA schemes.",https://doi.org/10.1016/j.compeleceng.2021.107593,https://www.sciencedirect.com/science/article/pii/S0045790621005292,,,,2022,De-CAPTCHA: A novel DFS based approach to solve CAPTCHA schemes,Aditya Atri and Ankita Bansal and Manju Khari and S. Vimal,article,ATRI2022107593,Computers & Electrical Engineering,,97,0045-7906,,,
,"Botnet, Bot detection, DNS-based bot detection, Anomaly detection, ELK stack, Machine learning, Isolation forests, Random forests",109725,,"In today’s cyberattacks, botnets are used as an advanced technique to generate sophisticated and coordinated attacks. Infected systems connect to a command and control (C&C) server to receive commands and attack. Thus, detecting infected hosts makes it possible to protect the network’s resources and prevent them from illicit activities toward third parties. This research elaborates on the design, implementation, and results of a bot infection detection system based on Domain Name System (DNS) traffic events for a network corporation. An infection detection feasibility analysis is performed by creating fingerprints. The traces are generated from a numerical analysis of 13 attributes. These attributes are obtained from the DNS logs of a DNS server. It looks for fingerprint anomalies using Isolation Forest to label a host as infected or not. In addition, on the traces cataloged as anomalous, a search will be carried out for queries to domains generated by Domain Generation Algorithms (DGA). Then, Random Forest generates a model that detects future bot infections on hosts. The devised system integrates the ELK stack and Python. This integration facilitates the management, transformation, and storage of events, generation of fingerprints, machine learning application, and analysis of fingerprint classification results with a precision greater than 99%.",https://doi.org/10.1016/j.comnet.2023.109725,https://www.sciencedirect.com/science/article/pii/S1389128623001706,,,,2023,Real-time bot infection detection system using DNS fingerprinting and machine-learning,Vicente Quezada and Fabian Astudillo-Salinas and Luis Tello-Oquendo and Paul Bernal,article,QUEZADA2023109725,Computer Networks,,228,1389-1286,,,
,"Systematic mapping study, Technical debt, Technical debt management, Tools, Automation",107375,,"Context:
Technical debt (TD) refers to non-optimal decisions made in software projects that may lead to short-term benefits, but potentially harm the system’s maintenance in the long-term. Technical debt management (TDM) refers to a set of activities that are performed to handle TD, e.g., identification or measurement of TD. These activities typically entail tasks such as code and architectural analysis, which can be time-consuming if done manually. Thus, substantial research work has focused on automating TDM tasks (e.g., automatic identification of code smells). However, there is a lack of studies that summarize current approaches in TDM automation. This can hinder practitioners in selecting optimal automation strategies to efficiently manage TD. It can also prevent researchers from understanding the research landscape and addressing the research problems that matter the most.
Objectives:
The main objective of this study is to provide an overview of the state of the art in TDM automation, analyzing the available tools, their use, and the challenges in automating TDM.
Methods:
We conducted a systematic mapping study (SMS), following the guidelines proposed by Kitchenham et al. From an initial set of 1086 primary studies, 178 were selected to answer three research questions covering different facets of TDM automation.
Results:
We found 121 automation artifacts that can be used to automate TDM activities. The artifacts were classified in 4 different types (i.e., tools, plugins, scripts, and bots); the inputs/outputs and interfaces were also collected and reported. Finally, a conceptual model is proposed that synthesizes the results and allows to discuss the current state of TDM automation and related challenges.
Conclusion:
The research community has investigated to a large extent how to perform various TDM activities automatically, considering the number of studies and automation artifacts we identified. Nonetheless, more research is needed towards fully automated TDM, specially concerning the integration of the automation artifacts.",https://doi.org/10.1016/j.infsof.2023.107375,https://www.sciencedirect.com/science/article/pii/S0950584923002306,,,,2024,Technical debt management automation: State of the art and future perspectives,João Paulo Biazotto and Daniel Feitosa and Paris Avgeriou and Elisa Yumi Nakagawa,article,BIAZOTTO2024107375,Information and Software Technology,,167,0950-5849,,,
,"Discussion re-organization, GitHub, Issue, Deep learning",120024,,"As a popular social code hosting platform, GitHub encourages developers to discuss and leave opinions on issues. However, the linear format of GitHub issue discussions makes popular discussions difficult for developers to organize and extract useful information effectively. In this paper, we propose an issue discussion re-organization approach, aiming at converting an issue discussion with the linear structure into a discussion tree with key information. First, we conduct a motivational study to investigate the current situation of issue discussions in GitHub. Further, to re-organize discussion structures, we employ a Transformer-based model with transfer learning to predict the response relationship between comments for re-building structures and utilize TF–IDF to extract key information from the content with different topics. The experimental results show that our approach outperforms other baselines, and achieves an average improvement of 14.54% on metrics in the task of predicting response relationships, as well as getting an average improvement of 27.19% in terms of metrics of the re-organizing task. To investigate our re-organized results from actual perspectives, we also conduct a human evaluation. The results show that our approach can predict the accurate response relationships for 80.74% of comments from actual perspectives and 63% of topics extracted by our approach are highly rated. Moreover, 90.00% of newcomers from the open-source community approve of re-organized discussion structures.",https://doi.org/10.1016/j.eswa.2023.120024,https://www.sciencedirect.com/science/article/pii/S0957417423005262,,,,2023,Automating discussion structure re-organization for GitHub issues,Shuotong Bai and Lei Liu and Chenkun Meng and Huaxiao Liu,article,BAI2023120024,Expert Systems with Applications,,225,0957-4174,,,
,"kairos, metanoia, GamerGate, bots, social media",118-138,,"This article examines the unique rhetorical affordances of Twitter bots as a way to offer student writers the kairotic means of understanding how networked writing functions in social media public spheres. Specifically, this article discusses how to theorize and construct protest bots in the ad hoc and post hoc Twitter publics of the GamerGate controversy. In addition to kairos, we suggest that the supplementary concept of metanoia offers a highly relevant lens to understand Twitter bots' anonymity and persistence in relationship to the ways in which publics spheres adapt and change over time.",https://doi.org/10.1016/j.compcom.2018.03.010,https://www.sciencedirect.com/science/article/pii/S875546151730049X,,,,2018,Cultivating Metanoia in Twitter Publics: Analyzing and Producing Bots of Protest in the #GamerGate Controversy,Steve Holmes and Rachael Graham Lussos,article,HOLMES2018118,Computers and Composition,,48,8755-4615,,,
,"Socio-smells, Socio-technical smells, Mining-software-repositories, Gitlog, Mailing-list, Issue-tracker, Identity-matching, Networks, Tools",111967,,"Context:
An extensive body of work has examined socio-technical activities in software development; however, the availability of tools to enable these studies is limited.
Aim:
We extend Kaiaulu, a software package for Mining Software Repositories to enable a broad spectrum analysis of Social Smells and Motifs.
Methods:
We perform a literature review to identify what tools are available which implement graph construction methods and social smell metrics, contextualizing the contributions of our tool.
Results:
The few tools identified in the literature either leverage fewer parts of the software ecosystem, have been archived, or depend on components no longer maintained.
Conclusion:
The socio-technical features in Kaiaulu complement existing tools and related literature, while providing a simple architecture to facilitate ease or use, and ease of learning, benefitting reproducibility.
Tool Repository:
github.com/sailuh/kaiaulu",https://doi.org/10.1016/j.jss.2024.111967,https://www.sciencedirect.com/science/article/pii/S0164121224000104,,,,2024,Analyzing the Tower of Babel with Kaiaulu,Carlos Paradis and Rick Kazman and Damian Tamburri,article,PARADIS2024111967,Journal of Systems and Software,,210,0164-1212,,,
,"Test amplification, Mutation testing, Continuous integration, Crash recovery, Pharo smalltalk",101255,,"Test amplification exploits the knowledge embedded in an existing test suite to strengthen it. A typical test amplification technique transforms the initial tests into additional test methods that increase the mutation coverage. Although past research demonstrated the benefits, additional steps need to be taken to incorporate test amplifiers in the everyday workflow of developers. This paper describes a proof-of-concept bot integrating Small-Amp with GitHub-Actions. The bot decides for itself which tests to amplify and does so within a limited time budget. To integrate the bot into the GitHub-Actions workflow, we incorporate three special-purpose features: (i) prioritization (to fit the process within a given time budget), (ii) sharding (to split lengthy tests into smaller chunks), and (iii) sandboxing (to make the amplifier crash-resilient). We evaluate our approach by installing the proof-of-concept extension of Small-Amp on five open-source projects deployed on GitHub. Our results show that a test amplification bot is feasible at a project level by integrating it into the build system. Moreover, we quantify the impact of prioritization, sharding, and sandboxing so that other test amplifiers may benefit from these special-purpose features. Our proof-of-concept demonstrates that the entry barrier for adopting test amplification can be significantly lowered.",https://doi.org/10.1016/j.cola.2023.101255,https://www.sciencedirect.com/science/article/pii/S2590118423000655,,,,2024,A test amplification bot for Pharo/Smalltalk,Mehrdad Abdi and Henrique Rocha and Alexandre Bergel and Serge Demeyer,article,ABDI2024101255,Journal of Computer Languages,,78,2590-1184,,,
,"DGA botnets datasets, DGA botnet detection, DGA botnet classification, Feature extraction, Machine learning",109508,,"The DGA botnet prevention is a burning topic in cybersecurity, with two problems: detection and classification. The DGA botnet dataset plays an essential role in the research allowing researchers to evaluate their proposed solutions. This study introduces a new dataset on DGA botnets named UTL_DGA22. Our proposed dataset not only inherits previous datasets' results but also has got own advantages. First, our new dataset includes only domain records and no other raw network traffic, helping to address the DGA botnet problem. Second, we removed duplicated botnet DGA families and added new botnet families for a total of 76 DGA botnet families presented. Third, we propose a valuable set of attributes as input for classification algorithms. Our experiments using the proposed features with several machine learning algorithms have had good results. It shows that our proposed attributes are firmly suitable for the input of the DGA botnet solution. Finally, we carefully compiled the dataset and attribute description documents to make it easy for researchers to use. The UTL_DGA22 dataset can serve as a database for researchers to develop their algorithms while objectively evaluating different solutions.",https://doi.org/10.1016/j.comnet.2022.109508,https://www.sciencedirect.com/science/article/pii/S1389128622005424,,,,2023,UTL_DGA22 - a dataset for DGA botnet detection and classification,Tong Anh Tuan and Nguyen Viet Anh and Tran Thi Luong and Hoang Viet Long,article,TUAN2023109508,Computer Networks,,221,1389-1286,,,
,"Augmented reality, Cloud, Chat bot, Human, API",4254-4257,,"A chat is a program that simulates the conversation with humans through text or voice commands. Now days, every company or organization is trying to reduce the manpower in many ways to gain some more profits and to increase the efficiency of the output. Chabot is one of the way to reduce the manpower and to reduce the human intervention. In early days websites and organizations use people to guide their clients and users to their respective outcome. But now days to reduce the manpower organizations are using the chatbots to interact their clients. In our paper, we want to create a chatbot using Augmented Reality and using cloud technologies. Our theme is to create a chatbot which interact with humans like there is another human talking to him and to increase interaction. This makes the organization to produce more accurate results for their clients and uses less human power.",https://doi.org/10.1016/j.matpr.2021.03.058,https://www.sciencedirect.com/science/article/pii/S2214785321020721,,,,2021,Augment reality chatbot using cloud,Viswanath Matukumalli and Sai {Naga Sasidhar Maddi} and Kushwanth {Krishna Angirekula} and Vivek {Reddy Pulicherla} and A.M. {Senthil kumar} and T. Maridurai and T. Sathish and D. Kasinathan,article,MATUKUMALLI20214254,Materials Today: Proceedings,,46,2214-7853,"International Conference on Materials, Manufacturing and Mechanical Engineering for Sustainable Developments-2020 (ICMSD 2020)",,
,"Charophyta, streptophyte algae, multicellularity, phylogenomics, plant terrestrialization, plant evolution, ancestral character state",670-681.e7,,"Summary
Streptophytes are best known as the clade containing the teeming diversity of embryophytes (land plants).1,2,3,4 Next to embryophytes are however a range of freshwater and terrestrial algae that bear important information on the emergence of key traits of land plants. Among these, the Klebsormidiophyceae stand out. Thriving in diverse environments—from mundane (ubiquitous occurrence on tree barks and rocks) to extreme (from the Atacama Desert to the Antarctic)—Klebsormidiophyceae can exhibit filamentous body plans and display remarkable resilience as colonizers of terrestrial habitats.5,6 Currently, the lack of a robust phylogenetic framework for the Klebsormidiophyceae hampers our understanding of the evolutionary history of these key traits. Here, we conducted a phylogenomic analysis utilizing advanced models that can counteract systematic biases. We sequenced 24 new transcriptomes of Klebsormidiophyceae and combined them with 14 previously published genomic and transcriptomic datasets. Using an analysis built on 845 loci and sophisticated mixture models, we establish a phylogenomic framework, dividing the six distinct genera of Klebsormidiophyceae in a novel three-order system, with a deep divergence more than 830 million years ago. Our reconstructions of ancestral states suggest (1) an evolutionary history of multiple transitions between terrestrial-aquatic habitats, with stem Klebsormidiales having conquered land earlier than embryophytes, and (2) that the body plan of the last common ancestor of Klebsormidiophyceae was multicellular, with a high probability that it was filamentous whereas the sarcinoids and unicells in Klebsormidiophyceae are likely derived states. We provide evidence that the first multicellular streptophytes likely lived about a billion years ago.",https://doi.org/10.1016/j.cub.2023.12.070,https://www.sciencedirect.com/science/article/pii/S0960982223017700,,,,2024,Phylogenomic insights into the first multicellular streptophyte,Maaike J. Bierenbroodspot and Tatyana Darienko and Sophie {de Vries} and Janine M.R. Fürst-Jansen and Henrik Buschmann and Thomas Pröschold and Iker Irisarri and Jan {de Vries},article,BIERENBROODSPOT2024670,Current Biology,3,34,0960-9822,,,
,"Experimental economics, Software, Laboratory experiments, Field experiments, Online experiments, Classroom experiments",88-97,,"oTree is an open-source and online software for implementing interactive experiments in the laboratory, online, the field or combinations thereof. oTree does not require installation of software on subjects’ devices; it can run on any device that has a web browser, be that a desktop computer, a tablet or a smartphone. Deployment can be internet-based without a shared local network, or local-network-based even without internet access. For coding, Python is used, a popular, open-source programming language. www.oTree.org provides the source code, a library of standard game templates and demo games which can be played by anyone.",https://doi.org/10.1016/j.jbef.2015.12.001,https://www.sciencedirect.com/science/article/pii/S2214635016000101,,,,2016,"oTree—An open-source platform for laboratory, online, and field experiments",Daniel L. Chen and Martin Schonger and Chris Wickens,article,CHEN201688,Journal of Behavioral and Experimental Finance,,9,2214-6350,,,
,"Network representation learning, Network embedding, Social bot detection, Random walk",101771,,"Recently, due to the rapid growth of online social networks (OSNs) such as Facebook, Twitter, Weibo, etc. the number of machine accounts/social bots that mimic human users has increased. Along with the development of artificial intelligence (AI), social bots are designed to become smarter and more sophisticated in their efforts at replicating the normal behaviors of human accounts. Constructing reliable and effective bot detection mechanisms is this considered crucial to keep OSNs clean and safe for users. Despite the rapid development of social bot detection platforms, recent state-of-the-art systems still encounter challenges which are related to the model’s generalization (and whether it can be adaptable for multiple types of OSNs) as well as the great efforts needed for feature engineering. In this paper, we propose a novel approach of applying network representation learning (NRL) to bot/spammer detection, called Bot2Vec. Our proposed Bot2Vec model is designed to automatically preserve both local neighborhood relations and the intra-community structure of user nodes while learning the representation of given OSNs, without using any extra features based on the user’s profile. By applying the intra-community random walk strategy, Bot2Vec promises to achieve better user node embedding outputs than recent state-of-the-art network embedding baselines for bot detection tasks. Extensive experiments on two different types of real-word social networks (Twitter and Tagged) demonstrate the effectiveness of our proposed model. The source code for implementing the Bot2Vec model is available at: https://github.com/phamtheanhphu/bot2vec",https://doi.org/10.1016/j.is.2021.101771,https://www.sciencedirect.com/science/article/pii/S0306437921000302,,,,2022,Bot2Vec: A general approach of intra-community oriented representation learning for bot detection in different types of social networks,Phu Pham and Loan T.T. Nguyen and Bay Vo and Unil Yun,article,PHAM2022101771,Information Systems,,103,0306-4379,,,
,"Artificial intelligence, Natural language processing, Quality assurance audit, NHS, Gynaecological oncology",105306,,"Background
The British Gynaecological Cancer Society (BGCS) has highlighted the disparity of ovarian cancer outcomes in the UK compared to other European countries. Therefore, cancer quality assurance audits and subspecialty training are important in improving the UK standard of care for these patients. The current workforce crisis afflicting the NHS creates difficulty in dedicating teams of clinicians to these audits. We present a single institution study to evaluate if NLP-generated code can improve the efficiency of ovarian cancer and subspeciality reaccreditations audits. We used the chat bot Google Bard to write Visual Basic Applications algorithms that utilise Excel files from electronic health records.
Methods
Primary ovarian cancer data from 2019 to 2022 was retrospectively collected from the Cambridge University Hospital electronic health records. The surgical subspecialty reaccreditation audit analysed the 2022 surgical database. A modular coding approach with Google Bard was applied to generate audit algorithms. The time to complete these current audits was compared against the 2016 ovarian cancer and 2020 subspeciality reaccreditation audits.
Results
The previous ovarian cancer audit conducted in 2016 required 3 clinicians for the 135 cases and data collection required 1800 min. Data analysis was completed in 300 min. The current ovarian cancer audit allocated 2 clinicians to the 600 surgical cases. Data collection was completed in 3120 min, 3360 min for code development and 720 min for testing. The 2020 subspecialty reaccreditation audit was completed in 360 min. The 2022 subspecialty reaccreditation audit was completed in 1680 min, with 960 min for code development, 240 for debugging and 480 min for testing.
Conclusion
We have demonstrated that NLP-generated code can significantly increase the efficiency of surgical quality assurance audits by eliminating the need for manual data analysis. With the current trajectory of NLP development, increasingly complex algorithms can be developed with minimal programming knowledge.",https://doi.org/10.1016/j.ijmedinf.2023.105306,https://www.sciencedirect.com/science/article/pii/S1386505623003246,,,,2024,Can natural language processing be effectively applied for audit data analysis in gynaecological oncology at a UK cancer centre?,Mark McGowan and Filipe {Correia Martins} and Jodi-Louise Keen and Amelia Whitehead and Ellie Davis and Pubudu Pathiraja and Helen Bolton and Peter Baldwin,article,MCGOWAN2024105306,International Journal of Medical Informatics,,182,1386-5056,,,
,"ChatGPT, Code classification, CodeBERT, Pre-trained Models",112059,,"Since its launch in November 2022, ChatGPT has gained popularity among users, especially programmers who use it to solve development issues. However, while offering a practical solution to programming problems, ChatGPT should be used primarily as a supporting tool (e.g., in software education) rather than as a replacement for humans. Thus, detecting automatically generated source code by ChatGPT is necessary, and tools for identifying AI-generated content need to be adapted to work effectively with code. This paper presents GPTSniffer– a novel approach to the detection of source code written by AI – built on top of CodeBERT. We conducted an empirical study to investigate the feasibility of automated identification of AI-generated code, and the factors that influence this ability. The results show that GPTSniffer can accurately classify whether code is human-written or AI-generated, outperforming two baselines, GPTZero and OpenAI Text Classifier. Also, the study shows how similar training data or a classification context with paired snippets helps boost the prediction. We conclude that GPTSniffer can be leveraged in different contexts, e.g., in software engineering education, where teachers use the tool to detect cheating and plagiarism, or in development, where AI-generated code may require peculiar quality assurance activities.",https://doi.org/10.1016/j.jss.2024.112059,https://www.sciencedirect.com/science/article/pii/S0164121224001043,,,,2024,GPTSniffer: A CodeBERT-based classifier to detect source code written by ChatGPT,Phuong T. Nguyen and Juri {Di Rocco} and Claudio {Di Sipio} and Riccardo Rubei and Davide {Di Ruscio} and Massimiliano {Di Penta},article,NGUYEN2024112059,Journal of Systems and Software,,214,0164-1212,,,
,"Honeypot, Honeypot framework, Cybersecurity, Threat intelligence",103737,,"Automated attacks allow adversaries to exploit vulnerabilities in enterprise IT systems at short notice. To identify such attacks as well as new cybersecurity threats, defenders use honeypot systems; these monitored decoy resources mimic legitimate devices to entice adversaries. The domain of enterprise IT honeypots has been an active area of development and research, especially in the open-source community. In this work, we survey open-source honeypots, honeypot frameworks, and tools that help to develop or discover honeypot deployments. In contrast to existing surveys, our work provides a detailed discussion of the honeypots’ system architecture, software architecture, and cloud-native deployment options. In addition, we cover the most recent academic research in honeypot detection and evasion techniques, and discuss how these advances impact current open-source honeypots. This work helps the reader to make an educated choice when selecting a honeypot for deployment or further development.",https://doi.org/10.1016/j.jnca.2023.103737,https://www.sciencedirect.com/science/article/pii/S108480452300156X,,,,2023,"A survey of contemporary open-source honeypots, frameworks, and tools",Niclas Ilg and Paul Duplys and Dominik Sisejkovic and Michael Menth,article,ILG2023103737,Journal of Network and Computer Applications,,220,1084-8045,,,
,"Botnet detection, Bot detection, DNS fingerprinting, Machine learning, Anomaly detection",14-33,,"The never-ending menace of botnet is causing many serious problems on the Internet. Although there are significant efforts on detecting botnet at the global level which rely heavily on finding failed queries and domain flux information for botnet detection, there are very few efforts being made to detect bot infection at an enterprise level. Detecting bot-infected machines is vital for any organization in combating various security threats. This work proposes a novel anomaly-based detection technique which considers hourly hosts DNS fingerprint and attempts to find anomalous behavior which is quite different from normal machine behavior. This work successfully demonstrates the DNS Anomaly Detection (named BotDAD) technique for detecting bot-infected machine in a network using DNS fingerprinting.",https://doi.org/10.1016/j.diin.2018.12.005,https://www.sciencedirect.com/science/article/pii/S174228761830272X,,,,2019,Detecting bot-infected machines using DNS fingerprinting,Manmeet Singh and Maninder Singh and Sanmeet Kaur,article,SINGH201914,Digital Investigation,,28,1742-2876,,,
,"Change intent analysis, Review effort, Machine learning",106408,,"Context: Code changes to software occur due to various reasons such as bug fixing, new feature addition, and code refactoring. Change intents have been studied for years to help developers understand the rationale behind code commits. However, in most existing studies, the intent of the change is rarely leveraged to provide more specific, context aware analysis. Objective: In this paper, we present the first study to leverage change intent to characterize and identify Large-Review-Effort (LRE) changes—changes with large review effort. Method: Specifically, we first propose a feedback-driven and heuristics-based approach to identify change intents of code changes. We then characterize the changes regarding review effort by using various features extracted from change metadata and the change intents. We further explore the feasibility of automatically classifying LRE changes. We conduct our study on four large-scale projects, one from Microsoft and three are open source projects, i.e., Qt, Android, and OpenStack. Results: Our results show that, (i) code changes with some intents (i.e., Feature and Refactor) are more likely to be LRE changes, (ii) machine learning based prediction models are applicable for identifying LRE changes, and (iii) prediction models built for code changes with some intents achieve better performance than prediction models without considering the change intent, the improvement in AUC can be up to 19 percentage points and is 7.4 percentage points on average. Conclusion: The change intent analysis and its application on LRE identification proposed in this study has already been used in Microsoft to provide the review effort and intent information of changes for reviewers to accelerate the review process. To show how to deploy our approaches in real-world practice, we report a case study of developing and deploying the intent analysis system in Microsoft. Moreover, we also evaluate the usefulness of our approaches by using a questionnaire survey. The feedback from developers demonstrate its practical value.",https://doi.org/10.1016/j.infsof.2020.106408,https://www.sciencedirect.com/science/article/pii/S0950584920300033,,,,2021,Large-scale intent analysis for identifying large-review-effort code changes,Song Wang and Chetan Bansal and Nachiappan Nagappan,article,WANG2021106408,Information and Software Technology,,130,0950-5849,,,
,"Ensemble learning, Aggregation function, Distributivity equation, Machine learning, Classification measure, Cybersecurity",109015,,"With the growing complexity and frequency of cyber threats, there is a pressing need for more effective defense mechanisms. Machine learning offers the potential to analyze vast amounts of data and identify patterns indicative of malicious activity, enabling faster and more accurate threat detection. Ensemble methods, by incorporating diverse models with varying vulnerabilities, can increase resilience against adversarial attacks. This study covers the usage and evaluation of the relevance of an innovative approach of ensemble classification for identifying intrusion threats on a large CICIDS2017 dataset. The approach is based on the distributivity equation that appropriately aggregates the underlying classifiers. It combines various standard supervised classification algorithms, including Multilayer Perceptron Network, k-Nearest Neighbors, and Naive Bayes, to create an ensemble. Experiments were conducted to evaluate the effectiveness of the proposed hybrid ensemble method. The performance of the ensemble approach was compared with individual classifiers using measures such as accuracy, precision, recall, F-score, and area under the ROC curve. Additionally, comparisons were made with widely used state-of-the-art ensemble models, including the soft voting method (Weighted Average Probabilities), Adaptive Boosting (AdaBoost), and Histogram-based Gradient Boosting Classification Tree (HGBC) and with existing methods in the literature using the same dataset, such as Deep Belief Networks (DBN), Deep Feature Learning via Graph (Deep GFL). Based on these experiments, it was found that some ensemble methods, such as AdaBoost and Histogram-based Gradient Classification Tree, do not perform reliably for the specific task of identifying network attacks. This highlights the importance of understanding the context and requirements of the data and problem domain. The results indicate that the proposed hybrid ensemble method outperforms traditional algorithms in terms of classification precision and accuracy, and offers insights for improving the effectiveness of intrusion detection systems.",https://doi.org/10.1016/j.fss.2024.109015,https://www.sciencedirect.com/science/article/pii/S0165011424001611,,,,2024,Effectiveness of an ensemble technique based on the distributivity equation in detecting suspicious network activity,Ewa Rak and Jaromir Sarzyński and Rafał Rak,article,RAK2024109015,Fuzzy Sets and Systems,,488,0165-0114,,,
,"Social bots detection, Social bots classification, Machine learning, Sentiment analysis, Social network analysis",106047,,"The term social bots refer to software-controlled accounts that actively participate in the social platforms to influence public opinion toward desired directions. To this extent, this data descriptor presents a Twitter dataset collected from October 4th to November 11th, 2019, within the context of the Spanish general election. Starting from 46 hashtags, the collection contains almost eight hundred thousand users involved in political discussions, with a total of 5.8 million tweets. The proposed data descriptor is related to the research article available at [1]. Its main objectives are: i) to enable worldwide researchers to improve the data gathering, organization, and preprocessing phases; ii) to test machine-learning-powered proposals; and, finally, iii) to improve state-of-the-art solutions on social bots detection, analysis, and classification. Note that the data are anonymized to preserve the privacy of the users. Throughout our analysis, we enriched the collected data with meaningful features in addition to the ones provided by Twitter. In particular, the tweets collection presents the tweets’ topic mentions and keywords (in the form of political bag-of-words), and the sentiment score. The users’ collection includes one field indicating the likelihood of one account being a bot. Furthermore, for those accounts classified as bots, it also includes a score that indicates the affinity to a political party and the followers/followings list.",https://doi.org/10.1016/j.dib.2020.106047,https://www.sciencedirect.com/science/article/pii/S2352340920309410,,,,2020,Twitter social bots: The 2019 Spanish general election data,Javier Pastor-Galindo and Mattia Zago and Pantaleone Nespoli and Sergio {López Bernal} and Alberto {Huertas Celdrán} and Manuel {Gil Pérez} and José A. Ruipérez-Valiente and Gregorio {Martínez Pérez} and Félix {Gómez Mármol},article,PASTORGALINDO2020106047,Data in Brief,,32,2352-3409,,,
,"Empirical software engineering, GitHub contributors, Software metrics, Experienced developers, Software architecture, Java, Spring, Maven",108842,,"Developers are extracted from 17 open-source projects from GitHub. Projects are chosen that use the java programming language, the Spring framework and Maven/Gradle build tools. Along with these developers, 24 software engineering metrics are extracted for each of them. These metrics are either calculated by analyzing the source code or relative to project management metadata. Each of these developers then are manually searched for in professional social media such as LinkedIn or Twitter to be labeled with their experience level in their project. Outliers are statistically detected and manually re-assigned when needed. The resulting dataset contains 703 anonymized developers qualified by their 24 project-related software engineering metrics and labeled for their experience. It is suitable for empirical software engineering studies that need to connect developers’ level of experience to tangible software engineering metrics.",https://doi.org/10.1016/j.dib.2022.108842,https://www.sciencedirect.com/science/article/pii/S2352340922010459,,,,2023,Dataset of open-source software developers labeled by their experience level in the project and their associated software metrics,Quentin Perez and Christelle Urtado and Sylvain Vauttier,article,PEREZ2023108842,Data in Brief,,46,2352-3409,,,
,"Education, Publication metrics, Dental education, Research grants, Research metrics",,,"This comprehensive manuscript endeavors to furnish orthodontic researchers with the necessary tools and knowledge to adeptly navigate the multifaceted landscape of academic publishing, thereby enhancing the efficacy and reach of their scholarly endeavors. It meticulously imparts critical insights and methodologies for comprehending and leveraging publication metrics, such as citation counts, the h-index, and Journal Impact Factors, to strategically plan research trajectories. Furthermore, it offers guidance on adeptly engaging with evaluation agencies such as the American Dental Association (ADA) and the National Institute of Dental and Craniofacial Research (NIDCR), thereby optimizing alignment with grant opportunities. Through the adept utilization of orthodontic bibliometrics, researchers can gain invaluable insights into prevailing collaboration trends and emerging research domains, thus facilitating informed decision-making and prioritization of scholarly pursuits. Additionally, the manuscript delves into the nuanced optimization of publication guidelines to maximize research impact. Spanning both established domains such as biomechanics, anchorage control, and aligner therapy, as well as burgeoning frontiers including 3D printing and artificial intelligence applications in aligner treatment, this manuscript equips orthodontic researchers with the requisite acumen to embark upon a journey of impactful scholarly contributions, thereby catalyzing advancements in patient care within the discipline.",https://doi.org/10.1053/j.sodo.2024.05.013,https://www.sciencedirect.com/science/article/pii/S1073874624000744,,,,2024,Understanding nuances of scholarly publishing in orthodontics: A comprehensive guide,Narayan H. Gandedkar and Veerasathpurush Allareddy and Nikhilesh R. Vaiid,article,GANDEDKAR2024,Seminars in Orthodontics,,,1073-8746,,,
,"Software documentation, Open science, Open access, Traceability",111117,,"Traceability between published scientific breakthroughs and their implementation is essential, especially in the case of open-source scientific software which implements bleeding-edge science in its code. However, aligning the link between GitHub repositories and academic papers can prove difficult, and the current practice of establishing and maintaining such links remains unknown. This paper investigates the role of academic paper references contained in these repositories. We conduct a large-scale study of 20 thousand GitHub repositories that make references to academic papers. We use a mixed-methods approach to identify public access, traceability and evolutionary aspects of the links. Although referencing a paper is not typical, we find that a vast majority of referenced academic papers are public access. These repositories tend to be affiliated with academic communities. More than half of the papers do not link back to any repository. We find that academic papers from top-tier SE venues are not likely to reference a repository, but when they do, they usually link to a GitHub software repository. In a network of arXiv papers and referenced repositories, we find that the most referenced papers are (i) highly-cited in academia and (ii) are referenced by repositories written in different programming languages.",https://doi.org/10.1016/j.jss.2021.111117,https://www.sciencedirect.com/science/article/pii/S0164121221002144,,,,2022,"GitHub repositories with links to academic papers: Public access, traceability, and evolution",Supatsara Wattanakriengkrai and Bodin Chinthanet and Hideaki Hata and Raula Gaikovina Kula and Christoph Treude and Jin Guo and Kenichi Matsumoto,article,WATTANAKRIENGKRAI2022111117,Journal of Systems and Software,,183,0164-1212,,,
,"Cyber-physical systems, Runtime monitoring, Model-driven engineering",111733,,"Runtime monitoring is critical for ensuring safe operation and for enabling self-adaptive behavior of Cyber-Physical Systems (CPS). Monitors are established by identifying runtime properties of interest, creating probes to instrument the system, and defining constraints to be checked at runtime. For many systems, implementing and setting up a monitoring platform can be tedious and time-consuming, as generic monitoring platforms do not adequately cover domain-specific monitoring requirements. This situation is exacerbated when the System under Monitoring (SuM) evolves, requiring changes in the monitoring platform. Most existing approaches lack support for the automated generation and setup of monitors for diverse technologies and do not provide adequate support for dealing with system evolution. In this paper, we present GRuM (Generating CPS Runtime Monitors), a framework that combines model-driven techniques and runtime monitoring, to automatically generate a customized monitoring platform for a given SuM. Relevant properties are captured in a Domain Model Fragment, and changes to the SuM can be easily accommodated by automatically regenerating the platform code. To demonstrate the feasibility and performance we evaluated GRuM against two different systems using TurtleBot robots and Unmanned Aerial Vehicles. Results show that GRuM facilitates the creation and evolution of a runtime monitoring platform with little effort and that the platform can handle a substantial amount of events and data.",https://doi.org/10.1016/j.jss.2023.111733,https://www.sciencedirect.com/science/article/pii/S0164121223001280,,,,2023,GRuM — A flexible model-driven runtime monitoring framework and its application to automated aerial and ground vehicles,Michael Vierhauser and Antonio Garmendia and Marco Stadler and Manuel Wimmer and Jane Cleland-Huang,article,VIERHAUSER2023111733,Journal of Systems and Software,,203,0164-1212,,,
,"GitHub, OpenMP, Software Statistics, Data Mining, Information Search",1261-1270,,"Writing scientific code usually implies the need to coordinate and conflate the contributions of several scientific programmers. Using Git hosting services eases this process, because the hosting services offer many features, which assist in collaborated work on code. The well-established hosting service GitHub has seen continuous growth in terms of number of users, repositories and commits over the last few years; therefore it offers a large data source of scientific codes as well as social interaction of associated scientific programmers. We present a tool, which allows to easily search through relevant GitHub repositories and perform more advanced analyses, which cannot be conducted solely with the GitHub API. Our tool combines benefits from online as well as offline approaches to retrieve and analyse data to optimise time of execution and consumption of storage. We discuss possible use cases and demonstrate the tool's capabilities by investigating the popularity of OpenMP directives in the scientific community.",https://doi.org/10.1016/j.procs.2022.09.182,https://www.sciencedirect.com/science/article/pii/S187705092201064X,,,,2022,Content queries and in-depth analysis on version-controlled software,Jannek Squar and Niclas Schroeter and Anna Fuchs and Michael Kuhn and Thomas Ludwig,article,SQUAR20221261,Procedia Computer Science,,207,1877-0509,Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 26th International Conference KES2022,,
,"Chatbots, Commercial, Lessons learned, DSL",103032,,"Chatbots are becoming a common component of many types of software systems. But they are typically developed as a side feature using ad-hoc tools and custom integrations. Moreover, current frameworks are efficient only when designing simple chatbot applications while they still require advanced technical knowledge to define complex interactions and are difficult to evolve along with the company needs. In addition, the deployment of a chatbot application usually requires a deep understanding of the targeted platforms, especially back-end connections, increasing the development and maintenance costs. In this paper, we discuss our experiences building, evolving and distributing the Xatkit framework. Xatkit is a model-based framework built around a Domain-Specific Language to define chatbots (and voicebots and bots in general) in a platform-independent way. Xatkit also comes with a runtime engine that automatically deploys the chatbot application and manages the defined conversation logic over the platforms of choice. Xatkit has significantly evolved since its initial release. This paper focuses on describing the evolution and the reasons (technical and non-technical) that triggered them. We believe our lessons learned can be useful to any other initiative trying to build a successful industrial-level chatbot platform, and in general, any type of model-based solution.",https://doi.org/10.1016/j.scico.2023.103032,https://www.sciencedirect.com/science/article/pii/S0167642323001144,,,,2024,Applying model-driven engineering to the domain of chatbots: The Xatkit experience,Gwendal Daniel and Jordi Cabot,article,DANIEL2024103032,Science of Computer Programming,,232,0167-6423,,,
,"Artificial intelligence, Computer vision, Object detection, Acupuncture, Patient safety",40-46,,"Objective
The unintentional retention of needles in patients can lead to severe consequences. To enhance acupuncture safety, the study aimed to develop a deep learning-based cloud system for automated process of counting acupuncture needles.
Methods
This project adopted transfer learning from a pre-trained Oriented Region-based Convolutional Neural Network (Oriented R-CNN) model to develop a detection algorithm that can automatically count the number of acupuncture needles in a camera picture. A training set with 590 pictures and a validation set with 1 025 pictures were accumulated for fine-tuning. Then, we deployed the MMRotate toolbox in a Google Colab environment with a NVIDIA Tesla T4 Graphics processing unit (GPU) to carry out the training task. Furthermore, we integrated the model with a newly-developed Telegram bot interface to determine the accuracy, precision, and recall of the needling counting system. The end-to-end inference time was also recorded to determine the speed of our cloud service system.
Results
In a 20-needle scenario, our Oriented R-CNN detection model has achieved an accuracy of 96.49%, precision of 99.98%, and recall of 99.84%, with an average end-to-end inference time of 1.535 s
Conclusion
The speed, accuracy, and reliability advancements of this cloud service system innovation have demonstrated its potential of using object detection technique to improve acupuncture practice based on deep learning.",https://doi.org/10.1016/j.dcmed.2024.04.005,https://www.sciencedirect.com/science/article/pii/S2589377724000235,,,,2024,A novel deep learning based cloud service system for automated acupuncture needle counting: a strategy to improve acupuncture safety,Tsz Ho Wong and Junyi Wei and Haiyong Chen and Bacon Fung Leung Ng,article,WONG202440,Digital Chinese Medicine,1,7,2589-3777,,,
,"Distributed Denial of Service (DDoS), Internet of Things (IoT), Botnets, Edge computing, Deep neural networks",108874,,"The growing number of IoT edge devices have inflicted a change in the cyber-attack space. The DDoS attacks, in particular, have significantly increased in magnitude and intensity. Of the existing DDoS solutions, while the destination-based defense mechanisms incur high false positives due to the seemingly legitimate nature of the attack traffic, defense mechanisms implemented at the source alone do not suffice due to the lack of visibility into ongoing DDoS attacks. This paper proposes a distributed DDoS detection and mitigation framework, SmartDefense, based on edge computing approaches towards detecting and mitigating DDoS attacks at and near the source. By mitigating the DDoS attacks near the source, SmartDefense significantly reduces unnecessary bandwidth otherwise consumed by DDoS traffic going from residential edge networks to the ISP edge network. Furthermore, SmartDefense demonstrates how ISPs can detect botnet devices in their customer’s network by having smart edge devices pass attributes that are processed by the botnet detection engine at the provider’s edge. The evaluation of this work shows that SmartDefense can improve the detection and mitigation rate, with over 90% of DDoS traffic caught at the source and over 97.5% of remaining DDoS traffic caught at the provider’s edge. Our experiments also demonstrate how using a botnet detection engine can further reduce the DDoS traffic by up to 51.95% by facilitating ISPs to detect bot devices in their customers’ edge network.",https://doi.org/10.1016/j.comnet.2022.108874,https://www.sciencedirect.com/science/article/pii/S1389128622000792,,,,2022,SmartDefense: A distributed deep defense against DDoS attacks with edge computing,Sowmya Myneni and Ankur Chowdhary and Dijiang Huang and Adel Alshamrani,article,MYNENI2022108874,Computer Networks,,209,1389-1286,,,
,,100555,,"- With the increase in the number of automobiles in urban cities, the number of accidents has increased manifold. Hence, the need for ambulances is increasing at an alarming rate. In order to increase the survival rates of the patients, an efficient communication of ambulances with the hospital and routing of the ambulances at the signal posts is very essential. Hence, the proposed architecture is distributed in nature. The system not only provides effective communication between the ambulance and the hospital but also helps the ambulance send the signal to nearby traffic signal posts to open up so that the ambulance can easily pass through saving ample amounts of time. The signal posts use a camera to detect the incoming ambulance and open up that lane so that the ambulance need not spend much time waiting for the traffic to get cleared.",https://doi.org/10.1016/j.measen.2022.100555,https://www.sciencedirect.com/science/article/pii/S2665917422001891,,,,2022,Adaptive ambulance monitoring system using IOT,S. Mahalakshmi and T. Ragunthar and N. Veena and S. Sumukha and Pranav R. Deshkulkarni,article,MAHALAKSHMI2022100555,Measurement: Sensors,,24,2665-9174,,,
,"Multidimensional time series, Shape-based clustering, Online popularity, Social media",113337,,"How is popularity gained online? Is being successful strictly related to rapidly becoming viral in an online platform, or is it possible to acquire popularity in a steady and disciplined fashion? What are other temporal characteristics that can unveil the popularity of online content? To answer these questions, we leverage a multifaceted temporal analysis of the evolution of popular online content. We present dipm-SC: a multidimensional shape-based time-series clustering algorithm with a heuristic to find the optimal number of clusters. First, we validate the accuracy of our algorithm on synthetic datasets generated from benchmark time series models. Second, we show that dipm-SC can uncover meaningful clusters of popularity behaviors in real-world GitHub and Twitter datasets. By clustering the multidimensional time-series of the popularity of contents coupled with other domain-specific dimensions, we discover two main patterns of popularity: bursty and steady temporal behaviors. Furthermore, we find that the way popularity is gained over time has no significant impact on the final cumulative popularity.",https://doi.org/10.1016/j.eswa.2020.113337,https://www.sciencedirect.com/science/article/pii/S0957417420301627,,,,2020,Discovering patterns of online popularity from time series,Mert Ozer and Anna Sapienza and Andrés Abeliuk and Goran Muric and Emilio Ferrara,article,OZER2020113337,Expert Systems with Applications,,151,0957-4174,,,
,"Event data behavioral analytics, Collaboration behavior, Mining resource behavior, Project mining, RFM, Social network analysis",106765,,"Organizations increasingly rely on teamwork to achieve their goals. Therefore they continuously strive to improve their teams as their performance is interwoven with that of the organization. To implement beneficial changes, accurate insights into the working of the team are necessary. However, team leaders tend to have an understanding of the team’s collaboration that is subjective and seldom completely accurate. Recently there has been an increase in the adoption of digital support systems for collaborative work that capture objective data on how the work took place in reality. This creates the opportunity for data-driven extraction of insights into the collaboration behavior of a team. This data however, does not explicitly record the collaboration relationships, which many existing techniques expect as input. Therefore, these relationships first have to be discovered. Existing techniques that apply discovery are not generally applicable because their notion of collaboration is tailored to the application domain. Moreover, the information that these techniques extract from the data about the nature of the relationships is often limited to the network level. Therefore, this research proposes a generic algorithm that can discover collaboration relationships between resources from event data on any collaborative project. The algorithm adopts an established framework to provide insights into collaboration on a fine-grained level. To this end, three properties are calculated for both the resources and their collaboration relationships: a recency, frequency, and monetary value. The technique’s ability to provide valuable insights into the team structure and characteristics is empirically validated on two use cases.",https://doi.org/10.1016/j.engappai.2023.106765,https://www.sciencedirect.com/science/article/pii/S0952197623009491,,,,2023,Mining Recency–Frequency–Monetary enriched insights into resources’ collaboration behavior from event data,Leen Jooken and Benoît Depaire and Mieke Jans,article,JOOKEN2023106765,Engineering Applications of Artificial Intelligence,,126,0952-1976,,,
,"Awareness, Unusual events, GitHub",237-247,,"In large and active software projects, it becomes impractical for a developer to stay aware of all project activity. While it might not be necessary to know about each commit or issue, it is arguably important to know about the ones that are unusual. To investigate this hypothesis, we identified unusual events in 200 GitHub projects using a comprehensive list of ways in which an artifact can be unusual and asked 140 developers responsible for or affected by these events to comment on the usefulness of the corresponding information. Based on 2,096 answers, we identify the subset of unusual events that developers consider particularly useful, including large code modifications and unusual amounts of reviewing activity, along with qualitative evidence on the reasons behind these answers. Our findings provide a means for reducing the amount of information that developers need to parse in order to stay up to date with development activity in their projects.",https://doi.org/10.1016/j.jss.2018.04.063,https://www.sciencedirect.com/science/article/pii/S0164121218300876,,,,2018,Unusual events in GitHub repositories,Christoph Treude and Larissa Leite and Maurício Aniche,article,TREUDE2018237,Journal of Systems and Software,,142,0164-1212,,,
,"Markets, Double auction, Competitive equilibrium, Efficiency, Inequality, Numerical experiments, Simulations",104729,,"We provide a dataset for our research article “Profitability, Efficiency and Inequality in Double Auction Markets with Snipers” [1]. This dataset [2] includes configuration files, raw output data, and replications of calculated metrics for our robot-populated market simulations. The raw data is subdivided into a hierarchy of folders corresponding to simulation treatment variables, in a 2 × 2 × 21 design for 84 treatments in total. Treatments variables include: (i) robot population ordering, either “primary” or “reverse”; (ii) two market schedules of agent's values and costs: equal-expected-profit “market 1” and unequal-expected-profit “market 2”; (iii) 21 robot populations identified by the number of Sniper Bots (0–20) on each side of the market. Each treatment directory contains a simulator input file and outputs for 10,000 periods of market data. The outputs include all acceptable buy and sell orders, all trades, profits for each agent, and market metrics such as efficiency-of-allocation, Gini coefficient, and price statistics. An additional public copy in Google Cloud is available for database query by users of Google BigQuery. The market simulator software is a private product created by Paul Brewer at Economic and Financial Technology Consulting LLC. Free open source modules are available for tech-savvy users at GitHub, NPM, and Docker Hub repositories and are sufficient to repeat the simulations. An easier-to-use paid market simulation product will eventually be available online from Econ1.Net. We provide instructions for repeating individual simulations using the free open source simulator and the free container tool Docker.",https://doi.org/10.1016/j.dib.2019.104729,https://www.sciencedirect.com/science/article/pii/S2352340919310844,,,,2019,Data and replication supplement for double auction markets with snipers,Paul Brewer and Anmol Ratan,article,BREWER2019104729,Data in Brief,,27,2352-3409,,,
,"Domain generation algorithm, Botnet, Machine learning, DNS query, Kullback-Leibner divergence, Jaccard Index",114551,,"Botnets are one of the major cyber infections used in several criminal activities. In most botnets, a Domain Generation Algorithm (DGA) is used by bots to make DNS queries aimed at establishing the connection with the Command and Control (C&C) server. The identification of such queries by monitoring the network DNS traffic is then crucial for bot detection. In this paper we present a methodology to detect DGA generated domain names based on a supervised machine learning process, trained with a dataset of known benign and malicious domain names. The proposed approach represents the domain names through a set of features which express the similarity between the 2-grams and 3-grams in a single unclassified domain name and those in domain names known as malicious or benign. We used the Kullback-Leibner divergence and the Jaccard Index to estimate the similarity, and we tested different machine learning algorithms to classify each domain name as benign or DGA-based (with both binary and multi-class approach). The results of our experiments demonstrate that the proposed methodology, which only exploits lexical features of domain names, attains a good level of accuracy and results in a general model able to classify previously unseen domains in an effective way. It is also able to outperform some of the state-of-the-art featur eless classification methods based on deep learning.",https://doi.org/10.1016/j.eswa.2020.114551,https://www.sciencedirect.com/science/article/pii/S0957417420311957,,,,2021,Algorithmically generated malicious domain names detection based on n-grams features,Alessandro Cucchiarelli and Christian Morbidoni and Luca Spalazzi and Marco Baldi,article,CUCCHIARELLI2021114551,Expert Systems with Applications,,170,0957-4174,,,
,"Graphical security modelling, Internet of things, Botnet attacks, Simulation, Security evaluation",103534,,"The proliferation of the Internet of Things (IoT) devices has provided attackers with tremendous opportunities to launch various cyber-attacks. It has been challenging to analyse the impact of cyber-attacks and evaluate the effectiveness of defences in real IoT environments due to the scale and heterogeneity of IoT networks. In this work, we propose a novel simulation framework and a software tool, IoT Security Simulator (IoTSecSim). IoTSecSim is operated based on a framework we propose for modelling and simulating cyber-attacks and various defences in IoT networks. IoTSecSim is not only able to support the creation of an IoT network with flexible settings of IoT devices and topology information but also models the attack behaviours, node-level, and network-level defences. Moreover, a systematic security evaluation can be performed by comparing the results based on the calculation of security metrics. We perform simulations with case studies on Mirai malware and its variants to model cyber-attack behaviours on IoT networks and evaluate the impact of these attacks and the effectiveness of defence techniques via IoTSecSim. Then, we carry out a sensitivity analysis to justify that the simulation results produced by IoTSecSim are accurate and feasible when compared with related works. We also perform a comparative performance analysis with four combinations of cyber-attack behaviours and show that these behaviours can influence IoT malware propagation in different situations. We consider multiple attacker models and deploy conventional defence techniques (including firewall, intrusion detection, and vulnerability patching) to investigate the effectiveness of defence techniques. IoTSecSim provides a generalised and extensible simulation framework that enables users to model emerging cyber-attacks against IoT networks and evaluate the effectiveness of defences against these attacks. This helps users focus on the design and performance evaluation of new defences before the actual implementation and deployment of the defences are required.",https://doi.org/10.1016/j.cose.2023.103534,https://www.sciencedirect.com/science/article/pii/S0167404823004443,,,,2024,IoTSecSim: A framework for modelling and simulation of security in Internet of things,Kok Onn Chee and Mengmeng Ge and Guangdong Bai and Dan Dongseong Kim,article,CHEE2024103534,Computers & Security,,136,0167-4048,,,
,"Network security, DDoS, Bloom filter, NAmpKeeper, DNS, Amplification attack",103718,,"Domain Name System (DNS) amplification attacks exploit botnets and open recursive DNS servers to launch Distributed Denial of Service (DDoS) attacks. During an attack, the attacker leverages infected computers (bots) to perpetually send small spoofed DNS queries to numerous open recursive DNS servers. The servers, in turn, respond with lots of large DNS responses, which are reflected back to the victim. Such responses are usually several times larger than the original queries, and could exhaust the resources of CPUs, memory, and network bandwidth, rendering them unavailable for benign users. However, most in-network DDoS mitigation systems today inevitably cause normal DNS responses to be discarded while scrubbing traffic, as they do not distinguish between legitimate and malicious responses. To address this issue, some existing solutions employ Bloom filters to filter out unsolicited DNS responses, utilizing the “one-to-one mapping” relationship between DNS queries and responses. In this work, we present a framework called DAmpADF, designed to defend against DNS amplification attacks. The framework employs Bloom filters at the edge or core routers of Internet Service Providers (ISPs) or organizations to filter out malicious DNS responses. To reduce the false positives of the Bloom filters, we propose a novel data structure called the Non-amplifier Keeper (NAmpKeeper), which maintains the most frequently queried DNS servers that are not DNS amplifiers. By excluding queries to non-amplifiers from the Bloom filters, the false positives of Bloom filters are decreased significantly. Experimental results show that DAmpADF outperforms previous methods and achieves a superior filtration ratio of illegitimate DNS responses. Furthermore, the proposed approach incurs small, constant processing and memory overhead, enabling support for high line rates.",https://doi.org/10.1016/j.cose.2024.103718,https://www.sciencedirect.com/science/article/pii/S0167404824000191,,,,2024,DAmpADF: A framework for DNS amplification attack defense based on Bloom filters and NAmpKeeper,Yunwei Dai and Tao Huang and Shuo Wang,article,DAI2024103718,Computers & Security,,139,0167-4048,,,
,"Git, Commit activity, Developer abandonment, Distributed software development, Prediction model",110573,,"Abandonment of active developers poses a significant risk for many open source software projects. This risk can be reduced by forecasting the future activity of contributors involved in such projects. Focusing on the commit activity of individuals involved in git repositories, this paper proposes a practicable probabilistic forecasting model based on the statistical technique of survival analysis. The model is empirically validated on a wide variety of projects accounting for 7528 git repositories and 5947 active contributors. We found that a model based on the last 20 observed days of commit activity per contributor provides the best concordance. We also found that the predictions provided by the model are generally close to actual observations, with slight underestimations for low probability predictions and slight overestimations for higher probability predictions. This model is implemented as part of an open source tool, called GAP, that predicts future commit activity.",https://doi.org/10.1016/j.jss.2020.110573,https://www.sciencedirect.com/science/article/pii/S0164121220300546,,,,2020,GAP: Forecasting commit activity in git projects,Alexandre Decan and Eleni Constantinou and Tom Mens and Henrique Rocha,article,DECAN2020110573,Journal of Systems and Software,,165,0164-1212,,,
,"Distributed software development, Bot identification, GitHub repositories, Text similarity, Classification model",110911,,"Bots are frequently used in Github repositories to automate repetitive activities that are part of the distributed software development process. They communicate with human actors through comments. While detecting their presence is important for many reasons, no large and representative ground-truth dataset is available, nor are classification models to detect and validate bots on the basis of such a dataset. This paper proposes a ground-truth dataset, based on a manual analysis with high interrater agreement, of pull request and issue comments in 5,000 distinct Github accounts of which 527 have been identified as bots. Using this dataset we propose an automated classification model to detect bots, taking as main features the number of empty and non-empty comments of each account, the number of comment patterns, and the inequality between comments within comment patterns. We obtained a very high weighted average precision, recall and F1-score of 0.98 on a test set containing 40% of the data. We integrated the classification model into an open source command-line tool to allow practitioners to detect which accounts in a given Github repository actually correspond to bots.",https://doi.org/10.1016/j.jss.2021.110911,https://www.sciencedirect.com/science/article/pii/S016412122100008X,,,,2021,A ground-truth dataset and classification model for detecting bots in GitHub issue and PR comments,Mehdi Golzadeh and Alexandre Decan and Damien Legay and Tom Mens,article,GOLZADEH2021110911,Journal of Systems and Software,,175,0164-1212,,,
,"Chatbot, Students, Emergency situation, COVID-19",e19517,,"Chatbots have arrived in higher education, and professors are trying to make the most of them. Typically, chatbots are used to help students learn academic subjects. In times of crisis, such as the COVID-19 pandemic, students who were not living with their families during the course, especially international students, were isolated and in critical situations. The student services offices were in constant contact with these students to solve problems, advise them and support them during their stay, within the constraints of confinement and the guidelines dictated by the country at the time. The student services offices were overwhelmed trying to help these students because, although the students' problems were very recurrent, the government guidelines changed from one day to the next. This article proposes the use of a chatbot to provide initial support to students during crisis situations, and facilitate communication between them and the university. The chatbot was tested by more than 160 students and student services staff. The findings support the use of chatbots as a potential tool to facilitate communication with students in emerging emergency situations, and encourage universities to adopt these types of smart tools to be prepared to respond quickly and efficiently to students in times of crisis.",https://doi.org/10.1016/j.heliyon.2023.e19517,https://www.sciencedirect.com/science/article/pii/S2405844023067257,,,,2023,Chatbot for communicating with university students in emergency situation,Antonio Balderas and Roberto Fermín García-Mena and Milagros Huerta and Nestor Mora and Juan Manuel Dodero,article,BALDERAS2023e19517,Heliyon,9,9,2405-8440,,,
,"Triage, Software, Update, Release Notes, Classifier, Evaluation",618-622,,"In the rapidly evolving domain of Industry 4.0, effective management of software updates is crucial for maintaining system continuity and security. This paper presents a novel machine learning-based approach for a prompt and effective triage of software updates, leveraging an evaluation of six release note classifiers to categorize updates by component type, release type, and security risk. Our methodology, tested on a dataset of 1,000 release notes commonly encountered in Industry 4.0 ecosystems, demonstrates Logistic Regression as the most accurate classifier. The findings not only highlight the practical applicability of our approach in real-world data but also set the foundation for future enhancements to streamline the machine learning triage process further.",https://doi.org/10.1016/j.procs.2024.06.069,https://www.sciencedirect.com/science/article/pii/S187705092401305X,,,,2024,Triage Software Update Impact via Release Notes Classification,Solomon Berhe and Vanessa Kan and Omhier Khan and Nathan Pader and Ali Zain Farooqui and Marc Maynard and Foutse Khomh,article,BERHE2024618,Procedia Computer Science,,238,1877-0509,"The 15th International Conference on Ambient Systems, Networks and Technologies Networks (ANT) / The 7th International Conference on Emerging Data and Industry 4.0 (EDI40), April 23-25, 2024, Hasselt University, Belgium",,
,"Decision Making Trial and Evaluation Laboratory, DEMATEL, Investment, Location, Profile analysis, Social network analysis",100249,,"This paper presents profile and social network analyses on concise systematic review corpora. It suggests two new robots and platforms for profile and social network analyses, that will serve previously proposed data, expert, and event-driven robots and platforms for energy and power industry. The literature is collected and stored in three topic clusters “location”, “investment”, and “DEMATEL” to prepare corpora. Twenty-five publications are selected in each sample corpus. A sample dataset of each corpus is prepared for thirty-one features such as “author’s full name and surname”, “applied methods”, and “publisher”. Afterward, “authors network matrices” are prepared in spreadsheet software. Data input files (*.csv) are prepared for each dataset. Gephi 0.9.2 201709241107 (free open-source software) is used for social network analyses with built-in layout and statistics algorithms on a desktop Windows 10 Pro, Intel(R) Core(TM) i5 CPU 650 @ 3.20 GHz, 6,00 GB RAM personal computer in an offline and active cybersecurity software environment. Force Atlas, Force Atlas 2, Fruchterman–Reingold, OpenOrd, Yifan Hu, and Yifan Hu Proportional layout algorithms with Noverlap layout algorithm are run one by one. Runtimes range 2–120 s. All default statistic algorithms are run for several metrics like average degree, average weighted degree, betweenness centrality, closeness centrality, harmonic closeness centrality, eccentricity, and density. Authors in “location” cluster have a centralized network, but authors in “investment” and “DEMATEL” clusters have distributed networks. General profile analyses are conducted based on authors’ publications in the literature without any data and information on social media sites and platforms. Two new profile analysis metrics are proposed as “researcher’s past research focus index”, and “researcher’s future research focus prediction index”. Detailed profile analysis is performed for only Burak Omer Saracoglu. All analyses and findings are compared and summarized in the end.",https://doi.org/10.1016/j.mlwa.2022.100249,https://www.sciencedirect.com/science/article/pii/S2666827022000019,,,,2022,Initialization of profile and social network analyses robot and platform with a concise systematic review,Burak Omer Saracoglu,article,SARACOGLU2022100249,Machine Learning with Applications,,7,2666-8270,,,
,"ChatGPT, Artificial intelligence, Social media, Public perception, Text mining, Online public opinion",102442,,"ChatGPT, an innovative artificial intelligence language model, is attracted significant attention around the world, sparking both enthusiasm and controversy, but identifying its societal impact and addressing its potential concerns necessitate an understanding of the prevailing public's attitudes toward the tool. In this study, we leverage text mining techniques to analyze the sentiments and themes prevalent among Chinese social media discussions of ChatGPT. In total, 96,435 comment data and 55,186 repost data were used, and the results show that public discussions mainly focused on ChatGPT's technical support, AI-related effectiveness, impact on human work, and effects on education and technology. Concerns were related to disinformation risks, technological unemployment, and the human–computer relationship. In addition, we found that social media played a prominent role in information dissemination, while official media and government units demonstrated a limited influence. The insights obtained through this study can inform policymakers, industry stakeholders, and the public of the public's prevailing attitude toward AI technologies, and they can facilitate informed decision-making.",https://doi.org/10.1016/j.techsoc.2023.102442,https://www.sciencedirect.com/science/article/pii/S0160791X23002476,,,,2024,Public attitudes and sentiments toward ChatGPT in China: A text mining analysis based on social media,Ying Lian and Huiting Tang and Mengting Xiang and Xuefan Dong,article,LIAN2024102442,Technology in Society,,76,0160-791X,,,
,"Amplification attack, Reflection attack, DDoS",102380,,"The rise of Distributed Denial of Service (DDoS) attacks have been steady in terms of the frequency and the impact of the attack. Traditionally, the attackers required control of a huge amount of resources to launch an attack. This has changed with the use of reflectors and amplifiers in DDoS attacks. A recent shift consisted of using other protocols than the traditional NTP and DNS protocols which were heavily used for ADDoS. In this paper, we review and organize amplification-based DDoS (ADDoS) attacks and associated countermeasures into a new taxonomy. Furthermore, we present a modus operandi of ADDoS attacks and analyze how it differs from traditional DDoS attacks. We also investigate how accessible ADDoS are for attackers with average resources. We survey readily available open-source scripts on GitHub and also the ADDoS features available in hire-to-DDoS platforms. We believe that accessibility and low-cost of hire-to-DDoS platforms are the major reasons for the increase of amplification-based DDoS attacks. Lastly, we provide a list of future directions that might be interesting for the community to focus on.",https://doi.org/10.1016/j.cose.2021.102380,https://www.sciencedirect.com/science/article/pii/S0167404821002042,,,,2021,A review of amplification-based distributed denial of service attacks and their mitigation,Salih Ismail and Hani Ragab Hassen and Mike Just and Hind Zantout,article,ISMAIL2021102380,Computers & Security,,109,0167-4048,,,
,"Moving Target Defense (MTD), MTD as a Service (MTDaaS), Network Functions Virtualization (NFV), Cloud security, Security as a Service (SECaaS), Zero-day vulnerabilities",100916,,"The Internet of Things (IoT) paradigm has been one of the main contributors, in recent years, to the growth in the number of connected equipment. This fact has predominantly contributed to IoT being constrained by the 5th Generation Mobile Network (5G) progress and the promises this technology brings. However, this can be a double-edged sword. On the one hand, it will benefit from those progresses, but on the other, it will also be impacted by any security risk associated with 5G. One of the more serious security problems associated with it is the new wave of virtualization and softwarization of networks and analogous appliances, brought to light by paradigms such as Network Functions Virtualization (NFV) and Multi-access Edge Computing (MEC). Considering these predicaments, we propose a state-of-the-art Moving Target Defense (MTD) approach that defends Cloud-based Network Functions (CNFs) launched within MEC and NFV environments. Furthermore, our mechanism follows the famous Everything as a Service (XaaS) ideology, allowing any CNF provider to use this protection system, working agonistically. In the end, we created a Proof of Concept (PoC) of our proposed methodology, which we then used to conduct an extensive practical security analysis against the multiple phases of the Intrusion Kill Chain. Our final results have proven that our MTD as a Service (MTDaaS) approach can effectively delay and, in some cases, stop an attacker from achieving its objectives when trying to attack a CNF, even if the related vulnerability is a zero-day.",https://doi.org/10.1016/j.iot.2023.100916,https://www.sciencedirect.com/science/article/pii/S2542660523002391,,,,2023,Moving Target Defense for the cloud/edge Telco environments,Pedro Escaleira and Vitor A. Cunha and Diogo Gomes and João P. Barraca and Rui L. Aguiar,article,ESCALEIRA2023100916,Internet of Things,,24,2542-6605,,,
,"Circular economy, Digital product passports, Modular ontology, Ontology design pattern, Information requirements, Built environment",248-268,,"The significant impact of the built environment on resource consumption and waste production has led to calls for a shift towards a circular economy model that maximizes the efficient use of resources. This study explores the use of digital product passports (DPPs) to improve how we manage products throughout their lifecycle. However, dealing with the complexity and large volume of data in DPPs can be challenging in terms of effective information management and utilization. We address this issue by adopting a modular ontological approach to systematically capture product lifecycle information from its origin to its end-of-life phase. To ensure interoperability and reusability of the ontology, we annotate key concepts and relationships using International Organization for Standardization (ISO) standards that promote circular economy. Our research led to the development of several ontology modules derived from literature reviews and interviews conducted with industry and academia experts who specialize in sustainability. These modules were then integrated to create a digital product passport ontology. The study demonstrates the feasibility of using a modular ontology approach to manage the complex information inherent in DPPs paving the way for more sustainable management practices in the built environment sector.",https://doi.org/10.1016/j.spc.2024.05.007,https://www.sciencedirect.com/science/article/pii/S2352550924001362,,,,2024,A modular ontology modeling approach to developing digital product passports to promote circular economy in the built environment,Rahel Kebede and Annika Moscati and He Tan and Peter Johansson,article,KEBEDE2024248,Sustainable Production and Consumption,,48,2352-5509,,,
,"Intelligent diagnosis, Traditional ML, ChatGPT, Google BARD, Comparative analysis",121186,,"Intelligent diagnosis processes rely on Artificial Intelligence (AI) techniques to provide possible diagnoses by analyzing patient data and medical information. To make accurate and quick diagnoses, it is possible to use AI tools to efficiently analyze huge amounts of data and find patterns that a clinician might miss. In recent years, new large language models (LLMs), such as ChatGPT and Google BARD, have shown remarkable capabilities in several domains, including intelligent diagnostics. This research aims to compare the performances of ChatGPT and traditional machine learning models for making diagnoses of low- and medium- risk diseases only based on their symptoms. On the basis of our study, we defined four research questions: RQ1) What are the benefits and limitations of using ChatGPT in intelligent diagnosis? RQ2) How do traditional machine learning approaches compare to ChatGPT for intelligent diagnosis? RQ3) How does ChatGPT compare with other LLMs and domain-specific natural language processing models in the intelligent diagnosis tasks?, and RQ4) What are the implications of the predictive models and ChatGPT for healthcare, and how can they be used to support people?. To answer these RQs, we first evaluate the performances of different engines of ChatGPT, also introducing a new prompt engineering methodology specifically tailored for achieving accurate diagnostic outcomes. Moreover, we compare these results with those achieved by different predictive models trained for intelligent diagnosis tasks, i.e., Google BARD, and two domain-specific NLP models. Finally, we propose a new interactive bot available for users that relies on the best-performing models evaluated in the previous steps. The experiments have been conducted using two medical datasets for disease prediction consisting of more than 100 symptoms associated with several diagnoses.",https://doi.org/10.1016/j.eswa.2023.121186,https://www.sciencedirect.com/science/article/pii/S0957417423016883,,,,2024,Can ChatGPT provide intelligent diagnoses? A comparative study between predictive models and ChatGPT to define a new medical diagnostic bot,Loredana Caruccio and Stefano Cirillo and Giuseppe Polese and Giandomenico Solimando and Shanmugam Sundaramurthy and Genoveffa Tortora,article,CARUCCIO2024121186,Expert Systems with Applications,,235,0957-4174,,,
,"FaaS, Serverless, Cloud computing",111589,,"Since its introduction in 2014 by Amazon, the Function as a Service (FaaS) model of serverless computing has set the expectation to fulfill the promise of on-demand, pay-as-you-go, infrastructure-independent processing, originally formulated by cloud computing. Yet, serverless applications are fundamentally different than traditional service-oriented software in that they pose specific performance (e.g., cold start), design (e.g., stateless), and development challenges (e.g., debugging). A growing number of cloud solutions have been continuously attempting to address each of these challenges as a result of the increasing popularity of FaaS. Yet, the characteristics of this model have been poorly understood; therefore, the challenges are poorly tackled. In this paper, we assess the state of FaaS in open-source community with a study on almost 2K real-world serverless applications. Our results show a jeopardized ecosystem, where, despite the hype of serverless solutions in the last years, a number of challenges remain untackled, especially concerning component reuse, support for software development, and flexibility among different platforms — resulting in arguably slow adoption of the FaaS model. We believe that addressing the issues discussed in this paper may help researchers shaping the next generation of cloud computing models.",https://doi.org/10.1016/j.jss.2022.111589,https://www.sciencedirect.com/science/article/pii/S0164121222002655,,,,2023,The uphill journey of FaaS in the open-source community,Nafise Eskandani and Guido Salvaneschi,article,ESKANDANI2023111589,Journal of Systems and Software,,198,0164-1212,,,
,"CAPTCHA, Annuli, Deep learning, Hough transform, Indistinguishable region",103025,,"Many websites and applications rely on CAPTCHA for protection from bot attacks. Otherwise, users and businesses will be exposed to risks. Although several different CAPTCHA systems have been proposed, the development of deep learning algorithms allows attackers to create more efficient and accurate attack methods. Many studies have shown that existing CAPTCHA systems are no longer safe, especially text-based CAPTCHA. To resolve this issue, a simple, secure, and effective annuli CAPTCHA system is proposed in this paper. In the proposed system, the annuli CAPTCHA image containing the overlapping of circles and ovals is randomly generated. The user wishing to gain access to the system is required to answer correctly the total number of circles and ovals in the image to prove that he/she is not a bot. The security of our proposed CAPTCHA system is verified by three attack methods. Additionally, the usability survey of our CAPTCHA system conducted by anonymous questionnaires shows that our system is user friendly. In other words, the proposed system maintains a high level of usability under the premise of high security. Compared with the existing CAPTCHA system, our CAPTCHA system is significantly better in terms of security, usability and ease of implementation.",https://doi.org/10.1016/j.cose.2022.103025,https://www.sciencedirect.com/science/article/pii/S0167404822004175,,,,2023,A secure annuli CAPTCHA system,Jie Zhang and Min-Yen Tsai and Kotcharat Kitchat and Min-Te Sun and Kazuya Sakai and Wei-Shinn Ku and Thattapon Surasak and Tipajin Thaipisutikul,article,ZHANG2023103025,Computers & Security,,125,0167-4048,,,
,"Android, Behavior, Dataset, Labeling, Malware",102845,,"The use of malware samples is usually required to test cyber security solutions. For that, the correct typology of the samples is of interest to properly estimate the exhibited performance of the tools under evaluation. Although several malware datasets are publicly available at present, most of them are not labeled or, if so, only one class or tag is assigned to each malware sample. We defend that just one label is not enough to represent the usual complex behavior exhibited by most of current malware. With this hypothesis in mind, and based on the varied classification generally provided by automatic detection engines per sample, we introduce here a simple multi-labeling approach to automatically tag the usual multiple behavior of malware samples. In the paper, we first analyze the coherence between the behaviors exhibited by a specific number of well-known malware samples dissected in the literature and the multiple tags provided for them by our labeling proposal. After that, the automatic multi-labeling scheme is executed over four public Android malware datasets, the different results and statistics obtained regarding their composition and representativeness being discussed. We share in a GitHub repository the multi-labeling tool developed, for public usage.",https://doi.org/10.1016/j.cose.2022.102845,https://www.sciencedirect.com/science/article/pii/S0167404822002395,,,,2022,"Multi-labeling of complex, multi-behavioral malware samples",P. García-Teodoro and J.A. Gómez-Hernández and A. Abellán-Galera,article,GARCIATEODORO2022102845,Computers & Security,,121,0167-4048,,,
,"Speech analysis, profanity prediction, toxic audio, ASR",62-69,,"With increasing multimedia content and social activities, moderation problems increase. There are different approaches to moderation and automation. However, they have limitations in terms of usage in real-time. The analysis of scientific papers revealed that most of the more common approaches solve the task of detection instead of prediction by considering the final utterance. For this reason, calls are unprotected in toxic languages, and online broadcasts can be unpredictable. In this work, a new way for automatic speech moderation in terms of dynamic word prediction was suggested. The considered task involves the analysis of the auditory and textual channels of speech. Words can have different meanings depending on the context, so in solving the problem it is planned to consider profanity, which is socially unacceptable regardless of the context. In this paper approaches for working with speech stream in the task of profanity prediction were proposed. It can be possible to have smaller latency with usage of audio features. We also suggest the pipeline for real-time (with the ability to predict the sequence with a higher duration than the latency of the processing) prediction for multimodal prediction, which compensates the latency of ASR systems. As a result, in this paper, we compared different solutions for the next color prediction task for English speech and reached the F1 score of 86.6 for 3 class prediction.",https://doi.org/10.1016/j.procs.2023.12.008,https://www.sciencedirect.com/science/article/pii/S1877050923019981,,,,2023,Multimodal prediction of profanity based on speech analysis,Ivan Smirnov and Anastasia Laushkina,article,SMIRNOV202362,Procedia Computer Science,,229,1877-0509,"12th International Young Scientists Conference in Computational Science, YSC2023",,
,"Intrusion Detection System (IDS), Deep learning, Unknown attacks, Internet of Things (IoT), Benchmark network datasets",103196,,"The majority of the intrusion detection solutions proposed using machine learning and deep learning approaches are based on known attack classes only. Comprehensive threat detection systems should consider both known and unknown attacks. Rapidly changing network environment and the advanced tools and techniques used by adversaries to launch new sophisticated attacks highlight a growing need to build intrusion detection systems that are more realistic, diverse, and robust to detect known and unknown attacks. We employed deep-learning models in our experiments to detect unknown threats, never introduced before to the model. This paper also studied the bias issues in connection with unknown threats detection. Many recent research studies based on conventional machine learning may report biased results and restricted training due to relying only on a single dataset; thus, there are existing threats that the model is unaware of, although the model may have high accuracy (in the known territories). This study presents a realistic IDS approach in which a deep learning classifiers' ensemble is trained on four benchmark IDS datasets for testing the unknown attack instances. Specifically, the model has no prior knowledge of some labels and traffic patterns in those experiments. The architecture proposed builds a deep learning ensemble using classifiers well-known to process and produce good results for sequential data. Our empirical results indicate that the proposed ensemble model can detect a range of unknown attacks with reasonable performance measures and a practical approach towards building a comprehensive IDS solution.",https://doi.org/10.1016/j.jisa.2022.103196,https://www.sciencedirect.com/science/article/pii/S2214212622000771,,,,2022,A Deep Learning Ensemble Approach to Detecting Unknown Network Attacks,Rasheed Ahmad and Izzat Alsmadi and Wasim Alhamdani and Lo'ai Tawalbeh,article,AHMAD2022103196,Journal of Information Security and Applications,,67,2214-2126,,,
,"Systematic literature review, Code reviewer recommendation, Reviewer recommendation, Modern code review, Pull request",102652,,"Code review is the process of inspecting code changes by a developer who is not involved in the development of the changeset. One of the initial and important steps of code review process is selecting code reviewer(s) for a given code change. To maximize the benefits of the code review process, the appropriate selection of the reviewer is essential. Code reviewer recommendation has been an active research area over the last few years, and many recommendation models have been proposed in the literature. In this study, we conduct a systematic literature review by inspecting 29 primary studies published from 2009 to 2020. Based on the outcomes of our review: (1) most preferred approaches are heuristic approaches closely followed by machine learning approaches, (2) the majority of the studies use open source projects to evaluate their models, (3) the majority of the studies prefer incremental training set validation techniques, (4) most studies suffer from reproducibility problems, (5) model generalizability and dataset integrity are the most common validity threats for the models and (6) refining models and conducting additional experiments are the most common future work discussions in the studies.",https://doi.org/10.1016/j.scico.2021.102652,https://www.sciencedirect.com/science/article/pii/S0167642321000459,,,,2021,A review of code reviewer recommendation studies: Challenges and future directions,H. Alperen Çetin and Emre Doğan and Eray Tüzün,article,CETIN2021102652,Science of Computer Programming,,208,0167-6423,,,
,"Affordances, Drug dealers, Opioids, Public health, Social networking sites, Natural language processing, Text analysis",100235,,"Social media has been documented as widely used for initiating online sales of illicit drugs such as opioids. However, not much is known about how affordances of social networking sites (SNS) influence how dealers advertise their supplies. To explore this topic, social media posts across 5 online platforms (Google Groups, Instagram, Twitter, Reddit, and Tumblr) were collected during 2020–2021. Biterm topic modeling (BTM) was used to identify signal posts specifically associated with the illegal online sale of opioids from drug selling social media accounts. Posts were analyzed by conducting a word count for drug names or slang terms associated with 5 categories: Opioids, Non-Opioid Prescription Controlled Drugs (e.g., Xanax, Valium), Other Illicit Drugs (e.g., Meth, Cocaine), Synthetic Opioids (Fentanyl), and Synthetic Marijuana. Number of mentions per post were calculated for each drug category and compared across platforms. Identifiers (e.g., publicly available email address) associated with posts were used to track dealers across different user accounts. Platforms with affordances for longer messages (e.g., Tumblr) had higher concentrations of drug mentions per post and higher variety of drug type mentions compared to SNS platforms Instagram and Twitter. Google Groups had the most drug mentions per post across all 5 categories. Additionally, each identifier was associated with multiple user accounts on a given platform. These results indicate that affordances of anonymity and message length may influence how drug dealers advertise their services on different platforms. Public health implications and strategies to counteract drug dealers and illicit drug diversion via SNS are also discussed.",https://doi.org/10.1016/j.chbr.2022.100235,https://www.sciencedirect.com/science/article/pii/S2451958822000690,,,,2022,The influence of social media affordances on drug dealer posting behavior across multiple social networking sites (SNS),Michael Robert Haupt and Raphael Cuomo and Jiawei Li and Matthew Nali and Tim K. Mackey,article,HAUPT2022100235,Computers in Human Behavior Reports,,8,2451-9588,,,
,"Mobile Game Security, ARM TrustZone, OPTEE, Application Integrity, Secure Update",102391,,"As the game industry is moving from PC to smartphone platforms, security problems related to mobile games are becoming critical. Considering the characteristics of mobile games such as having short life-cycles and high communication costs, the server/network-side security technologies designed for PC games are not appropriate for mobile games. In this study, we propose TZMon, a client-side game protection mechanism based on the ARM TrustZone, which protects the confidentiality and integrity of mobile games. TZMon is composed of application integrity protocol, secure update protocol, data hiding protocol, and timer synchronization protocol. To adequately safeguard game codes and data, TZMon is designed considering an environment of frequent communications with the game server, a stand-alone operation environment, and an unreliable environment using a rooted OS. Furthermore, flexibility is provided to game application developers who apply security policies by using the Java Native Interface (JNI). In this study, we use Android and the Open Portable Trusted Execution Environment (OPTEE) as the OS platforms for Normal World and Secure World, respectively. After implementing a full-featured prototype of TZMon, we apply it to several open-source mobile games. We prove through the experiments that the application of the proposed TZMon does not cause any noticeable performance degradation and can detect major cheating techniques of mobile games.",https://doi.org/10.1016/j.cose.2021.102391,https://www.sciencedirect.com/science/article/pii/S0167404821002157,,,,2021,TZMon: Improving mobile game security with ARM trustzone,Sanghoon Jeon and Huy Kang Kim,article,JEON2021102391,Computers & Security,,109,0167-4048,,,
,"Cognitive Neuroscience, Behavior",102320,,"Summary
Action potential spike widths are used to classify cell types as either excitatory or inhibitory; however, this approach obscures other differences in waveform shape useful for identifying more fine-grained cell types. Here, we present a protocol for using WaveMAP to generate nuanced average waveform clusters more closely linked to underlying cell types. We describe steps for installing WaveMAP, preprocessing data, and clustering waveform into putative cell types. We also detail cluster evaluation for functional differences and interpretation of WaveMAP output. For complete details on the use and execution of this protocol, please refer to Lee et al. (2021).1",https://doi.org/10.1016/j.xpro.2023.102320,https://www.sciencedirect.com/science/article/pii/S2666166723002873,,,,2023,WaveMAP for identifying putative cell types from in vivo electrophysiology,Kenji Lee and Nicole Carr and Alec Perliss and Chandramouli Chandrasekaran,article,LEE2023102320,STAR Protocols,2,4,2666-1667,,,
,"Cyber–Physical System, Internet of Things, IoT, Software-defined networks, SDN, Fog Computing, Distributed Denial of Service, DDoS, IoT-DDoS",100371,,"The wide dispersion of the Internet of Things (IoT), Software-defined Networks and Cloud Computing have given the wings to Cyber–Physical System adoption. The newfangled society relies so much on Cyber–Physical Systems, such as Smart Cities, Smart Agriculture, Medical Cyber System, that a dearth to any of the available services may lead to severe concerns. The IoT devices are unwittingly contributing to the denial of service attacks. Though the neoteric Software-defined Anything (SDx) paradigm has offered effective solution approaches to catastrophic IoT-based DDoS attacks, the novel designed solutions confront various vulnerabilities due to less secure IoT devices, high-volume real-time network traffic generated by the colossal amount of IoT devices, etc. In this paper, we present a comprehensive survey on vulnerability analysis of security solutions for Software-defined Cyber–Physical System. The paper delineates the architectural details of the Software-defined Cyber–Physical System and recommends amalgamation of Fog Computing as one of the architectural layers for overcoming a number of vulnerabilities. As contemporary technologies like IoT, Software-defined Networking and Cloud Computing are the soup ingredients of the Software-defined Cyber–Physical System, each of the individual components has been auscultated individually for security vulnerabilities with a focus on Distributed Denial of Service (DDoS and IoT-based DDoS) attacks. To anticipate the future recasting of the novel paradigm, we discuss the ongoing research and detailed vulnerability analysis with a focus on resiliency, performance, and scalability. Last but not least, we discuss the lessons learned and prospects to conclude.",https://doi.org/10.1016/j.cosrev.2021.100371,https://www.sciencedirect.com/science/article/pii/S1574013721000113,,,,2021,Vulnerability retrospection of security solutions for software-defined Cyber–Physical System against DDoS and IoT-DDoS attacks,Manish Snehi and Abhinav Bhandari,article,SNEHI2021100371,Computer Science Review,,40,1574-0137,,,
,"Common Data Environment, Federation, Issue Management, BIM Collaboration Format, Solid",102136,,"This paper analyses the requirements for managing interoperable building data in a federated Common Data Environment (CDE). We discuss the need for generic (meta)data storage patterns, semantic query interfaces, decentral authentication, data aggregation, and adaptation and prove that their combination is feasible with current-day technologies. We illustrate the mechanisms of such federated CDE by considering the topic of digital Issue Management, one of the primary functions of a CDE. In an exemplary data flow process, we show how generic (federated, Semantic Web-based) data patterns for Issue Management can be aggregated and restructured to match existing industry standards like buildingSMART’s BIM Collaboration Format (BCF) API. Finally, we show the methodology is compatible with current-day practice by implementing this process in a proof of concept. The main contribution of this research is a generic, federated framework for project-related, interdisciplinary collaboration for CDEs.",https://doi.org/10.1016/j.aei.2023.102136,https://www.sciencedirect.com/science/article/pii/S1474034623002641,,,,2023,A generic framework for federated CDEs applied to Issue Management,Jeroen Werbrouck and Oliver Schulz and Jyrki Oraskari and Erik Mannens and Pieter Pauwels and Jakob Beetz,article,WERBROUCK2023102136,Advanced Engineering Informatics,,58,1474-0346,,,
,"Emotional response, Corpus, Machine learning, Twitch, Video games",101651,,"This research explores for the first time the application of machine learning to detect emotional responses in video game streaming channels, specifically on Twitch, the most widely used platform for broadcasting content. Analyzing sentiment in gaming contexts is difficult due to the brevity of messages, the lack of context, and the use of informal language, which is exacerbated in the gaming environment by slang, abbreviations, memes, and jargon. First, a novel Spanish corpus was created from chat messages on Spanish video game Twitch channels, manually labeled for polarity and emotions. It is noteworthy as the first Spanish corpus for analyzing social responses on Twitch. Secondly, machine learning algorithms were used to classify polarity and emotions offering promising evaluations. The methodology followed in this work consists of three main steps: (1) Extracting Twitch chat messages from Spanish streamers’ channels related to gaming events and gameplays; (2) Processing and selecting the messages to form the corpus and manually annotating polarity and emotions; and (3) Applying machine learning models to detect polarity and emotions in the created corpus. The results have shown that a Bidirectional Encoder Representation from Transformers (BERT) based model excels with 78% accuracy in polarity detection, while deep learning and Random Forest models reach around 70%. For emotion detection, the BERT model performs best with 68%, followed by deep learning with 55%. It is worth noting that emotion detection is more challenging due to the subjective interpretation of emotions in the complex communicative context of video gaming on platforms such as Twitch. The use of supervised learning techniques, together with the rigorous corpus labeling process and the subsequent corpus pre-processing methodology, has helped to mitigate these challenges, and the algorithms have performed well. The main limitations of the research involve category and video game representation balance. Finally, it is important to stress that the integration of machine learning in video games and on Twitch is innovative, by allowing the identification of viewers’ emotions on streamers’ channels. This innovation could bring benefits such as a better understanding of audience sentiment, improving content and audience retention, providing personalized recommendations and detecting toxic behavior in chats.",https://doi.org/10.1016/j.csl.2024.101651,https://www.sciencedirect.com/science/article/pii/S0885230824000342,,,,2024,Applying machine learning to assess emotional reactions to video game content streamed on Spanish Twitch channels,Noemí Merayo and Rosalía Cotelo and Rocío Carratalá-Sáez and Francisco J. Andújar,article,MERAYO2024101651,Computer Speech & Language,,88,0885-2308,,,
,"Empirical software engineering, Code review, Sentiment analysis, Opinion mining, Affective analysis, Propensity score matching",37-54,,"Context
Modern code reviews are supported by tools to enhance developers’ interactions allowing contributors to submit their opinions for each committed change in form of comments. Although the comments are aimed at discussing potential technical issues, the text might enclose harmful sentiments that could erode the benefits of suggested changes.
Objective
In this paper, we study empirically the impact of sentiment embodied within developers’ comments on the time and outcome of the code review process.
Method
Based on historical data of four long-lived Open Source Software (OSS) projects from a code review system we investigate whether perceived sentiments have any impact on the interval time of code changes acceptance.
Results
We found that (1) contributors frequently express positive and negative sentiments during code review activities; (2) the expressed sentiments differ among the contributors depending on their position within the social network of the reviewers (e.g., core vs peripheral contributors); (3) the sentiments expressed by contributors tend to be neutral as they progress from the status of newcomer in an OSS project to the status of core team contributors; (4) the reviews with negative comments on average took more time to complete than the reviews with positive/neutral comments, and (5) the reviews with controversial comments took significantly longer time in one project.
Conclusion
Through this work, we provide evidences that text-based sentiments have an impact on the duration of the code review process as well as the acceptance or rejection of the suggested changes.",https://doi.org/10.1016/j.infsof.2019.06.005,https://www.sciencedirect.com/science/article/pii/S0950584919301387,,,,2019,An empirical study of sentiments in code reviews,Ikram El Asri and Noureddine Kerzazi and Gias Uddin and Foutse Khomh and M.A. {Janati Idrissi},article,ASRI201937,Information and Software Technology,,114,0950-5849,,,
,,3,,,https://doi.org/10.1016/S1353-4858(18)30021-7,https://www.sciencedirect.com/science/article/pii/S1353485818300217,,,,2018,In brief,,article,20183,Network Security,3,2018,1353-4858,,,
,"Machine learning, Collaborative model, Malware, IoT Botnet, Early detection",107525,,"With the rapid growth of threats and diversity in the manner of attack, Internet of things (IoT) systems has major challenges in providing methods to detect security vulnerabilities and attacks. There have been increasing developments of many detection tools and methods using full-time series data during malware execution based on machine learning/deep learning. However, the effectiveness of existing works is tightly bound by the requirement to use full-time series data. On the other hand, an earlier detection would help propose better solutions to respond to the IoT Botnet. Therefore, it mitigating the damage from potential attacks. In this paper, going beyond the full-time series data-based methods, we propose a collaborative machine learning model to effectively automate the early detection of IoT Botnet based on many features. The proposed model is 99.37% accurate on a dataset of 5023 IoT botnet and 3888 benign samples.",https://doi.org/10.1016/j.compeleceng.2021.107525,https://www.sciencedirect.com/science/article/pii/S0045790621004717,,,,2022,A collaborative approach to early detection of IoT Botnet,Giang L. Nguyen and Braulio Dumba and Quoc-Dung Ngo and Hai-Viet Le and Tu N. Nguyen,article,NGUYEN2022107525,Computers & Electrical Engineering,,97,0045-7906,,,
,"Digital Tools, Organizational Agility, Digital Innovation Capability, Agile Culture, Automotive Startups",107-116,,"Digital tools can be an enabler for automotive startups to strengthen their digital innovation capability. Still, few empirical studies describe how automotive startups apply digital tools to do this. Digital innovation capability is essential for survival in a volatile global digital marketplace. Therefore, we conducted a qualitative study based on 23 interviews with nine global automotive startups to understand how they apply digital tools to strengthen their digital innovation. The results showed that automotive startups use cloud services almost exclusively for their business. We conclude that startups choose to use digital tools as SaaS to strengthen their organizational agility and digital innovation initiatives. It harmonizes with their agile culture, effectively enabling innovation collaborations between employees internally and with external actors enabling rapidness to market. SaaS providers’ startup programs enabled startups to remain focused on their innovation initiatives and not worry about scalability since the solutions scaled from the start.",https://doi.org/10.1016/j.procs.2021.11.079,https://www.sciencedirect.com/science/article/pii/S1877050921022183,,,,2022,How Digital Tools Align with Organizational Agility and Strengthen Digital Innovation in Automotive Startups,Dulce Gonçalves and Magnus Bergquist and Sverker Alänge and Richard Bunk,article,GONCALVES2022107,Procedia Computer Science,,196,1877-0509,International Conference on ENTERprise Information Systems / ProjMAN - International Conference on Project MANagement / HCist - International Conference on Health and Social Care Information Systems and Technologies 2021,,
,,3,,,https://doi.org/10.1016/S1353-4858(14)70108-4,https://www.sciencedirect.com/science/article/pii/S1353485814701084,,,,2014,In brief,,article,20143,Network Security,11,2014,1353-4858,,,
,"Scientific excellence paradigms, Conference contributions, Scientific reputation, Community software development",101278,,"Like any other scientific discipline, the High Performance Computing community suffers under the publish or perish paradigm. As a result, a significant portion of novel algorithm designs and hardware-optimized implementations never make it into production code but are instead abandoned once they served the purpose of yielding (another) publication. At the same time, community software packages driving scientific research lack the addition of new technology and hardware-specific implementations. This results in a very unsatisfying situation where researchers and software developers are working independently, and the traditional peer reviewing is reaching its capacity limits. A paradigm shift that accepts high-quality software pull requests to open source research software as conference contributions may create incentives to realize new and/or improved algorithms in community software ecosystems. In this paper, we propose to complement code reviews on pull requests to scientific open source software with scientific reviews, and allow the presentation and publication of high quality software contributions that present an academic improvement to the state-of-the-art at scientific conferences.",https://doi.org/10.1016/j.jocs.2020.101278,https://www.sciencedirect.com/science/article/pii/S1877750320305743,,,,2021,Crediting pull requests to open source research software as an academic contribution,Hartwig Anzt and Eileen Kuehn and Goran Flegar,article,ANZT2021101278,Journal of Computational Science,,49,1877-7503,,,
,"Git, Workflows, Feature-based modelling, Version control, Branching",106811,,"Context:
Git is a popular distributed version control system that provides flexibility and robustness for software development projects. Several workflows have been proposed to codify the way project contributors work collaboratively with Git. Some workflows are highly prescriptive while others allow more leeway but do not provide the same level of code quality assurance, thus, preventing their comparison to determine the most suitable for a specific set of requirements, or to ascertain if a workflow is being properly followed.
Objective:
In this paper, we propose a novel feature-based framework for describing Git workflows, based on a study of 26 existing instances. The framework enables workflows’ comparison, to discern how, and to what extent, they exploit Git capabilities for collaborative software development.
Methods:
The framework uses feature-based modelling to map Git capabilities, regularly expressed as contribution guidelines, and a set of features that can be impartially applied to all the workflows considered. Through this framework, each workflow was characterised based on their publicly available descriptions. The characterisations were then vectorised and processed using hierarchical clustering to determine workflows’ similarities and to identify which features are most popular, and more relevant for discriminatory purposes.
Results:
Comparative analysis evidenced that some workflows claiming to be closely related, when described and then characterised, turned out to have more differences than similarities. The analysis also showed that most workflows focus on the branching and code integration strategies, whilst others emphasise subtle differences from other popular workflows or describe a specific development route and are, thus, widely reused.
Conclusion:
The characterisation and clustering analysis demonstrated that our framework can be used to compare and analyse Git workflows.",https://doi.org/10.1016/j.infsof.2021.106811,https://www.sciencedirect.com/science/article/pii/S0950584921002433,,,,2022,A unifying framework for the systematic analysis of Git workflows,Julio César {Cortés Ríos} and Suzanne M. Embury and Sukru Eraslan,article,CORTESRIOS2022106811,Information and Software Technology,,145,0950-5849,,,
,"HIV-1 vaccine, Epigenetics, DNA methylation",103956,,"Summary
Background
The BCN02-trial combined therapeutic vaccination with a viral latency reversing agent (romidepsin, RMD) in HIV-1-infected individuals and included a monitored antiretroviral pause (MAP) as an efficacy read-out identifying individuals with an early or late (< or > 4weeks) viral-rebound. Integrated -omics analyses were applied prior treatment interruption to identify markers of virus control during MAP.
Methods
PBMC, whole-genome DNA methylation and transcriptomics were assessed in 14 BCN02 participants, including 8 Early and 4 Late viral-rebound individuals. Chromatin state, histone marks and integration analysis (histone-3 acetylation (H3Ac), viral load, proviral levels and HIV-specific T cells responses) were included. REDUC-trial samples (n = 5) were included as a control group for RMD administration alone.
Findings
DNA methylation imprints after receiving the complete intervention discriminated Early versus Late viral-rebound individuals before MAP. Also, differential chromatin accessibility and histone marks at DNA methylation level were detected. Importantly, the differential DNA methylation positions (DMPs) between Early and Late rebounders before MAP were strongly associated with viral load, proviral levels as well as the HIV-specific T-cell responses. Most of these DMPs were already present prior to the intervention and accentuated after RMD infusion.
Interpretation
This study identifies host DNA methylation profiles and epigenetic cascades that are predictive of subsequent virus control in a kick-and-kill HIV cure strategy.
Funding
European Union Horizon 2020 Framework Programme for Research and Innovation under Grant Agreement N°681137-EAVI2020 and N°847943-MISTRAL, the Ministerio de Ciencia e Innovación (SAF2017_89726_R), and the National Institutes of Health–National Institute of Allergy and Infectious Diseases Program Grant P01-AI131568.",https://doi.org/10.1016/j.ebiom.2022.103956,https://www.sciencedirect.com/science/article/pii/S2352396422001402,,,,2022,Epigenetic landscape in the kick-and-kill therapeutic vaccine BCN02 clinical trial is associated with antiretroviral treatment interruption (ATI) outcome,Bruna Oriol-Tordera and Anna Esteve-Codina and María Berdasco and Míriam Rosás-Umbert and Elena Gonçalves and Clara Duran-Castells and Francesc Català-Moll and Anuska Llano and Samandhy Cedeño and Maria C. Puertas and Martin Tolstrup and Ole S. Søgaard and Bonaventura Clotet and Javier Martínez-Picado and Tomáš Hanke and Behazine Combadiere and Roger Paredes and Dennis Hartigan-O'Connor and Manel Esteller and Michael Meulbroek and María Luz Calle and Alex Sanchez-Pla and José Moltó and Beatriz Mothe and Christian Brander and Marta Ruiz-Riol,article,ORIOLTORDERA2022103956,eBioMedicine,,78,2352-3964,,,
,"HTTP/2, HTTP/3, QUIC, IDS, Machine Learning, Anomaly Detection, Vulnerabilities, DDoS, Attack, Dataset",103051,,"Following QUIC protocol ratification on May 2021, the third major version of the Hypertext Transfer Protocol, namely HTTP/3, was published around one year later in RFC 9114. In light of these consequential advancements, the current work aspires to provide a full-blown coverage of the following issues, which to our knowledge have received feeble or no attention in the literature so far. First, we provide a complete review of attacks against HTTP/2, and elaborate on if and in which way they can be migrated to HTTP/3. Second, through the creation of a testbed comprising the at present six most popular HTTP/3-enabled servers, we examine the effectiveness of a quartet of attacks, either stemming directly from the HTTP/2 relevant literature or being entirely new. This scrutiny led to the assignment of at least one CVE ID with a critical base score by MITRE. No less important, by capitalizing on a realistic, abundant in devices testbed, we compiled a voluminous, labeled corpus containing traces of ten diverse attacks against HTTP and QUIC services. An initial evaluation of the dataset mainly by means of machine learning techniques is included as well. Given that the 30 GB dataset is made available in both pcap and CSV formats, forthcoming research can easily take advantage of any subset of features, contingent upon the specific network topology and configuration.",https://doi.org/10.1016/j.cose.2022.103051,https://www.sciencedirect.com/science/article/pii/S0167404822004436,,,,2023,A hands-on gaze on HTTP/3 security through the lens of HTTP/2 and a public dataset,Efstratios Chatzoglou and Vasileios Kouliaridis and Georgios Kambourakis and Georgios Karopoulos and Stefanos Gritzalis,article,CHATZOGLOU2023103051,Computers & Security,,125,0167-4048,,,
,"CTF, Capture the Flag, Cyber range, Computer network operations, Cyber security exercises, Cyber security training",102470,,"Capture the Flag (CTF) is a computer security competition that is generally used to give participants experience in securing (virtual) machines and responding to cyber attacks. CTF contests have been getting larger and are receiving many participants every year (e.g., DEFCON, NYU-CSAW). CTF competitions are typically hosted in virtual environments, specifically set up to fulfill the goals and scenarios of the CTF. This article investigates the underlying infrastructures and CTF environments, specifically open-source CTF environments. A systematic review is conducted to assess functionality and game configuration in CTF environments where the source code is available on the web (i.e., open-source software). In particular, from out of 28 CTF platforms, we found 12 open-source CTF environments. As four platforms were not installable for several reasons, we finally examined 8 open-source CTF environments (PicoCTF, FacebookCTF, HackTheArch, WrathCTF, Pedagogic-CTF, RootTheBox, CTFd and Mellivora) regarding their features and functions for hosting CTFs (e.g., scoring, statistics or supported challenge types) and providing game configurations (e.g., multiple flags, points, hint penalities). Surprisingly, while many platforms provide similar base functionality, game configurations between the platforms varied strongly. For example, hint penalty, time frames for solving challenges, limited number of attempts or dependencies between challenges are game options that might be relevant for potential CTF organizers and for choosing a technology. This article contributes to the general understanding of CTF software configurations and technology design and implementation. Potential CTF organizers and participants may use this as a reference for challenge configurations and technology utilization. Based on our analysis, we would like to further review commercial and other platforms in order to establish a golden standard for CTF environments and further contribute to a better understanding of CTF design and development.",https://doi.org/10.1016/j.jnca.2019.102470,https://www.sciencedirect.com/science/article/pii/S1084804519303303,,,,2020,An Empirical Survey of Functions and Configurations of Open-Source Capture the Flag (CTF) Environments,Stela Kucek and Maria Leitner,article,KUCEK2020102470,Journal of Network and Computer Applications,,151,1084-8045,,,
,"Smart multi-energy grids, Multi-carrier energy flows, DSM, Aggregator, Energy modeling, Renewable generation, Energy storage",100079,,"This paper presents the PEACEFULNESS software platform (Platform for transvErse evAluation of Control stratEgies For mULti-eNErgy Smart gridS), an open framework dedicated to multi-energy smart-grids, based on a techno-economic model that integrates economic considerations (contracts). As such, it is mainly oriented towards the evaluation of multi-energy grid supervision strategies, that is, energy management, and the corresponding policies and legal organization. The main goal is then to highlight the various possible behaviors and strategies to organize the probable future interconnections between the different energy carriers. In particular, it aims at investigating how to maximize the use of renewable energy sources (RES), using Demand Side Management (DSM) techniques and energy storage, in a shared economy context. The open-source tool PEACEFULNESS, written in Python, is described here in detail. It combines a top-down description of the energy networks and connections between the various agents (energy providers, distribution system operators, aggregators, consumers, producers, prosumers, etc.), together with a techno-economic bottom-up description for all devices. Here, both public databases and users’ data (basic heating demands or based on building modeling) can be used, as well as generic or more specific models (e.g., PV panels with constant or temperature-dependent efficiency). One of its major unique features compared with other tools is that it extends the use of DSM techniques to various energy grids which can also interact together. Furthermore, different economic models can be set for both the aggregators and the customers, and even within these groups. As a last competitive advantage, PEACEFULNESS allows the user to simulate the operation and supervision of tens up to hundreds of thousands of agents. It also provides a reporting system giving access to all the data, with a configurable granularity and frequency for the retained indicators. Finally, several validation cases are presented, followed by a series of test cases with increasing size: a smart home, a smart district (2 000 dwellings) and a smart community (50 000 dwellings).",https://doi.org/10.1016/j.segy.2022.100079,https://www.sciencedirect.com/science/article/pii/S266695522200017X,,,,2022,Platform for transverse evaluation of control strategies for multi-energy smart grids,Timothé Gronier and Erwin Franquet and Stéphane Gibout,article,GRONIER2022100079,Smart Energy,,7,2666-9552,,,
,"Hierarchical Byte-based CNN, Network intrusion detection, Few sample problem, Auto-extraction of abstract features",108117,,"Network intrusion detection system (IDS) protects the target network from the threats of data breaches and the insecurity of people’s privacy. However, most of existing researches on network intrusion detection cannot fulfil effectively the protection of targets, especially, depending heavily on the statistical features that are manually designed with domain experts’ knowledge and experiences, and failing to address the few sample data problem. Network traffic has a hierarchical structure, i.e., byte-packet-flow, which is similar to phrase-sentence-article in an article. This paper proposes a hierarchical packet byte-based CNN, called PBCNN, where the first level extracts abstract features automatically from bytes in a packet in raw Pcap files, and then the second level further constructs the representation from packets in a flow or session, instead of using feature-ready CSV files, to make full use of original data information. Multiple convolution-pooling modules are cascaded with byte-friendly sizes of multiple filters, and one-layer TextCNN to obtain the representation of traffic flow, feeding the representation to 3 layers of fully connected networks for intrusion classification. PBCNN-based few shot learning is applied to improve the detection reliability of network attack categories with the few sample problem. Several experiments are performed and the results show that the evaluation metrics are superior to the existing researches in regard to CIC-IDS2017 and CSE-CIC-IDS2018 datasets.",https://doi.org/10.1016/j.comnet.2021.108117,https://www.sciencedirect.com/science/article/pii/S1389128621001948,,,,2021,PBCNN: Packet Bytes-based Convolutional Neural Network for Network Intrusion Detection,Lian Yu and Jingtao Dong and Lihao Chen and Mengyuan Li and Bingfeng Xu and Zhao Li and Lin Qiao and Lijun Liu and Bei Zhao and Chen Zhang,article,YU2021108117,Computer Networks,,194,1389-1286,,,
,"Misinformation, COVID-19, Vaccine hesitancy, Sentiment analysis, Topic modeling",1505-1512,,"Background
The COVID-19 pandemic fueled one of the most rapid vaccine developments in history. However, misinformation spread through online social media often leads to negative vaccine sentiment and hesitancy.
Methods
To investigate COVID-19 vaccine-related discussion in social media, we conducted a sentiment analysis and Latent Dirichlet Allocation topic modeling on textual data collected from 13 Reddit communities focusing on the COVID-19 vaccine from Dec 1, 2020, to May 15, 2021. Data were aggregated and analyzed by month to detect changes in any sentiment and latent topics.
Results
Polarity analysis suggested these communities expressed more positive sentiment than negative regarding the vaccine-related discussions and has remained static over time. Topic modeling revealed community members mainly focused on side effects rather than outlandish conspiracy theories.
Conclusion
Covid-19 vaccine-related content from 13 subreddits show that the sentiments expressed in these communities are overall more positive than negative and have not meaningfully changed since December 2020. Keywords indicating vaccine hesitancy were detected throughout the LDA topic modeling. Public sentiment and topic modeling analysis regarding vaccines could facilitate the implementation of appropriate messaging, digital interventions, and new policies to promote vaccine confidence.",https://doi.org/10.1016/j.jiph.2021.08.010,https://www.sciencedirect.com/science/article/pii/S1876034121002288,,,,2021,Public sentiment analysis and topic modeling regarding COVID-19 vaccines on the Reddit social media platform: A call to action for strengthening vaccine confidence,Chad A. Melton and Olufunto A. Olusanya and Nariman Ammar and Arash Shaban-Nejad,article,MELTON20211505,Journal of Infection and Public Health,10,14,1876-0341,"Special Issue on COVID-19 – Vaccine, Variants and New Waves",,
,"Computer vision, Tracking, Monitoring, Goats, Behavior",107831,,"Computer vision is an interesting tool for animal behavior monitoring, mainly because it limits animal handling and it can be used to record various traits using only one sensor. From previous studies, this technic has shown to be suitable for various species and behavior. However it remains challenging to collect individual information, i.e. not only to detect animals and behavior on the video frames, but also to identify them. Animal identification is a prerequisite to gather individual information in order to characterize individuals and compare them. A common solution to this problem, known as multiple objects tracking, consists in detecting the animals on each video frame, and then associate detections to a unique animal ID. Association of detections between two consecutive frames are generally made to maintain coherence of the detection locations and appearances. To extract appearance information, a common solution is to use a convolutional neural network (CNN), trained on a large dataset before running the tracking algorithm. For farmed animals, designing such network is challenging as far as large training dataset are still lacking. In this article, we proposed an innovative solution, where the CNN used to extract appearance information is parameterized using offline unsupervised training. The algorithm, named Wizard, was evaluated for the purpose of goats monitoring in outdoor conditions. 17 annotated videos were used, for a total of 4H30, with various number of animals on the video (from 3 to 8) and different level of color differences between animals. First, the ability of the algorithm to track the detected animals was evaluated. When animals were detected, the algorithm found the correct animal ID in 94.82% of the frames. When tracking and detection were evaluated together, we found that Wizard found the correct animal ID in 86.18% of the video length. In situations where the animal detection rate could be high, Wizard seems to be a suitable solution for individual behavior analysis experiments based on computer vision.",https://doi.org/10.1016/j.compag.2023.107831,https://www.sciencedirect.com/science/article/pii/S0168169923002193,,,,2023,Wizard: Unsupervised goats tracking algorithm,Jehan-Antoine Vayssade and Xavier Godard and Mathieu Bonneau,article,VAYSSADE2023107831,Computers and Electronics in Agriculture,,209,0168-1699,,,
,"Automated trading, Candlestick images, Cryptocurrency, Deep reinforcement learning, Ensemble approach",121373,,"Despite their high risk, cryptocurrencies have gained popularity as viable trading options. Cryptocurrencies are digital assets that experience significant fluctuations in a market operating 24 h a day. Recently, considerable attention has been paid to developing trading bots using machine-learning-based artificial intelligence. Previous studies have employed machine learning techniques to predict financial market trends or make trading decisions, primarily using numerical data extracted from candlesticks. However, these data often overlook the temporal and spatial information of candlesticks, leading to a limited understanding of their significance. In this study, we utilize multi-resolution candlestick images containing temporal and spatial information. Our rationale for using visual information from candlestick charts is to replicate the decision-making processes of human trading experts. To achieve this, we employ deep reinforcement learning algorithms to generate trading signals based on a state vector that includes embedded candlestick-chart images. The trading signal is generated using a multi-agent weighted voting ensemble approach. We test the proposed approach on two BTC/USDT datasets under both bullish and bearish market scenarios. Additionally, we use an attention-based technique to identify significant areas in the candlestick images targeted by the proposed approach. Our findings demonstrate that models using candlestick images 'as-is', outperform those using raw numeric data and other baseline models.",https://doi.org/10.1016/j.eswa.2023.121373,https://www.sciencedirect.com/science/article/pii/S0957417423018754,,,,2024,Automated cryptocurrency trading approach using ensemble deep reinforcement learning: Learn to understand candlesticks,Liu Jing and Yuncheol Kang,article,JING2024121373,Expert Systems with Applications,,237,0957-4174,,,
,"Iterative Learning Control, Vibration Suppression, Robotic Manipulation",9360-9365,,"Many industries extensively use flexible materials. effective approaches for handling flexible objects with a robot manipulator must address residual vibrations. Existing solutions rely on complex models, use additional instrumentation for sensing the vibrations, or do not exploit the repetitive nature of most industrial tasks. This paper develops an iterative learning control approach that jointly learns model parameters and residual dynamics using only the interoceptive sensors of the robot. The learned model is subsequently utilized to design optimal point-to-point (PTP) trajectories that accounts for residual vibration, nonlinear kinematics of the manipulator and joint limits. We experimentally show that the proposed approach reduces the residual vibrations by an order of magnitude compared with optimal vibration suppression using the analytical model and threefold compared with the available state-of-the-art method. These results demonstrate that effective handling of a flexible object does not require neither complex models nor additional instrumentation.",https://doi.org/10.1016/j.ifacol.2023.10.225,https://www.sciencedirect.com/science/article/pii/S2405896323005761,,,,2023,Vibration Free Flexible Object Handling with a Robot Manipulator Using Learning Control,Daniele Ronzani and Shamil Mamedov and Jan Swevers,article,RONZANI20239360,IFAC-PapersOnLine,2,56,2405-8963,22nd IFAC World Congress,,
,"Sentiment analysis, Text mining, Text analytics, Social media, Twitter, Migrants",100059,,"In this paper, we propose a sentiment analysis of Twitter data focused on the attitudes and sentiments of Polish migrants and stayers during the pandemic. We collected 9 million tweets and retweets between January and August 2021, and analysed them using MultiEmo, the multilingual, multilevel, multi-domain sentiment analysis corpus. We discovered that the sentiment of tweets differs between migrants and stayers over time, and it relates to the country of migration. The general sentiment is similar for migrants and stayers, but a more detailed analysis reveals that hashtags related to staying safe and staying at home, as well as vaccinations are more polarised for migrants than for stayers, and they reflect the general development trend of the pandemic in Europe. In addition to comparing migrants with stayers, we also compared migrants staying in different countries. amongst the countries of migration, for which we collected at least 3000 tweets, the most positive sentiment of Polish migrants’ tweets was observed in Belgium, with the most negative sentiment coming from Estonia. We also observed that the sentiment of tweets written in Polish by stayers in Poland is less negative when compared to Polish migrants in most of the countries with the highest number of tweets.",https://doi.org/10.1016/j.teler.2023.100059,https://www.sciencedirect.com/science/article/pii/S2772503023000191,,,,2023,Migrants vs. stayers in the pandemic – A sentiment analysis of Twitter content,Olga Czeranowska and Karol Chlasta and Piotr Miłkowski and Izabela Grabowska and Jan Kocoń and Krzysztof Hwaszcz and Jan Wieczorek and Agata Jastrzębowska,article,CZERANOWSKA2023100059,Telematics and Informatics Reports,,10,2772-5030,,,
,"Cyberbullying, Information and communication technology, Bystander behavior, Behavior change, Experimental paradigm",100110,,"The investigation of bystander behavior in response to cyberbullying is a developing area of research that is still in its infancy. To advance this area of inquiry, researchers can use information and communication technology (ICT) platforms, such as simulated social media websites, as an experimental paradigm to facilitate and measure the behavior change of cyber-bystanders in a controlled virtual environment. However, this is a method that remains under-utilized by researchers and it remains unclear why. Thus, the purpose of this paper is to use the '5 principles of cyberbullying research' as an informed and empirical framework to systematically identify the methodological shortcomings that contribute to the underutilization of ICT platforms in cyber-bystander research. The final section of the paper builds on these 5 principles by critically analyzing the unique features of ICT platforms to outline ways in which researchers can design paradigms that are informed by both theory and practice. Overall, this paper aims to further develop the types of experimental methods that are used in the field of cyberbullying to create new avenues of research.",https://doi.org/10.1016/j.chbr.2021.100110,https://www.sciencedirect.com/science/article/pii/S2451958821000580,,,,2021,Information and communication technology platforms as an experimental paradigm in cyber-bystander research: A critique of methodology,Pooja Megha Nagar and Victoria Talwar,article,NAGAR2021100110,Computers in Human Behavior Reports,,4,2451-9588,,,
,,3,,,https://doi.org/10.1016/S1353-4858(14)70002-9,https://www.sciencedirect.com/science/article/pii/S1353485814700029,,,,2014,In brief,,article,20143,Network Security,1,2014,1353-4858,,,
,,3,,,https://doi.org/10.1016/S1353-4858(21)00002-7,https://www.sciencedirect.com/science/article/pii/S1353485821000027,,,,2021,Threatwatch,,article,20213,Network Security,1,2021,1353-4858,,,
,"Misinformation, Motivation, Vaccine hesitancy, Science communication, Social media, Social psychology",100085,,"The COVID-19 pandemic exposed significant weaknesses in the healthcare information system. The overwhelming volume of misinformation on social media and other socioeconomic factors created extraordinary challenges to motivate people to take proper precautions and get vaccinated. In this context, our work explored a novel direction by analyzing an extensive dataset collected over two years, identifying the topics de/motivating the public about COVID-19 vaccination. We analyzed these topics based on time, geographic location, and political orientation. We noticed that while the motivating topics remain the same over time and geographic location, the demotivating topics change rapidly. We also identified that intrinsic motivation, rather than external mandate, is more advantageous to inspire the public. This study addresses scientific communication and public motivation in social media. It can help public health officials, policymakers, and social media platforms develop more effective messaging strategies to cut through the noise of misinformation and educate the public about scientific findings.",https://doi.org/10.1016/j.nlp.2024.100085,https://www.sciencedirect.com/science/article/pii/S2949719124000335,,,,2024,Cutting through the noise to motivate people: A comprehensive analysis of COVID-19 social media posts de/motivating vaccination,Ashiqur Rahman and Ehsan Mohammadi and Hamed Alhoori,article,RAHMAN2024100085,Natural Language Processing Journal,,8,2949-7191,,,
,"Code review, Patch, Early prediction, Merged, Abandoned",106756,,"Context:
The modern code review process is an integral part of the current software development practice. Considerable effort is given here to inspect code changes, find defects, suggest an improvement, and address the suggestions of the reviewers. In a code review process, several iterations usually take place where an author submits code changes and a reviewer gives feedback until is happy to accept the change. In around 12% cases, the changes are abandoned, eventually wasting all the efforts.
Objective:
In this research, our objective is to design a tool that can predict whether a code change would be merged or abandoned at an early stage to reduce the waste of efforts of all stakeholders (e.g., program author, reviewer, project management, etc.) involved. The real-world demand for such a tool was formally identified by a study by Fan et al. (2018).
Method:
We have mined 146,612 code changes from the code reviews of three large and popular open-source software and trained and tested a suite of supervised machine learning classifiers, both shallow and deep learning-based. We consider a total of 25 features in each code change during the training and testing of the models. The features are divided into five dimensions: reviewer, author, project, text, and code.
Results:
The best performing model named PredCR (Predicting Code Review), a LightGBM-based classifier achieves around 85% AUC score on average and relatively improves the state-of-the-art (Fan et al., 2018) by 14%–23%. In our extensive empirical study involving PredCR on the 146,612 code changes from the three software projects, we find that (1) The new features like reviewer dimensions that are introduced in PredCR are the most informative. (2) Compared to the baseline, PredCR is more effective towards reducing bias against new developers. (3) PredCR uses historical data in the code review repository and as such the performance of PredCR improves as a software system evolves with new and more data.
Conclusion:
PredCR can help save time and effort by helping developers/code reviewers to prioritize the code changes that they are asked to review. Project management can use PredCR to determine how code changes can be assigned to the code reviewers (e.g., select code changes that are more likely to be merged for review before the changes that might be abandoned).",https://doi.org/10.1016/j.infsof.2021.106756,https://www.sciencedirect.com/science/article/pii/S0950584921002032,,,,2022,Early prediction for merged vs abandoned code changes in modern code reviews,Khairul Islam and Toufique Ahmed and Rifat Shahriyar and Anindya Iqbal and Gias Uddin,article,ISLAM2022106756,Information and Software Technology,,142,0950-5849,,,
,"Cybersecurity, Cyber-defense competitions, Hands-on education, Information technology, Instructional computing environments, Tutorials and exercises",12-40,,"Hands-on tutorials and exercises are recognized as an effective means for gaining much needed cybersecurity and communication and information technology skills. These exercises must be performed in dedicated and virtually isolated computing environments or laboratories, most of which make use of virtualization technology. Building, modifying, and deploying the virtual environments that enable hands-on instruction is currently very time consuming. A new complete exercise instance must be deployed and configured for each course or module, tutorial or exercise, and student. In addition, efficient sharing and reuse of hands-on exercises between organizations is currently extremely difficult, unless the computing resources and virtualization environment are also shared. ADLES is a specification language and associated deployment system created to address these issues up-front. ADLES enables: (1) the formal specification of hands-on virtual computing, networking, and cybersecurity exercises, (2) the automated deployment of specified exercises, and (3) the efficient sharing of such exercises and their computing environment. In this article, we describe in detail the ADLES specification language and deployment system. We also demonstrate ADLES capabilities using two case studies: a pentesting tutorial and a cyber defense competition. The ADLES system is open source and available for all educators to use and improve.",https://doi.org/10.1016/j.cose.2017.12.007,https://www.sciencedirect.com/science/article/pii/S0167404817302742,,,,2018,"ADLES: Specifying, deploying, and sharing hands-on cyber-exercises",Daniel {Conte de Leon} and Christopher E. Goes and Michael A. Haney and Axel W. Krings,article,CONTEDELEON201812,Computers & Security,,74,0167-4048,,,
,"DDoS, DNS, Filtering",103259,,"Distributed Denial-of-Service (DDoS) attacks exhaust resources, leaving a server unavailable to legitimate clients. The Domain Name System (DNS) is a frequent target of DDoS attacks. Since DNS is a critical infrastructure service, protecting it from DoS is imperative. Many prior approaches have focused on specific filters or anti-spoofing techniques to protect generic services. DNS root nameservers are more challenging to protect, since they use fixed IP addresses, serve very diverse clients and requests, receive predominantly UDP traffic that can be spoofed, and must guarantee high quality of service. In this paper we propose a layered DDoS defense for DNS root nameservers. Our defense uses a library of defensive filters, which can be optimized for different attack types, with different levels of selectivity. We further propose a method that automatically and continuously evaluates and selects the best combination of filters throughout the attack. We show that this layered defense approach provides exceptional protection against all attack types using traces of ten real attacks from a DNS root nameserver. Our automated system can select the best defense within seconds and quickly reduces traffic to the server within a manageable range, while keeping collateral damage lower than 2%. We show our system can successfully mitigate resource exhaustion using replay of a real-world attack. We can handle millions of filtering rules without noticeable operational overhead.",https://doi.org/10.1016/j.adhoc.2023.103259,https://www.sciencedirect.com/science/article/pii/S1570870523001798,,,,2023,Defending Root DNS Servers against DDoS Using Layered Defenses (Extended),ASM Rizvi and Jelena Mirkovic and John Heidemann and Wesley Hardaker and Robert Story,article,RIZVI2023103259,Ad Hoc Networks,,151,1570-8705,,,
,"Cryptocurrencies, Statistical causality, Blockchain regression, Multiple-output Gaussian process, Natural language processing, Cryptonews sentiment",100063,,"This paper establishes a new framework for assessing multimodal statistical causality between cryptocurrency market (cryptomarket) sentiment and cryptocurrency price processes. In order to achieve this, we present an efficient algorithm for multimodal statistical causality analysis based on Multiple-Output Gaussian Processes. Signals from different information sources (modalities) are jointly modelled as a Multiple-Output Gaussian Process, and then using a novel approach to statistical causality based on Gaussian Processes (GPs), we study linear and non-linear causal effects between the different modalities. We demonstrate the effectiveness of our approach in a machine learning application by studying the relationship between cryptocurrency spot price dynamics and sentiment time-series data specific to the crypto sector, which we conjecture influences retail investor behaviour. The investor sentiment is extracted from cryptomarket news data via methods developed in the area of statistical machine learning known as Natural Language Processing (NLP). To capture sentiment, we present a novel framework for text to time-series embedding, which we then use to construct a sentiment index from publicly available news articles. We conduct a statistical analysis of our sentiment statistical index model and compare it to alternative state-of-the-art sentiment models popular in the NLP literature. In regard to the multimodal causality, the investor sentiment is our primary modality of exploration, in addition to price and a blockchain technology-related indicator (hash rate). Analysis shows that our approach is effective in modelling causal structures of variable degree of complexity between heterogeneous data sources and illustrates the impact that certain modelling choices for the different modalities can have on detecting causality. A solid understanding of these factors is necessary to gauge cryptocurrency adoption by retail investors and provide sentiment- and technology-based insights about the cryptocurrency market dynamics.",https://doi.org/10.1016/j.bcra.2022.100063,https://www.sciencedirect.com/science/article/pii/S2096720922000033,,,,2022,On-chain analytics for sentiment-driven statistical causality in cryptocurrencies,Ioannis Chalkiadakis and Anna Zaremba and Gareth W. Peters and Michael J. Chantler,article,CHALKIADAKIS2022100063,Blockchain: Research and Applications,2,3,2096-7209,,,
,,3,,,https://doi.org/10.1016/S1353-4858(13)70025-4,https://www.sciencedirect.com/science/article/pii/S1353485813700254,,,,2013,In brief,,article,20133,Network Security,2,2013,1353-4858,,,
,"High throughput computing, Distributed computing, Parallel computing",57-64,,"For many scientific disciplines, the transition to using advanced cyberinfrastructure comes not out of a desire to use the most advanced or most powerful resources available, but because their current operational model is no longer sufficient to meet their computational needs. Many researchers begin their computations on their desktop or local workstation, only to discover that the time required to simulate their problem, analyze their instrument data, or score the multitude of entities that they want to would require far more time than they have available. Launcher is a simple utility which enables the execution of high throughput computing workloads on managed HPC systems quickly and with as little effort as possible on the part of the user. Basic usage of the Launcher is straightforward, but Launcher provides several more advanced capabilities including use of Intel® Xeon Phi™ coprocessor cards and task binding support for multi-/many-core architectures. We step through the processes of setting up a basic Launcher job, including creating a job file, setting appropriate environment variables, and using scheduler integration. We also describe how to enable use of the Intel® Xeon Phi™ coprocessor cards, take advantage of Launcher's task binding system, and execute many parallel (OpenMP/MPI) applications at once.",https://doi.org/10.1016/j.bdr.2017.04.001,https://www.sciencedirect.com/science/article/pii/S2214579616300648,,,,2017,Using the Launcher for Executing High Throughput Workloads,Lucas A. Wilson,article,WILSON201757,Big Data Research,,8,2214-5796,Tutorials on Tools and Methods using High Performance Computing resources for Big Data,,
,,100265,,"Three dissimilar methodologies in the field of artificial intelligence (AI) appear to be following a common path toward biological authenticity. This trend could be expedited by using a common tool, artificial nervous systems (ANS), for recreating the biology underpinning all three. ANS would then represent a new paradigm for AI with application to many related fields.",https://doi.org/10.1016/j.patter.2021.100265,https://www.sciencedirect.com/science/article/pii/S266638992100091X,,,,2021,Artificial nervous systems—A new paradigm for artificial intelligence,Fredric Narcross,article,NARCROSS2021100265,Patterns,6,2,2666-3899,,,
,"Data-driven smart buildings, Data interoperability, Ontology comparison and evaluation, Ontology compatibility, Ontology design patterns, Brick Schema, RealEstateCore, Project Haystack, Digital Buildings",113054,,"Ontologies play a critical role in data exchange, information integration, and knowledge sharing across diverse smart building applications. Yet, semantic differences between the prevailing building ontologies hamper their purpose of bringing data interoperability and restrict the ability to reuse building ontologies in real-world applications. In this paper, we propose and adopt a framework to conduct a systematic comparison and evaluation of four popular building ontologies (Brick Schema, RealEstateCore, Project Haystack, and Digital Buildings) from both axiomatic design and assertions in a use case, namely the Terminological Box (TBox) evaluation and the Assertion Box (ABox) evaluation. In the TBox evaluation, we use the SQuaRE-based Ontology Quality Evaluation (OQuaRE) framework and concede that Project Haystack and Brick Schema are more compact with respect to the ontology axiomatic design. In the ABox evaluation, we apply an empirical study with sample building data that suggests Brick Schema and RealEstateCore have greater completeness and expressiveness in capturing the main concepts and relations within the building domain. The results indicate that there is no universal building ontology for integrating Linked Building Data (LBD). We also discuss ontology compatibility and investigate building ontology design patterns (ODPs) to support ontology matching, alignment, and harmonisation.",https://doi.org/10.1016/j.enbuild.2023.113054,https://www.sciencedirect.com/science/article/pii/S0378778823002840,,,,2023,A systematic comparison and evaluation of building ontologies for deploying data-driven analytics in smart buildings,Zhangcheng Qiang and Stuart Hands and Kerry Taylor and Subbu Sethuvenkatraman and Daniel Hugo and Pouya {Ghiasnezhad Omran} and Madhawa Perera and Armin Haller,article,QIANG2023113054,Energy and Buildings,,292,0378-7788,,,
,"DDoS, Machine learning, IoT, Deep learning, Cyber security, Review",100631,,"Distributed Denial of Service (DDoS) attacks in IoT networks are one of the most devastating and challenging cyber-attacks. The number of IoT users is growing exponentially due to the increase in IoT devices over the past years. Consequently, DDoS attack has become the most prominent attack as vulnerable IoT devices are becoming victims of it. In the literature, numerous techniques have been proposed to detect IoT-based DDoS attacks. However, techniques based on Artificial Intelligence (AI) have proven to be effective in the detection of cyber-attacks in comparison to other alternative techniques. This paper presents a systematic literature review of AI-based tools and techniques used for analysis, classification, and detection of the most threatening, prominent, and dreadful IoT-based DDoS attacks between the years 2019 to 2023. A comparative study of real datasets having IoT traffic features has also been illustrated. The findings of this systematic review provide useful insights into the existing research landscape for designing AI-based models to detect IoT-based DDoS attacks specifically. Additionally, the study sheds light on IoT botnet lifecycle, various botnet families, the taxonomy of IoT-based DDoS attacks, prominent tools used to launch DDoS attack, publicly available IoT datasets, the taxonomy of AI techniques, popular software available for ML/DL modeling, a list of numerous research challenges and future directions that may aid in the development of novel and reliable methods for identifying and categorizing IoT-based DDoS attacks.",https://doi.org/10.1016/j.cosrev.2024.100631,https://www.sciencedirect.com/science/article/pii/S1574013724000157,,,,2024,"AI techniques for IoT-based DDoS attack detection: Taxonomies, comprehensive review and research challenges",Bindu Bala and Sunny Behal,article,BALA2024100631,Computer Science Review,,52,1574-0137,,,
,"Robotics, Education, Circularity, Open-science, Recycling, Low-cost",e00484,,"The advent of robotics in schools and universities curricula are preparing students to encompass new didactic fields. This article presents ReFiBot which is an education robot that has been used to increase the technical literacy on robotics and bring more awareness to open science at Wageningen University. The ReFiBot combines open-source hardware and software, integrated with a chassis made from recycled plastic from fishnets. The ReFiBot was carefully designed to be easily assembled with off-the-shelf electronic parts and programmed using the Arduino IDE. Moreover, a software library is facilitated to ease its adoption in educational activities from any curricula level. The ReFiBot has been mainly used for education but can also be used for research on swarm robotics. The CAD files, components list, software files, and tutorial within this contribution will guide the reader through the assemblage and best practices of this circular robotics kit.",https://doi.org/10.1016/j.ohx.2023.e00484,https://www.sciencedirect.com/science/article/pii/S2468067223000913,,,,2023,The ReFiBot makers guide: Fostering academic open science and circularity with a robotic educational kit,Christos Pantos and Jurrian Doornbos and Gonzalo Mier and João Valente,article,PANTOS2023e00484,HardwareX,,16,2468-0672,,,
,"Auction, Critical value condition, DDoS attack, Differential payment, Marginal utility",101763,,"Complexity and severity of DDoS attacks is increasing day by day. Internet has highly inconsistent structure in terms of resource distribution. Numerous technical solutions are present in this domain but solutions considering economic aspects have not been given attention. Therefore, in this paper, a multi attribute based auction mechanism to mitigate DDoS attacks has been proposed. A reputation based detection mechanism has been proposed where reputation of a user is assessed through his marginal utility. Along with detection mechanism, two payment mechanisms have been proposed for legitimate and malicious users separately. A greedy resource allocation is devised to allocate resources fairly among the legitimate users. Malicious users who manipulate their bid to acquire maximum share of limited resources are charged with penalty according to differential payment scheme. Since, this is a generalized concept to mitigate DDoS attacks on any platform, we have taken our case study on cloud computing. So, simulations have been carried out on CloudSim. Results obtained from simulations clearly showed that proposed approach performs better than existing DDoS attack mitigation techniques.",https://doi.org/10.1016/j.cose.2020.101763,https://www.sciencedirect.com/science/article/pii/S016740482030047X,,,,2020,Multi attribute auction based incentivized solution against DDoS attacks,Amrita Dahiya and B.B. Gupta,article,DAHIYA2020101763,Computers & Security,,92,0167-4048,,,
,"Artificial intelligence, Data science, Electronic health records, Natural language processing, Predictive modeling, Real-world evidence",341-351,"Diabetes Digital Health, Telehealth, and Artificial Intelligence","Natural language processing (NLP) is used increasingly widely in the field of diabetes, ranging from the identification of hypoglycemic events to building predictive models for adverse clinical outcomes. More recent studies have shown a relationship between quantitative characteristics of text (e.g., the length of a sentence describing a patient-provider discussion) and outcomes like glucose levels, implying that these computational characteristics likely reflect care delivered to the patient. Barriers to the broader use of NLP in diabetes care and research (e.g., scarcity of human and data resources) can be overcome by promoting the training of endocrinologists with expertise in data science and cross-institutional collaborations.",https://doi.org/10.1016/B978-0-443-13244-5.00004-3,https://www.sciencedirect.com/science/article/pii/B9780443132445000043,,Academic Press,978-0-443-13244-5,2024,Chapter 27 - Natural Language Processing for Diabetes Digital Health,Alexander Turchin,incollection,TURCHIN2024341,,,,,,David C. Klonoff and David Kerr and Juan C. Espinoza,
,"Evolutionary algorithms, Hearthstone, Videogames, Evolution strategy, Artificial intelligence, Games, Card games, Collectible card games",105032,,"Digital collectible card games are not only a growing part of the video game industry, but also an interesting research area for the field of computational intelligence. This game genre allows researchers to deal with hidden information, uncertainty and planning, among other aspects. This paper proposes the use of evolutionary algorithms (EAs) to develop agents who play a card game, Hearthstone, by optimizing a data-driven decision-making mechanism that takes into account all the elements currently in play. Agents feature self-learning by means of a competitive coevolutionary training approach, whereby no external sparring element defined by the user is required for the optimization process. One of the agents developed through the proposed approach was runner-up (best 6%) in an international Hearthstone Artificial Intelligence (AI) competition. Our proposal performed remarkably well, even when it faced state-of-the-art techniques that attempted to take into account future game states, such as Monte-Carlo Tree search. This outcome shows how evolutionary computation could represent a considerable advantage in developing AIs for collectible card games such as Hearthstone.",https://doi.org/10.1016/j.knosys.2019.105032,https://www.sciencedirect.com/science/article/pii/S0950705119304356,,,,2020,Optimizing Hearthstone agents using an evolutionary algorithm,Pablo García-Sánchez and Alberto Tonda and Antonio J. Fernández-Leiva and Carlos Cotta,article,GARCIASANCHEZ2020105032,Knowledge-Based Systems,,188,0950-7051,,,
,"true polar wander, planetary reorientation, tidal deformation, Pluto",118270,,"Planets and moons reorient in space due to mass redistribution associated with various types of internal and external processes. While the equilibrium orientation of a tidally locked body is well understood, much less explored are the dynamics of the reorientation process (or true polar wander, TPW, used here for the motion of either the rotation or the tidal pole). TPW dynamics can be non-trivial and are important for predicting the patterns of TPW-induced surface fractures, as well as for assessing whether enough time has passed for the equilibrium orientation to be reached. The only existing and relatively complex numerical method for an accurate evaluation of the reorientation dynamics of a tidally locked body was described in a series of papers by Hu et al., 2017a, Hu et al., 2017b, Hu et al., 2019. Here we demonstrate that an identical solution can be obtained with a simpler approach, denoted as oω||mMIA, because during TPW the tidal and the rotation axes closely follow respectively the minor and the major axes of the total, time-evolving inertia tensor of the body. Motivated by the presumed reorientation of Pluto, the use of the oω||mMIA method is illustrated on several test examples. In particular, we vary the load sign and the mass of the host body and analyze whether TPW paths are curved or straight. When tidal forcing is relatively small, the paths of negative anomalies (e.g. basins) towards the rotation pole are highly curved, while positive loads may reach the sub- or anti-host point straightforwardly. The obtained behavior is explained by the relative timing of longitudinal and latitudinal reorientation. Our results suggest that the Sputnik Planitia basin cannot be a negative anomaly at present day, and that the remnant figure of Pluto must have formed prior to the reorientation. Finally, the presented method is complemented with an energy balance that can be used to test the numerical solution and to quantify the changes in orbital distance due to TPW. A new release of the custom written code LIOUSHELL that is used to perform the simulations is made freely available on GitHub.",https://doi.org/10.1016/j.epsl.2023.118270,https://www.sciencedirect.com/science/article/pii/S0012821X23002832,,,,2023,Dynamic reorientation of tidally locked bodies: Application to Pluto,Vojtěch Patočka and Martin Kihoulou,article,PATOCKA2023118270,Earth and Planetary Science Letters,,617,0012-821X,,,
,"Mining software repositories, Deep learning, Encoder–decoder neural network, Third-party libraries upgrade",117267,,"To keep their code up-to-date with the newest functionalities as well as bug fixes offered by third-party libraries, developers often need to replace an old version of third-party libraries (TPLs) with a newer one. However, choosing a suitable version for a library to be upgraded is complex and susceptible to error. So far, Dependabot is the only tool that supports library upgrades; however, it targets only security fixes and singularly analyzes libraries without considering the whole set of related libraries. In this work, we propose DeepLib as a practical approach to learn upgrades for third-party libraries that have been performed by similar clients. Such upgrades are considered safe, i.e., they do not trigger any conflict, since, in the training clients, the libraries already co-exist without causing any compatibility or dependency issues. In this way, the upgrades provided by DeepLib allow developers to maintain a harmonious relationship with other libraries. By mining the development history of projects, we build migration matrices to train deep neural networks. Once being trained, the networks are then used to forecast the subsequent versions of the related libraries, exploiting the well-founded background related to the machine translation domain. As input, DeepLib accepts a set of library versions and returns a set of future versions to which developers should upgrade the libraries. The framework has been evaluated on two real-world datasets curated from the Maven Central Repository. The results show promising outcomes: DeepLib can recommend the next version for a library as well as a set of libraries under investigation. At its best performance, DeepLib gains a perfect match for several libraries, earning an accuracy of 1.0.",https://doi.org/10.1016/j.eswa.2022.117267,https://www.sciencedirect.com/science/article/pii/S0957417422006388,,,,2022,DeepLib: Machine translation techniques to recommend upgrades for third-party libraries,Phuong T. Nguyen and Juri {Di Rocco} and Riccardo Rubei and Claudio {Di Sipio} and Davide {Di Ruscio},article,NGUYEN2022117267,Expert Systems with Applications,,202,0957-4174,,,
,"Internet of things, Flood analytics information system, Machine learning, Big Data, Flood situational awareness, The Carolinas.",104828,,"With the rapid development of the Internet of Things (IoT) and Big Data infrastructure, crowdsourcing techniques have emerged to facilitate data processing and problem solving particularly for flood emergences purposes. A Flood Analytics Information System (FAIS) has been developed as a Python Web application to gather Big Data from multiple servers and analyze flooding impacts during historical and real-time events. The application is smartly designed to integrate crowd intelligence, machine learning (ML), and natural language processing of tweets to provide flood warning with the aim to improve situational awareness for flood risk management. FAIS, a national scale prototype, combines flood peak rates and river level information with geotagged tweets to identify a dynamic set of at-risk locations to flooding. The prototype was successfully tested in real-time during Hurricane Dorian flooding as well as for historical event (Hurricanes Florence) across the Carolinas, USA where the storm made extensive disruption to infrastructure and communities.",https://doi.org/10.1016/j.envsoft.2020.104828,https://www.sciencedirect.com/science/article/pii/S1364815220308859,,,,2020,A national scale big data analytics pipeline to assess the potential impacts of flooding on critical infrastructures and communities,N. Donratanapat and S. Samadi and J.M. Vidal and S. {Sadeghi Tabas},article,DONRATANAPAT2020104828,Environmental Modelling & Software,,133,1364-8152,,,
,,3,,,https://doi.org/10.1016/S1353-4858(20)30123-9,https://www.sciencedirect.com/science/article/pii/S1353485820301239,,,,2020,Threatwatch,,article,20203,Network Security,11,2020,1353-4858,,,
,"DDoS attack, SYN Flooding attack, Time series, MFDFA, Exponential weighted moving average",102315,,"The TCP SYN flooding (half-open connection) attack is a type of DDoS attack, which denies the services by consuming the server resources. This attack prevents legitimate users from using their desired service. The SYN flooding attack exploits the normal TCP three-way handshake by sending stream of SYN packets to the server with spoofed IP addresses. The detection of this attack is hard since the internet routing infrastructure cannot differentiate between legitimate and spoofed SYN packets. In this paper we present a new detection method for the SYN flooding attack based on Multifractal Detrended Fluctuation Analysis (MFDFA) in addition to an adaptive threshold, thus we can detect the abnormal behavior in the TCP protocol time series.",https://doi.org/10.1016/j.cose.2021.102315,https://www.sciencedirect.com/science/article/pii/S0167404821001395,,,,2021,Multifractal detrended fluctuation analysis based detection for SYN flooding attack,Dalia Nashat and Fatma A. Hussain,article,NASHAT2021102315,Computers & Security,,107,0167-4048,,,
,"(MeSH): Vaccines, Pharmacoepidemiology, Self-controlled Case Series, Self-controlled Risk Interval, Myocarditis, Electronic Health Records, Meta-analysis",3039-3048,,"Introduction
The aim of this study was to assess the possible extent of bias due to violation of a core assumption (event-dependent exposures) when using self-controlled designs to analyse the association between COVID-19 vaccines and myocarditis.
Methods
We used data from five European databases (Spain: BIFAP, FISABIO VID, and SIDIAP; Italy: ARS-Tuscany; England: CPRD Aurum) converted to the ConcePTION Common Data Model. Individuals who experienced both myocarditis and were vaccinated against COVID-19 between 1 September 2020 and the end of data availability in each country were included. We compared a self-controlled risk interval study (SCRI) using a pre-vaccination control window, an SCRI using a post-vaccination control window, a standard SCCS and an extension of the SCCS designed to handle violations of the assumption of event-dependent exposures.
Results
We included 1,757 cases of myocarditis. For analyses of the first dose of the Pfizer vaccine, to which all databases contributed information, we found results consistent with a null effect in both of the SCRI and extended SCCS, but some indication of a harmful effect in a standard SCCS. For the second dose, we found evidence of a harmful association for all study designs, with relatively similar effect sizes (SCRI pre = 1.99, 1.40 – 2.82; SCRI post 2.13, 95 %CI – 1.43, 3.18; standard SCCS 1.79, 95 %CI 1.31 – 2.44, extended SCCS 1.52, 95 %CI = 1.08 – 2.15). Adjustment for calendar time did not change these conclusions. Findings using all designs were also consistent with a harmful effect following a second dose of the Moderna vaccine.
Conclusions
In the context of the known association between COVID-19 vaccines and myocarditis, we have demonstrated that two forms of SCRI and two forms of SCCS led to largely comparable results, possibly because of limited violation of the assumption of event-dependent exposures.",https://doi.org/10.1016/j.vaccine.2024.03.043,https://www.sciencedirect.com/science/article/pii/S0264410X2400330X,,,,2024,A comparison of four self-controlled study designs in an analysis of COVID-19 vaccines and myocarditis using five European databases,Anna Schultze and Ivonne Martin and Davide Messina and Sophie Bots and Svetlana Belitser and Juan {José Carreras-Martínez} and Elisa Correcher-Martinez and Arantxa Urchueguía-Fornes and Mar Martín-Pérez and Patricia García-Poza and Felipe Villalobos and Meritxell Pallejà-Millán and Carlo {Alberto Bissacco} and Elena Segundo and Patrick Souverein and Fabio Riefolo and Carlos E. Durán and Rosa Gini and Miriam Sturkenboom and Olaf Klungel and Ian Douglas,article,SCHULTZE20243039,Vaccine,12,42,0264-410X,,,
,"Cybersecurity, DDoS attack prediction, Survey, Network security",109553,,"Distributed Denial of Service (DDoS) attack is one of the biggest cyber threats. DDoS attacks have evolved in quantity and volume to evade detection and increase damage. Changes during the COVID-19 pandemic have left traditional perimeter-based security measures vulnerable to attackers that have diversified their activities by targeting health services, e-commerce, and educational services. DDoS attack prediction searches for signals of attack preparation to warn about the imminence of the attack. Prediction is necessary to handle high-volumetric DDoS attacks and to increase the time to defend against them. This survey article presents the classification of studies from the literature comprising the current state-of-the-art on DDoS attack prediction. It highlights the results of this extensive literature review categorizing the works by prediction time, architecture, employed methodology, and the type of data utilized to predict attacks. Further, this survey details each identified study and, finally, it emphasizes the research opportunities to evolve the DDoS attack prediction state-of-the-art.",https://doi.org/10.1016/j.comnet.2022.109553,https://www.sciencedirect.com/science/article/pii/S1389128622005874,,,,2023,"Distributed denial of service attack prediction: Challenges, open issues and opportunities",Anderson Bergamini {de Neira} and Burak Kantarci and Michele Nogueira,article,DENEIRA2023109553,Computer Networks,,222,1389-1286,,,
,"Infodemic, Misinformation, Media diet, Machine learning, COVID-19",100123,,"There is an abundance of misinformation, disinformation, and “fake news” related to COVID-19, leading the director-general of the World Health Organization to term this an ‘infodemic’. Given the high volume of COVID-19 content on the Internet, many find it difficult to evaluate veracity. Vulnerable and marginalized groups are being misinformed and subject to high levels of stress. Riots and panic buying have also taken place due to “fake news”. However, individual research-led websites can make a major difference in terms of providing accurate information. For example, the Johns Hopkins Coronavirus Resource Center website has over 81 million entries linked to it on Google. With the outbreak of COVID-19 and the knowledge that deceptive news has the potential to measurably affect the beliefs of the public, new strategies are needed to prevent the spread of misinformation. This study seeks to make a timely intervention to the information landscape through a COVID-19 “fake news”, misinformation, and disinformation website. In this article, we introduce CoVerifi, a web application which combines both the power of machine learning and the power of human feedback to assess the credibility of news. By allowing users the ability to “vote” on news content, the CoVerifi platform will allow us to release labelled data as open source, which will enable further research on preventing the spread of COVID-19-related misinformation. We discuss the development of CoVerifi and the potential utility of deploying the system at scale for combating the COVID-19 “infodemic”.",https://doi.org/10.1016/j.osnem.2021.100123,https://www.sciencedirect.com/science/article/pii/S2468696421000070,,,,2021,CoVerifi: A COVID-19 news verification system,Nikhil L. Kolluri and Dhiraj Murthy,article,KOLLURI2021100123,Online Social Networks and Media,,22,2468-6964,,,
,"Video engagement, DeepWalk, Online behavior, One-class model",228-237,,"Video engagement is important in online advertisements where there is no physical interaction with the consumer. Engagement can be directly measured as the number of seconds after which a consumer skips an advertisement. In this paper, we propose a model to predict video engagement of an advertisement using only a few samples. This allows for early identification of poor quality videos. This can also help identify advertisement frauds where a robot runs fake videos behind the name of well-known brands. We leverage on the fact that videos with high engagement have similar viewing patterns over time. Hence, we can create a similarity network of videos and use a graph-embedding model called DeepWalk to cluster videos into significant communities. The learned embedding is able to identify viewing patterns of fraud and popular videos. In order to assess the impact of a video, we also consider how the view counts increase or decrease over time. This results in a heterogeneous graph where an edge indicates similar video engagement or history of view counts between two videos. Since it is difficult to find labelled samples for ‘fraud’ video, we leverage on a one-class model that can determine ‘fraud’ videos with outlier or abnormal behavior. The proposed model outperforms baselines in F-measure by over 20%.",https://doi.org/10.1016/j.neucom.2021.08.127,https://www.sciencedirect.com/science/article/pii/S0925231221013382,,,,2021,Predicting video engagement using heterogeneous DeepWalk,Iti Chaturvedi and Kishor Thapa and Sandro Cavallari and Erik Cambria and Roy E. Welsch,article,CHATURVEDI2021228,Neurocomputing,,465,0925-2312,,,
,"Botnet detection, Dga botnets, Deep learning, Lstm network, Attention Layer, UMUDGA Dataset",102549,,"Botnets are a frequent threat to information systems on the Internet, capable of launching denial-of-service attacks, spreading spam and malware on a large scale. Detecting and preventing botnets is very important in cybersecurity. Previous studies have suggested anomaly-based, signature-based, or HoneyNet-based botnet detection solutions. This paper presents new solutions for detecting and classifying families of Domain Generation Algorithm (DGA) botnets. Our solution can be applied in practice to disable botnets even if they have infected the computer. Our works help solve two problems, including binary classification and multiclass classification, specifically: (1) Determining whether a domain name is malicious or benign; (2) For malicious domains, identify their DGA botnet family. We proposed two deep learning models called LA_Bin07 and LA_Mul07 by combining the LSTM network and Attention layer. Our evaluation used the UMUDGA dataset recently published in 2020, with 50 DGA botnet families. The experimental results show that the LA_Bin07 and LA_Mul07 models solve the DGA botnets problem for binary and multiclass classification problems with very high accuracy.",https://doi.org/10.1016/j.cose.2021.102549,https://www.sciencedirect.com/science/article/pii/S0167404821003734,,,,2022,On Detecting and Classifying DGA Botnets and their Families,Tong Anh Tuan and Hoang Viet Long and David Taniar,article,TUAN2022102549,Computers & Security,,113,0167-4048,,,
,"Agile software development, Agile practices, Teaching, University, Adapting, Contextualization",501-510,,"Teaching agile practices has found its place in software engineering curricula in many universities across the globe. As a result, educators and students have embraced different ways to apply agile practices during their courses through lectures, games, projects, workshops and more for effective theoretical and practical learning. Practicing agile in university contexts comes with challenges for students and to counter these challenges, they perform some adaptations to standard agile practices making them effective and easier to use in university contexts. This study describes the constraints the students faced while applying agile practices in a university course taught at the University of Auckland, including difficulty in setting up common time for all team members to work together, limited availability of customer due to busy schedule and the modifications the students introduced to adapt agile practices to suit the university context, such as daily stand-ups with reduced frequency, combining sprint meetings, and rotating scrum master from team. In addition, it summarizes the effectiveness of these modifications based on reflection of the students. Recommendations for educators and students are also provided. Our findings and recommendations will help educators and students better coordinate and apply agile practices on industry-based projects in university contexts.",https://doi.org/10.1016/j.jss.2018.07.011,https://www.sciencedirect.com/science/article/pii/S0164121218301419,,,,2018,Adapting agile practices in university contexts,Zainab Masood and Rashina Hoda and Kelly Blincoe,article,MASOOD2018501,Journal of Systems and Software,,144,0164-1212,,,
,"Fake news, Astroturfing, Graph convolutional networks, Disinformation, Graph attention networks",100104,,"The detection of organised disinformation campaigns that spread fake news, by first camouflaging them as real ones is crucial in the battle against misinformation and disinformation in social media. This article presents a method for classifying the diffusion graphs of news formed in social media, by taking into account the profiles of the users that participate in the graph, the profiles of their social relations and the way the news spread, ignoring the actual text content of the news or the messages that spread it. This increases the robustness of the method and widens its applicability in different contexts. The results of this study show that the proposed method outperforms methods that rely on textual information only and provide a model that can be employed for detecting similar disinformation campaigns on different context in the same social medium.",https://doi.org/10.1016/j.jjimei.2022.100104,https://www.sciencedirect.com/science/article/pii/S2667096822000477,,,,2022,Detection of fake news campaigns using graph convolutional networks,Dimitrios Michail and Nikos Kanakaris and Iraklis Varlamis,article,MICHAIL2022100104,International Journal of Information Management Data Insights,2,2,2667-0968,,,
,,107391,,"Last years have witnessed more and more DDoS attacks towards high-profile websites, as the Mirai botnet attack on September 2016, or more recently the memcached attack on March 2018, this time with no botnet required. These two outbreaks were not detected nor mitigated during their spreading, but only at the time they happened. Such attacks are generally preceded by several stages, including infection of hosts or device fingerprinting; being able to capture this activity would allow their early detection. In this paper, we propose a technique for the early detection of emerging botnets and newly exploited vulnerabilities, which consists in (i) splitting the detection process over different network segments and retaining only distributed anomalies, (ii) monitoring at the port-level, with a simple yet efficient change-detection algorithm based on a modified Z-score measure. We argue how our technique, named Split-and-Merge, can ensure the detection of large-scale zero-day attacks and drastically reduce false positives. We apply the method on two datasets: the MAWI dataset, which provides daily traffic traces of a transpacific backbone link, and the UCSD Network Telescope dataset which contains unsolicited traffic mainly coming from botnet scans. The assumption of a normal distribution – for which the Z-score computation makes sense – is verified through empirical measures. We also show how the solution generates very few alerts; an extensive evaluation on the last three years allows identifying major attacks (including Mirai and memcached) that current Intrusion Detection Systems (IDSs) have not seen. Finally, we classify detected known and unknown anomalies to give additional insights about them.",https://doi.org/10.1016/j.comnet.2020.107391,https://www.sciencedirect.com/science/article/pii/S1389128620300761,,,,2020,Detection of zero-day attacks: An unsupervised port-based approach,Agathe Blaise and Mathieu Bouet and Vania Conan and Stefano Secci,article,BLAISE2020107391,Computer Networks,,180,1389-1286,,,
,"IT Security, Common vulnerability scoring system, Classification, National vulnerability database, Security management, Deep learning",103286,,"The number of newly published vulnerabilities is constantly increasing. Until now, the information available when a new vulnerability is published is manually assessed by experts using a Common Vulnerability Scoring System (CVSS) vector and score. This assessment is time consuming and requires expertise. Various works already try to predict CVSS vectors or scores using machine learning based on the textual descriptions of the vulnerability to enable faster assessment. However, for this purpose, previous works only use the texts available in databases such as National Vulnerability Database. With this work, the publicly available web pages referenced in the National Vulnerability Database are analyzed and made available as sources of texts through web scraping. A Deep Learning based method for predicting the CVSS vector is implemented and evaluated. The present work provides a classification of the National Vulnerability Database’s reference texts based on the suitability and crawlability of their texts. While we identified the overall influence of the additional texts is negligible, we outperformed the state-of-the-art with our Deep Learning prediction models.",https://doi.org/10.1016/j.cose.2023.103286,https://www.sciencedirect.com/science/article/pii/S0167404823001967,,,,2023,Common vulnerability scoring system prediction based on open source intelligence information sources,Philipp Kühn and David N. Relke and Christian Reuter,article,KUHN2023103286,Computers & Security,,131,0167-4048,,,
,"Product Data, Linked Data, Semantic Web technologies, Construction industry, Linked Product Data",103927,,"The digitalisation of the Architecture, Engineering and Construction domain introduced new methods for digital collaboration, i.e. Building Information Modelling (BIM). While this method focuses on building data, the distribution of digital product models is still problematic, complicating uniform product searches and automated product data processing. Existing schemas, such as a subpart of the Industry Foundation Classes or the German VDI 3805, rely on rigid or template-driven schemas, that do not support the description of innovative or multi-functional products or impose a large schema overhead and complexity on manufacturers. Therefore, this article combines flexible and modular product descriptions with Semantic Web technologies and Linked Data. By applying Web-based technologies, the searchability of product data and the applicability of distributed data are expected to be enhanced. More precisely, this article proposes a concept for Linked Building Product Data and introduces the generic Building Product Ontology as a potential core schema of the concept. To demonstrate the feasibility of Linked Building Product Data and the Building Product Ontology, the authors apply both the concept and the data schema to innovative and multi-functional example products that cannot be described with the existing approaches for product descriptions. The evaluation demonstrates the flexibility, modularity and overall suitability of the presented concepts, meeting all collected requirements for digital product descriptions. Hence, Linked Building Product Data may solve existing issues with rigid product description schemas. At the same time, this approach complements the current research trend of Linked Building Data.",https://doi.org/10.1016/j.autcon.2021.103927,https://www.sciencedirect.com/science/article/pii/S0926580521003782,,,,2022,Building product ontology: Core ontology for Linked Building Product Data,Anna Wagner and Wendelin Sprenger and Christoph Maurer and Tilmann E. Kuhn and Uwe Rüppel,article,WAGNER2022103927,Automation in Construction,,133,0926-5805,,,
,"Advanced persistent threat, Anti-Virus evasion, Process injection, Covert communication, Anti-Debug, Anti-Virtual machine, Evasive manoeuvers re-Engineering framework(EMRF), Fileless malware, DLL Hijacking, Code obfuscation, IAT Hooking, Windows management instrumentation(WMI)",102627,,"The modern day cyber attacks are highly targeted and incorporate advanced tactics, techniques and procedures for greater stealth, impact and success. These attacks are also known as Advanced Persistent Threats(APT) because of their evasive and stealth nature along with longer foothold on the victim’s digital infrastructure. The malware involved in APT attacks are sophisticated and developed with the intention of sabotaging the victim’s digital infrastructure or performing espionage. They are capable of targeting multiple operating environments starting from desktop and server operating systems (Windows, Linux and MacOS), Mobile platforms (Android, iOS), Embedded platforms (IoT Devices), to Industrial control systems (ICS/SCADA Devices). The evolution of evasive tactics and techniques employed in such advanced malware leads to extensive research efforts to develop mechanisms that can counter these evasion techniques. The research primarily aims to demonstrate that evasive manoeuvers are currently over-weighing the security countermeasures deployed by the prevalent security solutions. This paper will first explain the evasion mechanism in a systematic manner employed in modern APT malware and aims to implement a novel Evasive Manoeuvers Re-Engineering Framework(EMRF).EMRF aims to establish and demonstrate combinations of evasive manoeuvers with much known APT malware samples to elude security solutions. The payload variants, i.e., executable, dynamic link library, and shell-code, were experimented through a research-based framework EMRF to demonstrate 36% to 96% of evasive behavior countering the majority of defender engines. The EMRF system with its dynamic user defined evasion manoeuvers is able to transform non-zero-day payloads more potent by evading majority of the modern security solutions. This research clearly demonstrates the attacker’s ability to deliver non-zero-day payloads easily rather than investing resources and time in discovering zero-day exploits and developing zero-day payloads. This important observation can potentially disrupt the Advanced Persistent Threat Defenses incorporated in modern day security solution where focus is mainly on to detect zero-day payloads and exploits. Exhibiting the threat landscape poised due to APT, the paper utilizes a dataset of 4403 APT malware samples to extract and orchestrate the prevalence of evasive manoeuvers like stealth, covert communication, and anti-analysis mechanisms. This paper will contribute towards advanced malware analysis as an avenue to analyzing intrusion, evasion, and deception to prevent detection and verification, an association of responsibility, and determination of intent.",https://doi.org/10.1016/j.cose.2022.102627,https://www.sciencedirect.com/science/article/pii/S0167404822000268,,,,2022,Orchestration of APT malware evasive manoeuvers employed for eluding anti-virus and sandbox defense,Amit Sharma and Brij B. Gupta and Awadhesh Kumar Singh and V.K. Saraswat,article,SHARMA2022102627,Computers & Security,,115,0167-4048,,,
,"Malware detection, Machine learning, Deep learning",632-649,,"Implementation of malware detection using Artificial Intelligence (AI) has emerged as a significant research theme to combat evolving various types of malwares. Researchers implement various detection mechanisms using shallow and deep learning models to counter new malware, and they continue to develop these mechanisms today. However, in the field of malware detection using AI, there are difficulties in collecting data, and it is difficult to compare research content and performance with related studies. Meanwhile, the number of well-organized papers is not sufficient to understand the overall research flow of these related studies. Before starting new research, researchers need to analyze the current state of research in the malware detection field they want to study. Therefore, based on these requirements, we present a summary of the general criteria related to malware detection and a classification table for detection mechanisms. Additionally, we have organized many studies in the field of various types of malware detection so that they can be viewed at a glance. We hope that the provided survey can help new researchers quickly understand the research flow in the field of AI-based malware detection and establish the direction for future research.",https://doi.org/10.1016/j.icte.2024.03.005,https://www.sciencedirect.com/science/article/pii/S2405959524000298,,,,2024,A study of the relationship of malware detection mechanisms using Artificial Intelligence,Jihyeon Song and Sunoh Choi and Jungtae Kim and Kyungmin Park and Cheolhee Park and Jonghyun Kim and Ikkyun Kim,article,SONG2024632,ICT Express,3,10,2405-9595,,,
,"Cybersecurity, Risk identification, Deep learning, Language model, Construction industry",105565,,"Modern construction projects are vulnerable to cyber-attacks due to insufficient attention to cybersecurity. Cyber risks in construction projects are not fully recognized, and the relevant literature is limited. To address this gap, the capabilities of a language model were leveraged to analyze extensive text, tailored to identify cyber risks. The model was trained using a curated corpus related to construction cybersecurity, enhanced by Supervised Fine-Tuning and Reinforcement Learning from Human Feedback techniques. The findings demonstrate advancements in the model's ability to understand cybersecurity and generate responses to cybersecurity questions. Using this model, a prioritized checklist of cyber risks across project phases was developed, establishing a new industry benchmark. This checklist can be utilized by various groups, including project managers and risk analysts. The model allows for updates with new data, ensuring the checklist remains current. The upgraded model holds significant promise for industry-wide applications, serving as an intelligent cybersecurity consultant.",https://doi.org/10.1016/j.autcon.2024.105565,https://www.sciencedirect.com/science/article/pii/S0926580524003017,,,,2024,Enhancing cyber risk identification in the construction industry using language models,Dongchi Yao and Borja {García de Soto},article,YAO2024105565,Automation in Construction,,165,0926-5805,,,
,"Instant messaging, Developer communication, Reusable knowledge, Software engineering themes, Thematic analysis",111397,,"Software developers use instant messaging (e.g., Slack, Gitter) to collaboratively discuss software engineering problems and solutions. This communication takes place in chat rooms that generally contain a description of the main topic of discussion and the messages exchanged. To analyze whether and how the knowledge accumulated in these chat rooms is relevant to other developers, we first need to understand the themes discussed in these chat rooms. In this paper, we used thematic analysis to manually identify software engineering themes in the description of 87 chat rooms of Gitter, an instant messaging tool for software developers. Then, we checked whether these themes also occur in 184 public chat rooms of Slack, another instant messaging tool. We identified 47 themes in Gitter chat rooms, and regarding the applicability of themes, we could relate 36 of our themes to 173 Slack chat rooms. Our results indicate that, in the context of our study, chat rooms in developer instant messaging communication are mostly about software development technologies and practices rather than development processes. Furthermore, most chat rooms are topic- rather than project-related (e.g., a chat room used by developers of a particular software development project).",https://doi.org/10.1016/j.jss.2022.111397,https://www.sciencedirect.com/science/article/pii/S0164121222001133,,,,2022,A qualitative analysis of themes in instant messaging communication of software developers,Camila {Costa Silva} and Matthias Galster and Fabian Gilson,article,COSTASILVA2022111397,Journal of Systems and Software,,192,0164-1212,,,
,"Wikipedia, reliability, websites, reliable sources, information quality, topic classification",3290-3299,,"Despite the fact, that over 21 years Wikipedia is edited by volunteers from all over the world with different views, culture, education and competences, this free encyclopedia is one of the most popular source of knowledge in the Internet. Freedom to edit does not mean, that you can put there whatever content you want. One of the core rules of Wikipedia says, that information in its articles should be based on reliable sources and Wikipedia readers must be able to verify particular facts in text. However, reliability is a subjective concept and a reputation of the same source can be assessed diffidently depending on a person (or group of persons), language and topic. So each language version of Wikipedia may have own rules or criteria on how the website must be assessed before it can be used as a source in references. At the same time, nowadays there are over 1 billion websites on the Internet and only few developed language chapters of the encyclopedia contains non-exhaustive lists of less than 1 thousand popular websites with reliability assessment. Additionally, since reputation of the source can be changed during the time, such lists must be updated regularly. This study presents result of important web sources identification based on analysis of over 230 million references that were extracted from over 40 million Wikipedia article of 42 most developed language version. Additionally, general statistics on references usage for each considered Wikipedia language were counted, including average number of references, number of unique references, scientific score, number of websites in references. Next, Wikipedia articles were assigned to different topics in each considered language. This allows to find differences in reliability and popularity of the same sources of information between Wikipedia languages, as well as find important websites in specific areas of knowledge.",https://doi.org/10.1016/j.procs.2022.09.387,https://www.sciencedirect.com/science/article/pii/S1877050922012777,,,,2022,Identification of Important Web Sources of Information on Wikipedia across various Topics and Languages,Włodzimierz Lewoniewski,article,LEWONIEWSKI20223290,Procedia Computer Science,,207,1877-0509,Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 26th International Conference KES2022,,
,"Anomaly based detection, Cloud computing, DDoS attack, Economic denial of sustainability, Machine learning, Deep learning, Statistical methods",100332,,"Cloud computing model provides on demand, elastic and fully managed computer system resources and services to organizations. However, attacks on cloud components can cause inestimable losses to cloud service providers and cloud users. One such category of attacks is the Distributed Denial of Service (DDoS), which can have serious consequences including impaired customer experience, service outage and in severe cases, complete shutdown and total economic unsustainability. Advances in Internet of Things (IoT) and network connectivity have inadvertently facilitated launch of DDoS attacks which have increased in volume, frequency and intensity. Recent DDoS attacks involving new attack vectors and strategies, have precipitated the need for this survey. In this survey, we mainly focus on finding the gaps, as well as bridging those gaps between the future potential DDoS attacks and state-of-the-art scientific and commercial DDoS attack defending solutions. It seeks to highlight the need for a comprehensive detection approach by presenting the recent threat landscape and major cloud attack incidents, estimates of future DDoS, illustrative use cases, commercial DDoS solutions, and the laws governing DDoS attacks in different nations. An up-to-date survey of DDoS detection methods, particularly anomaly based detection, available research tools, platforms and datasets, has been given. This paper further explores the use of machine learning methods for detection of DDoS attacks and investigates features, strengths, weaknesses, tools, datasets, and evaluates results of the methods in the context of the cloud. A summary comparison of statistical, machine learning and hybrid methods has been brought forth based on detailed analysis. This paper is intended to serve as a ready reference for the research community to develop effective and innovative detection mechanisms for forthcoming DDoS attacks in the cloud environment. It will also sensitize cloud users and providers to the urgent need to invest in deployment of DDoS detection mechanisms to secure their assets.",https://doi.org/10.1016/j.cosrev.2020.100332,https://www.sciencedirect.com/science/article/pii/S1574013720304329,,,,2021,Distributed denial of service attacks in cloud: State-of-the-art of scientific and commercial solutions,Aanshi Bhardwaj and Veenu Mangat and Renu Vig and Subir Halder and Mauro Conti,article,BHARDWAJ2021100332,Computer Science Review,,39,1574-0137,,,
,"Quantum computing, Education, Quantum game theory, Tic-Tac-Toe",100125,,"Quantum mechanics is a complex matter. Nonetheless, given the impending arrival of quantum computers and the necessity for quantum programming abilities, more students should get acquainted with this subject. We provide a game-based learning approach based on Tic-Tac-Toe in a quantum modified version as a result of our study. We created a prototype to demonstrate and evaluate our assumptions using the design science research technique. Qualitative user feedback provided us with vital insights and shown that this game-based method helps to cope with quantum physics in a fun way. A majority of those who took part in the study stated that their interest in the subject had increased. However, for novices, it is necessary to follow them during the initial period of their training. The comments were quite helpful in optimizing the prototype. We found that our strategy, which included the use of a virtual opponent as well as the presentation of extra information about the quantum circuit, was more effective in helping participants comprehend quantum physics than earlier Tic-Tac-Toe-based learning settings.",https://doi.org/10.1016/j.caeo.2023.100125,https://www.sciencedirect.com/science/article/pii/S2666557323000046,,,,2023,Quantum Tic-Tac-Toe - learning the concepts of quantum mechanics in a playful way,Maurice Weingärtner and Tim Weingärtner,article,WEINGARTNER2023100125,Computers and Education Open,,4,2666-5573,,,
,"Determining relevant and efficient feature subsets, Lightweight IDSs, Fine-tuned LSVMs and feature selectors, IoT network security",103598,,"Intrusion detection systems (IDSs) play a crucial role in ensuring the security and integrity of Internet of Things (IoT) networks by blocking unwanted packets and facilitating secure traffic flow. However, traditional IDSs based on data mining, fuzzy logic, heuristics, rough sets, or conventional machine learning (ML) techniques often lack accuracy and are not energy efficient, primarily due to inappropriate feature selection or the use of all features in datasets. To address these challenges, this study proposes a lightweight, accurate, and high-performance IDSs for IoT networks using fine-tuned Linear Support Vector Machines (LSVMs) and feature selection methods. Four feature selectors, including Importance Coefficient-, Forward- and Backward-Sequential-, and Correlation Coefficient-based approaches, were applied to identify the most important and efficient features from three datasets: KDD Cup-1999, BotIoT-2018, and N-BaIoT-2021. The fine-tuned LSVMs algorithm was then trained on subsets of the selected and full features of the datasets to detect various IoT botnet attacks. Evaluation results show that the IDS models trained with subsets of relevant features outperform those trained with the full feature sets of the datasets in terms of training and test performance and accuracy. The study concludes that it is possible to develop lightweight IDSs by training them with a reduced number of features (6) instead of using the full features (40, 15, 115) in KDD Cup-1999, BotIoT-2018, and N-BaIoT-2021, respectively. The findings highlight a potential for significantly improving the efficiency and accuracy of IDSs on IoT networks using the fine-tuned feature selectors and LSVMs.",https://doi.org/10.1016/j.cose.2023.103598,https://www.sciencedirect.com/science/article/pii/S0167404823005084,,,,2024,Designing accurate lightweight intrusion detection systems for IoT networks using fine-tuned linear SVM and feature selectors,Jahongir Azimjonov and Taehong Kim,article,AZIMJONOV2024103598,Computers & Security,,137,0167-4048,,,
,"Misinformation, Twitter, Social media, COVID-19, Fake news, Coronavirus, Diffusion of information",100104,,"During the COVID-19 pandemic, social media has become a home ground for misinformation. To tackle this infodemic, scientific oversight, as well as a better understanding by practitioners in crisis management, is needed. We have conducted an exploratory study into the propagation, authors and content of misinformation on Twitter around the topic of COVID-19 in order to gain early insights. We have collected all tweets mentioned in the verdicts of fact-checked claims related to COVID-19 by over 92 professional fact-checking organisations between January and mid-July 2020 and share this corpus with the community. This resulted in 1500 tweets relating to 1274 false and 226 partially false claims, respectively. Exploratory analysis of author accounts revealed that the verified twitter handle(including Organisation/celebrity) are also involved in either creating(new tweets) or spreading(retweet) the misinformation. Additionally, we found that false claims propagate faster than partially false claims. Compare to a background corpus of COVID-19 tweets, tweets with misinformation are more often concerned with discrediting other information on social media. Authors use less tentative language and appear to be more driven by concerns of potential harm to others. Our results enable us to suggest gaps in the current scientific coverage of the topic as well as propose actions for authorities and social media users to counter misinformation.",https://doi.org/10.1016/j.osnem.2020.100104,https://www.sciencedirect.com/science/article/pii/S2468696420300458,,,,2021,An exploratory study of COVID-19 misinformation on Twitter,Gautam Kishore Shahi and Anne Dirkson and Tim A. Majchrzak,article,SHAHI2021100104,Online Social Networks and Media,,22,2468-6964,,,
,"Privacy, Social networks, Temporal, Predict",103879,,"The pursuit of dividends from the burgeoning realm of data traffic has emerged as a prevailing trend. Given this current state of affairs, the safeguarding of personal information has become an urgent task. Current methods for personal privacy protection primarily offer alerts when information breaches occur, but at that stage, irreversible breaches have already transpired. Thus, the study of preemptive privacy breach prediction is a task of significant importance within the realm of privacy protection. However, the endeavor to predict privacy breaches in advance remains exceedingly challenging, owing to several factors: (i) The complexity of social networks gives rise to high-dimensional features. (ii) Concerning the comprehensive and precise capture of pathways leading to information leakage. (iii) How to employ time series data effectively to realize early predictions. This study proposes a novel approach for constructing graph neural networks and forecasting privacy breaches, centered on the context of user-generated content within specific time frames, integrates spatial graph structures with temporal series information. The integration can entirely achieve the advance prediction of users' privacy status, thereby preventing information leakage. Empirical tests on real-world datasets demonstrate that our approach surpasses traditional time series forecasting methods in privacy breach predictions, achieving a notable average improvement of 2% in F1 score, Recall, and Precision metrics.",https://doi.org/10.1016/j.cose.2024.103879,https://www.sciencedirect.com/science/article/pii/S0167404824001809,,,,2024,Precursor of privacy leakage detection for individual user,Xuefeng Li and Chensu Zhao and Yi Hu and Honglin Xie and Yuhang Wang and Jingyang Zhao,article,LI2024103879,Computers & Security,,142,0167-4048,,,
,"Malicious contents, Social media, Vulnerability, Active exploitation",103971,,"While Twitter remains one of the most popular social media networks within the information security community, threat actors continue to abuse the platform to create, share, and spread malicious contents. In this study, we focus on whether Twitter- and vulnerability-related features can help predict vulnerabilities known to be actively exploited. Using a sample of 6004 tweets, results show that Twitter features (tweets and quote tweets) that combine the benefits of both content creation and sharing can predict active exploitation of vulnerabilities. Furthermore, findings show that certain technical and vulnerability-related features are also capable of predicting active exploitations.",https://doi.org/10.1016/j.im.2024.103971,https://www.sciencedirect.com/science/article/pii/S0378720624000533,,,,2024,The diffusion of malicious content on Twitter and its impact on security,Yaman Roumani,article,ROUMANI2024103971,Information & Management,5,61,0378-7206,,,
,"Misogyny detection, Multi-modal content, Memes, Cybersexism, Visual and textual cues",108526,,"In this paper we present a benchmark dataset generated as part of a project for automatic identification of misogyny within online content, which focuses in particular on memes. The benchmark here described is composed of 800 memes collected from the most popular social media platforms, such as Facebook, Twitter, Instagram and Reddit, and consulting websites dedicated to collection and creation of memes. To gather misogynistic memes, specific keywords that refer to misogynistic content have been considered as search criterion, considering different manifestations of hatred against women, such as body shaming, stereotyping, objectification and violence. In parallel, memes with no misogynist content have been manually downloaded from the same web sources. Among all the collected memes, three domain experts have selected a dataset of 800 memes equally balanced between misogynistic and non-misogynistic ones. This dataset has been validated through a crowdsourcing platform, involving 60 subjects for the labelling process, in order to collect three evaluations for each instance. Two further binary labels have been collected from both the experts and the crowdsourcing platform, for memes evaluated as misogynistic, concerning aggressiveness and irony. Finally for each meme, the text has been manually transcribed. The dataset provided is thus composed of the 800 memes, the labels given by the experts and those obtained by the crowdsourcing validation, and the transcribed texts. This data can be used to approach the problem of automatic detection of misogynistic content on the Web relying on both textual and visual cues, facing phenomenons that are growing every day such as cybersexism and technology-facilitated violence.",https://doi.org/10.1016/j.dib.2022.108526,https://www.sciencedirect.com/science/article/pii/S235234092200720X,,,,2022,Benchmark dataset of memes with text transcriptions for automatic detection of multi-modal misogynistic content,Francesca Gasparini and Giulia Rizzi and Aurora Saibene and Elisabetta Fersini,article,GASPARINI2022108526,Data in Brief,,44,2352-3409,,,
,"Internet of things, DDoS attack, Botnet, Machine learning, Software defined network",103096,,"IoT offers capabilities to gather information from digital devices, infer from their results, and maintain and optimize these devices in different domains. IoT is heterogeneous in nature, which makes it prone to various security threats like confidentiality and integrity breaches, lack of availability of resources, trust issues, etc. The security concerns lead to different attacks over the system, and the Distributed Denial of Services (DDoS) bout is growing generously. DDoS is an assault that targets the availability of resources and servers of a network by flooding the communication medium from distinct locations by utilizing various IoT devices, which makes it harder to detect. Thus, analyzing and defending DDoS is a protruding field of research these days. The paper gives a thorough knowledge of DDoS over IoT. In this, we have critically analysed the existing DDoS variants, IoT Security issues, the execution of DDoS attempts, along with the exploitation of IoT devices and creation of them in Botnets or zombies. Moreover, the paper will also cover prevailing DDoS defense methodologies as well as their comparative analysis for ease of understanding.",https://doi.org/10.1016/j.cose.2023.103096,https://www.sciencedirect.com/science/article/pii/S0167404823000068,,,,2023,A comprehensive study of DDoS attacks over IoT network and their countermeasures,Pooja Kumari and Ankit Kumar Jain,article,KUMARI2023103096,Computers & Security,,127,0167-4048,,,
,"Digital forensic tools, Published software, Literature review, Open source software, Availability",300999,,"Publications in the digital forensics domain frequently come with tools – a small piece of functional software. These tools are often released to the public for others to reproduce results or use them for their own purposes. However, there has been no study on the tools to understand better what is available and what is missing. For this paper we analyzed almost 800 articles from pertinent venues from 2014 to 2019 to answer the following three questions (1) what tools (i.e., in which domains of digital forensics): have been released; (2) are they still available, maintained, and documented; and (3) are there possibilities to enhance the status quo? We found 62 different tools which we categorized according to digital forensics subfields. Only 33 of these tools were found to be publicly available, the majority of these were not maintained after development. In order to enhance the status quo, one recommendation is a centralized repository specifically for tested tools. This will require tool researchers (developers) to spend more time on code documentation and preferably develop plugins instead of stand-alone tools.",https://doi.org/10.1016/j.fsidi.2020.300999,https://www.sciencedirect.com/science/article/pii/S2666281720301864,,,,2020,Digital forensic tools: Recent advances and enhancing the status quo,Tina Wu and Frank Breitinger and Stephen O'Shaughnessy,article,WU2020300999,Forensic Science International: Digital Investigation,,34,2666-2817,,,
,"Malware analysis, APK, Android, Marketplace",88-98,,"This paper aims to evaluate possible threats with unofficial Android marketplaces, and geo-localize the malware distribution over three main regions: China; Europe; and Russia. It provides a comprehensive review of existing academic literature about security in Android focusing especially on malware detection systems and existing malware databases. Through the implementation of a methodology for identification of malicious applications it has been collected data revealing a 5% of them as malicious in an overall analysis. Furthermore, the analysis shown that Russia and Europe have a preponderance of generic detections and adware, while China is found to be targeted mainly by riskware and malware.",https://doi.org/10.1016/j.diin.2017.10.002,https://www.sciencedirect.com/science/article/pii/S1742287617300245,,,,2017,A methodology for the security evaluation within third-party Android Marketplaces,William J. Buchanan and Simone Chiale and Richard Macfarlane,article,BUCHANAN201788,Digital Investigation,,23,1742-2876,,,
,"Security, Privacy, Website Fingerprinting, Tor Browser, Dataset Collection Framework, Webpage Crawling",101778,,"Website Fingerprinting (WFP) is a technique that analyses browsing network traffic to infer a webpage that a user browsed in Tor Browser. A sufficiently large and clean dataset is essential for quality and accurate WFP experiments. Thus, there is a corresponding need to automate the dataset collection, filtering, and validation processes. This work introduces a new paradigm, WFP-Collector, an automatic dataset collection framework for WFP experiments. WFP-Collector enables researchers to automatically (1) create a visit database for webpage crawling, (2) collect various data and log for in-depth analysis, (3) webpage visits in tablet and mobile browsing modes, (4) throttle network bandwidth and latency performance, (5) validate and filter the collected data, (6) compress and upload the collected data to cloud storage, and (7) completion notification using Telegram and email. We developed a proof-of-concept of the WFP framework for simulation and comparison. We found that the WFP-Collector framework collects nine data items and produces over 55% larger collected data size than existing approaches. The captured packet size in tablet and mobile browsing modes is up to 57.5% smaller than in desktop mode. Moreover, the file compression in WFP-Collector can reduce up to 39.9% of the storage space required for data collection.",https://doi.org/10.1016/j.jksuci.2023.101778,https://www.sciencedirect.com/science/article/pii/S1319157823003324,,,,2023,WFP-Collector: Automated dataset collection framework for website fingerprinting evaluations on Tor Browser,Mohamad Amar Irsyad {Mohd Aminuddin} and Zarul Fitri Zaaba,article,MOHDAMINUDDIN2023101778,Journal of King Saud University - Computer and Information Sciences,9,35,1319-1578,,,
,,1-2,,"Threat actors are actively exploiting a critical flaw in Apache's Log4j logging library that allows them to execute arbitrary code, often with elevated privileges. The vulnerability (CVE-2021-44228) is trivially easy to exploit. And while a patch has been released, the library is in such widespread use – including by major platforms and services – that it may take some time before the threat is eliminated.",https://doi.org/10.1016/S1353-4858(21)00136-7,https://www.sciencedirect.com/science/article/pii/S1353485821001367,,,,2021,Critical Java flaw puts millions of organisations at risk,,article,20211,Network Security,12,2021,1353-4858,,,
,"Building energy flexibility, Semantic interoperability, Ontology, Grid-interactive efficient buildings, Demand side management",100113,,"Energy flexibility of buildings can be an essential resource for a sustainable and reliable power grid with the growing variable renewable energy shares and the trend to electrify and decarbonize buildings. Traditional demand-side management technologies, advanced building controls, and emerging distributed energy resources (including electric vehicle, energy storage, and on-site power generation) enable the transition of the building stock to grid-interactive efficient buildings (GEBs) that operate efficiently to meet service needs and are responsive to grid pricing or carbon signals to achieve energy and carbon neutrality. Although energy flexibility has received growing attention from industry and the research community, there remains a lack of common ground for energy flexibility terminologies, characterization, and quantification methods. This paper presents a semantic ontology—EFOnt (Energy Flexibility Ontology)—that extends existing terminologies, ontologies, and schemas for building energy flexibility applications. EFOnt aims to serve as a standardized tool for knowledge co-development and streamlining energy flexibility related applications. We demonstrate potential use cases of EFOnt via two examples: (1) energy flexibility analytics with measured data from a residential smart thermostat dataset and a commercial building, and (2) modeling and simulation to evaluate energy flexibility of buildings. The compatibility of EFOnt with existing ontologies and the outlook of EFOnt's role in the building energy data tool ecosystem are discussed.",https://doi.org/10.1016/j.adapen.2022.100113,https://www.sciencedirect.com/science/article/pii/S2666792422000312,,,,2022,A semantic ontology for representing and quantifying energy flexibility of buildings,Han Li and Tianzhen Hong,article,LI2022100113,Advances in Applied Energy,,8,2666-7924,,,
,"Autosomal recessive inheritance, Etat-criblé, Hemorrhagic stroke, NIT1, Small vessel disease",101105,,"Purpose
To describe a recessively inherited cerebral small vessel disease, caused by loss-of-function variants in Nitrilase1 (NIT1).
Methods
We performed exome sequencing, brain magnetic resonance imaging, neuropathology, electron microscopy, western blotting, and transcriptomic and metabolic analyses in 7 NIT1-small vessel disease patients from 5 unrelated pedigrees.
Results
The first identified patients were 3 siblings, compound heterozygous for the NIT1 c.727C>T; (p.Arg243Trp) variant and the NIT1 c.198_199del; p.(Ala68∗) variant. The 4 additional patients were single cases from 4 unrelated pedigrees and were all homozygous for the NIT1 c.727C>T; p.(Arg243Trp) variant. Patients presented in mid-adulthood with movement disorders. All patients had striking abnormalities on brain magnetic resonance imaging, with numerous and massively dilated basal ganglia perivascular spaces. Three patients had non-lobar intracerebral hemorrhage between age 45 and 60, which was fatal in 2 cases. Western blotting on patient fibroblasts showed absence of NIT1 protein, and metabolic analysis in urine confirmed loss of NIT1 enzymatic function. Brain autopsy revealed large electron-dense deposits in the vessel walls of small and medium sized cerebral arteries.
Conclusion
NIT1-small vessel disease is a novel, autosomal recessively inherited cerebral small vessel disease characterized by a triad of movement disorders, massively dilated basal ganglia perivascular spaces, and intracerebral hemorrhage.",https://doi.org/10.1016/j.gim.2024.101105,https://www.sciencedirect.com/science/article/pii/S1098360024000388,,,,2024,"Bi-allelic NIT1 variants cause a brain small vessel disease characterized by movement disorders, massively dilated perivascular spaces, and intracerebral hemorrhage",Julie W. Rutten and Minne N. Cerfontaine and Kyra L. Dijkstra and Aat A. Mulder and Jeroen Vreijling and Mark Kruit and Roman I. Koning and Susanne T. {de Bot} and Koen M. {van Nieuwenhuizen} and Hans J. Baelde and Henk W. Berendse and Leon H. Mei and George J.G. Ruijter and Frank Baas and Carolina R. Jost and Sjoerd G. {van Duinen} and Esther A.R. Nibbeling and Gido Gravesteijn and Saskia A.J. {Lesnik Oberstein},article,RUTTEN2024101105,Genetics in Medicine,6,26,1098-3600,,,
,"Computer Science, Artificial Intelligence, Human-Computer Interaction",102340,,"Summary
Global coordination is required to solve a wide variety of challenging collective action problems from network colorings to the tragedy of the commons. Recent empirical study shows that the presence of a few noisy autonomous agents can greatly improve collective performance of humans in solving networked color coordination games. To provide analytical insights into the role of behavioral randomness, here we study myopic artificial agents attempting to solve similar network coloring problems using decision update rules that are only based on local information but allow random choices at various stages of their heuristic reasonings. We show that the resulting efficacy of resolving color conflicts is dependent on the implementation of random behavior of agents and specific population characteristics. Our work demonstrates that distributed greedy optimization algorithms exploiting local information should be deployed in combination with occasional exploration via random choices in order to overcome local minima and achieve global coordination.",https://doi.org/10.1016/j.isci.2021.102340,https://www.sciencedirect.com/science/article/pii/S2589004221003084,,,,2021,Random choices facilitate solutions to collective network coloring problems by artificial agents,Matthew I. Jones and Scott D. Pauls and Feng Fu,article,JONES2021102340,iScience,4,24,2589-0042,,,
,"Material Science entity extraction, Material science relation extraction, Triplet (entity, relation, entity) extraction from material science, Triplet extraction",112659,,"Material science literature is a rich source of factual information about various categories of entities (like materials and compositions) and various relations between these entities, such as conductivity, voltage, etc. Automatically extracting this information to generate a material science knowledge base is a challenging task. In this paper, we propose MatSciRE (Material Science Relation Extractor), a Pointer Network-based encoder–decoder framework, to jointly extract entities and relations from material science articles as a triplet (entity1,relation,entity2). Specifically, we target the battery materials and identify five relations to work on — conductivity, coulombic efficiency, capacity, voltage, and energy. Our proposed approach achieved a much better F1-score (0.771) than a previous attempt using ChemDataExtractor (0.716). The overall graphical framework of MatSciRE is shown in Fig. 1. The material information is extracted from material science literature in the form of entity–relation triplets using MatSciRE.",https://doi.org/10.1016/j.commatsci.2023.112659,https://www.sciencedirect.com/science/article/pii/S0927025623006535,,,,2024,MatSciRE: Leveraging pointer networks to automate entity and relation extraction for material science knowledge-base construction,Ankan Mullick and Akash Ghosh and G. Sai Chaitanya and Samir Ghui and Tapas Nayak and Seung-Cheol Lee and Satadeep Bhattacharjee and Pawan Goyal,article,MULLICK2024112659,Computational Materials Science,,233,0927-0256,,,
,"Chatbots, Process mining, Natural language processing, Conformance checking",102176,,"Chatbots enable organizations in the business-to-customer domain to respond to repetitive requests efficiently. Extant approaches in Natural Language Processing (NLP) already address the essential requirement of understanding user input and synthesizing a response as close as possible to a response a human interlocutor would give. However, we argue that the organizational adoption of chatbots further depends on the underlying model’s capability to learn and comply with organizations’ business processes, for example, authenticating a customer before providing sensitive details. To address this issue, we develop an approach that quantifies chatbots’ ability to learn business processes using standardized process mining metrics. We demonstrate our approach by training chatbots on a dataset of more than 500,000 customer service conversations from three companies on Twitter and show how our approach supports the quantification of a chatbot’s overall ability to learn business processes from the training data. Furthermore, we quantify a chatbot’s ability to learn a particular variant of the underlying process and we show how to compare the chatbot’s executed steps against a given normative process model. Our approach that seamlessly integrates with existing approaches to evaluate NLP-based chatbots mitigates the current hurdles that practitioners face and, therefore, strives to foster the adoption of chatbots in practice.",https://doi.org/10.1016/j.is.2023.102176,https://www.sciencedirect.com/science/article/pii/S0306437923000121,,,,2023,Quantifying chatbots’ ability to learn business processes,Christoph Kecht and Andreas Egger and Wolfgang Kratsch and Maximilian Röglinger,article,KECHT2023102176,Information Systems,,113,0306-4379,,,
,"Artificial Intelligence, ChatGPT, Claude, Clinical reasoning, Neonatal care",104771,,"Aim
To assess the clinical reasoning capabilities of two large language models, ChatGPT-4 and Claude-2.0, compared to those of neonatal nurses during neonatal care scenarios.
Design
A cross-sectional study with a comparative evaluation using a survey instrument that included six neonatal intensive care unit clinical scenarios.
Participants
32 neonatal intensive care nurses with 5–10 years of experience working in the neonatal intensive care units of three medical centers.
Methods
Participants responded to 6 written clinical scenarios. Simultaneously, we asked ChatGPT-4 and Claude-2.0 to provide initial assessments and treatment recommendations for the same scenarios. The responses from ChatGPT-4 and Claude-2.0 were then scored by certified neonatal nurse practitioners for accuracy, completeness, and response time.
Results
Both models demonstrated capabilities in clinical reasoning for neonatal care, with Claude-2.0 significantly outperforming ChatGPT-4 in clinical accuracy and speed. However, limitations were identified across the cases in diagnostic precision, treatment specificity, and response lag.
Conclusions
While showing promise, current limitations reinforce the need for deep refinement before ChatGPT-4 and Claude-2.0 can be considered for integration into clinical practice. Additional validation of these tools is important to safely leverage this Artificial Intelligence technology for enhancing clinical decision-making.
Impact
The study provides an understanding of the reasoning accuracy of new Artificial Intelligence models in neonatal clinical care. The current accuracy gaps of ChatGPT-4 and Claude-2.0 need to be addressed prior to clinical usage.",https://doi.org/10.1016/j.ijnurstu.2024.104771,https://www.sciencedirect.com/science/article/pii/S002074892400083X,,,,2024,An evaluation of the capabilities of language models and nurses in providing neonatal clinical decision support,Chedva Levin and Tehilla Kagan and Shani Rosen and Mor Saban,article,LEVIN2024104771,International Journal of Nursing Studies,,155,0020-7489,,,
,"ChatGPT, Sentiment analysis, Emotion analysis, Science, Large language models",100541,,"ChatGPT, a chatbot developed by OpenAI, has gained widespread popularity and media attention since its release in November 2022. However, little hard evidence is available regarding its perception in various sources. In this paper, we analyze over 300,000 tweets and more than 150 scientific papers to investigate how ChatGPT is perceived and discussed. Our findings show that ChatGPT is generally viewed as of high quality, with positive sentiment and emotions of joy dominating social media. Its perception has slightly decreased since its debut, however, with joy decreasing and (negative) surprise on the rise, and it is perceived more negatively in languages other than English. In recent scientific papers, ChatGPT is characterized as a great opportunity across various fields including the medical domain, but also as a threat concerning ethics and receives mixed assessments for education. Our comprehensive meta-analysis of ChatGPT’s perception after 2.5 months since its release can contribute to shaping the public debate and informing its future development. We make our data available.11https://github.com/NL2G/ChatGPTReview.",https://doi.org/10.1016/j.mlwa.2024.100541,https://www.sciencedirect.com/science/article/pii/S2666827024000173,,,,2024,ChatGPT: A meta-analysis after 2.5 months,Christoph Leiter and Ran Zhang and Yanran Chen and Jonas Belouadi and Daniil Larionov and Vivian Fresen and Steffen Eger,article,LEITER2024100541,Machine Learning with Applications,,16,2666-8270,,,
,"Social media analysis, Protest, COVID-19, Natural language processing, Manual labelling",110527,,"The Netherlands police are looking for measures to examine sentiment on social media related to protest demonstrations. While models exist to detect more subtle expressions of sentiment within tweets, models trained in the Dutch language are scarce. Being able to predict sentiment development during protests is relevant for parties like the Dutch government and the police to get more insight to when and where potential law enforcement is needed for public order and safety. Therefore, to analyse sentiment before, during, and after protest demonstrations, data was collected with tweets related to a Black Lives Matter protest that took place in Amsterdam during the COVID-19 pandemic. All tweets have been manually labelled by a dedicated open-source intelligence (OSINT) team within the Netherlands police following an established protocol. Both the data and the protocol are available, and interesting for researchers in natural language processing, topic detection, sentiment analysis, and protests analysis. The developed labelling tool for the labelling process is publicly available.",https://doi.org/10.1016/j.dib.2024.110527,https://www.sciencedirect.com/science/article/pii/S2352340924004955,,,,2024,"Dutch tweets before, during, and after a black lives matter demonstration in Amsterdam: Expert annotated data, protocol, and labelling tool",Laurens H.F. Müter and Christof {van Nimwegen} and Remco C. Veltkamp,article,MUTER2024110527,Data in Brief,,55,2352-3409,,,
,"Experimental economics, Web-based, Software, Online experiments, Web-based experiments, Economic experiments",138-160,,"Web-based experiments that cut across the lab vs. field distinction are increasingly popular with economists. However, non-standardized software features and services hinder comparability and replication. This study reviews a wide selection of experimental economics software packages and evaluates them against criteria based on the logistics and operational requirements of economic experiments. We find that oTree and SoPHIE rank highest across criteria, but Veconlab and classEx might be suitable for those with a dominant need for a large library of ready-made experiments. We find a portability gap: no presently available software allows portability of experiments across platforms because of technical complexity and the challenging coordination needs of experimental economists. As a result, experiments may be replicated only on the same platform or with the same software, but general replicability is slow and costly. This constrains the development of experimental economics as a replicable science.",https://doi.org/10.1016/j.jbef.2019.04.007,https://www.sciencedirect.com/science/article/pii/S221463501830090X,,,,2019,Web-based experimental economics software: How do they compare to desirable features?,Shu Wing Chan and Steven Schilizzi and Md Sayed Iftekhar and Raymond {Da Silva Rosa},article,CHAN2019138,Journal of Behavioral and Experimental Finance,,23,2214-6350,,,
,"Thermal, Mechanics, Coupling, Arctic coastal erosion, Permafrost",113533,,"Although the Arctic comprises one-third of the global coastline and has some of the fastest eroding coasts, current tools for quantifying permafrost erosion are unable to explain the episodic, storm-driven erosion events that occur in this region. In this paper, we present a novel multi-physics finite element model for the numerical simulation of Arctic coastal permafrost degradation: the terrestrial component of the Arctic Coastal Erosion (ACE) model. This model is comprised of two main ingredients: (1) a solid mechanics model that calculates the three-dimensional (3D) stress, strain and displacement fields of the underlying permafrost developing in response to a frozen water content dependent plasticity model, and (2) a novel thermal model governing the 3D heat conduction and solid–liquid phase change occurring within the permafrost. These two physics sets are coupled via a sequential thermo-mechanical coupling scheme developed within the Albany LCM open-source finite element code. Unlike prior approaches, our modeling methodology enables failure from any allowable deformation (block failure, thermo-denudation, thermo-abrasion); moreover, failure modes develop from constitutive (rather than empirical) relationships inherent in the underlying finite element model. Elements are dynamically removed from the underlying finite element mesh so as to simulate transient permafrost erosion events. Our thermo-mechanical terrestrial model is evaluated on a pseudo-realistic problem in which a slice of permafrost is exposed to realistic oceanic and atmospheric forcing boundary condition data occurring at Drew Point, Alaska in July 2018.",https://doi.org/10.1016/j.cam.2021.113533,https://www.sciencedirect.com/science/article/pii/S0377042721001527,,,,2021,A thermo-mechanical terrestrial model of Arctic coastal erosion,Jennifer Frederick and Alejandro Mota and Irina Tezaur and Diana Bull,article,FREDERICK2021113533,Journal of Computational and Applied Mathematics,,397,0377-0427,,,
,"Style transfer, Controllable generation, Discrete space, Text generation",103643,,"Language models, such as BART and GPT, have been shown to be highly effective at producing quality headlines. However, without clear guidelines for what constitutes a particular writing style, they may generate text that does not meet the desired style criteria (i.e., attention-grabbing), even if the resulting text is grammatically correct and semantically coherent. In this study, we introduce a novel approach called Discretized Style Transfer (DST) for unsupervised style transfer. We argue that the textual style signal is inherently abstract and separate from the text itself. Therefore, we discretize the style representation into a discrete space, where each discrete point corresponds to a particular category of style that can be elicited by the syntactic structure. To evaluate the effectiveness of our approach, we propose two new automatic evaluation metrics along with several conventional criteria, especially STR metric is nearly 0.9 in TechST, 0.87 in GYAFC datasets, and the best PPL metrics. Furthermore, we conduct thorough human evaluations by directly measuring click-through rates as an indicator of attractiveness, showing our model receives the most popularity. Our results demonstrate that DST achieves competitive performance on style transfer and can effectively capture the written structure of specified styles. This approach has the potential to significantly enhance its relevance and is capable of generating appealing content.",https://doi.org/10.1016/j.ipm.2024.103643,https://www.sciencedirect.com/science/article/pii/S0306457324000037,,,,2024,Latent representation discretization for unsupervised text style generation,Yang Gao and Qianhui Liu and Yizhe Yang and Ke Wang,article,GAO2024103643,Information Processing & Management,3,61,0306-4573,,,
,"Bug triage, Recommendation system, Multi-task learning, Deep learning",111133,,"Assigning developers and allocating issue types are two important tasks in the bug triage process. Existing approaches tackle these two tasks separately, which is time-consuming due to repetition of effort and negating the values of correlated information between tasks. In this paper, a multi-triage model is proposed that resolves both tasks simultaneously via multi-task learning (MTL). First, both tasks can be regarded as a classification problem, based on historical issue reports. Second, performances on both tasks can be improved by jointly interpreting the representations of the issue report information. To do so, a text encoder and abstract syntax tree (AST) encoder are used to extract the feature representation of bug descriptions and code snippets accordingly. Finally, due to the disproportionate ratio of class labels in training datasets, the contextual data augmentation approach is introduced to generate syntactic issue reports to balance the class labels. Experiments were conducted on eleven open-source projects to demonstrate the effectiveness of this model compared with state-of-the-art methods.",https://doi.org/10.1016/j.jss.2021.111133,https://www.sciencedirect.com/science/article/pii/S0164121221002302,,,,2022,Multi-triage: A multi-task learning framework for bug triage,Thazin Win Win Aung and Yao Wan and Huan Huo and Yulei Sui,article,AUNG2022111133,Journal of Systems and Software,,184,0164-1212,,,
,"Building Information Modelling (BIM), conservation, knowledge management",34-51,,"A reliable data exchange often including geometry-related data between stakeholders is crucial in construction projects. In this regard, data exchange frameworks built on Linked Data principles are very promising for combining disparate data sets. However, existing proposals to combine geometry and Linked Data either demand dedicated applications or support only a limited number of common geometry schemas. If any existing geometry schema could be used in a Linked Data context, error-prone geometry conversions are avoided and stakeholders do not need to invest in new geometry engines. In this paper, the applicability of Resource Description Framework (RDF) literals for including a wide variety of existing geometry schemas is studied and applied in a built heritage context. The uniform linking pattern and related terminology of the Ontology for Managing Geometry are used to implement this approach. Subsequently, the File Ontology for Geometry formats and Geometry Metadata Ontology are developed to ease the reuse of linked geometry descriptions. The effectiveness of the entire data structure is demonstrated in a built heritage case study project. The receiving party is able to create successfully a coordinated view using a demo web application on shared, but disparate, RDF data sets containing geometry descriptions.",https://doi.org/10.1680/jsmic.19.00014,https://www.sciencedirect.com/science/article/pii/S2397875920000022,,,,2020,Including widespread geometry schemas into Linked Data-based BIM applied to built heritage,Mathias Bonduel and Anna Wagner and Pieter Pauwels and Maarten Vergauwen and Ralf Klein,article,BONDUEL202034,Proceedings of the Institution of Civil Engineers - Smart Infrastructure and Construction,1,172,2397-8759,,,
,"Botnet, DDoS, Reputation, Resurrection, Social network, 5G",102284,,"As explosive development of the 5th generation wireless systems (5 G), the traces of botnet could be found in a cellular phone, intelligent equipment, cloud, and even Bitcoin network. Hackers are then able to launch the distributed denial of service (DDoS) attack via mastering these vulnerable devices. No doubt that the enterprise and government must suffer from the tremendous loss once specific services cannot function normally due to the DDoS. Inspired by a counterintuitive thinking, we actively predict a variant of hybrid botnet based on social network. The addressed prototype, resurrection social hybrid botnet (RSHB), could offer cyber researcher to formulate corresponding defense strategy against botnet. According to comprehensive simulations, the survivability has demonstrated that RSHB is much more dangerous than other botnets. Consequently, RSHB might be a coming sample for cyber engineer to explore the defense methodology.",https://doi.org/10.1016/j.cose.2021.102284,https://www.sciencedirect.com/science/article/pii/S0167404821001085,,,,2021,Preserving indomitable DDoS vitality through resurrection social hybrid botnet,Chit-Jie Chew and Ying-Chin Chen and Jung-San Lee and Chih-Lung Chen and Kuo-Yu Tsai,article,CHEW2021102284,Computers & Security,,106,0167-4048,,,
,"Rasa, Admission chatbot, RNN, BERT",100036,,"In the last few years, intelligent chatbot systems have been prevalent in various application fields, especially in education. Therefore, the demand for such online consulting services like chatbots is getting higher respectively. However, most communications between potential students and universities are performed manually, which is very time-consuming procedure, becoming a burden on the head of admissions. In this paper, we introduce an AI-based chatbot where students can instantly get daily updates of curriculum, admission for new students, tuition fees, IELTS writing task II score, etc. Our chatbot was developed by Deep Learning models, which are already integrated into the Rasa framework. We also proposed a rational pipeline for Vietnamese chatbots with our data preprocessing to obtain optimal accuracy and to avoid the overfitting of the model. Our model can detect more than fifty types of questions from users' input with an accuracy of 97.1% on test set. The chatbot was applied for National Economics University's official admission Fanpage on the Facebook platform, which is the most famous social network in Vietnam. This research shows detailed guidelines on how to build an AI chatbot from scratch, and the techniques we used, which can be applied to any language globally.",https://doi.org/10.1016/j.caeai.2021.100036,https://www.sciencedirect.com/science/article/pii/S2666920X21000308,,,,2021,NEU-chatbot: Chatbot for admission of National Economics University,Trung Thanh Nguyen and Anh Duc Le and Ha Thanh Hoang and Tuan Nguyen,article,NGUYEN2021100036,Computers and Education: Artificial Intelligence,,2,2666-920X,,,
,,32-40,,,https://doi.org/10.1016/S0262-4079(23)01427-6,https://www.sciencedirect.com/science/article/pii/S0262407923014276,,,,2023,HOW TO THINK ABOUT AI… AND HOW TO LIVE WITH IT,,article,202332,New Scientist,3449,259,0262-4079,,,
,"Answer set programming (ASP), Epistemic reasoning, Probabilistic reasoning, Event calculus, Knowledge representation, Artificial intelligence",109101,,"We describe a general procedure for translating Epistemic Probabilistic Event Calculus (EPEC) action language domains into Answer Set Programs (ASP), and show how the Python-driven features of the ASP solver Clingo can be used to provide efficient computation in this probabilistic setting. EPEC supports probabilistic, epistemic reasoning in domains containing narratives that include both an agent's own action executions and environmentally triggered events. Some of the agent's actions may be belief-conditioned, and some may be imperfect sensing actions that alter the strengths of previously held beliefs. We show that our ASP implementation can be used to provide query answers that fully correspond to EPEC's own declarative, Bayesian-inspired semantics.",https://doi.org/10.1016/j.ijar.2023.109101,https://www.sciencedirect.com/science/article/pii/S0888613X23002323,,,,2024,An answer set programming-based implementation of epistemic probabilistic event calculus,Fabio Aurelio D'Asaro and Antonis Bikakis and Luke Dickens and Rob Miller,article,DASARO2024109101,International Journal of Approximate Reasoning,,165,0888-613X,,,
,"Malware forensics, IoT, Embedded systems, Data analytics, Machine learning, Expert systems",267-281,,"Malware targeting interconnected infrastructures has surged in recent years. A major factor driving this phenomenon is the proliferation of large networks of poorly secured IoT devices. This is exacerbated by the commoditization of the malware development industry, in which tools can be readily obtained in specialized hacking forums or underground markets. However, despite the great interest in targeting this infrastructure, there is little understanding of what the main features of this type of malware are, or the motives of the criminals behind it, apart from the classic denial of service attacks. This is vital to modern malware forensics, where analyses are required to measure the trustworthiness of files collected at large during an investigation, but also to confront challenges posed by tech-savvy criminals (e.g., Trojan Horse Defense). In this paper, we present a comprehensive characterization of Linux-based malware. Our study is tailored to IoT malware and it leverages automated techniques using both static and dynamic analysis to classify malware into related threats. By looking at the most representative dataset of Linux-based malware collected by the community to date, we are able to show that our system can accurately characterize known threats. As a key novelty, we use our system to investigate a number of threats unknown to the community. We do this in two steps. First, we identify known patterns within an unlabeled dataset using a classifier trained with the labeled dataset. Second, we combine our features with a custom distance function to discover new threats by clustering together similar samples. We further study each of the unknown clusters by using state-of-the-art reverse engineering and forensic techniques and our expertise as malware analysts. We provide an in-depth analysis of what the most recent unknown trends are through a number of case studies. Among other findings, we observe that: i) crypto-mining malware is permeating the IoT infrastructure, ii) the level of sophistication is increasing, and iii) there is a rapid proliferation of new variants with minimal investment in infrastructure.",https://doi.org/10.1016/j.future.2020.04.031,https://www.sciencedirect.com/science/article/pii/S0167739X19325002,,,,2020,Characterizing Linux-based malware: Findings and recent trends,J. Carrillo-Mondéjar and J.L. Martínez and G. Suarez-Tangil,article,CARRILLOMONDEJAR2020267,Future Generation Computer Systems,,110,0167-739X,,,
,,626-654,,"This article examines the overlapping influence of China in Russia and five countries that have experienced democratic backsliding: Azerbaijan, Nicaragua, Serbia, Turkey, and Uganda. Drawing on a wide range of data sources, including media watchdog reports, key informant interviews, and quantitative data, the paper maps the portfolio of specific digital censorship tools – legislative, institutional, and technological—that governments in China and Russia use to censor their domestic digital content. Then the digital censorship tools in the five case study countries are documented to examine where their governments’ tactics overlapped with those of the Kremlin and Beijing. These case study countries differ in their levels of development and democracy, with Russia, China, and the West all vying for influence. Key findings include the importance of timing when installing a digital censorship regime, and that Uganda and Nicaragua stand out among the case study countries.",https://doi.org/10.1016/j.orbis.2023.08.009,https://www.sciencedirect.com/science/article/pii/S0030438723000431,,,,2023,Innovators and Emulators: China and Russia’s Compounding Influence on Digital Censorship,Catherine Andrzejewski and Ana Horigoshi and Abigail I. Maher and Jonathan A. Solis,article,ANDRZEJEWSKI2023626,Orbis,4,67,0030-4387,"The Belt and Road Initiative, the Global South, and US-China Competition",,
,"Wikipedia, Modeling",129253,,"A simple dynamical model of collective edit activity of Wikipedia articles and their content evolution is introduced. Based on the recent empirical findings, each editor in the model is characterized by an ability to make content edit, i.e., improving the article by adding content and a tendency to make maintenance edit, i.e., dealing with formal aspects and maintaining the edit flow. In addition, each article is characterized by a level of maturity as compared to a potential quality needed to comprehensively cover its topic. This model is found to reproduce the basic structure of the bipartite network between editors and articles of Wikipedia. Furthermore, the relation between the model parameters of editors and articles and the metrics of those calculated from the emergent network turns out to be robust, i.e. depending only on the rate of the introduction of new articles to the editing activity. This results provides us a way to relate observations in the real data to the hidden characteristics of editors and articles. For the nestedness of the networks, systems with weighted parameter distribution gives better match to the empirical one. This suggests the importance of high-dimensional nature of the ability of editors and quality of articles in the real system.",https://doi.org/10.1016/j.physa.2023.129253,https://www.sciencedirect.com/science/article/pii/S0378437123008087,,,,2023,A simple model of edit activity in Wikipedia,Takashi Shimada and Fumiko Ogushi and János Török and János Kertész and Kimmo Kaski,article,SHIMADA2023129253,Physica A: Statistical Mechanics and its Applications,,630,0378-4371,,,
,"Knowledge injection, Knowledge graphs, Large language models, Transformers, BERT, Classification, Natural language processing",108166,,"In recent years, transformer-based models have emerged as powerful tools for natural language processing tasks, demonstrating remarkable performance in several domains. However, they still present significant limitations. These shortcomings become more noticeable when dealing with highly specific and complex concepts, particularly within the scientific domain. For example, transformer models have particular difficulties when processing scientific articles due to the domain-specific terminologies and sophisticated ideas often encountered in scientific literature. To overcome these challenges and further enhance the effectiveness of transformers in specific fields, researchers have turned their attention to the concept of knowledge injection. Knowledge injection is the process of incorporating outside knowledge into transformer models to improve their performance on certain tasks. In this paper, we present a comprehensive study of knowledge injection strategies for transformers within the scientific domain. Specifically, we provide a detailed overview and comparative assessment of four primary methodologies, evaluating their efficacy in the task of classifying scientific articles. For this purpose, we constructed a new benchmark including both 24K labelled papers and a knowledge graph of 9.2K triples describing pertinent research topics. We also developed a full codebase to easily re-implement all knowledge injection strategies in different domains. A formal evaluation indicates that the majority of the proposed knowledge injection methodologies significantly outperform the baseline established by Bidirectional Encoder Representations from Transformers.",https://doi.org/10.1016/j.engappai.2024.108166,https://www.sciencedirect.com/science/article/pii/S0952197624003245,,,,2024,A comparative analysis of knowledge injection strategies for large language models in the scholarly domain,Andrea Cadeddu and Alessandro Chessa and Vincenzo {De Leo} and Gianni Fenu and Enrico Motta and Francesco Osborne and Diego {Reforgiato Recupero} and Angelo Salatino and Luca Secchi,article,CADEDDU2024108166,Engineering Applications of Artificial Intelligence,,133,0952-1976,,,
,"Re-identification, Deep learning, 3D-CNNs, Cross attention",104474,,"Video-based re-identification (ReID) is a crucial task in computer vision that draws increasing attention due to advances in deep learning (DL) and modern computational devices. Despite recent success with CNN architectures, single models (e.g., 2D-CNNs or 3D-CNNs) alone failed to leverage temporal information with spatial cues. This is due to uncontrolled surveillance scenarios and variable poses leading to inevitable misalignment of ROIs across the tracklets, which is accompanied by occlusion and motion blur. In this context, designing temporal and spatial cues for two different models and their combinations can be beneficial, considering the global of a video-tracklet. 3D-CNNs allow encoding of temporal information while 2D-CNNs extract spatial or appearance information. In this paper, we propose a Spatio-Temporal Cross Attention (STCA) network to utilize both 2D-CNNs and 3D-CNNs that calculate the cross attention mapping both from the layer of 3D-CNNs and 2D-CNNs along a person's trajectory to gate the following layers of 2D-CNNs; and highlight relevant appearance features for the person ReID. Given an input tracklet, the proposed cross attention (CA) is able to capture the salient regions that propagate throughout the tracklet to obtain the global view. This provides a spatio-temporal attention approach that can be dynamically aggregated with spatial features of 2D-CNNs to perform finer-grained recognition. Additionally, we exploit the advantage of utilizing cosine similarity while triplet sampling as well as for calculating the final recognition score. Experimental analyses on three challenging benchmark datasets indicate that integrating spatio-temporal cross attention into the state-of-the-art video ReID backbone CNN architecture allows for improving their recognition accuracy.",https://doi.org/10.1016/j.imavis.2022.104474,https://www.sciencedirect.com/science/article/pii/S0262885622001032,,,,2022,STCA: Utilizing a spatio-temporal cross-attention network for enhancing video person re-identification,Amran Bhuiyan and Jimmy Xiangji Huang,article,BHUIYAN2022104474,Image and Vision Computing,,123,0262-8856,,,
,"Industrial communication system, Cyber-physical systems, Network intrusion detection, Distributed artificial intelligence",109512,,"There is a growing body of knowledge on network intrusion detection, and several open data sets with network traffic and cyber-security threats have been released in the past decades. However, many data sets have aged, were not collected in a contemporary industrial communication system, or do not easily support research focusing on distributed anomaly detection. This paper presents the Westermo network traffic data set, 1.8 million network packets recorded in over 90 minutes in a network built up of twelve hardware devices. In addition to the raw data in PCAP format, the data set also contains pre-processed data in the form of network flows in CSV files. This data set can support the research community for topics such as intrusion detection, anomaly detection, misconfiguration detection, distributed or federated artificial intelligence, and attack classification. In particular, we aim to use the data set to continue work on resource-constrained distributed artificial intelligence in edge devices. The data set contains six types of events: harmless SSH, bad SSH, misconfigured IP address, duplicated IP address, port scan, and man in the middle attack.",https://doi.org/10.1016/j.dib.2023.109512,https://www.sciencedirect.com/science/article/pii/S2352340923006121,,,,2023,The Westermo network traffic data set,Per Erik Strandberg and David Söderman and Alireza Dehlaghi-Ghadim and Miguel Leon and Tijana Markovic and Sasikumar Punnekkat and Mahshid Helali Moghadam and David Buffoni,article,STRANDBERG2023109512,Data in Brief,,50,2352-3409,,,
,"Information security, Internet of things, IoT, DDoS-attacks, Smart house, Cyberthreats, Security at the network level, Application-level security, Vulnerability of software",179-182,,"The development of methods of information protection against cyber threats is a priority and the most labor-intensive direction in the development of the IoT sector. The relevance of the topic is growing due to the growing user interest in the Internet of things. Basic for studying in this work was the traditional IoT architecture format, which consists of three ""slices"". This perception, network and application levels. Each ""cut"" characterizes its key problems in the field of information security. The most difficult part is the network layer. The arising difficulties are provoked by the features of the structure (multivariance of things, different methods of networks) and a high numerical index of objects. The Internet of things accumulates information data from a huge number of devices that have different formats and various characteristics. As a result, there are failures of DoS, which arise due to a heavy load on the network, as well as disruptions in the operation of programs.",https://doi.org/10.1016/j.procs.2020.02.132,https://www.sciencedirect.com/science/article/pii/S1877050920302556,,,,2020,Information security of Internet things,Dmitry Bagay,article,BAGAY2020179,Procedia Computer Science,,169,1877-0509,"Postproceedings of the 10th Annual International Conference on Biologically Inspired Cognitive Architectures, BICA 2019 (Tenth Annual Meeting of the BICA Society), held August 15-19, 2019 in Seattle, Washington, USA",,
,"Building permit, Building official, Building application, Ontology, Assignment process, Shapes Constraint Language (SHACL)",102216,,"Building permit processes lie on the divide between architecture, engineering, and construction (AEC) and public administration. To ensure consistent and effective digitization in building permitting, it is necessary to consider and merge both areas. Hence, for advanced building permit processes, foundations must be developed, which begins with understanding and formalizing building permit authorities’ organizational structures and processes. Therefore, this study developed an ontology that covers a semantic representation of a building permit authority along with a subprocess of the building permit process called the assignment process. The assignment process describes how and on what basis building applications are assigned to appropriate building officials. Proposing a semantic representation of the assignment process, tacit knowledge from previously conducted data sets was analyzed and implemented in the ontology. As a case study, a sample building permit authority was described and implemented in the ontology. On the one hand, the developed ontology serves as a basis for decision support for building permit processes, while on the other hand, it enables a fully automated assignment process in a building permit authority. The approach not only makes the assignment process more objective and transparent for all parties involved in the building permit process but also allows time and personnel capacities to be used in its other subprocesses.",https://doi.org/10.1016/j.aei.2023.102216,https://www.sciencedirect.com/science/article/pii/S1474034623003440,,,,2023,Ontology for building permit authorities (OBPA) for advanced building permit processes,Judith Fauth and Sebastian Seiß,article,FAUTH2023102216,Advanced Engineering Informatics,,58,1474-0346,,,
,,I-CXIV,,,https://doi.org/10.1016/S1936-878X(23)00525-9,https://www.sciencedirect.com/science/article/pii/S1936878X23005259,,,,2024,Full Issue PDF,,article,2024I,JACC: Cardiovascular Imaging,1,17,1936-878X,,,
,"Open data, Data publishing, Data use, Occupant behavior, FAIR Data, Ontology, Anonymi, z, ation, Metadata schema",106848,,"Many new tools for improving the design and operation of buildings try to realize the potential of big data. In particular, data is an important element for occupant-centric design and operation as occupants’ presence and actions are affected by a high degree of uncertainty and, hence, are hard to model in general. For such research, data handling is an important challenge, and following an open science paradigm based on open data can increase efficiency and transparency of scientific work. This article reviews current practices and infrastructure for open data-driven research on occupant-centric design and operation of buildings. In particular, it covers related work on open data in general and for the built environment in particular, presents survey results for existing scientific practices, reviews technical solutions for handling data and metadata, discusses ethics and privacy protection and analyses principles for the sharing of open data. In summary, this study establishes the status quo and presents an outlook on future work for methods and infrastructures to support the open data community within the built environment.",https://doi.org/10.1016/j.buildenv.2020.106848,https://www.sciencedirect.com/science/article/pii/S0360132320302079,,,,2020,Current practices and infrastructure for open data based research on occupant-centric design and operation of buildings,Mikkel B. Kjærgaard and Omid Ardakanian and Salvatore Carlucci and Bing Dong and Steven K. Firth and Nan Gao and Gesche Margarethe Huebner and Ardeshir Mahdavi and Mohammad Saiedur Rahaman and Flora D. Salim and Fisayo Caleb Sangogboye and Jens Hjort Schwee and Dawid Wolosiuk and Yimin Zhu,article,KJAERGAARD2020106848,Building and Environment,,177,0360-1323,,,
,"HITRAN, Spectroscopic database, Molecular spectroscopy, Spectroscopic line parameters, Absorption cross-sections, Collision-induced absorption, Aerosols, Molecular opacities",107949,,"The HITRAN database is a compilation of molecular spectroscopic parameters. It was established in the early 1970s and is used by various computer codes to predict and simulate the transmission and emission of light in gaseous media (with an emphasis on terrestrial and planetary atmospheres). The HITRAN compilation is composed of five major components: the line-by-line spectroscopic parameters required for high-resolution radiative-transfer codes, experimental infrared absorption cross-sections (for molecules where it is not yet feasible for representation in a line-by-line form), collision-induced absorption data, aerosol indices of refraction, and general tables (including partition sums) that apply globally to the data. This paper describes the contents of the 2020 quadrennial edition of HITRAN. The HITRAN2020 edition takes advantage of recent experimental and theoretical data that were meticulously validated, in particular, against laboratory and atmospheric spectra. The new edition replaces the previous HITRAN edition of 2016 (including its updates during the intervening years). All five components of HITRAN have undergone major updates. In particular, the extent of the updates in the HITRAN2020 edition range from updating a few lines of specific molecules to complete replacements of the lists, and also the introduction of additional isotopologues and new (to HITRAN) molecules: SO, CH3F, GeH4, CS2, CH3I and NF3. Many new vibrational bands were added, extending the spectral coverage and completeness of the line lists. Also, the accuracy of the parameters for major atmospheric absorbers has been increased substantially, often featuring sub-percent uncertainties. Broadening parameters associated with the ambient pressure of water vapor were introduced to HITRAN for the first time and are now available for several molecules. The HITRAN2020 edition continues to take advantage of the relational structure and efficient interface available at www.hitran.org and the HITRAN Application Programming Interface (HAPI). The functionality of both tools has been extended for the new edition.",https://doi.org/10.1016/j.jqsrt.2021.107949,https://www.sciencedirect.com/science/article/pii/S0022407321004416,,,,2022,The HITRAN2020 molecular spectroscopic database,I.E. Gordon and L.S. Rothman and R.J. Hargreaves and R. Hashemi and E.V. Karlovets and F.M. Skinner and E.K. Conway and C. Hill and R.V. Kochanov and Y. Tan and P. Wcisło and A.A. Finenko and K. Nelson and P.F. Bernath and M. Birk and V. Boudon and A. Campargue and K.V. Chance and A. Coustenis and B.J. Drouin and J.–M. Flaud and R.R. Gamache and J.T. Hodges and D. Jacquemart and E.J. Mlawer and A.V. Nikitin and V.I. Perevalov and M. Rotger and J. Tennyson and G.C. Toon and H. Tran and V.G. Tyuterev and E.M. Adkins and A. Baker and A. Barbe and E. Canè and A.G. Császár and A. Dudaryonok and O. Egorov and A.J. Fleisher and H. Fleurbaey and A. Foltynowicz and T. Furtenbacher and J.J. Harrison and J.–M. Hartmann and V.–M. Horneman and X. Huang and T. Karman and J. Karns and S. Kassi and I. Kleiner and V. Kofman and F. Kwabia–Tchana and N.N. Lavrentieva and T.J. Lee and D.A. Long and A.A. Lukashevskaya and O.M. Lyulin and V.Yu. Makhnev and W. Matt and S.T. Massie and M. Melosso and S.N. Mikhailenko and D. Mondelain and H.S.P. Müller and O.V. Naumenko and A. Perrin and O.L. Polyansky and E. Raddaoui and P.L. Raston and Z.D. Reed and M. Rey and C. Richard and R. Tóbiás and I. Sadiek and D.W. Schwenke and E. Starikova and K. Sung and F. Tamassia and S.A. Tashkun and J. {Vander Auwera} and I.A. Vasilenko and A.A. Vigasin and G.L. Villanueva and B. Vispoel and G. Wagner and A. Yachmenev and S.N. Yurchenko,article,GORDON2022107949,Journal of Quantitative Spectroscopy and Radiative Transfer,,277,0022-4073,,,
,"3D-Printing, Fused filament fabrication, Adhesion",e00258,,"The adhesion of parts to the build surface plays a central role in the Fused Filament Fabrication (FFF) process. Without sufficient adhesion, the part will deform (so called warping) due to thermal shrinkage, so that no defined geometries can be created. Nevertheless, there is no established method to measure the adhesion of printed parts and therefore it is not possible to targeted improve it. This article presents a measurement method based on the DIN EN 28510-1 standard and a corresponding test device which makes it possible to identify the optimum build surface for a filament and also to improve the process parameters in a targeted manner. The test device combines a FFF printer with a measuring unit so that all common filaments can be tested close to the process up to a processing temperature of 400 °C in the nozzle and around 150 °C on the build platform. The test device uses only open-source parts and software and costs about 1700€.",https://doi.org/10.1016/j.ohx.2022.e00258,https://www.sciencedirect.com/science/article/pii/S2468067222000037,,,,2022,Device for measuring part adhesion in FFF process,Daniel Laumann and Dieter Spiehl and Edgar Dörsam,article,LAUMANN2022e00258,HardwareX,,11,2468-0672,,,
,,22-29,,"The Conflict-Free Electric Vehicle Routing Problem (CF-EVRP) is a combinatorial optimization problem of designing routes for vehicles to visit customers such that a cost function, typically the number of vehicles or the total travelled distance, is minimized. The CF-EVRP involves constraints such as time windows on the delivery to the customers, limited operating range of the vehicles, and limited capacity on the number of vehicles that a road segment can simultaneously accommodate. In previous work, the compositional algorithm ComSat was introduced and that solves the CF-EVRP by breaking it down into sub-problems and iteratively solve them to build an overall solution. Though ComSat showed good performance in general, some problems took significant time to solve due to the high number of iterations required to find solutions that satisfy the road segments’ capacity constraints. The bottleneck is the Path Changing Problem, i.e., the sub-problem of finding a new set of shortest paths to connect a subset of the customers, disregarding previously found shortest paths. This paper presents an improved version of the PathsChanger function to solve the Path Changing Problem that exploits the unsatisfiable core, i.e., information on which constraints conflict, to guide the search for feasible solutions. Experiments show faster convergence to feasible solutions compared to the previous version of PathsChanger.",https://doi.org/10.1016/j.ifacol.2022.10.319,https://www.sciencedirect.com/science/article/pii/S2405896322023564,,,,2022,Leveraging Conflicting Constraints in Solving Vehicle Routing Problems,Sabino Francesco Roselli and Remco Vader and Martin Fabian and Knut Åkesson,article,ROSELLI202222,IFAC-PapersOnLine,28,55,2405-8963,16th IFAC Workshop on Discrete Event Systems WODES 2022,,
,,100784,,,https://doi.org/10.1016/S2772-963X(23)00815-3,https://www.sciencedirect.com/science/article/pii/S2772963X23008153,,,,2023,Full Issue PDF,,article,2023100784,JACC: Advances,10,2,2772-963X,,,
,,395-409,Software Defined Networks (Second Edition),,https://doi.org/10.1016/B978-0-12-804555-8.09984-1,https://www.sciencedirect.com/science/article/pii/B9780128045558099841,Boston,Morgan Kaufmann,978-0-12-804555-8,2017,Index,,incollection,2017395,,,,,,Paul Göransson and Chuck Black and Timothy Culver,Second Edition
Advances in Computers,"Agent, Artificial intelligence, Rationality, Games, Game world, Game development",251-303,,"The field of artificial intelligence has come a long way in the last 50 years, and studies of its methods soon expanded to a field in which they are of great practical value—computer games. The concept of intelligent agents provides a much needed theoretical background for the comparison of various different approaches to intelligent, rational behavior of computer-controlled characters in games. By combining rationality with certain limitations to the capabilities of our agents, we can achieve behavior resembling that of a human player, which is also desirable in games. The goal of this article is to introduce various types of agents that are used in games, show how to implement meaningful, reasonable limitations to agent capabilities into the game world, and provide a freely available, open-source application for the comparison of such agents. Additionally, in this article we show that even the simplest agents can succeed in their tasks in certain task environments, whereas more difficult task environments often require a more sophisticated agent architecture. Our application consists of two task environments with nine agents in total but could easily be extended with additional task environments and agent implementations. In the end, we find the addition of goals into the agent architecture has the biggest impact on the agent's behavior and performance, whereas the state-based approach helps keep our implementation simple and compact.",https://doi.org/10.1016/bs.adcom.2019.07.005,https://www.sciencedirect.com/science/article/pii/S0065245819300312,,Elsevier,,2020,Chapter Five - Intelligent agents in games: Review with an open-source tool,Matej Vitek and Peter Peer,incollection,VITEK2020251,,1,116,0065-2458,,Ali R. Hurson and Veljko Milutinović,
,"Empirical study, JavaScript engine, Software bug, SpiderMonkey, Chakra, V8",107105,,"Context:
JavaScript is a prototype-based dynamic type scripting language. The correct running of a JavaScript program depends on the correctness of both the program and the JavaScript engine.
Objective:
An in-depth understanding of the characteristics of bugs in JavaScript engines can help detect and fix them.
Methods:
We conduct an empirical study on the bugs in three mainstream JavaScript engines: V8, SpiderMonkey, and Chakra. Such an empirical study involves 19,019 bug reports, 16,437 revisions, 805 test cases, and root causes of randomly selected 540 bugs.
Results:
(1) The Compiler and the DOM are the most buggy component in V8 and SpiderMonkey, respectively. Most of the source files contain only one bug. (2) The scales of the testing programs that reveal bugs are usually small. Most bug fixes involve only limited modifications since the number of modified source files and lines of code modified are small. (3) Most bugs can be fixed within half a year (80.33% for V8 and 91.9% for SpiderMonkey). Only 4.33% of SpiderMonkey bugs need more than a year to fix. Bugs in SpiderMonkey are usually fixed faster than bugs in V8. (4) High priority tends to be assigned to Infrastructure bugs in V8 and Release Automation bugs in SpiderMonkey. The duration of bugs is not strictly correlated with their priorities. (5) Semantic bugs are the most common root causes of bugs. And among semantic bugs, the processing bugs, missing features bugs and function call bugs are more than others.
Conclusion:
This study deepens our understanding of bugs in JavaScript engines, and empirical results could indicate some potential problems during the detecting and fixing of bugs in JavaScript engines, assist developers of JavaScript engines in improving their development quality, assist maintainers in detecting and fixing bugs more effectively, and suggest users of JavaScript evade potential risks.",https://doi.org/10.1016/j.infsof.2022.107105,https://www.sciencedirect.com/science/article/pii/S0950584922002142,,,,2023,An empirical study on bugs in JavaScript engines,Ziyuan Wang and Dexin Bu and Nannan Wang and Sijie Yu and Shanyi Gou and Aiyue Sun,article,WANG2023107105,Information and Software Technology,,155,0950-5849,,,
,"Sequential decision-making, Data-driven control, Learning, Densities optimization",81-102,,"This survey is focused on certain sequential decision-making problems that involve optimizing over probability functions. We discuss the relevance of these problems for learning and control. The survey is organized around a framework that combines a problem formulation and a set of resolution methods. The formulation consists of an infinite-dimensional optimization problem. The methods come from approaches to search optimal solutions in the space of probability functions. Through the lenses of this overarching framework we revisit popular learning and control algorithms, showing that these naturally arise from suitable variations on the formulation mixed with different resolution methods. A running example, for which we make the code available, complements the survey. Finally, a number of challenges arising from the survey are also outlined.",https://doi.org/10.1016/j.arcontrol.2022.09.003,https://www.sciencedirect.com/science/article/pii/S1367578822000967,,,,2022,Probabilistic design of optimal sequential decision-making algorithms in learning and control,Émiland Garrabé and Giovanni Russo,article,GARRABE202281,Annual Reviews in Control,,54,1367-5788,,,
,"AI technologies, Generality, Capabilities, Technology readiness, TRLs",101525,,"Artificial Intelligence (AI) offers the potential to transform our lives in radical ways. However, the main unanswered questions about this foreseen transformation are its depth, breadth and timelines. To answer them, not only do we lack the tools to determine what achievements will be attained in the near future, but we even ignore what various technologies in present-day AI are capable of. Many so-called breakthroughs in AI are associated with highly-cited research papers or good performance in some particular benchmarks. However, research breakthroughs do not directly translate into a technology that is ready to use in real-world environments. In this paper, we present a novel exemplar-based methodology to categorise and assess several AI technologies, by mapping them onto Technology Readiness Levels (TRL) (representing their depth in maturity and availability). We first interpret the nine TRLs in the context of AI, and identify several categories in AI to which they can be assigned. We then introduce a generality dimension, which represents increasing layers of breadth of the technology. These two dimensions lead to the new readiness-vs-generality charts, which show that higher TRLs are achievable for low-generality technologies, focusing on narrow or specific abilities, while high TRLs are still out of reach for more general capabilities. We include numerous examples of AI technologies in a variety of fields, and show their readiness-vs-generality charts, serving as exemplars. Finally, we show how the timelines of several AI technology exemplars at different generality layers can help forecast some short-term and mid-term trends for AI.",https://doi.org/10.1016/j.tele.2020.101525,https://www.sciencedirect.com/science/article/pii/S0736585320301842,,,,2021,Futures of artificial intelligence through technology readiness levels,Fernando Martínez-Plumed and Emilia Gómez and José Hernández-Orallo,article,MARTINEZPLUMED2021101525,Telematics and Informatics,,58,0736-5853,,,
,"Internet of Things (IoT), Blockchain, Supply Chain Management (SCM), Cloud computing (CC), Artificial Intelligence (AI)",101215,,"Supply Chain Management (SCM) systems require time sequencing, coordination and tracking the movement of goods and processes. Internet of Things (IoT) and Blockchain technologies are useful to develop a secure automated SCM. IoT devices with in-built sensors and actuators help to keep track of the state, location, temperature or other parameters of an entity, and control the automation of routine as well as hazardous tasks. Blockchain technology supports time-stamping, authentication, process coordination, non-repudiation, commercial transactions, and also provides security for transactions and storage. The pharmaceutical SCM demands accurate, immediate and secure control system. Additionally, the supply chain process data from IoTs is stored and processed in Cloud by Analytics applications, for business planning and improvement. An efficient and secure IoT-Cloud-Blockchain based system for both SCM automation and analytics has been proposed in this work. It leverages a hierarchical IoT, Mist, Edge, Fog, Cloud computing (IMEFC) architecture to enhance Communication-Response-Compute-Security-Storage (CRCSS) in the system. Blockchain technology provides security for the SCM transactions and data. The efficiency of the Blockchain is measured in terms of upload time, download time and transaction fees for Bitcoin, Ethereum and Filecoin platforms. The Filecoin blockchain platform is quicker and cost-effective for larger file sizes, compared to Ethereum and Bitcoin, making it suitable for Pharmaceutical SCM systems.",https://doi.org/10.1016/j.iot.2024.101215,https://www.sciencedirect.com/science/article/pii/S2542660524001562,,,,2024,Secure pharmaceutical supply chain using blockchain in IoT cloud systems,Mangala N. and Naveen D.R. and B. Eswara Reddy and Rajkumar Buyya and Venugopal K.R. and S.S. Iyengar and L.M. Patnaik,article,N2024101215,Internet of Things,,26,2542-6605,,,
,"GPT–4, Artificial general intelligence, Knowledge diffusion, Interpretability and explainability, Societal influences, Governance",100078,,"Recent breakthroughs in artificial intelligence (AI) research include advancements in natural language processing (NLP) achieved by large language models (LLMs), and; in particular, generative pre–trained transformer (GPT) architectures. The latest GPT developed by OpenAI, GPT–4, has shown remarkable intelligence across various domains and tasks. It exhibits capabilities in abstraction, comprehension, vision, computer coding, mathematics, and more, suggesting it to be a significant step towards artificial general intelligence (AGI), a level of AI that possesses capabilities similar to human intelligence. This paper explores this AGI, its knowledge diffusive and societal influences, and its governance. In addition to coverage of the major associated topics studied in the literature, and making up for their loopholes, we scrutinize how GPT-4 can facilitate the diffusion of knowledge across different areas of science by promoting their interpretability and explainability (IE) to inexperts. Where applicable, the topics are also accompanied by their specific potential implications on medical imaging.",https://doi.org/10.1016/j.metrad.2024.100078,https://www.sciencedirect.com/science/article/pii/S2950162824000316,,,,2024,"The general intelligence of GPT–4, its knowledge diffusive and societal influences, and its governance",Mohammad Mahdi {Jahani Yekta},article,JAHANIYEKTA2024100078,Meta-Radiology,2,2,2950-1628,,,
,"Graph-based finance, Representation learning, Complete incidence matrix, Convolutional neural network, Matrix factorization",108841,,"Knowledge graph (KG) has increasingly been seen as a significant resource in financial applications (e.g., risk control, auditing and anti-fraud). However, there are few prior studies that focus on multi-relational circles, extracting additional information under the completed KG and selecting similarity measures for knowledge representation. In this paper, we introduce multi-relational circles and propose a novel embedding model, which considers entity weights calculated by PageRank algorithm to improve TransE method. In order to extract additional information, we use entity weights to convert embeddings into an on-map mining problem, and propose a model called CNNe based on entity weights and a convolutional neural network with three hidden layers, which converts vectors of entities, entity weights and relationships into matrices to perform link prediction in the same way as image processing. With the help of ten different similarity measures, it is demonstrated that the choice of distance measure greatly effect the results of the translation embedding models. Moreover, we propose two embedding methods, sMFE and tMFE, to enhance the results using matrix factorization. The complete incidence matrix is first applied to knowledge embedding, which contains the most comprehensive topological properties of the graph. Experimental results on standard benchmark datasets demonstrate that the proposed models are effective. In particular, CNNe achieves a mean rank of 166 less than the baseline method and an improvement of 2.1% on the proportion of correct entities ranked in the top ten on YAGO3-10 dataset.",https://doi.org/10.1016/j.patcog.2022.108841,https://www.sciencedirect.com/science/article/pii/S0031320322003223,,,,2022,An entity-weights-based convolutional neural network for large-sale complex knowledge embedding,Zhengdi Wang and Lvqing Yang and Zhenfeng Lei and Anwar {Ul Haq} and Defu Zhang and Shuangyuan Yang and Akindipe Olusegun Francis,article,WANG2022108841,Pattern Recognition,,131,0031-3203,,,
,"Artificial intelligence, Deep learning, Internet of things, Machine learning",837-888,Knowledge is Power in Four Dimensions: Models to Forecast Future Paradigm,"Artificial Intelligence (AI) is one of those technologies that seem to be expanding outward in every direction, and this expansion is driven by sheer volume of data that we are encountering in our daily routine life in these days, where technology is deviating from its tradition format to the more modern world of electronic gadget. In today's modern technological world, we are accumulating so much data in real time with speed of electron through the world of Internet of Things (IoT), and it comes to us in Omni-Direction space. Dealing with these data in the form of structured and unstructured, we have no choice except to turn to AI for assistant, in order to stay on top of all the information that is collected from these data for us to have a knowledge that allows us to consequently have power of right and accurate decision-making in real time in our daily routine as stakeholder. However, comes with AI needs its two other integrated components, namely Machine Learning (ML) and Deep Learning (DL) to be more effective to us as human being, where we are relying on Artificial Intelligence to run our day-to-day operation in very resilience form.",https://doi.org/10.1016/B978-0-323-95112-8.00027-1,https://www.sciencedirect.com/science/article/pii/B9780323951128000271,,Academic Press,978-0-323-95112-8,2022,"Chapter 27 - Artificial intelligence, machine learning, and deep learning driving big data",Bahman Zohuri and Farhang Mossavar-Rahmani and Farahnaz Behgounia,incollection,ZOHURI2022837,,,,,,Bahman Zohuri and Farhang Mossavar-Rahmani and Farahnaz Behgounia,
,,I-CXLII,,,https://doi.org/10.1016/S2666-0873(23)00346-0,https://www.sciencedirect.com/science/article/pii/S2666087323003460,,,,2023,Full Issue PDF,,article,2023I,JACC: CardioOncology,6,5,2666-0873,,,
,"scholarly communication, web, internet, data, information dissemination, impact, data, blogs, microblogs, Twitter, social networking sites, social reference managers, social peer review, peer review, recommendation systems, Wikipedia, data repositories, data sharing, service providers, aggregators, stakeholders, researchers, universities, libraries, publishers, funders, public, audience, altmetrics, webometrics, social media, social media metrics, social media analysis, awareness, attention",55-104,Altmetrics for Information Professionals,"In the second part the current altmetric research is presented. This part begins with an overview of scholarly communication on the web, its potential, and current status. This is followed by an overview of some of the sources of these new online metrics. The service providers or aggregators of altmetrics are briefly presented, followed by a discussion of the different stakeholders. There are many stakeholders connected to altmetrics, all of whom can use them somewhat differently and benefit from them in various ways. Some of the earlier research of altmetrics will be presented, research that has pushed the development of altmetrics forward and continues to push it as the web evolves and the way we use the web changes.",https://doi.org/10.1016/B978-0-08-100273-5.00002-8,https://www.sciencedirect.com/science/article/pii/B9780081002735000028,,Chandos Publishing,978-0-08-100273-5,2016,2 - The Present,Kim Holmberg,incollection,HOLMBERG201655,,,,,,Kim Holmberg,
,"Blockchain, Consensus algorithms, Cryptocurrency, Distributed ledger, Healthcare data, Security & privacy",103633,,"Blockchain has become popular in recent times through its data integrity and wide scope of applications. It has laid the foundation for cryptocurrencies such as Ripple, Bitcoin, Ethereum, and so on. Blockchain provides a platform for decentralization and trust in various applications such as finance, commerce, IoT, reputation systems, and healthcare. However, prevailing challenges like scalability, resilience, security and privacy are yet to be overcome. Due to rigorous regulatory constraints such as HIPAA, blockchain applications in the healthcare industry usually require more stringent authentication, interoperability, and record sharing requirements. This article presents an extensive study to showcase the significance of blockchain technology from both application and technical perspectives for healthcare domain. The article discusses the features and use-cases of blockchain in different applications along with the healthcare domain interoperability. The detailed working operation of the blockchain and the consensus algorithms are presented in the context of healthcare. An outline of the blockchain architecture, platforms, and classifications are discussed to choose the right platform for healthcare applications. The current state-of-the-art research in healthcare blockchain and available blockchain based healthcare applications are summarized. Furthermore, the challenges and future research opportunities along with the performance evaluation metrics in realizing the blockchain technology for healthcare are presented to provide insight for future research. We also layout the various security attacks on the blockchain protocol with the classifications of threat models and presented a comparative analysis of the detection and protection techniques. Techniques to enhance the security and privacy of the blockchain network is also discussed.",https://doi.org/10.1016/j.jnca.2023.103633,https://www.sciencedirect.com/science/article/pii/S1084804523000528,,,,2023,"Blockchain for healthcare systems: Architecture, security challenges, trends and future directions",Andrew J and Deva Priya Isravel and K. Martin Sagayam and Bharat Bhushan and Yuichi Sei and Jennifer Eunice,article,J2023103633,Journal of Network and Computer Applications,,215,1084-8045,,,
,,I-CXXXI,,,https://doi.org/10.1016/S1936-878X(23)00322-4,https://www.sciencedirect.com/science/article/pii/S1936878X23003224,,,,2023,Full Issue PDF,,article,2023I,JACC: Cardiovascular Imaging,8,16,1936-878X,,,
,"Mobile apps, COVID, Contact-tracing, User reviews, Software engineering, Software in society, Data mining",111136,,"Context:
More than 78 countries have developed COVID contact-tracing apps to limit the spread of coronavirus. However, many experts and scientists cast doubt on the effectiveness of those apps. For each app, a large number of reviews have been entered by end-users in app stores.
Objective:
Our goal is to gain insights into the user reviews of those apps, and to find out the main problems that users have reported. Our focus is to assess the “software in society” aspects of the apps, based on user reviews.
Method:
We selected nine European national apps for our analysis and used a commercial app-review analytics tool to extract and mine the user reviews. For all the apps combined, our dataset includes 39,425 user reviews.
Results:
Results show that users are generally dissatisfied with the nine apps under study, except the Scottish (“Protect Scotland”) app. Some of the major issues that users have complained about are high battery drainage and doubts on whether apps are really working.
Conclusion:
Our results show that more work is needed by the stakeholders behind the apps (e.g., app developers, decision-makers, public health experts) to improve the public adoption, software quality and public perception of these apps.",https://doi.org/10.1016/j.jss.2021.111136,https://www.sciencedirect.com/science/article/pii/S0164121221002338,,,,2022,Mining user reviews of COVID contact-tracing apps: An exploratory analysis of nine European apps,Vahid Garousi and David Cutting and Michael Felderer,article,GAROUSI2022111136,Journal of Systems and Software,,184,0164-1212,,,
,,I-CLXXIX,,,https://doi.org/10.1016/S2452-302X(24)00173-6,https://www.sciencedirect.com/science/article/pii/S2452302X24001736,,,,2024,Full Issue PDF,,article,2024I,JACC: Basic to Translational Science,5,9,2452-302X,,,
,"Resource consumption analysis, Cloud computing, Behavioural type system, Subject reduction, Concurrent programming",27-53,,"We propose a static analysis technique that computes upper bounds of virtual machine usages in a concurrent language with explicit acquire and release operations of virtual machines. In our language it is possible to delegate other (ad-hoc or third party) concurrent code to release virtual machines (by passing them as arguments of invocations). Our technique is modular and consists of (i) a type system associating programs with behavioural types that record relevant information for resource usage (creations, releases, and concurrent operations), (ii) a translation function that takes behavioural types and returns cost equations, and (iii) an automatic off-the-shelf solver for the cost equations. A soundness proof of the type system establishes the correctness of our technique with respect to the cost equations. We have experimentally evaluated our technique using a cost analysis solver and we report some results.",https://doi.org/10.1016/j.scico.2017.03.008,https://www.sciencedirect.com/science/article/pii/S0167642317300679,,,,2017,Static analysis of cloud elasticity,Abel Garcia and Cosimo Laneve and Michael Lienhardt,article,GARCIA201727,Science of Computer Programming,,147,0167-6423,Selected and Extended papers from the International Symposium on Principles and Practice of Declarative Programming 2015,,
,"IoT data analytics, AutoML, Concept drift, Machine learning",105366,,"With the wide spread of sensors and smart devices in recent years, the data generation speed of the Internet of Things (IoT) systems has increased dramatically. In IoT systems, massive volumes of data must be processed, transformed, and analyzed on a frequent basis to enable various IoT services and functionalities. Machine Learning (ML) approaches have shown their capacity for IoT data analytics. However, applying ML models to IoT data analytics tasks still faces many difficulties and challenges, specifically, effective model selection, design/tuning, and updating, which have brought massive demand for experienced data scientists. Additionally, the dynamic nature of IoT data may introduce concept drift issues, causing model performance degradation. To reduce human efforts, Automated Machine Learning (AutoML) has become a popular field that aims to automatically select, construct, tune, and update machine learning models to achieve the best performance on specified tasks. In this paper, we conduct a review of existing methods in the model selection, tuning, and updating procedures in the area of AutoML in order to identify and summarize the optimal solutions for every step of applying ML algorithms to IoT data analytics. To justify our findings and help industrial users and researchers better implement AutoML approaches, a case study of applying AutoML to IoT anomaly detection problems is conducted in this work. Lastly, we discuss and classify the challenges and research directions for this domain.",https://doi.org/10.1016/j.engappai.2022.105366,https://www.sciencedirect.com/science/article/pii/S0952197622003803,,,,2022,IoT data analytics in dynamic environments: From an automated machine learning perspective,Li Yang and Abdallah Shami,article,YANG2022105366,Engineering Applications of Artificial Intelligence,,116,0952-1976,,,
,"Data fusion, Neural networks, Intelligent control, Requirements",102427,,"Today the tasks of complex artificial and natural objects control have come to the fore in the majority of subject domains. The efficiency and effectiveness of solving these tasks directly depends of the efficiency and effectiveness of data fusion (DF). Data fusion methods are designed to integrate data from multiple sources and transform it in order to produce more consistent, accurate, and useful information than that provided by any individual data source. Although DF has been extensively studied for a considerable period of time it is still hardly applicable in practice in the processes of the control of the real world objects with complex structure and behavior as the data produced by the objects is, in the majority of cases, heterogeneous, multimodal, and imperfect, has huge volume. To ensure proper response to the changes in the state and behavior of the controlled objects that can be caused by both internal and external influencing factors the data should be processed with high accuracy and with minimum delays. Despite the importance of the tasks of complex objects control till now there are no researches that clarify to what extent the DF problem has been solved from the perspective of its application in the processes of objects control based on the data received from the objects. In the survey we define the requirements to DF in the interests of the control of complex artificial and natural objects, consider the structure of the multilevel process of intelligent object control, identify the neural networks that can be used in the control process for data fusion. Despite the wide capabilities of the existing NN we reveal that they still do not meet all the requirements to DF for complex objects control. Based on the analysis of NN architectures, we define requirements for advanced NN architectures and discuss future research directions. To facilitate our literature analyses, we also perform conceptual exploration of collected papers with lattices of closed itemsets and implications from Formal Concept Analysis and Data Mining used for knowledge processing in similar large-scale studies.",https://doi.org/10.1016/j.inffus.2024.102427,https://www.sciencedirect.com/science/article/pii/S1566253524002057,,,,2024,Neural networks for intelligent multilevel control of artificial and natural objects based on data fusion: A survey,Tianxing Man and Vasily Yu. Osipov and Nataly Zhukova and Alexey Subbotin and Dmitry I. Ignatov,article,MAN2024102427,Information Fusion,,110,1566-2535,,,
,,101479,,"This paper presents a proposal aiming at better understanding a workload of SQL queries and detecting coherent explorations hidden within the workload. In particular, our work investigates SQLShare (Jain et al., 2016), a database-as-a-service platform targeting scientists and data scientists with minimal database experience, whose workload was made available to the research community. According to the authors of (Jain et al., 2016), this workload is the only one containing primarily ad-hoc hand-written queries over user-uploaded datasets. We analyzed this workload by extracting features that characterize SQL queries and we investigate three different machine learning approaches to use these features to separate sequences of SQL queries into meaningful explorations. The first approach is unsupervised and based only on similarity between contiguous queries. The second approach uses transfer learning to apply a model trained over a dataset where ground truth is available. The last approach uses weak labeling to predict the most probable segmentation from heuristics meant to label a training set. We ran several tests over various query workloads to evaluate and compare the proposed methods.",https://doi.org/10.1016/j.is.2019.101479,https://www.sciencedirect.com/science/article/pii/S0306437919305319,,,,2020,Detecting coherent explorations in SQL workloads,Verónika Peralta and Patrick Marcel and Willeme Verdeaux and Aboubakar Sidikhy Diakhaby,article,PERALTA2020101479,Information Systems,,92,0306-4379,,,
,,I-CCVIII,,,https://doi.org/10.1016/S1936-878X(21)00040-1,https://www.sciencedirect.com/science/article/pii/S1936878X21000401,,,,2021,Full Issue PDF,,article,2021I,JACC: Cardiovascular Imaging,2,14,1936-878X,,,
,"Code review, Empirical study, Abandoned change",108-120,,"Context: Software developers contribute numerous changes every day to the code review systems. However, not all submitted changes are merged into a codebase because they might not pass the code review process. Some changes would be abandoned or be asked for resubmission after improvement, which results in more workload for developers and reviewers, and more delays to deliverables. Objective: To understand the underlying reasons why changes are abandoned, we conduct an empirical study on the code review of four open source projects (Eclipse, LibreOffice, OpenStack, and Qt). Method: First, we manually analyzed 1459 abandoned changes. Second, we leveraged the open card sorting method to label these changes with reasons why they were abandoned, and we identified 12 categories of reasons. Next, we further investigated the frequency distribution of the categories across projects. Finally, we studied the relationship between the categories and time-to-abandonment. Results: Our findings include the following: (1) Duplicate changes are the majority of the abandoned changes; (2) the frequency distribution of abandoned changes across the 12 categories is similar for the four open source projects; (3) 98.39% of the changes are abandoned within a year. Conclusion: Our study concluded the root causes of abandoned changes, which will help developers submit high-quality code changes.",https://doi.org/10.1016/j.infsof.2019.02.007,https://www.sciencedirect.com/science/article/pii/S0950584919300424,,,,2019,Why is my code change abandoned?,Qingye Wang and Xin Xia and David Lo and Shanping Li,article,WANG2019108,Information and Software Technology,,110,0950-5849,,,
,"Security operations, Software defined networking, Global flow, Weak vertex cover",56-70,,"One of the key challenges of network security is that security middle boxes, such as firewalls and Intrusion Detection Systems (IDSs), only have local view of the network. This lowers the efficiency of security detection and makes it difficult to locate the sources of the threats. There have been growing demands for security operations and appliances that are aware of the distribution and behavior of flows in the whole network; logically centralized control ability of Software-Defined Network (SDN) makes it possible for the network controller to acquire the global view of the network. In this paper, we propose a mechanism named Global Flow Table (GFT) which can provide security appliances and operators with paths of all the flows in SDN network, in addition to their sources, destinations, setup and terminate time, traffic volume and directions. A weak vertex cover based GFT algorithm which sacrifices less than 5% accuracy is also provided to improve scalability. Tests with different network topologies of cloud computing center and enterprise networks show promising performance. Utilizing the Global Flow Table, we built several applications to illustrate how GFT could benefit the security operations.",https://doi.org/10.1016/j.comnet.2017.04.002,https://www.sciencedirect.com/science/article/pii/S1389128617301251,,,,2017,Global Flow Table: A convincing mechanism for security operations in SDN,Xiaofeng Qiu and Kai Zhang and Qiuzheng Ren,article,QIU201756,Computer Networks,,120,1389-1286,,,
,"Trust, Awareness, Attribution error, Perceived trustworthiness, Global software engineering, Empirical studies",328-341,,"Trust remains a key challenge for globally distributed teams despite decades of research. Awareness, a key component of collaboration, has even more research around it. However, detailed accounts of the interrelationship of awareness and trust are still lacking in the literature, particularly in the setting of software teams. The gap we seek to fill with this article is to examine how software tool support for awareness can engender trust among globally distributed software developers. We highlight qualitative results from a previous and extensive field study that shows how trust is still a problem in contemporary teams. These results motivate a specific examination of how developers form attributions of one another. We describe a collection of visualization widgets designed to address the specific issues found in the field. To evaluate their effectiveness, we performed a controlled laboratory study with 28 students and 12 professional software developers who used these visualizations collected into a tool environment called Theseus. The results show that in general, participants using the visualizations make more accurate attributions, and their perceived trustworthiness of their remote teammates more accurately reflects actual circumstances. We conclude with a discussion of the implications of our results for theory and practice.",https://doi.org/10.1016/j.jss.2018.06.028,https://www.sciencedirect.com/science/article/pii/S0164121218301250,,,,2018,Bridging the gap between awareness and trust in globally distributed software teams,Erik H. Trainer and David F. Redmiles,article,TRAINER2018328,Journal of Systems and Software,,144,0164-1212,,,
,,100310,,,https://doi.org/10.1016/j.jpi.2023.100310,https://www.sciencedirect.com/science/article/pii/S2153353923001244,,,,2023,Pathology Visions 2022 Overview,,article,2023100310,Journal of Pathology Informatics,,14,2153-3539,,,
,,I-CXI,,,https://doi.org/10.1016/S1936-8798(24)00738-6,https://www.sciencedirect.com/science/article/pii/S1936879824007386,,,,2024,Full Issue PDF,,article,2024I,JACC: Cardiovascular Interventions,10,17,1936-8798,,,
,"Mental health disorders, Early risk prediction, Emotions, Cognitive styles, Deep learning, Social media",480-494,,"Mental disorders can severely affect quality of life, constitute a major predictive factor of suicide, and are usually underdiagnosed and undertreated. Early detection of signs of mental health problems is particularly important, since unattended, they can be life-threatening. This is why a deep understanding of the complex manifestations of mental disorder development is important. We present a study of mental disorders in social media, from different perspectives. We are interested in understanding whether monitoring language in social media could help with early detection of mental disorders, using computational methods. We developed deep learning models to learn linguistic markers of disorders, at different levels of the language (content, style, emotions), and further try to interpret the behavior of our models for a deeper understanding of mental disorder signs. We complement our prediction models with computational analyses grounded in theories from psychology related to cognitive styles and emotions, in order to understand to what extent it is possible to connect cognitive styles with the communication of emotions over time. The final goal is to distinguish between users diagnosed with a mental disorder and healthy users, in order to assist clinicians in diagnosing patients. We consider three different mental disorders, which we analyze separately and comparatively: depression, anorexia, and self-harm tendencies.",https://doi.org/10.1016/j.future.2021.05.032,https://www.sciencedirect.com/science/article/pii/S0167739X21001825,,,,2021,An emotion and cognitive based analysis of mental health disorders from social media data,Ana-Sabina Uban and Berta Chulvi and Paolo Rosso,article,UBAN2021480,Future Generation Computer Systems,,124,0167-739X,,,
,"High performance computing, Sensitive data, Secure computing, Data encryption",677-691,,"Driven by the progress of data and compute-intensive methods in various scientific domains, there is an increasing demand from researchers working with highly sensitive data to have access to the necessary computational resources to be able to adapt those methods in their respective fields. To satisfy the computing needs of those researchers cost-effectively, it is an open quest to integrate reliable security measures on existing High Performance Computing (HPC) clusters. The fundamental problem with securely working with sensitive data is, that HPC systems are shared systems that are typically trimmed for the highest performance—not for high security. For instance, there are commonly no additional virtualization techniques employed, thus, users typically have access to the host operating system. Since new vulnerabilities are being continuously discovered, solely relying on the traditional Unix permissions is not secure enough. In this paper, we discuss Secure HPC, a workflow allowing users to transfer, store and analyze data with the highest privacy requirements. Our contributions are the design of a multi-node secure workflow with parallel I/O, a strict security model enforced by the system and network features, and lastly the demonstration of a medical use case. In our experiments, we see an advantage in the asynchronous execution of IO requests in dm_crypt, while reaching 80% of the ideal performance. When comparing eCryptFS with GoCryptFS as two representative filesystem-level encryption stacks, eCryptFS was twice as fast. In a real use case, we observed on average 97% of the native performance.",https://doi.org/10.1016/j.future.2022.12.019,https://www.sciencedirect.com/science/article/pii/S0167739X2200423X,,,,2023,Secure HPC: A workflow providing a secure partition on an HPC system,Hendrik Nolte and Nicolai Spicher and Andrew Russel and Tim Ehlers and Sebastian Krey and Dagmar Krefting and Julian Kunkel,article,NOLTE2023677,Future Generation Computer Systems,,141,0167-739X,,,
,,I-CXXXVII,,,https://doi.org/10.1016/S2452-302X(23)00089-X,https://www.sciencedirect.com/science/article/pii/S2452302X2300089X,,,,2023,Full Issue PDF,,article,2023I,JACC: Basic to Translational Science,3,8,2452-302X,,,
,,I-CXXIII,,,https://doi.org/10.1016/S2452-302X(21)00355-7,https://www.sciencedirect.com/science/article/pii/S2452302X21003557,,,,2021,Full Issue PDF,,article,2021I,JACC: Basic to Translational Science,11,6,2452-302X,,,
,"Systemic risk measure, Machine learning, Cross-sectional measures, Conditional capital shortfall, Marginal expected shortfall (MES), SRISK",106416,,"This paper explores ways to improve the existing systemic risk measures by incorporating machine learning algorithms into the measurement. We aim to overcome the shortcomings of existing methods that rely on restricted modeling and are difficult to tap into various data resources. To this end, this paper unifies a dynamic quantification framework for systemic risk and links it to a two-step supervised learning problem, which allows for hierarchical structure of the systemic event and the return dependence. We leverage the generalization and predictive powers of machine learning to statistically model the tail events and the co-movements of the equity returns during the shocks to the macro-economy. Our results show that most machine learning algorithms enhance the systemic risk measure’s predictive power. Numerous comparative and sensitivity backtesting studies for United States and Hong Kong markets are conducted, from which we recommend the best machine learning algorithm for systemic risk measurement.",https://doi.org/10.1016/j.jbankfin.2022.106416,https://www.sciencedirect.com/science/article/pii/S0378426622000164,,,,2022,Machine-Learning-enhanced systemic risk measure: A Two-Step supervised learning approach,Ruicheng Liu and Chi Seng Pun,article,LIU2022106416,Journal of Banking & Finance,,136,0378-4266,,,
,"Computational intelligence, Artificial intelligence, Chatbots, Conversational agents, ChatGPT",100632,,"This review paper offers an in-depth analysis of AI-powered virtual conversational agents, specifically focusing on OpenAI’s ChatGPT. The main contributions of this paper are threefold: (i) an exhaustive review of prior literature on chatbots, (ii) a background of chatbots including existing chatbots/conversational agents like ChatGPT, and (iii) a UI/UX design analysis of prominent chatbots. Another contribution of this review is the comprehensive exploration of ChatGPT’s applications across a multitude of sectors, including education, business, public health, and more. This review highlights the transformative potential of ChatGPT, despite the challenges it faces such as hallucination, biases in training data, jailbreaks, and anonymous data collection. The review paper then presents a comprehensive survey of prior literature reviews on chatbots, identifying gaps in the prior work and highlighting the need for further research in areas such as chatbot evaluation, user experience, and ethical considerations. The paper also provides a detailed analysis of the UI/UX design of prominent chatbots, including their conversational flow, visual design, and user engagement. The paper also identifies key future research directions, including mitigating language bias, enhancing ethical decision-making capabilities, improving user interaction and personalization, and developing robust governance frameworks. By solving these issues, we can ensure that AI chatbots like ChatGPT are used responsibly and effectively across a broad variety of applications. This review will be a valuable resource for researchers and practitioners in understanding the current state and future potential of AI chatbots like ChatGPT.",https://doi.org/10.1016/j.cosrev.2024.100632,https://www.sciencedirect.com/science/article/pii/S1574013724000169,,,,2024,"A contemporary review on chatbots, AI-powered virtual conversational agents, ChatGPT: Applications, open challenges and future research directions",Avyay Casheekar and Archit Lahiri and Kanishk Rath and Kaushik Sanjay Prabhakar and Kathiravan Srinivasan,article,CASHEEKAR2024100632,Computer Science Review,,52,1574-0137,,,
,"IIoT, Security, Privacy, Blockchain, Smart Factory, Smart Grid, Supply Chain, E-Healthcare, VANET",102481,,"In recent years, the growing popularity of Internet of Things (IoT) is providing a promising opportunity not only for the development of various home automation systems but also for different industrial applications. By leveraging these benefits, automation is brought about in the industries giving rise to the Industrial Internet of Things (IIoT). IoT is prone to several cyberattacks and needs challenging approaches to achieve the desired security. Moreover, with the emergence of IIoT, the security vulnerabilities posed by it are even more devastating. Therefore, in order to provide a guideline to researchers, this survey primarily attempts to classify the attacks based on the objects of vulnerability. Subsequently, each of the individual attacks is mapped to one or more layers of the generalized IoT/IIoT architecture followed by a discussion on the countermeasures proposed in literature. Some relevant real-life attacks for each of these categories are also discussed. We further discuss the countermeasures proposed for the most relevant security threats in IIoT. A case study on two of the most important industrial IoT applications is also highlighted. Next, we explore the challenges brought by the centralized IoT/IIoT architecture and how blockchain can effectively be used towards addressing such challenges. In this context, we also discuss in detail one IoT specific Blockchain design known as Tangle, its merits and demerits. We further highlight the most relevant Blockchain-based solutions provided in recent times to counter the challenges posed by the traditional cloud-centered applications. The blockchain-related solutions provided in the context of two of the most relevant applications for each of IoT and IIoT is also discussed. Subsequently, we design a taxonomy of the security research areas in IoT/IIoT along with their corresponding solutions. Finally, several open research directions relevant to the focus of this survey are identified.",https://doi.org/10.1016/j.jnca.2019.102481,https://www.sciencedirect.com/science/article/pii/S1084804519303418,,,,2020,"A Comprehensive Survey on Attacks, Security Issues and Blockchain Solutions for IoT and IIoT",Jayasree Sengupta and Sushmita Ruj and Sipra {Das Bit},article,SENGUPTA2020102481,Journal of Network and Computer Applications,,149,1084-8045,,,
,"Deep learning, Artificial neural networks, Machine learning, Data analysis, Image analysis, Medical image analysis, Medical image processing, Medical imaging, Patient data, Pathology, Detection, Segmentation, Registration, Generative adversarial networks, PubMed, Systematic, Review, Survey, Meta-review, Meta-survey",106874,,"Deep learning has remarkably impacted several different scientific disciplines over the last few years. For example, in image processing and analysis, deep learning algorithms were able to outperform other cutting-edge methods. Additionally, deep learning has delivered state-of-the-art results in tasks like autonomous driving, outclassing previous attempts. There are even instances where deep learning outperformed humans, for example with object recognition and gaming. Deep learning is also showing vast potential in the medical domain. With the collection of large quantities of patient records and data, and a trend towards personalized treatments, there is a great need for automated and reliable processing and analysis of health information. Patient data is not only collected in clinical centers, like hospitals and private practices, but also by mobile healthcare apps or online websites. The abundance of collected patient data and the recent growth in the deep learning field has resulted in a large increase in research efforts. In Q2/2020, the search engine PubMed returned already over 11,000 results for the search term ‘deep learning’, and around 90% of these publications are from the last three years. However, even though PubMed represents the largest search engine in the medical field, it does not cover all medical-related publications. Hence, a complete overview of the field of ‘medical deep learning’ is almost impossible to obtain and acquiring a full overview of medical sub-fields is becoming increasingly more difficult. Nevertheless, several review and survey articles about medical deep learning have been published within the last few years. They focus, in general, on specific medical scenarios, like the analysis of medical images containing specific pathologies. With these surveys as a foundation, the aim of this article is to provide the first high-level, systematic meta-review of medical deep learning surveys.",https://doi.org/10.1016/j.cmpb.2022.106874,https://www.sciencedirect.com/science/article/pii/S0169260722002565,,,,2022,Medical deep learning—A systematic meta-review,Jan Egger and Christina Gsaxner and Antonio Pepe and Kelsey L. Pomykala and Frederic Jonske and Manuel Kurz and Jianning Li and Jens Kleesiek,article,EGGER2022106874,Computer Methods and Programs in Biomedicine,,221,0169-2607,,,
,"Reinforcement Learning, Deep Learning, Optimization, Neural Networks, Control",8049-8056,,"Deep reinforcement learning makes it possible to train control policies that map high-dimensional observations to actions. These methods typically use gradient-based optimization techniques to enable relatively efficient learning, but are notoriously sensitive to hyperparameter choices and do not have good convergence properties. Gradient-free optimization methods, such as evolutionary strategies, can offer a more stable alternative but tend to be much less sample efficient. In this work we propose a combination, using the relative strengths of both. We start with a gradient-based initial training phase, which is used to quickly learn both a state representation and an initial policy. This phase is followed by a gradient-free optimization of only the final action selection parameters. This enables the policy to improve in a stable manner to a performance level not obtained by gradient-based optimization alone, using many fewer trials than methods using only gradient-free optimization. We demonstrate the effectiveness of the method on two Atari games, a continuous control benchmark and the CarRacing-v0 benchmark. On the latter we surpass the best previously reported score while using significantly fewer episodes.",https://doi.org/10.1016/j.ifacol.2020.12.2240,https://www.sciencedirect.com/science/article/pii/S2405896320329001,,,,2020,"Fine-tuning Deep RL with Gradient-Free Optimization⁎⁎This work is part of the research programme Deep Learning for Robust Robot Control (DL-Force) with project number 656.000.003, which is (partly) financed by the Netherlands Organisation for Scientific Research (NWO).",Tim {de Bruin} and Jens Kober and Karl Tuyls and Robert Babuška,article,DEBRUIN20208049,IFAC-PapersOnLine,2,53,2405-8963,21st IFAC World Congress,,
,"Named Data Networking, Denial-of-Service attacks, Interest Flooding Attack, NDN Security",293-306,,"Named Data Networking (NDN) is a promising candidate for Future Internet Architecture (FIA), where the focus of communication is the content itself rather than the source of the requested content. NDN is one of the implementations of Information-Centric Networking (ICN). Among other salient features, NDN provides intrinsic security where security is provided to the content directly, rather than securing the communication channel. However, despite promising features offered by NDN, it is still susceptible to various Denial of Service (DoS) attacks, mainly Interest Flooding Attacks (IFA). Various mitigation solutions exist in the literature; however, legitimate users and their traffic are usually affected by these solutions. In this paper, we propose a lightweight mechanism called MSIDN, to mitigate sophisticated interest flooding-based DoS and Distributed DoS (DDoS) attacks in NDN. MSIDN aims to mitigate attacks at the source of communication without affecting the legitimate users. MSIDN relies on data producers’ feedback which is used by the routers to employ precise rate-limiting and block the attackers. Extensive simulations were conducted to evaluate the proposed MSIDN in terms of its robustness during various attack scenarios, dealing with malicious traffic without affecting the legitimate requests, and mitigating attacks at the source side of the communication.",https://doi.org/10.1016/j.future.2020.01.043,https://www.sciencedirect.com/science/article/pii/S0167739X19328729,,,,2020,MSIDN: Mitigation of Sophisticated Interest flooding-based DDoS attacks in Named Data Networking,Ahmed Benmoussa and Abdou el Karim Tahari and Chaker Abdelaziz Kerrache and Nasreddine Lagraa and Abderrahmane Lakas and Rasheed Hussain and Farhan Ahmad,article,BENMOUSSA2020293,Future Generation Computer Systems,,107,0167-739X,,,
,"Bibliometrics, Altmetrics, MHq, Societal impact, Case studies, Research excellence framework, REF2014",325-340,,"Altmetrics have been proposed as a way to assess the societal impact of research. Although altmetrics are already in use as impact or attention metrics in different contexts, it is still not clear whether they really capture or reflect societal impact. This study is based on altmetrics, citation counts, research output and case study data from the UK Research Excellence Framework (REF), and peers’ REF assessments of research output and societal impact. We investigated the convergent validity of altmetrics by using two REF datasets: publications submitted as research output (PRO) to the REF and publications referenced in case studies (PCS). Case studies, which are intended to demonstrate societal impact, should cite the most relevant research papers. We used the MHq’ indicator for assessing impact – an indicator which has been introduced for count data with many zeros. The results of the first part of the analysis show that news media as well as mentions on Facebook, in blogs, in Wikipedia, and in policy-related documents have higher MHq’ values for PCS than for PRO. Thus, the altmetric indicators seem to have convergent validity for these data. In the second part of the analysis, altmetrics have been correlated with REF reviewers’ average scores on PCS. The negative or close to zero correlations question the convergent validity of altmetrics in that context. We suggest that they may capture a different aspect of societal impact (which can be called unknown attention) to that seen by reviewers (who are interested in the causal link between research and action in society).",https://doi.org/10.1016/j.joi.2019.01.008,https://www.sciencedirect.com/science/article/pii/S1751157718302700,,,,2019,Do altmetrics assess societal impact in a comparable way to case studies? An empirical test of the convergent validity of altmetrics based on data from the UK research excellence framework (REF),Lutz Bornmann and Robin Haunschild and Jonathan Adams,article,BORNMANN2019325,Journal of Informetrics,1,13,1751-1577,,,
,"Advanced Persistent Threat (APT), Cyber espionage, Cyber attacks, Targeted attacks, Targeted malware",26-59,,"The increase of cyber attacks for the purpose of espionage is a growing threat. Recent examples, such as hacking of the Democratic National Committee and indicting by the FBI of Chinese military personnel for cyber economic espionage, are testaments of the severity of the problem. Unfortunately, research on the topic of Advanced Persistent Threats (APT) is complicated due to the fact that information is fragmented across a large number of Internet resources. This paper aims at providing a comprehensive survey of open source publications related to APT actors and their activities, focusing on the APT activities, rather than research on defensive or detective measures. It is intended to serve as a quick reference on the state of the knowledge of APT actors, where interested researchers can find what primary sources are most relevant to their research. The paper covers publications related to around 40 APT groups from multiple regions across the globe. A short summary of the main findings of each publication is presented.",https://doi.org/10.1016/j.cose.2017.08.005,https://www.sciencedirect.com/science/article/pii/S0167404817301608,,,,2018,Survey of publicly available reports on advanced persistent threat actors,Antoine Lemay and Joan Calvet and François Menet and José M. Fernandez,article,LEMAY201826,Computers & Security,,72,0167-4048,,,
,"melanoma, lipid droplets, DGAT1, fatty acids, reactive oxygen species, SOD1, oxidative stress",110995,,"Summary
Dysregulated cellular metabolism is a cancer hallmark for which few druggable oncoprotein targets have been identified. Increased fatty acid (FA) acquisition allows cancer cells to meet their heightened membrane biogenesis, bioenergy, and signaling needs. Excess FAs are toxic to non-transformed cells but surprisingly not to cancer cells. Molecules underlying this cancer adaptation may provide alternative drug targets. Here, we demonstrate that diacylglycerol O-acyltransferase 1 (DGAT1), an enzyme integral to triacylglyceride synthesis and lipid droplet formation, is frequently up-regulated in melanoma, allowing melanoma cells to tolerate excess FA. DGAT1 over-expression alone transforms p53-mutant zebrafish melanocytes and co-operates with oncogenic BRAF or NRAS for more rapid melanoma formation. Antagonism of DGAT1 induces oxidative stress in melanoma cells, which adapt by up-regulating cellular reactive oxygen species defenses. We show that inhibiting both DGAT1 and superoxide dismutase 1 profoundly suppress tumor growth through eliciting intolerable oxidative stress.",https://doi.org/10.1016/j.celrep.2022.110995,https://www.sciencedirect.com/science/article/pii/S2211124722007811,,,,2022,Oxidative stress from DGAT1 oncoprotein inhibition in melanoma suppresses tumor growth when ROS defenses are also breached,Daniel J. Wilcock and Andrew P. Badrock and Chun W. Wong and Rhys Owen and Melissa Guerin and Andrew D. Southam and Hannah Johnston and Brian A. Telfer and Paul Fullwood and Joanne Watson and Harriet Ferguson and Jennifer Ferguson and Gavin R. Lloyd and Andris Jankevics and Warwick B. Dunn and Claudia Wellbrock and Paul Lorigan and Craig Ceol and Chiara Francavilla and Michael P. Smith and Adam F.L. Hurlstone,article,WILCOCK2022110995,Cell Reports,12,39,2211-1247,,,
,"Software protection, Standardization, Risk framing, Risk assessment, Risk mitigation",103321,,"The last years have seen an increase in Man-at-the-End (MATE) attacks against software applications, both in number and severity. However, software protection, which aims at mitigating MATE attacks, is dominated by fuzzy concepts and security-through-obscurity. This paper presents a rationale for adopting and standardizing the protection of software as a risk management process according to the NIST SP800-39 approach. We examine the relevant constructs, models, and methods needed for formalizing and automating the activities in this process in the context of MATE software protection. We highlight the open issues that the research community still has to address. We discuss the benefits that such an approach can bring to all stakeholders. In addition, we present a Proof of Concept (PoC) decision support system that instantiates many of the discussed construct, models, and methods and automates many activities in the risk analysis methodology for the protection of software. Despite being a prototype, the PoC’s validation with industry experts indicated that several aspects of the proposed risk management process can already be formalized and automated with our existing toolbox and that it can actually assist decision making in industrially relevant settings.",https://doi.org/10.1016/j.cose.2023.103321,https://www.sciencedirect.com/science/article/pii/S0167404823002316,,,,2023,"Design, implementation, and automation of a risk management approach for man-at-the-End software protection",Cataldo Basile and Bjorn {De Sutter} and Daniele Canavese and Leonardo Regano and Bart Coppens,article,BASILE2023103321,Computers & Security,,132,0167-4048,,,
,"Detection, Permission, Resource, Risk, Supervised learning",101-154,Mobile Security and Privacy,"This chapter aims to present a new approach for detecting Android malware by relying permissions and supervised learning techniques. For that, we present security and its flaws in the Android system. Then we present concepts around machine learning and how they can be used for malware detection in general. We discuss works using permissions as key feature for the characterization of applications to detect malicious behavior. We present a detection system combining the proportion of requested permissions and risks induced on resources. This system requires the user to specify resources to protect and inform in an understandable way, activities performed in background with those permissions. We pass through some graphical interfaces of the implementation, then elucidate results concerning detection and prediction performance with the support of learning algorithms. We compare these results against well-known antiviruses and related solutions on the same collected datasets of malicious and benign applications. It is revealed that our system outperforms most of them and it is able to detect zero-day malware. Therefore it constitutes an interesting step forward to help users understanding the risks induced on resources and to help them detecting malware.",https://doi.org/10.1016/B978-0-12-804629-6.00006-7,https://www.sciencedirect.com/science/article/pii/B9780128046296000067,Boston,Syngress,978-0-12-804629-6,2017,Chapter 6 - Supervised Learning Based Detection of Malware on Android,F. Tchakounté and F. Hayata,incollection,TCHAKOUNTE2017101,,,,,,Man Ho Au and Kim-Kwang Raymond Choo,
,,I-CCLXXII,,,https://doi.org/10.1016/S2405-500X(23)00891-5,https://www.sciencedirect.com/science/article/pii/S2405500X23008915,,,,2023,Full Issue PDF,,article,2023I,JACC: Clinical Electrophysiology,12,9,2405-500X,,,
,"Autism spectrum disorder, Diagnosis, Rehabilitation, Deep learning, Neuroimaging, Neuroscience",104949,,"Accurate diagnosis of Autism Spectrum Disorder (ASD) followed by effective rehabilitation is essential for the management of this disorder. Artificial intelligence (AI) techniques can aid physicians to apply automatic diagnosis and rehabilitation procedures. AI techniques comprise traditional machine learning (ML) approaches and deep learning (DL) techniques. Conventional ML methods employ various feature extraction and classification techniques, but in DL, the process of feature extraction and classification is accomplished intelligently and integrally. DL methods for diagnosis of ASD have been focused on neuroimaging-based approaches. Neuroimaging techniques are non-invasive disease markers potentially useful for ASD diagnosis. Structural and functional neuroimaging techniques provide physicians substantial information about the structure (anatomy and structural connectivity) and function (activity and functional connectivity) of the brain. Due to the intricate structure and function of the brain, proposing optimum procedures for ASD diagnosis with neuroimaging data without exploiting powerful AI techniques like DL may be challenging. In this paper, studies conducted with the aid of DL networks to distinguish ASD are investigated. Rehabilitation tools provided for supporting ASD patients utilizing DL networks are also assessed. Finally, we will present important challenges in the automated detection and rehabilitation of ASD and propose some future works.",https://doi.org/10.1016/j.compbiomed.2021.104949,https://www.sciencedirect.com/science/article/pii/S0010482521007435,,,,2021,Deep learning for neuroimaging-based diagnosis and rehabilitation of Autism Spectrum Disorder: A review,Marjane Khodatars and Afshin Shoeibi and Delaram Sadeghi and Navid Ghaasemi and Mahboobeh Jafari and Parisa Moridian and Ali Khadem and Roohallah Alizadehsani and Assef Zare and Yinan Kong and Abbas Khosravi and Saeid Nahavandi and Sadiq Hussain and U. Rajendra Acharya and Michael Berk,article,KHODATARS2021104949,Computers in Biology and Medicine,,139,0010-4825,,,
,"Visual analytics, Product recall, Social media, Statistical Process Control",544-559,,"In the last decade, there have been high profile product safety events that captured public attention on social networks. Researchers have attempted various studies on consumers' reaction to product recalls but hardly any studies were conducted to find out a way to identify recalls by using users' comments specifically on social media. The earlier a company can detect a product disruption, the more a company can do in preparation to reduce its impact. In this paper, we propose a visualization framework capable of identifying a possible product recall via social networks, like Facebook or Twitter. Customers' comments found in data that express a negative sentiment are considered as non-conforming observations and plotted on a p-chart, which helps to identify when the proportion of negative comments get out of control and, as a result, a company can diminish the response time. To check its viability, we conducted three event studies of well-known companies that have experienced product recalls. The results show that customers’ negative sentiments could be monitored with the aim of predicting when a product might necessitate a recall as well as reducing decision-makers response time.",https://doi.org/10.1016/j.ijpe.2018.12.020,https://www.sciencedirect.com/science/article/pii/S0925527318304985,,,,2019,Visual analytics for identifying product disruptions and effects via social media,Araceli Zavala and Jose Emmanuel Ramirez-Marquez,article,ZAVALA2019544,International Journal of Production Economics,,208,0925-5273,,,
Intelligence-Based Medicine: Subspecialty Series,"Artificial intelligence, Cardiovascular clinicians, Deep learning technology, Human-machine intelligence continuum, Machine learning, Neuroscience",3-120,Intelligence-Based Cardiology and Cardiac Surgery,"The impressive gains in deep learning (DL) started in 2012 and its successful utilization in image interpretation have led to the current momentum for artificial intelligence (AI) awareness and adoption. In 2016, Google DeepMind's AlphaGo software soundly defeated the best human Go champion Lee Sedol to introduce the capability of DL outside of image interpretation. More recently, there have been impressive exponential advances in natural language processing with transformer tools such as GPT-3, GPT-4, and now ChatGPT. DeepMind and its AlphaFold AI tool has been able to predict the three-dimensional (3D) structure of proteins since 2021 and was Science magazine's “Breakthrough of the Year.” All of these AI accomplishments heralded the recent new era in AI. Major universities with AI departments (such as Stanford, MIT, and Carnegie Mellon) and technology giants (such as IBM, Apple, Facebook, and Microsoft in the United States as well as other large companies such as Baidu, Alibaba, and Tencent [BAT] in China) are all fervidly exploring real-life applications of AI. There is also a movement to democratize AI so that “no-code platforms” can accommodate people who do not know how to code [1].",https://doi.org/10.1016/B978-0-323-90534-3.00010-X,https://www.sciencedirect.com/science/article/pii/B978032390534300010X,,Academic Press,978-0-323-90534-3,2024,Chapter 1 - Introduction to artificial intelligence for cardiovascular clinicians,Anthony C. Chang and Alfonso Limon,incollection,CHANG20243,,,,,,Anthony C. Chang and Alfonso Limon,
,"Deep learning, Betting exchange, Market depth, Classification",38-51,,"We present the implementation of a short-term forecasting system of price movements in exchange markets using market depth data and a systematic procedure to enable a fully automated trading system. Three types of Deep Learning (DL) Neural Network (NN) methodologies are trained and tested: Deep NN Classifier (DNNC), Long Short-Term Memory (LSTM) and Convolutional NN (CNN). Although the LSTM is more suitable for multivariate time series analysis from a theoretical point of view, test results indicate that the CNN has on average the best predictive power in the case study under analysis, which is the UK to Win Horse Racing market during pre-live stage in the world’s most relevant betting exchange. Implications from the generalized use of automated trading systems in betting exchange markets are discussed.",https://doi.org/10.1016/j.infoecopol.2019.05.002,https://www.sciencedirect.com/science/article/pii/S0167624518300702,,,,2019,Deep learning in exchange markets,Rui Gonçalves and Vitor Miguel Ribeiro and Fernando Lobo Pereira and Ana Paula Rocha,article,GONCALVES201938,Information Economics and Policy,,47,0167-6245,The Economics of Artificial Intelligence and Machine Learning,,
,"Attack graphs, Security resource allocation, Guiding security decision-makers, Proactive security defense, Meta-heuristic for learning attacks, Markov Random Field, Intedependent systems",103927,,"We design a resource allocation framework for securing interdependent systems managed by multiple defenders. Our framework models these multi-defender interdependent systems with the notion of attack graphs. We propose three defense scenarios that are derived from the top attack paths that defenders predict, based on their system knowledge, which attackers may consider to launch their attacks. Furthermore, we propose a defense method with low sensitivity to the number of concurrent attacks, based on a graph-theoretical notion known as the Markov random field (MRF). We elucidate the advantages gained from our decision-making framework through comprehensive evaluation experiments on fourteen attack graphs (that includes multiple real-world interdependent systems). In our evaluation, we compare different defense scenarios and provide information about the most effective resource allocation approach against each attack scenario. In particular, we quantify the level of security improvement under our defense methods compared to three well-known resource allocation algorithms. Our experimental results show that our framework surpasses these resource allocation algorithms. In particular, our proposed defense leads to an average relative reduction in the expected security cost of 72% under equal initial investments on all edges. Moreover, it leads to an average relative reduction in the expected security cost of 78% under random initial investments on all edges. Under high security budget, our proposed defense approach has a relative reduction above 94% for 10 of the 14 attack graphs. These results signify notable enhancements in security resource allocation which contributes to improved security decision-making.",https://doi.org/10.1016/j.cose.2024.103927,https://www.sciencedirect.com/science/article/pii/S016740482400230X,,,,2024,GeniGraph: A genetic-based novel security defense resource allocation method for interdependent systems modeled by attack graphs,Mohammad Ryiad Al-Eiadeh and Mustafa Abdallah,article,ALEIADEH2024103927,Computers & Security,,144,0167-4048,,,
,"Industry 4.0, Technological change, Employment, Skill analysis, Text mining",121177,,"ESCO is a multilingual classification of Skills, Competences, Qualifications, and Occupations created by the European Commission to improve the supply of information on skills demand in the labour market. It is designed to assist individuals, employers, universities and training providers by giving them up to date and standardized information on skills. Rapid technological change means that ESCO needs to be updated in a timely manner. Evidence is presented here of how text-mining techniques can be applied to the analysis of data on emerging skill needs arising from Industry 4.0 to ensure that ESCO provides information which is current. The alignment between ESCO and Industry 4.0 technological trends is analysed. Using text mining techniques, information is extracted on Industry 4.0 technologies from: (i) two versions of ESCO (v1.0 - v1.1.); and (ii) from the 4.0 related scientific literature. These are then compared to identify potential data gaps in ESCO. The findings demonstrate that text mining applied on scientific literature to extract technology trends, can help policy makers to provide more up-to-date labour market intelligence.",https://doi.org/10.1016/j.techfore.2021.121177,https://www.sciencedirect.com/science/article/pii/S0040162521006107,,,,2021,Towards ESCO 4.0 – Is the European classification of skills in line with Industry 4.0? A text mining approach,Filippo Chiarello and Gualtiero Fantoni and Terence Hogarth and Vito Giordano and Liga Baltina and Irene Spada,article,CHIARELLO2021121177,Technological Forecasting and Social Change,,173,0040-1625,,,
,,I-CXXXV,,,https://doi.org/10.1016/S1936-878X(24)00224-9,https://www.sciencedirect.com/science/article/pii/S1936878X24002249,,,,2024,Full issue PDF,,article,2024I,JACC: Cardiovascular Imaging,7,17,1936-878X,,,
,"Control of switched systems, Decentralized control, Flying robots, Multi-vehicle systems, Networked robotic systems, Robust control applications",7418-7423,,"In this paper, we implement a switched decentralized controller, along with a proposed communication protocol, to control a nested multi-agent system without the need for a centralized processing node. More specifically, we apply a recently developed method for switched systems synthesis, which gives exact conditions for existence of a block-lower triangular path-dependent controller with L2 induced norm performance. The synthesis conditions are given in the form of a semidefinite program (SDP), which is computed offline for a predefined switching sequence. Each robot is equipped with a ultra-wideband (UWB) unit, which allows it to both estimate its position and communicate with other robots.",https://doi.org/10.1016/j.ifacol.2020.12.1281,https://www.sciencedirect.com/science/article/pii/S2405896320316839,,,,2020,Robust Decentralized Switching Control of UAVs using UWB-based Localization and Cooperation⁎⁎The authors were partially supported by NSF Grant 1629949.,Joao P. Jansch-Porto and Geir E. Dullerud,article,JANSCHPORTO20207418,IFAC-PapersOnLine,2,53,2405-8963,21st IFAC World Congress,,
,"Mobile online social networks, DDoS attacks, Authentication, Key-refilling, Machine learning, NS3 simulation, ProVerif simulation",103115,,"The rapid development of smartphone technology and the Internet services in mobile devices facilitates easy access to online social networking (OSN) sites anytime, anywhere. At the same time, this allures the adversaries to exploit the OSNs as a soft target for easy execution of various attacks that can quickly spread to a large number of users. In distributed denial-of-service (DDoS) attacks, an adversary aims to overwhelm the normal traffic of a targeted server with a flood of fake login messages so that the associated Internet service or website turns inoperable. In this paper, we propose a secure and lightweight authentication scheme (PRDoS) that resists DDoS and other security attacks in mobile OSN environments. We provide a multi-faceted solution towards the remedy of DDoS attacks in the OSN environment. After a certain threshold, the scheme discards further user login attempts and blocks an adversary who intends to overload the network server. We use the pre-loaded shadow identity and emergency key pairs, and a key-refilling strategy that rebuilds the essential synchronization between a blocked naive user and the OSN server. This technique restores the intended un-linkability property of the protocol. Using NS3 simulation, we study the impact of DDoS attackers on network throughput and network delay. Moreover, we validate and compare the proposed scheme against state-of-the-art solutions using the real attacks and benign datasets. We use the Canadian Institute for Cybersecurity (CIC) DoS dataset 2017, which is generated by capturing the normal and DoS attack packets separately with subsequent pre-processed for testing. We also use the machine learning (ML) algorithms, such as K-Nearest Neighbor (KNN), Gaussian Naive Bayes, and Multilayer Perceptron (MLP) to demonstrate the performance of the proposed solution in a practical attack detection scenario. We observe that these algorithms provide 97.05%, 95.48%, and 96.6% DDoS attack detection accuracy, respectively.",https://doi.org/10.1016/j.jisa.2022.103115,https://www.sciencedirect.com/science/article/pii/S2214212622000084,,,,2022,DDoS attack resisting authentication protocol for mobile based online social network applications,Munmun Bhattacharya and Sandip Roy and Ashok Kumar Das and Samiran Chattopadhyay and Soumya Banerjee and Ankush Mitra,article,BHATTACHARYA2022103115,Journal of Information Security and Applications,,65,2214-2126,,,
,"Smart homes, IoT, Privacy, Security, Trust, Blockchain, SDN, NFV",100588,,"Due to millions of loosely coupled devices, the smart-home security is gaining the attention of industry professionals, attackers, and academic researchers. The smart home is a typical home where many sensors, actuators, and IoT devices are used to automate home users’ daily activities. Although a smart home provides comfort, safety, and satisfaction to users, it opens up multiple challenging security issues when automating and offering intelligent services. Recent studies have investigated not only blockchain but SDN and NFV to address these challenges. We present a comprehensive survey on blockchain, SDN, and NFV for smart-home security. The paper also proposes a new architecture of the smart-home security. First, we describe the features of the smart home and its current security issues. Next, we outline the characteristics of blockchain, SDN, and NFV, including their contribution to improving the smart-home security. While SDN enhances the management and access control of the home network by providing a programmable controller to home nodes, NFV implements the functions of network appliances (e.g., network monitoring, firewall) as virtual machines and ensures the high availability of the network. Blockchain reinforces IoT data’s privacy, integrity, and security and improves the trust in transactions among untrusted IoT devices. Finally, we discuss open issues and challenges in the field and propose recommendations towards high-level security for the smart home.",https://doi.org/10.1016/j.iot.2022.100588,https://www.sciencedirect.com/science/article/pii/S2542660522000750,,,,2022,"A survey on blockchain, SDN and NFV for the smart-home security",N’guessan Yves-Roland Douha and Monowar Bhuyan and Shigeru Kashihara and Doudou Fall and Yuzo Taenaka and Youki Kadobayashi,article,DOUHA2022100588,Internet of Things,,20,2542-6605,,,
,,100875,,,https://doi.org/10.1016/S2772-963X(24)00053-X,https://www.sciencedirect.com/science/article/pii/S2772963X2400053X,,,,2024,Full Issue PDF,,article,2024100875,JACC: Advances,2,3,2772-963X,,,
,"Natural language processing, Fake news, Post-truth, Deception detection, Automatic fact-checking, Clickbait detection, Stance detection, Credibility, Human language technologies, Applied computing, Document management and text processing, Document capture, Document analysis",112943,,"Post-truth is a term that describes a distorting phenomenon that aims to manipulate public opinion and behavior. One of its key engines is the spread of Fake News. Nowadays most news is rapidly disseminated in written language via digital media and social networks. Therefore, to detect fake news it is becoming increasingly necessary to apply Artificial Intelligence (AI) and, more specifically Natural Language Processing (NLP). This paper presents a review of the application of AI to the complex task of automatically detecting fake news. The review begins with a definition and classification of fake news. Considering the complexity of the fake news detection task, a divide-and-conquer methodology was applied to identify a series of subtasks to tackle the problem from a computational perspective. As a result, the following subtasks were identified: deception detection; stance detection; controversy and polarization; automated fact checking; clickbait detection; and, credibility scores. From each subtask, a PRISMA compliant systematic review of the main studies was undertaken, searching Google Scholar. The various approaches and technologies are surveyed, as well as the resources and competitions that have been involved in resolving the different subtasks. The review concludes with a roadmap for addressing the future challenges that have emerged from the analysis of the state of the art, providing a rich source of potential work for the research community going forward.",https://doi.org/10.1016/j.eswa.2019.112943,https://www.sciencedirect.com/science/article/pii/S095741741930661X,,,,2020,Fighting post-truth using natural language processing: A review and open challenges,Estela Saquete and David Tomás and Paloma Moreda and Patricio Martínez-Barco and Manuel Palomar,article,SAQUETE2020112943,Expert Systems with Applications,,141,0957-4174,,,
,,I-CXCIV,,,https://doi.org/10.1016/S1936-878X(20)30043-7,https://www.sciencedirect.com/science/article/pii/S1936878X20300437,,,,2020,Full Issue PDF,,article,2020I,JACC: Cardiovascular Imaging,"2, Part 1",13,1936-878X,,,
,"Blockchain technology, Security supervision, Peer-to-peer (P2P) network, Transaction, User identity, Heuristics, Graph theory",102859,,"Due to decentralization, immutability, circulation, anonymity, blockchain technology has become a hot topic but also a hotbed of various cyber-crimes. Many perpetrators attack blockchain to steal cryptocurrencies or use anonymous addresses to conduct illicit financial transactions or receive ransoms while hiding their identities. Since blockchain technology has not developed for a long time, the security issues in this area cannot be well resolved through its own mechanisms, which brings great challenges to protect the security of blockchain and users. Although there are some protective measures to prevent attackers from attacking, most of them are proposed after attacks, and it is impossible to find the masterminds behind modern cyber-crimes, so it is necessary to continuously monitor suspicious nodes or users. In this paper, we first present a systematic overview of blockchain technology and security issues according to the four-layer structure, and explain the problem of security supervision of blockchain. Subsequently, we divide the key technologies for security supervision of blockchain into three aspects: node discovery technology on the network layer, data analysis technology of transaction records on the transaction layer, and network traffic analysis technology on the application layer. In terms of each aspect, we summarize the studies from various angles according to its characteristics. In the end, we discuss the relationship between blockchain and traditional law. Moreover, we present the challenges of security supervision and possible future research directions in this field.",https://doi.org/10.1016/j.jisa.2021.102859,https://www.sciencedirect.com/science/article/pii/S2214212621000922,,,,2021,Survey of security supervision on blockchain from the perspective of technology,Yu Wang and Gaopeng Gou and Chang Liu and Mingxin Cui and Zhen Li and Gang Xiong,article,WANG2021102859,Journal of Information Security and Applications,,60,2214-2126,,,
,"Bug handling process, Rapid release cycle, Feature freeze, Continuous software development, Software maintenance, Empirical software engineering",110882,,"Large software projects follow a continuous development process with regular releases during which bugs are handled. In recent years, many software projects shifted to rapid releases that reduce time-to-market and claim a faster delivery of fixed issues, but also have a shorter period to address bugs. To better understand the impact of rapid releases on bug handling activity, we empirically analyze successive releases of the Eclipse Core projects, focusing on the bug handling rates and durations as well as the feature freeze period. We study the impact of Eclipse’s transition from a yearly to quarterly release cycle. We confirm our findings through feedback received from five Eclipse Core maintainers. Among others, our results reveal that Eclipse’s bug handling process is becoming more stable over time, with a decreasing number of reported bugs before releases, an increasing bug fixing rate and an increasingly balanced bug handling workload before and after releases. The transition to a quarterly release cycle continued to improve bug handling. In addition, more effort is spent on bug fixing during the feature freeze period, while the bug handling rates do not differ between both periods.",https://doi.org/10.1016/j.jss.2020.110882,https://www.sciencedirect.com/science/article/pii/S0164121220302727,,,,2021,On the impact of release policies on bug handling activity: A case study of Eclipse,Zeinab {Abou Khalil} and Eleni Constantinou and Tom Mens and Laurence Duchien,article,ABOUKHALIL2021110882,Journal of Systems and Software,,173,0164-1212,,,
,"Cyber threat intelligence (CTI), Systematic literature review, virtual Chief Information Security Officer (vCISO), Agriculture 4.0, Agriculture 5.0, Smart farming infrastructures (SFIs), Digital twin technology",103754,,"The digitisation of agriculture, integral to Agriculture 4.0, has brought significant benefits while simultaneously escalating cybersecurity risks. With the rapid adoption of smart farming technologies and infrastructure, the agricultural sector has become an attractive target for cyberattacks. This paper presents a systematic literature review that assesses the applicability of existing cyber threat intelligence (CTI) techniques within smart farming infrastructures (SFIs). We develop a comprehensive taxonomy of CTI techniques and sources, specifically tailored to the SFI context, addressing the unique cyber threat challenges in this domain. A crucial finding of our review is the identified need for a virtual Chief Information Security Officer (vCISO) in smart agriculture. While the concept of a vCISO is not yet established in the agricultural sector, our study highlights its potential significance. The implementation of a vCISO could play a pivotal role in enhancing cybersecurity measures by offering strategic guidance, developing robust security protocols, and facilitating real-time threat analysis and response strategies. This approach is critical for safeguarding the food supply chain against the evolving landscape of cyber threats. Our research underscores the importance of integrating a vCISO framework into smart farming practices as a vital step towards strengthening cybersecurity. This is essential for protecting the agriculture sector in the era of digital transformation, ensuring the resilience and sustainability of the food supply chain against emerging cyber risks.",https://doi.org/10.1016/j.cose.2024.103754,https://www.sciencedirect.com/science/article/pii/S0167404824000555,,,,2024,Agriculture 4.0 and beyond: Evaluating cyber threat intelligence sources and techniques in smart farming ecosystems,Hang Thanh Bui and Hamed Aboutorab and Arash Mahboubi and Yansong Gao and Nazatul Haque Sultan and Aufeef Chauhan and Mohammad Zavid Parvez and Michael Bewong and Rafiqul Islam and Zahid Islam and Seyit A. Camtepe and Praveen Gauravaram and Dineshkumar Singh and M. {Ali Babar} and Shihao Yan,article,BUI2024103754,Computers & Security,,140,0167-4048,,,
,"Automatic keyword extraction, Text summarization, Deep Learning",102088,,"With the advent of Web 2.0, there exist many online platforms that results in massive textual data production such as social networks, online blogs, magazines etc. This textual data carries information that can be used for betterment of humanity. Hence, there is a dire need to extract potential information out of it. This study aims to present an overview of approaches that can be applied to extract and later present these valuable information nuggets residing within text in brief, clear and concise way. In this regard, two major tasks of automatic keyword extraction and text summarization are being reviewed. To compile the literature, scientific articles were collected using major digital computing research repositories. In the light of acquired literature, survey study covers early approaches up to all the way till recent advancements using machine learning solutions. Survey findings conclude that annotated benchmark datasets for various textual data-generators such as twitter and social forms are not available. This scarcity of dataset has resulted into relatively less progress in many domains. Also, applications of deep learning techniques for the task of automatic keyword extraction are relatively unaddressed. Hence, impact of various deep architectures stands as an open research direction. For text summarization task, deep learning techniques are applied after advent of word vectors, and are currently governing state-of-the-art for abstractive summarization. Currently, one of the major challenges in these tasks is semantic aware evaluation of generated results.",https://doi.org/10.1016/j.ipm.2019.102088,https://www.sciencedirect.com/science/article/pii/S0306457319300044,,,,2019,Textual keyword extraction and summarization: State-of-the-art,Zara Nasar and Syed Waqar Jaffry and Muhammad Kamran Malik,article,NASAR2019102088,Information Processing & Management,6,56,0306-4573,,,
,,I-CLXVIII,,,https://doi.org/10.1016/S1936-878X(22)00139-5,https://www.sciencedirect.com/science/article/pii/S1936878X22001395,,,,2022,Full issue PDF,,article,2022I,JACC: Cardiovascular Imaging,4,15,1936-878X,,,
,,521-557,CISSP Study Guide (Third Edition),,https://doi.org/10.1016/B978-0-12-802437-9.00011-4,https://www.sciencedirect.com/science/article/pii/B9780128024379000114,Boston,Syngress,978-0-12-802437-9,2016,Glossary,,incollection,2016521,,,,,,Eric Conrad and Seth Misenar and Joshua Feldman,Third Edition
,"Network security, Fast DDoS attack detection, Network graph based all packets, Directed weisfeiler-lehman graph kernel, Dynamic threshold mechanism",103079,,"DDoS attack detection methods play a very important role in protecting computer network security. However, the existing flow-based DDoS attack detection methods face the non-negligible time delay and are not general for different types of DDoS attacks at different rates. In order to fill this research gap, a fast all-packets-based DDoS attack detection approach (FAPDD) is proposed. The FAPDD firstly designs a new time series network graph model to effectively simplify the processing of network traffic handling compared with the flow-based detections. Furthermore, it is the first time that the directed Weisfeiler-Lehman graph kernel is built for measuring the divergence between the current network graph and the normalization network graphs. Due to the new graph model and kernel measurement method to judge network changes, the different types and rates of DDoS attacks can be especially detected. In addition, the dynamic threshold and freezing mechanism are constructed to display standard traffic changes and prevent the pollution of attack traffic to the standard network. Finally, a number of real DDoS attack datasets are applied to evaluate the effectiveness of the proposed method, as well as the overall time efficiency and detection effect. Compared with other methods, the FAPDD can better meet the real-time requirements and achieve good detection effects in different types of DDoS attacks with different attack rates.",https://doi.org/10.1016/j.jnca.2021.103079,https://www.sciencedirect.com/science/article/pii/S1084804521001016,,,,2021,A fast all-packets-based DDoS attack detection approach based on network graph and graph kernel,Xinqian Liu and Jiadong Ren and Haitao He and Bing Zhang and Chen Song and Yunxue Wang,article,LIU2021103079,Journal of Network and Computer Applications,,185,1084-8045,,,
,"High-performance, NGAV, Malwares, Artificial neural networks, Real-time malware detection, Computer forensics",103724,,"Background and Objective
Every second, on average, 8 (eight) new malware are created. So, our goal is to propose an antivirus, endowed with artificial intelligence, able of identifying malwares through models based on fast training and high-performance neural networks.
Methods
Our NGAV (Next Generation Antivirus) is equipped with an authorial ELM (Extreme Learning Morphological) machine. Our bmELMs (Bitwise-Morphological ELMs) are inspired by the image processing theory of Mathematical Morphology. We claim that bmELMs are able to adapt in any machine learning dataset. Inspired by Mathematical Morphology, our bmELMs are capable of modeling any form present at the decisions boundaries of neural networks.
Results
Our bmELMs results are compared with classical ELMs and evaluated through widely used classification metrics. Our antivirus, provided with Bitwise-Morphology, achieves an average accuracy of 97.88%, 93.07%, 93.07% and 91.74% in malware detection of PE (Portable Executable), Java, JavaScript and PHP, respectively.
Conclusions
Our NGAV enables high performance, large capacity of parallelism, and simple, low-power architecture with low power consumption. We concluded that our Bitwise-Morphology assists to the main requirements for the proper operation and confection of antivirus in hardware.",https://doi.org/10.1016/j.micpro.2020.103724,https://www.sciencedirect.com/science/article/pii/S0141933120308693,,,,2021,Next generation antivirus endowed with bitwise morphological extreme learning machines,Sidney M.L. Lima and Danilo M. Souza and Ricardo P. Pinheiro and Sthéfano H.M.T. Silva and Petrônio G. Lopes and Rafael D.T. {de Lima} and Jemerson R. {de Oliveira} and Thyago de A. Monteiro and Sérgio M.M. Fernandes and Edison de Q. Albuquerque and Washington W.A. {da Silva} and Wellington P. {dos Santos},article,LIMA2021103724,Microprocessors and Microsystems,,81,0141-9331,,,
,,503-521,Intelligence-Based Medicine,,https://doi.org/10.1016/B978-0-12-823337-5.00026-3,https://www.sciencedirect.com/science/article/pii/B9780128233375000263,,Academic Press,978-0-12-823337-5,2020,Index,,incollection,2020503,,,,,,Anthony C. Chang,
,"Artificial intelligence, AI, Cognitive computing, Expert systems, Machine learning, Research agenda",101994,,"As far back as the industrial revolution, significant development in technical innovation has succeeded in transforming numerous manual tasks and processes that had been in existence for decades where humans had reached the limits of physical capacity. Artificial Intelligence (AI) offers this same transformative potential for the augmentation and potential replacement of human tasks and activities within a wide range of industrial, intellectual and social applications. The pace of change for this new AI technological age is staggering, with new breakthroughs in algorithmic machine learning and autonomous decision-making, engendering new opportunities for continued innovation. The impact of AI could be significant, with industries ranging from: finance, healthcare, manufacturing, retail, supply chain, logistics and utilities, all potentially disrupted by the onset of AI technologies. The study brings together the collective insight from a number of leading expert contributors to highlight the significant opportunities, realistic assessment of impact, challenges and potential research agenda posed by the rapid emergence of AI within a number of domains: business and management, government, public sector, and science and technology. This research offers significant and timely insight to AI technology and its impact on the future of industry and society in general, whilst recognising the societal and industrial influence on pace and direction of AI development.",https://doi.org/10.1016/j.ijinfomgt.2019.08.002,https://www.sciencedirect.com/science/article/pii/S026840121930917X,,,,2021,"Artificial Intelligence (AI): Multidisciplinary perspectives on emerging challenges, opportunities, and agenda for research, practice and policy",Yogesh K. Dwivedi and Laurie Hughes and Elvira Ismagilova and Gert Aarts and Crispin Coombs and Tom Crick and Yanqing Duan and Rohita Dwivedi and John Edwards and Aled Eirug and Vassilis Galanos and P. Vigneswara Ilavarasan and Marijn Janssen and Paul Jones and Arpan Kumar Kar and Hatice Kizgin and Bianca Kronemann and Banita Lal and Biagio Lucini and Rony Medaglia and Kenneth {Le Meunier-FitzHugh} and Leslie Caroline {Le Meunier-FitzHugh} and Santosh Misra and Emmanuel Mogaji and Sujeet Kumar Sharma and Jang Bahadur Singh and Vishnupriya Raghavan and Ramakrishnan Raman and Nripendra P. Rana and Spyridon Samothrakis and Jak Spencer and Kuttimani Tamilmani and Annie Tubadji and Paul Walton and Michael D. Williams,article,DWIVEDI2021101994,International Journal of Information Management,,57,0268-4012,,,
,"Artificial intelligence, machine learning, deep learning, neural network, precision farming, yield monitoring, field mapping, crop scouting, weather tracking & forecasting, drone analytics, agriculture robot, smart greenhouse management, soil management, moisture monitoring, nutrient monitoring",641-668,Bioinformatics in Agriculture,"Artificial intelligence (AI) mimics the cognitive functions of the human brain, that is, learning from experiences using a set of algorithms by identifying hidden patterns. AI has already demonstrated its game-changing capabilities in many fields such as the banking sector, healthcare, e-commerce, among others. Recent advances in both computer hardware and large-scale generation of biological data have created room for the applicability of AI in agriculture by employing methods like machine learning, deep learning, natural language processing, artificial or convoluted neural networks either independently or in combination thereof. Currently, AI is being utilized in multiple domains of agriculture and contributing toward increasing crop yield as well as minimizing the risk associated with crop cultivation. Data generated from different agricultural domains such as weather, soil, temperature, humidity, irrigation, sowing requirements, and other crop-related criterion are being analyzed and integrated for agriculture-related predictions. An increase in crop yield is being achieved not only by predicting the best time for sowing, harvesting, and monitoring crop health but also by reducing the cost of agricultural inputs like chemicals, fertilizers, irrigation, etc., through precision farming. Correspondingly, agricultural risks are also being minimized by addressing issues such as poor rainfall, weed growth, pest attacks, and postharvest losses. Besides, AI is also being used for crop/commodity price forecasting and agricultural automation via robots. The predictive agricultural analytics and chatbots are used to disseminate information to farmers as a part of advisory services by these agribusinesses. This chapter will discuss AI technologies and their various applications for the development of better farm practices to improve plant productivity as well as technological advancements due to AI and its anticipated challenges in the future will be explored.",https://doi.org/10.1016/B978-0-323-89778-5.00007-6,https://www.sciencedirect.com/science/article/pii/B9780323897785000076,,Academic Press,978-0-323-89778-5,2022,Chapter 37 - Artificial intelligence: a way forward for agricultural sciences,Neeru S. Redhu and Zoozeal Thakur and Shikha Yashveer and Poonam Mor,incollection,REDHU2022641,,,,,,Pradeep Sharma and Dinesh Yadav and Rajarshi Kumar Gaur,
,"DNS servers, IP addresses, DDOS, HTTp, DHCP, LANs, ISPs",587-612,The Illustrated Network (Second Edition),"In this chapter, you will learn how DNS gives the Internet a more user-friendly way to access resources. We’ll see how names are associated with IP addresses and how applications find this information. We will also see how the openness and necessity of DNS makes the whole Internet more vulnerable to attack. You will learn how DNS servers provide information about local networks, and how this information is distributed and shared on the Internet. We’ll also use show tools to help examine DNS.",https://doi.org/10.1016/B978-0-12-811027-0.00023-0,https://www.sciencedirect.com/science/article/pii/B9780128110270000230,Boston,Morgan Kaufmann,978-0-12-811027-0,2017,Chapter 23 - The Domain Name System,Walter Goralski,incollection,GORALSKI2017587,,,,,,Walter Goralski,Second Edition
,"Virtual environment, Virtual robotics, Artificial intelligence, Game engine, Computational simulation, Artificial life, Situated cognition, Embodied cognition, Unity",73-95,,"Braitenberg vehicles are simple robotic platforms, equipped with rudimentary sensor and motor components. Such vehicles have typically featured as part of thought experiments that are intended to show how complex behaviours are apt to emerge from the interaction of inner control mechanisms with aspects of bodily structure and features of the wider (extra-agential) environment. The present paper describes a framework for creating Braitenberg-like vehicles, which is built on top of a widely used and freely available game engine, namely, the Unity game engine. The framework can be used to study the behaviour of virtual vehicles within a multiplicity of virtual environments. All aspects of the vehicle’s design, as well as the wider virtual environment in which the vehicle is situated, can be modified during the design phase, as well as at runtime. The result is a general-purpose simulation capability that is intended to provide the foundation for studies in so-called computational situated cognition—a field of study whose primary objective is to support the computational modelling of cognitive processes associated with the physically-embodied, environmentally-embedded, and materially-extended mind.",https://doi.org/10.1016/j.cogsys.2020.06.001,https://www.sciencedirect.com/science/article/pii/S1389041720300358,,,,2020,Planet Braitenberg: Experiments in virtual psychology,Paul R. Smart,article,SMART202073,Cognitive Systems Research,,64,1389-0417,,,
,", , ",102716,,"Link prediction methods anticipate the likelihood of a future connection between two nodes in a given network. The methods are essential in social networks to infer social interactions or to suggest possible friends to the users. Rapid social network growth trigger link prediction analysis to be more challenging especially with the significant advancement in complex social network modeling. Researchers implement numerous applications related to link prediction analysis in different network contexts such as dynamic network, weighted network, heterogeneous network and cross network. However, link prediction applications namely, recommendation system, anomaly detection, influence analysis and community detection become more strenuous due to network diversity, complex and dynamic network contexts. In the past decade, several reviews on link prediction were published to discuss the algorithms, state-of-the-art, applications, challenges and future directions of link prediction research. However, the discussion was limited to physical domains and had less focus on social network perspectives. To reduce the gap of the existing reviews, this paper aims to provide a comprehensive review and discuss link prediction applications in different social network contexts and analyses, focusing on social networks. In this paper, we also present conventional link prediction measures based on previous researches. Furthermore, we introduce various link prediction approaches and address how researchers combined link prediction as a base method to perform other applications in social networks such as recommender systems, community detection, anomaly detection and influence analysis. Finally, we conclude the review with a discussion on recent researches and highlight several future research directions of link prediction in social networks.",https://doi.org/10.1016/j.jnca.2020.102716,https://www.sciencedirect.com/science/article/pii/S1084804520301909,,,,2020,Applications of link prediction in social networks: A review,Nur Nasuha Daud and Siti Hafizah {Ab Hamid} and Muntadher Saadoon and Firdaus Sahran and Nor Badrul Anuar,article,DAUD2020102716,Journal of Network and Computer Applications,,166,1084-8045,,,
,"Hedgehog signaling, CRISPR screen, Smoothened, neural tube patterning, primary cilia, protein trafficking, morphogen signaling, ciliopathy, congenital heart disease, heterotaxy",113-129.e8,,"Summary
To uncover regulatory mechanisms in Hedgehog (Hh) signaling, we conducted genome-wide screens to identify positive and negative pathway components and validated top hits using multiple signaling and differentiation assays in two different cell types. Most positive regulators identified in our screens, including Rab34, Pdcl, and Tubd1, were involved in ciliary functions, confirming the central role for primary cilia in Hh signaling. Negative regulators identified included Megf8, Mgrn1, and an unannotated gene encoding a tetraspan protein we named Atthog. The function of these negative regulators converged on Smoothened (SMO), an oncoprotein that transduces the Hh signal across the membrane. In the absence of Atthog, SMO was stabilized at the cell surface and concentrated in the ciliary membrane, boosting cell sensitivity to the ligand Sonic Hedgehog (SHH) and consequently altering SHH-guided neural cell-fate decisions. Thus, we uncovered genes that modify the interpretation of morphogen signals by regulating protein-trafficking events in target cells.",https://doi.org/10.1016/j.devcel.2017.12.003,https://www.sciencedirect.com/science/article/pii/S1534580717309887,,,,2018,CRISPR Screens Uncover Genes that Regulate Target Cell Sensitivity to the Morphogen Sonic Hedgehog,Ganesh V. Pusapati and Jennifer H. Kong and Bhaven B. Patel and Arunkumar Krishnan and Andreas Sagner and Maia Kinnebrew and James Briscoe and L. Aravind and Rajat Rohatgi,article,PUSAPATI2018113,Developmental Cell,1,44,1534-5807,,,
,"Digital transformation, Industry 4.0, Ontology Engineering, Agile methodologies, Organisational learning",103690,,"Ontologies are increasingly recognised among the key enablers of the digital transformation of knowledge management processes, but still with a low level of adoption in manufacturing companies. Because ontologies and underlying technologies are complex, Ontology Engineering Methodologies (OEMs) provide a set of guidelines to move from an informal to a formal representation of the company’s knowledge base. This study evaluates three agile OEMs, i.e. UPONLite, SAMOD and RapidOWL, in terms of their process and outcome features, i.e. the OEM steps and the expected quality of the ontological models produced. The assessment is performed from the viewpoint of developers of ontology-based technologies in real industrial use cases. Results show that the three agile OEMs reflect different features to effectively support the digital transformation of companies' knowledge management; thus, they cannot be interchangeable. UPONLite is more effective in contexts where there is a lack of skills in OE, with the need for a structured approach in involving domain experts and generating documentation. SAMOD requires a more extended development period, but with several cycles that allow to map different types of knowledge and enable a “try-and-learn” approach. Conversely, RapidOWL lacks a structured sequence of modelling activities and encourages developers to be creative, but at the same time requires higher expertise in OE. Thus, companies and personnel dedicated to OE should choose the methodology according to the main aims guiding their digitalisation process, the current development status, and the level of expertise.",https://doi.org/10.1016/j.compind.2022.103690,https://www.sciencedirect.com/science/article/pii/S0166361522000872,,,,2022,An evaluation of agile Ontology Engineering Methodologies for the digital transformation of companies,Daniele Spoladore and Elena Pessot,article,SPOLADORE2022103690,Computers in Industry,,140,0166-3615,,,
,"Climate change, COP26, Digital world, Information management, Information systems, Information technology, Sustainability, Sustainable Development Goals (SDGs)",102456,,"The UN COP26 2021 conference on climate change offers the chance for world leaders to take action and make urgent and meaningful commitments to reducing emissions and limit global temperatures to 1.5 °C above pre-industrial levels by 2050. Whilst the political aspects and subsequent ramifications of these fundamental and critical decisions cannot be underestimated, there exists a technical perspective where digital and IS technology has a role to play in the monitoring of potential solutions, but also an integral element of climate change solutions. We explore these aspects in this editorial article, offering a comprehensive opinion based insight to a multitude of diverse viewpoints that look at the many challenges through a technology lens. It is widely recognized that technology in all its forms, is an important and integral element of the solution, but industry and wider society also view technology as being part of the problem. Increasingly, researchers are referencing the importance of responsible digitalization to eliminate the significant levels of e-waste. The reality is that technology is an integral component of the global efforts to get to net zero, however, its adoption requires pragmatic tradeoffs as we transition from current behaviors to a more climate friendly society.",https://doi.org/10.1016/j.ijinfomgt.2021.102456,https://www.sciencedirect.com/science/article/pii/S0268401221001493,,,,2022,Climate change and COP26: Are digital technologies and information management part of the problem or the solution? An editorial reflection and call to action,Yogesh K. Dwivedi and Laurie Hughes and Arpan Kumar Kar and Abdullah M. Baabdullah and Purva Grover and Roba Abbas and Daniela Andreini and Iyad Abumoghli and Yves Barlette and Deborah Bunker and Leona {Chandra Kruse} and Ioanna Constantiou and Robert M. Davison and Rahul De’ and Rameshwar Dubey and Henry Fenby-Taylor and Babita Gupta and Wu He and Mitsuru Kodama and Matti Mäntymäki and Bhimaraya Metri and Katina Michael and Johan Olaisen and Niki Panteli and Samuli Pekkola and Rohit Nishant and Ramakrishnan Raman and Nripendra P. Rana and Frantz Rowe and Suprateek Sarker and Brenda Scholtz and Maung Sein and Jeel Dharmeshkumar Shah and Thompson S.H. Teo and Manoj Kumar Tiwari and Morten Thanning Vendelø and Michael Wade,article,DWIVEDI2022102456,International Journal of Information Management,,63,0268-4012,,,
,"Artificial intelligence, Education technology, Emotion recognition, Gamification, Schema theory, Video-based learning",100109,,"Background
As a natural and continual process, the initial learning stages encompass mastering and recalling basic facts. The process proves effective with the integration of new information with pre-existing knowledge characterised as schema to facilitate memory encoding. Additionally, emotions also have the ability to modulate human cognition in terms of learning and memory. The recent advent of gamification in e-learning, which has garnered much scholarly and industrial interest, necessitates a thorough examination between video-based learning and its subsequent implications on schema, emotions, and gamification.
Objectives
The current multidisciplinary research triangulated cognitive psychology, affective science, and education technology with artificial intelligence for evaluating digital learning pedagogy based on memory retrieval accuracy, response time, and emotional valence.
Design
This three-way (2 x 2 x 2) mixed factorial experiment design with repeated measures entailed 64 healthy young adult volunteers (n = 64) with 32 in the schema congruent group and 32 in the schema incongruent group. Additionally, 27 (42%) of the volunteers were males, while 37 (58%) were females with an age range between 20 and 39 years old (mean age 27.78 years, SD = 4.77 years).
Results
The findings demonstrate that the schema congruent group attained a statistically significant and higher retrieval accuracy (p < .001). The delayed recall response time was faster than its immediate recall counterpart (p < .001). Overall, the gamified learning mode depicted more positive emotions compared to non-gamified learning, although both groups primarily portrayed more negative emotions (p = .05).
Implications
The synthesis of current research aimed to recommend an AI-based multidisciplinary framework to assess the impact on adult learners in terms of schema and evaluate their emotions in experiencing gamified or non-gamified video materials as a learning medium. The implications expedited from this research offer valuable insights for diverse stakeholders engaged in the video-based learning ecosystem.",https://doi.org/10.1016/j.caeai.2022.100109,https://www.sciencedirect.com/science/article/pii/S2666920X22000649,,,,2022,AI-based multidisciplinary framework to assess the impact of gamified video-based learning through schema and emotion analysis,Anjana Junius Vidanaralage and Anuja Thimali Dharmaratne and Shamsul Haque,article,VIDANARALAGE2022100109,Computers and Education: Artificial Intelligence,,3,2666-920X,,,
,"Atmospheric emissions inventory, Emission factors, SO, NO, Non-methane volatile organic compounds (NMVOC), CO",201-216,,"Within the frame of an air quality study of the Great Casablanca Area (GCA), an atmospheric emission inventory concerning the major pollutants: SO2; NOx; non-methane volatile organic compounds (NMVOC); and CO has been realized. This inventory has a spatial resolution of 1 km2 and is established for the reference year 1992. The area, which covers 2500 km2 includes a region which is very sensitive to atmospheric pollution since it is heavily populated and contains up to 60% of the industrial activities of Morocco. The results, which include both biogenic and anthropogenic sources, show as expected very large emissions of pollutants mainly due to the presence of a refinery, several power plants and, contrary to the general European situation, the production of NOx is not dominated by road traffic.",https://doi.org/10.1016/S0048-9697(98)80111-3,https://www.sciencedirect.com/science/article/pii/S0048969798801113,,,,1998,The air quality management of the region of Great Casablanca (Morocco). Part 1: atmospheric emission inventory for the year 1992,A. Khatami and J.-L. Ponche and E. Jabry and Ph. Mirabel,article,KHATAMI1998201,Science of The Total Environment,2,209,0048-9697,,,
Side Effects of Drugs Annual,,146-153,,"Publisher Summary
This chapter describes the adverse effects of neuromuscular blocking agents and skeletal muscle relaxants. Persistent paralysis has been reported after the long-term administration of neuromuscular blocking agents in critically ill patients. Neuromuscular transmission monitoring helps avoid the overdosing of neuromuscular blocking agents, which might prevent persistent paralysis. Glucocorticoids have been linked to acute quadriplegic myopathy and severe muscle weakness in patients receiving neuromuscular blocking agents. Heterotopic ossification or myositis ossificans has been reported after the long-term administration of neuromuscular blocking agents to patients in intensive care units. Allergic reactions to muscle relaxants result in a massive release of cell mediators, such as histamine, tryptase, serotonin, kinins, prostaglandins, and leukotrienes. This release is usually triggered by the bridging of IgE-receptor complexes with allergens. Tertiary and quaternary ammonium ions are important elements at the allergenic site of muscle relaxants that may explain cross-reactivity among muscle relaxants. Plasma tryptase concentration is a sensitive and relatively specific marker of anaphylaxis.",https://doi.org/10.1016/S0378-6080(99)80017-8,https://www.sciencedirect.com/science/article/pii/S0378608099800178,,Elsevier,,1999,Neuromuscular blocking agents and skeletal muscle relaxants,O. Zuzan and M. Leuwer,incollection,ZUZAN1999146,,,22,0378-6080,,J.K. Aronson and J. Elis,
,,75-80,,"The dielectric relaxation of deuterated K4Me11(CN)6·3H2O doped with NH41 has been investigated in the vicinity of the transition temperature. In all cases the dielectric band appeared to be non-symmetrical and may be described by means of the Williams-Watts empirical decay function ϕ(Φ) ⇌ exp[−(−/τ-)]. A mechanism for the asymmetry of the dielectric absorption due to fluctuation of the “Glarum defects” is proposed. Also, the nature of the dielectric absorption in the crystals is discussed.",https://doi.org/10.1016/0301-0104(83)87008-6,https://www.sciencedirect.com/science/article/pii/0301010483870086,,,,1983,Dielectric relaxation in cyano complexes of the K4Me11(CN)6·3H2O type. II. Isotopic effect,H.A. Kołłodziej and S. Sorriso,article,KOLLODZIEJ198375,Chemical Physics,1,78,0301-0104,,,
,"laser bending, laminated plate, temperature gradient mechanism, thickening phenomenon, thermal expansion thickening, extrusion thickening",454-459,,"A metal laminated plate, taking stainless steel/carbon steel laminated plate (SCLP) for example, is being increasingly used in the aircraft, ship, car and automotive industries. Based on the temperature gradient and thickening mechanisms, the thickening phenomenon was investigated for the SCLP forming and application widely. The bending zone thickness increases after laser bending of the SCLP. Then, an IPP image processing software was used to evaluate the grain size and thickness changes in laser bending zone. There are three areas they are stainless steel squeezed layer on the top, carbon steel extended layer at the middle and the bottom layer of stainless steel. The research results show that the grain size increases bigger in laser bending process which means thermal expansion thickening (TET) on one hand. In the positive bending process, grains extended by laser heating are squeezed through the bending stress and extrusion thickening (ET) on the other hand. The sizes of both stainless steel at upper layer and carbon steel layer at middle get thicker, but the bottom stainless layer changed little. The research outcomes also show the thickening size consists of TET and ET, where TET effect accounts for great proportion in the range of bending angle 5-20 degree. While ET effect increases in the range of bending angle 30-60 degree, the thickening ratio of TET and ET reaches 2 to 3 at bigger angles. The researches of the thickening phenomenon provide a deeper understand on laser bending theory and technology.",https://doi.org/10.1016/j.procir.2016.02.231,https://www.sciencedirect.com/science/article/pii/S2212827116005151,,,,2016,A Study of Thickening Phenomenon in Laser Bending Zone of a Metal Laminated Plate,Xuyue Wang and Xupeng Ma and Zihui Li and Rui Wang,article,WANG2016454,Procedia CIRP,,42,2212-8271,18th CIRP Conference on Electro Physical and Chemical Machining (ISEM XVIII),,
,"Abies, Picea, Pinus, Pinaceae, insoluble phenolics, hydroxycinnamic acids, flavonol glycosides, localization, cell wall, chemotaxonomy.",3517-3521,,"The occurrence of insoluble conjugated (ester-bound) hydroxycinnamic acids (p-coumaric and ferulic acids) and flavonol glycosides (kaempferol 3-O-β-glucopyranoside and 3-O-α-rhamnopyranoside, and quercetin 3-O-β-glucopyranoside and 3-O-α-arabinofuranoside) in cell wall preparations from leaves of 54 species from various Conifer taxa has been investigated. the bound β-coumaric and ferulic acids seem to be widespread among members of the Coniferae-with β-coumaric acid as the major compounds in most species investigated-, while the presence of bound flavonol glycosides appears to be of chemotaxonomic relevance for members of the Pinaceae. The Pinaceae species generally gave kaempferol 3-O-glucoside, although Abies gave in addition kaempferol 3-O-rhamnoside and Pinus quercetin 3-0-glucoside and 3-O-arabinoside.",https://doi.org/10.1016/0031-9422(88)80759-3,https://www.sciencedirect.com/science/article/pii/0031942288807593,,,,1988,Cell wall-conjugated phenolics from coniferae leaves,Dieter Strack and Jürgen Heilemann and Martina Mömken and Victor Wray,article,STRACK19883517,Phytochemistry,11,27,0031-9422,,,
,,41-48,,,https://doi.org/10.1016/0304-3479(86)90037-2,https://www.sciencedirect.com/science/article/pii/0304347986900372,,,,1986,Жизнестроение,Hans Günther,article,GUNTHER198641,Russian Literature,1,20,0304-3479,The Russian Avant-Grade XXIII The Zagreb Symposia IV,,
,"-HS-glycoprotein, Fetuin, Gene regulation, mRNA, Development",149-156,,"Human α2-HS-glycoprotein (AHSG) is a plasma protein synthesized in liver and selectively concentrated in bone matrix. It has been reported to be involved in bone formation and resorption as well as immune responses. Recently, AHSG was found to be the species equivalent protein of fetuin, the major fetal serum protein in cattle and sheep. The function and regulation of AHSG/fetuin in different species are not understood. We have isolated a liver cDNA clone that encodes the human AHSG/bovine fetuin homologue in the mouse. The AHSG/fetuin gene may have a role in differentiation since it is expressed in mouse limb buds and brain only at certain stages during development. Mouse liver AHSG/fetuin mRNA was present at low level at 12 days gestation but its level increased during the late part of gestation and peaked between 1 to 3 months after birth. The regulation of mouse AHSG/fetuin synthesis during development was found to be significantly different from that of sheep and bovine fetuin. Compared to fetuin, which is reduced in adult to 1 to 2% of the fetal level, mouse AHSG synthesis subsides only 50% 4 months after birth.",https://doi.org/10.1016/0167-4781(92)90522-2,https://www.sciencedirect.com/science/article/pii/0167478192905222,,,,1992,Human α2-HS-glycoprotein/bovine fetuin homologue in mice: identification and developmental regulation of the gene,Funmei Yang and Zi-Lian Chen and Judith M. Bergeron and Rod L. Cupples and William E. Friedrichs,article,YANG1992149,Biochimica et Biophysica Acta (BBA) - Gene Structure and Expression,2,1130,0167-4781,,,
,,207-229,,"Historically, the high latitude ionosphere has been viewed as the most complex of the ionospheric regions because it is driven by both magnetospheric and solar inputs. At lower latitudes the direct, and highly variable, magnetospheric input is relatively unimportant, which makes these other regions amenable to empirical modeling. To date, however, no empirical model of the high latitude ionosphere is available which includes these complex dependencies. On the other hand, numerical models that include the physics of this region have been developed and have proven to be successful at the climatology level. In this study we present the climatological results of one of these models, namely the Utah State University (USU) timedependent ionospheric model (TDIM). A total of 108 separate TDIM simulations for different ionospheric conditions were used to elucidate the high latitude ionospheric trends. These trends depend on solar cycle, season, universal time (UT), magnetic activity, interplanetary magnetic field (IMF) orientation, and hemisphere. The ionospheric climatology is not dominated by any one of these parameters. The solar cycle (F10.7 index), season (day), and magnetic activity (Kp index) compete on an even footing for control of the high latitude ionosphere. Mean variations of over an order of magnitude in NmF2, of over 150 km in hmF2, and of over 50 km in the transition height are present in the high latitude ionospheric climatology. The 108 simulations quantify the trends and show the UT dependence and spatial variability of the ionosphere. Some aspects of these UT trends are compared successfully with observations. Many of the simulation results are predictions that can be verified as more complete observational databases become available. The UT dependence, which at times can be a factor of two modulation of the F region densities, is a key reason for the failure of statistical models at high latitudes. At lower latitudes, statistical models based mainly on local time rather than UT have been very successful. At high latitudes, this is not so and, therefore, local time and UT (longitude) must be treated as independent variables. This fact alone explains why data sets based on a fixed ground location or satellite orbital plane cannot unravel the LT and UT dependencies at high latitudes. Also, the high latitude ionosphere is not spatially uniform; morphological features on latitudinal scales of 1–2 ° are present. These structures play a key role in identifying the ionospheric climatology.",https://doi.org/10.1016/S1364-6826(96)00037-5,https://www.sciencedirect.com/science/article/pii/S1364682696000375,,,,1997,Simulations of high latitude ionospheric climatology,J.J. Sojka and R.W. Schunk,article,SOJKA1997207,Journal of Atmospheric and Solar-Terrestrial Physics,2,59,1364-6826,,,
,,33-34,,"ABSTRACT
Last year at the Guelph meeting I had my first good taste of illumination and liked it to the last drop. At that time I remember there was some discussion regarding what illumination would do for the late hatched pullets. At that time I had hatched five different ages of leghorn pullets for the purpose of a demonstration as to the proper or most desirable time of hatching for egg production. It was therefore an easy matter to divide these pullets into two lots and provide electric lights for one and allow the other to get along as best it could without. The pullets were therefore divided into two pens A. and B. and in each pen there were eight pullets from each of five different hatches but all hatched from eggs produced by the same pen. The hatching dates were for lot 1, March first, lot 2, March 25, . . .",https://doi.org/10.3382/ps.0070033,https://www.sciencedirect.com/science/article/pii/S2666365119303850,,,,1921,Illumination and Late Hatched Pullets,R.B. THOMPSON,article,THOMPSON192133,Journal of the American Association of Instructors and Investigators of Poultry Husbandry,5,7,2666-3651,,,
,"Mobile device, Mobile security, Smartphone, Tablets, Privacy, Encryption, Forensics, Individuals, Organizations, Sociology",5-55,Mobile Security and Privacy,"This chapter looks at some of the sociological aspects of the increase in the use of mobile devices as the world transforms rapidly in a move toward mobile ubiquity. It then describes the challenges surrounding mobile device security for practitioners, highlighting the key risks for individuals and the key concerns for organizations interacting with a digital native workforce who rely on these mobile devices. It offers insights on various threats, risks, issues, mitigations, and mobile security strategies, as well as sections covering privacy, forensics, and individual versus organizational impacts. Finally, it concludes with 10 suggested steps to secure mobile devices.",https://doi.org/10.1016/B978-0-12-804629-6.00002-X,https://www.sciencedirect.com/science/article/pii/B978012804629600002X,Boston,Syngress,978-0-12-804629-6,2017,Chapter 2 - Mobile Security: A Practitioner’s Perspective,S. Tully and Y. Mohanraj,incollection,TULLY20175,,,,,,Man Ho Au and Kim-Kwang Raymond Choo,
,"Cyber range, Security testbed, Scenarios, Cyber security, Security exercise",101636,,"The first line of defense against cyber threats and cyber crimes is to be aware and get ready, e.g., through cyber security training. Training can have two forms, the first is directed towards security professionals and aims at improving understanding of the latest threats and increasing skill levels in defending and mitigating against them. The second form of training, which used to attract less attention, aims at increasing cyber security awareness among non-security professionals and the general public. Conducting such training programs requires dedicated testbeds and infrastructures that help realizing and executing the training scenarios and provide a playground for the trainees. A cyber range is an environment that aims at providing such testbeds. The purpose of this paper is to study the concept of a cyber range, and provide a systematic literature review that covers unclassified cyber ranges and security testbeds. In this study we develop a taxonomy for cyber range systems and evaluate the current literature focusing on architecture and scenarios, but including also capabilities, roles, tools and evaluation criteria. The results of this study can be used as a baseline for future initiatives towards the development and evaluation of cyber ranges in accordance with existing best practices and lessons learned from contemporary research and developments.",https://doi.org/10.1016/j.cose.2019.101636,https://www.sciencedirect.com/science/article/pii/S0167404819301804,,,,2020,"Cyber ranges and security testbeds: Scenarios, functions, tools and architecture",Muhammad Mudassar Yamin and Basel Katt and Vasileios Gkioulos,article,YAMIN2020101636,Computers & Security,,88,0167-4048,,,
,"GUI testing, GUI-based testing, Software testing, Code review, Modern code review, Guidelines, Practices",107299,,"Context:
Review of software artifacts, such as source or test code, is a common practice in industrial practice. However, although review guidelines are available for source and low-level test code, for GUI-based testing artifacts, such guidelines are missing.
Objective:
The goal of this work is to define a set of guidelines from literature about production and test code, that can be mapped to GUI-based testing artifacts.
Method:
A systematic literature review is conducted, using white and gray literature to identify guidelines for source and test code. These synthesized guidelines are then mapped, through examples, to create actionable, and applicable, guidelines for GUI-based testing artifacts.
Results:
The results of the study are 33 guidelines, summarized in nine guideline categories, that are successfully mapped as applicable to GUI-based testing artifacts. Of the collected literature, only 10 sources contained test-specific code review guidelines. These guideline categories are: perform automated checks, use checklists, provide context information, utilize metrics, ensure readability, visualize changes, reduce complexity, check conformity with the requirements and follow design principles and patterns.
Conclusion:
This pivotal set of guidelines provides an industrial contribution in filling the gap of general guidelines for review of GUI-based testing artifacts. Additionally, this work highlights, from an academic perspective, the need for future research in this area to also develop guidelines for other specific aspects of GUI-based testing practice, and to take into account other facets of the review process not covered by this work, such as reviewer selection.",https://doi.org/10.1016/j.infsof.2023.107299,https://www.sciencedirect.com/science/article/pii/S0950584923001532,,,,2023,Code review guidelines for GUI-based testing artifacts,Andreas Bauer and Riccardo Coppola and Emil Alégroth and Tony Gorschek,article,BAUER2023107299,Information and Software Technology,,163,0950-5849,,,
,,23-38,Physiological Processes Limiting Plant Productivity,,https://doi.org/10.1016/B978-0-408-10649-8.50006-X,https://www.sciencedirect.com/science/article/pii/B978040810649850006X,,Butterworth-Heinemann,978-0-408-10649-8,1981,2 - DOES LIGHT LIMIT CROP PRODUCTION?,J.L. MONTEITH,incollection,MONTEITH198123,,,,,,C.B. JOHNSON,
,"adenylate cyclase, human platelet, vanadate, GTF, GDP, prostaglandins",371-376,,,https://doi.org/10.1016/0049-3848(83)90048-8,https://www.sciencedirect.com/science/article/pii/0049384883900488,,,,1983,The activation of human platelet adenylate cyclase by vanadate,Katalin Ajtai and Katalin Tuka and E.N.A. Biró,article,AJTAI1983371,Thrombosis Research,3,29,0049-3848,,,
,"clothiapine, clozapine, obsessive-compulsive disorder, childhood schizophrenia",1469-1472,,"ABSTRACT
Serotonergic dysregulation in obsessive-compulsive disorder has been repeatedly demonstrated. Recent reports on the emergence of obsessive-compulsive symptoms in patients treated with clozapine support a hyposerotonergic hypothesis of obsessive-compulsive disorder. The authors report the emergence of de novo compulsive symptoms in a drug-naive 8-year-old schizophrenic child, shortly after the initiation of treatment with clothiapine. Clothiapine, an atypical antipsychotic agent, shares with clozapine its strong antiserotonergic properties. It seems that antagonistic activity of atypical neuroleptics at postsynaptic serotonergic receptors might be responsible for the development of iatrogenic obsessive-compulsive symptoms.",https://doi.org/10.1097/00004583-199511000-00013,https://www.sciencedirect.com/science/article/pii/S0890856709639654,,,,1995,Emergence of Transient Compulsive Symptoms during Treatment with Clothiapine,PAZ TOREN and ELIAHU SAMUEL and RONIT WEIZMAN and ABIGAIL GOLOMB and SOFIA ELDAR and NATHANIEL LAOR,article,TOREN19951469,Journal of the American Academy of Child & Adolescent Psychiatry,11,34,0890-8567,,,
,"Network attacks, Tools, Systems, Protocol, DoS",307-324,,"To prevent and defend networks from the occurrence of attacks, it is highly essential that we have a broad knowledge of existing tools and systems available in the public domain. Based on the behavior and possible impact or severity of damages, attacks are categorized into a number of distinct classes. In this survey, we provide a taxonomy of attack tools in a consistent way for the benefit of network security researchers. This paper also presents a comprehensive and structured survey of existing tools and systems that can support both attackers and network defenders. We discuss pros and cons of such tools and systems for better understanding of their capabilities. Finally, we include a list of observations and some research challenges that may help new researchers in this field based on our hands-on experience.",https://doi.org/10.1016/j.jnca.2013.08.001,https://www.sciencedirect.com/science/article/pii/S1084804513001756,,,,2014,"Network attacks: Taxonomy, tools and systems",N. Hoque and Monowar H. Bhuyan and R.C. Baishya and D.K. Bhattacharyya and J.K. Kalita,article,HOQUE2014307,Journal of Network and Computer Applications,,40,1084-8045,,,
The Morgan Kaufmann Series in Networking,,1-38,Policy-Based Network Management,"Publisher Summary
This chapter provides a brief retrospective on how policy-based network management (PBNM) was designed. It outlines two fundamental problems—the lack of use of an information model and the inability to use business rules to drive configuration of devices, services, and networks. Quality of service (QoS) is one of the primary drivers for implementing PBNM solutions. PBNM solutions require information models that contain business and system entities that can be easily implemented. The chapter introduces a unique object-oriented information model, known as DEN-ng (Directory Enabled Networks-new generation). It is being developed in the TM Forum. An object-oriented information model is a means to represent various entities in a managed environment. An entity can be a person, a computer, a router, or even a protocol message—anything that needs a uniform and consistent representation for configuration and management is a possibility for definition and representation in DEN-ng. An object-oriented information model provides a common language in which different types of management entities can be represented.",https://doi.org/10.1016/B978-155860859-7/50034-7,https://www.sciencedirect.com/science/article/pii/B9781558608597500347,Burlington,Morgan Kaufmann,,2004,Chapter 1 - The Foundation of Policy Management,John Strassner,incollection,STRASSNER20041,,,,18759351,,John Strassner,
,,213-233,,"The cuticle of a new cycad, Pseudoctenis ornata Archangelsky et al., sp. nov. is described and discussed in relation to the physical paleoenvironment in which the plant lived. The specimens occur in the Early Cretaceous Baqueró Formation, near Estancia El Verano in the Santa Cruz Province, Argentina. A detailed stratigraphic section records four facies, namely (1) fluvial channel, (2) flood plain, (3) lacustrine, and (4) flat and extended plains. A detail of each facies is provided. Pseudoctenis cuticles are found in the flood plain facies; the other components of the plant association are Gleichenites, Araucaria and Taeniopteris. The depositional history of this succession is related to a braided river that periodically received volcanic ash. Plants grew until complete burial by ash. Leaves of Pseudoctenis are pinnate, hypostomatic, with polycyclic stomata that form ill-defined rows. Abundant papillae and hair bases are present, especially on the lower cuticle. Comparisons are made with other Pseudoctenis species found in the same formation, and in other regions of the world. It is suggested that the paleoenvironment had a strong influence on the vegetation, especially the ash fall, and that it may have played a role in the formation of xeromorphic structures that characterize several gymnosperms present in this stratigraphic unit, including Pseudoctenis ornata. The lack of burning features on the cuticle suggests a cold ash fall. This fall probably was responsible for changes in edaphic patterns and atmospheric conditions that governed the growth and distribution of plant communities during the deposition of the Baqueró Formation.",https://doi.org/10.1016/0034-6667(95)00011-X,https://www.sciencedirect.com/science/article/pii/003466679500011X,,,,1995,"Cuticular characters adapted to volcanic stress in a new Cretaceous cycad leaf from Patagonia, Argentina. Considerations on the stratigraphy and depositional history of the Baqueró Formation",Ana Archangelsky and Renato R. Andreis and Sergio Archangelsky and Analia Artabe,article,ARCHANGELSKY1995213,Review of Palaeobotany and Palynology,3,89,0034-6667,,,
,,125-140,,,https://doi.org/10.1016/S0304-3479(04)00101-2,https://www.sciencedirect.com/science/article/pii/S0304347905800250,,,,2005,“На пороге как бы двойного бытия...”: тени и призраки в лирике Тютчева,Н.Е. Меднис,article,MDNIS2005125,Russian Literature,1,57,0304-3479,,,
,"Chemiluminescence, Phagocytosis, Polystyrene particles, Granulo-cytol, In vitro assay",263-271,,"Chemiluminescence (CL) was used to study the uptake of differently sized model drug carriers (polystyrene latex particles) by human granulocytes. The polystyrene particles were incubated with the granulocytes on microtitre plates and the CL monitored for a period of 3 hours. The sensitivity of the chemiluminescence (CL) assay could be increased by optimization of the luminol concentration, cell number and particle number (mass) per well. The intensity (uptake)/time profiles were characterized by the intensity Imax (uptake velocity) and the area under the curve (AUC, total uptake of particles). The reproducibility within one cell isolation was good. To compare CL measurements from different isolations internal standards were included to compensate for biological variations in the granulocyte function. The total uptake of particles increased with increasing particle size and at low to medium particle concentrations. It levelled or even decreased at high particle concentrations reducing the sensitivity of the assay. The AUC correlated with the total mass of phagocytosed particles and could therefore be used to compare the uptake of nano- and microparticles differing in size.",https://doi.org/10.1016/0168-3659(92)90101-V,https://www.sciencedirect.com/science/article/pii/016836599290101V,,,,1992,"In vitro phagocytosis assay of nano- and microparticles by chemiluminescence. I. Effect of analytical parameters, particle size and particle concentration",S. Rudt and R.H. Müller,article,RUDT1992263,Journal of Controlled Release,3,22,0168-3659,,,
,,181-187,,"H2Ti4O9, xH2O was prepared from K2Ti4O9 by hydrolysis with 0.4 M nitric acid as described by Marchand and co-workers. The K2Ti4O9 was prepared by a conventional solid state reaction, and by a sol/gel procedure. The ac conductivity was measured conventionally, and also under a load of 0.5 V. The temperature range was from 20–100°C. The measuring cell was purged with gas (N2 or H2) saturated with water vapor at the measuring temperature. Carbon electrodes were used. The dc conductivity was measured on tablets with platinum black electrodes in an atmosphere of hydrogen saturated with water vapour at 75% RH. The maximum conductivity was 1.8 × 10−3 (Ω cm)−1.",https://doi.org/10.1016/0167-2738(88)90008-2,https://www.sciencedirect.com/science/article/pii/0167273888900082,,,,1988,"Proton conduction in H2Ti4O9, 1.2 H2O",E. {Krogh Andersen} and I.G. {Krogh Andersen} and E. Skou,article,KROGHANDERSEN1988181,Solid State Ionics,3,27,0167-2738,,,
,"Ants, Myrmecochory, Seed-carrying behavior, EAG, Chemical senses",149-159,,"The sensory bases of seed-carrying by ants were studied through behavioral, physiological, and morphological methods. Fourteen colonies from 4 ant species [Aphaenogaster rudis Emery, Lasius alienus Foerster, Formica subsericea Say, and Camponotus ferrigineus (F.)] were behaviorally tested for olfactory and gustatory responses to seeds of A. candense. Results indicate that ants do not perceive these seeds, which have elaiosomes, by olfaction. Rather, they respond to these seeds only if the seeds are antennated. These results indicate that these ants are not “attracted” to A. canadense seeds by olfactory cues. Electroantennograms (EAGs) recorded from F. subsericea in response to olfactory and gustatory application of mixed isomer diolein, a major component of many seed elaiosomes, support the behavioral data. Olfactory delivery produced EAG responses no different from that of controls, while gustatory delivery produced responses with dose-dependence. Scanning electron microscopy (SEM) of the antennae of A. rudis, F. subsericea, and C. ferrigineus revealed the presence of sensilla chaetica, presumed to be contact chemoreceptors, and sensilla placodea and/or sensilla trichodea curvata that are believed to be olfactory receptors.",https://doi.org/10.1016/0022-1910(95)00087-9,https://www.sciencedirect.com/science/article/pii/0022191095000879,,,,1996,"The role of chemical senses in seed-carrying behavior by ants: A behavioral, physiological, and morphological study",S.L. Sheridan and K.A. Iversen and H. Itagaki,article,SHERIDAN1996149,Journal of Insect Physiology,2,42,0022-1910,,,
,"Internet of things, Moving target defense, Graphical security models, Diversity",103685,,"The Internet of Things (IoT) has become increasingly prevalent in various aspects of our lives, enabling billions of devices to connect and communicate seamlessly. However, the intricate nature of IoT connections and device vulnerabilities exposes the devices to security threats. To address the security challenges, we propose a proactive defense framework that leverages a model-based approach for security analysis and facilitates the defense strategies. Our proposed approach incorporates proactive defense mechanisms that combine Moving Target Defense techniques with cyber deception. The proposed approach involves the use of a decoy nodes as a deception technique and operating system based diversity as a moving target defense strategy to change the attack surface area of IoT networks. Additionally, we introduce a technique known as Important Measure-based Operating System Diversity to reduce defense cost. The effectiveness of the defense mechanisms was evaluated by using a graphical security model in a Software Defined Networking-based IoT network. Simulation results demonstrate the effectiveness of our approach in mitigating the impact of attacks while maintaining high performance levels in IoT networks.",https://doi.org/10.1016/j.cose.2023.103685,https://www.sciencedirect.com/science/article/pii/S0167404823005953,,,,2024,Proactive defense mechanism: Enhancing IoT security through diversity-based moving target defense and cyber deception,Zubaida Rehman and Iqbal Gondal and Mengmeng Ge and Hai Dong and Mark Gregory and Zahir Tari,article,REHMAN2024103685,Computers & Security,,139,0167-4048,,,
," Sims, Sugar, Organic acid, Amino acid, ACC, ACC synthase, ACC oxidase, Ethylene treatment",199-207,,"A study was undertaken to investigate the pattern of changes in some chemical constituents, ethylene biosynthesis, and the effect of ethylene treatment during postharvest ripening in purple passion fruit (Passiflora edulis Sims.). During ripening, sucrose content decreased while fructose and glucose contents increased. Citric and malic acid contents slightly increased during the early stage of ripening and decreased thereafter. Amino acids did not change significantly, except for proline, which increased rapidly towards the late stage of ripening. While 1-aminocyclopropane-1-carboxylic acid (ACC) content and ACC synthase activity increased in parallel with ethylene production, ACC oxidase activity was already high when harvested at the turning stage and further increased during ripening. Application of 1000 ppm ethylene for 24 h did not induce earlier onset of ethylene production when applied on harvest day, but was effective when applied one day or five days after harvest. The results indicate that purple passion fruit produces ethylene with the same biosynthetic pathway as other tissues in higher plants; its ethylene biosynthesis is regulated mainly by ACC synthase activity, and the sensitivity to ethylene might have changed after harvest as the fruit ripened.",https://doi.org/10.1016/0925-5214(95)00073-9,https://www.sciencedirect.com/science/article/pii/0925521495000739,,,,1996,Postharvest ripening and ethylene biosynthesis in purple passion fruit,Shinjiro Shiomi and Yasutaka Kubo and Leonard S. Wamocho and Hiroshi Koaze and Reinosuke Nakamura and Akitugu Inaba,article,SHIOMI1996199,Postharvest Biology and Technology,3,8,0925-5214,,,
Pergamon Programmed Texts,,283-305,Response of Plants to Multiple Stresses,,https://doi.org/10.1016/B978-0-08-092483-0.50018-9,https://www.sciencedirect.com/science/article/pii/B9780080924830500189,San Diego,Academic Press,978-0-08-092483-0,1991,13 - Annual Plants: Potential Responses to Multiple Stresses,F.A. Bazzaz and S.R. Morse,incollection,BAZZAZ1991283,,,,,,Harold A. Mooney and William E. Winner and Eva J. Pell,
,,428-430,,,https://doi.org/10.1016/0042-6822(64)90035-2,https://www.sciencedirect.com/science/article/pii/0042682264900352,,,,1964,The antigenic connection between two different types of foot-and-mouth disease viruses and their subparticles,C.J. {Van Oss} and Léone Dhennin and Louis Dhennin,article,VANOSS1964428,Virology,3,22,0042-6822,,,
,,113-114,,,https://doi.org/10.1016/0376-8716(80)90435-4,https://www.sciencedirect.com/science/article/pii/0376871680904354,,,,1980,Effects of sodium dipropylacetate on the withdrawal syndrome and alcohol consumption in a free-choice situation in alcohol-dependent rats,Bernard {Le Bourhis} and Gilles Aufrère,article,LEBOURHIS1980113,Drug and Alcohol Dependence,1,6,0376-8716,5th Biennial international symposium on alcoholism,,
,"Ethanol, Self-Administration, Abstinence, Alcohol deprivation effect, Acamprosate, Relapse",125-133,,"Acamprosate (calcium-acetyl homotaurinate) is a relatively new compound developed for the treatment of alcoholism and has been shown to be effective in attenuating relapse in human alcoholics. In the current study, the effects of this drug were further examined using an animal model of oral ethanol self-administration in a limited access paradigm. Male Wistar rats were trained to respond for ethanol (10% w/v) or water in a two-lever free-choice opérant condition. Acute administration of acamprosate (400 mg/kg) reduced ethanol consumption and increased responding for water. Chronic administration of lower daily doses of acamprosate (100 and 200 mg/kg) blocked the increased ethanol consumption typically observed in rats after an imposed abstinence period. This effect of acamprosate was selective for ethanol, as responding for water was unaffected at any dose tested. These results with rats suggest a model by which to explore the mechanisms for anti-relapse effects of acamprosate.",https://doi.org/10.1016/S0893-133X(97)00130-9,https://www.sciencedirect.com/science/article/pii/S0893133X97001309,,,,1998,Chronic acamprosate eliminates the alcohol deprivation effect while having limited effects on baseline responding for ethanol in rats,Charles J. Heyser and Gery Schulteis and Philippe Durbin and George F. Koob,article,HEYSER1998125,Neuropsychopharmacology,2,18,0893-133X,,,
,"Decay-associated spectrum, Flavin nucleotide, Photosynthesis, Plant phenolic, Pyridine nucleotide",58-68,,"Synchrotron radiation and the time-correlated single-photon-counting technique were used to investigate the spectral and time-resolved characteristics of blue-green fluorescence of leaves, mesophyll and chloroplasts. Four kinetic components were resolved. Decay-associated spectra and comparative analysis showed that the fluorescence of leaves, on both sides, was dominated by the fast (0.3 ns) and the medium (1 ns) kinetic components, comprising fluorophores emitting principally in the blue and present in the epidermal layer. In the mesophyll, these two faster components have two maxima, in the blue and in the green part of the spectrum, with a shift of the blue maxima to longer wavelengths when compared to leaves. The slow component (3.5 ns) was green-related with a strong indication for the presence of flavins. The very slow component (9 ns) had a maximal fractional intensity in mesophyll and was blue-related. The excitation and emission characteristics and the effect of anaerobic atmosphere on the fractional intensities of the slow and very slow component showed that they contain fluorescence of flavin nucleotides and nicotinamide nucleotides, respectively. Time-resolved measurements could be a means to extract the information on nucleotide fluorescence from the overall leaf fluorescence, and therefore to evaluate changes in mesophyll redox sate.",https://doi.org/10.1016/0005-2728(94)90022-1,https://www.sciencedirect.com/science/article/pii/0005272894900221,,,,1994,"Time-resolved spectral studies of blue-green fluorescence of leaves, mesophyll and chloroplasts of sugar beet (Beta vulgaris L.)",Zoran G. Cerovic and Fermín Morales and Ismael Moya,article,CEROVIC199458,Biochimica et Biophysica Acta (BBA) - Bioenergetics,1,1188,0005-2728,,,
,"DevOps, Extreme Programming, Object, Object-Oriented Programming, Procedural languages, Spiral Model, Systems Development Life Cycle, Waterfall Model",459-508,CISSP® Study Guide (Fourth Edition),"This chapter introduces Domain 8 of the CISSP®, Software Development Security. The most important aspects of this domain are related to managing the development of software and applications. Approaches to software development that attempt to reduce the likelihood of defects or flaws are a key topic in this domain. In particular, the Waterfall, Spiral, and Rapid Application Development (RAD) models of software development are considered. Another significant portion of this chapter is dedicated to understanding the principles of Object-Oriented programming and design. A basic discussion of several types of software vulnerabilities and the issues surrounding disclosure of the vulnerabilities are also a topic for this domain. Finally, databases, being a key component of many applications, are considered.",https://doi.org/10.1016/B978-0-443-18734-6.00008-8,https://www.sciencedirect.com/science/article/pii/B9780443187346000088,,Syngress,978-0-443-18734-6,2023,Chapter 9 - Domain 8: Software Development Security,Eric Conrad and Seth Misenar and Joshua Feldman,incollection,CONRAD2023459,,,,,,Eric Conrad and Seth Misenar and Joshua Feldman,Fourth Edition
,", , stratospheric ozone depletion, UV-B radiation",223-233,,"The effects of enhanced UV-B (280–320 nm) on the susceptibility of 18 irrigated lowland rice cultivars to rice blast (Pyricularia grisea) were investigated. The rice cultivars were irradiated with UV-B 313 lamps that were either filtered with cellulose acetate of 0.13 mm thickness (light transmission greater than 290 nm) or with Mylar D of 0.13 mm thickness (light transmission greater than 320 nm). Irradiation was for 6 h daily for 21 days starting at 9 days after planting. After irradiation, plants were inoculated with one or two blast isolates. In 18 out of 36 measured interactions the number of lesions per plant was higher in the presence of UV-B than in its absence. However, only two interactions were statistically significant. In a second experiment the dose-response relationship between the cultivars IR30 and IR72 and UV-B was established in the presence and absence of disease. Increasing levels of UV-B significantly reduced leaf areas, dry weights, and heights of both cultivars. Disease severity was either unaffected or decreased by UV-B. However, disease significantly changed the effects of UV-B on plant growth and recovery from UV-B damage. IR30 but not IR72 recovered from UV-B damage in the absence of disease within 5 days. No recovery occurred when inoculated. IR72 suffered even greater reductions of leaf area and dry weight by UV-B when inoculated. Although the effects of UV-B on disease severity may be small, it appears that the tolerance of plants to disease is decreased by UV-B radiation.",https://doi.org/10.1016/0167-8809(94)00529-N,https://www.sciencedirect.com/science/article/pii/016788099400529N,,,,1995,Effects of enhanced UV-B radiation on the growth of rice and its susceptibility to rice blast under glasshouse conditions,Maria R. Finckh and Arlene Q. Chavez and Q. Dai and Paul S. Teng,article,FINCKH1995223,"Agriculture, Ecosystems & Environment",2,52,0167-8809,,,
,"Outsourcing, IT, Telecom, Strategic relationships, Operational cost, Towers outsourcing",400-416,,"Outsourcing is not a recent phenomenon in the industry. Companies have been outsourcing non-core services or functions for many years. Outsourcing of IT management picked up in the late 80's and since then it has mushroomed into a multi-billion dollar industry. Initially the key driver for outsourcing was controlling operational expenses but over the period of time several other factors have been prominent such as flexibility in control of investments and resources, risk sharing, acquisition of special skills and competencies, revenue sharing, establishing long term strategic relationship, etc. The decision of outsourcing attaches special significance in the strategy formulation in the company or any operation. Large numbers of research papers have been published in the past two decades on outsourcing and researchers have studied and analyzed various internal and external factors having bearing on outsourcing decision. Over a period of time new business models and frameworks have emerged helping decision makers in the process. Some researchers have adopted research methodologies that are case studies based or while others have designed empirical formulations by conducting extensive surveys. Interestingly most conclusions from these studies tend to converge on similar set of key factors. This paper provides detailed review of the published research body of knowledge on outsourcing IT management and explores relevance to telecom operations. In the case of telecom operators, it is observed that the basic set of parameters influencing the decision of outsourcing is same as rest of the industry. In the recent past, it is observed that telecom operators have extended this model by outsourcing management of network infrastructure, management of towers, billing systems, marketing, etc. This is creating new working models and relationships. The paper concludes by providing the direction for the future research work in this domain",https://doi.org/10.1016/j.sbspro.2014.04.207,https://www.sciencedirect.com/science/article/pii/S1877042814031176,,,,2014,A Review on Outsourcing with a Special Reference to Telecom Operations,Sunil Patil and Y.S. Patil,article,PATIL2014400,Procedia - Social and Behavioral Sciences,,133,1877-0428,"International Conference on Trade, Markets and Sustainability (ICTMS-2013)",,
,,485-502,,"It is argued that since in asymptotically free Yang-Mills theories the quantum ground state is not controlled by perturbation theory, there is no a priori reason to believe that individual orbits corresponding to minima of the classical action dominate the Euclidean functional integral. To examine and classify the vacua of the quantum gauge theory, we propose an effective action in which the gauge field coupling constant g is replaced by the effective coupling g(t), t = ln[Fμνa)2μ4]. The vacua of this model correspond to paramagnetism and perfect paramagnetism, for which the gauge field is Fμνa = 0, and ferromagnetism, for which (Fμνa)2 = λ2, i.e. spontaneous magnetization of the vacuum occurs. We show that there are no instanton solutions to the quantum effective action. The equations for a point classical source of color spin are solved, and we show that the field infrared energy becomes linearly divergent in the limit of spontaneous magnetization. This implies bag formation, and an electric Meissner effect confining the bag contents.",https://doi.org/10.1016/0550-3213(78)90065-2,https://www.sciencedirect.com/science/article/pii/0550321378900652,,,,1978,Vacuum of the quantum Yang-Mills theory and magnetostatics,Heinz Pagels and E. Tomboulis,article,PAGELS1978485,Nuclear Physics B,3,143,0550-3213,,,
,,523-528,,"Decreased complement levels and impairment of polymorphonuclear leukocyte function increase the risk of infection during cardiopulmonary bypass (CPB). The effects of different types of oxygenator and of blood suction on this natural humoral and cellular host defense mechanism were investigated in dogs undergoing CPB during sham open-heart operations. Airborne contamination of the wound area and the CPB circuit was performed by aerosolizing Staphylococcus aureus. A membrane oxygenator in the CPB circuit maintained a normal host defense mechanism. The use of cardiotomy suction during CPB with this type of oxygenator affected the host defense to some extent. The use of a bubble oxygenator in the CPB circuit together with cardiotomy suction seriously impaired the host defense. Postoperatively bacteremia developed in no dogs in the membrane oxygenator group, whereas 8 of 15 dogs in the bubble oxygenator group had a positive blood culture for the indicator microorganism. We conclude that the use of a membrane oxygenator is helpful to maintain the host defense. Attention has to be paid to reduce the deleterious effects of cardiotomy suction.",https://doi.org/10.1016/S0003-4975(10)62114-5,https://www.sciencedirect.com/science/article/pii/S0003497510621145,,,,1987,Bubble Oxygenation and Cardiotomy Suction Impair the Host Defense during Cardiopulmonary Bypass: A Study in Dogs,Willem {van Oeveren} and Jacob Dankert and Charles R.H. Wildevuur,article,VANOEVEREN1987523,The Annals of Thoracic Surgery,5,44,0003-4975,,,
,,225-242,,"Ex situ decomposition of leaf litter of Paraserianthes falcataria, Eucalyptus tereticornis and Tectona grandis was studied under field and laboratory conditions for a period of 18 months using the litter-bag technique. The amount of CO2 evolved from the decaying litters and the population of fungi, bacteria and actinomycetes associated with the litters were quantified. A laboratory study was also conducted to determine the amount of organic carbon added to soil during decomposition. The dry weight loss of litter under field and laboratory conditions, respectively, were 94 and 74% for albizia, 64% and 60% for eucalypt and 96 and 92% for teak. The decay rate of the three types of litters varied significantly both in the field and in the laboratory. Teak litter decomposed rapidly as compared with others; decomposition of eucalypt litter was the slowest. Weight loss was positively correlated with litter moisture content as well as rainfall. The CO2 evolution differed significantly between the species, but in general it was highest during the southwest monsoon. The weight loss and CO2 evolution were significantly higher in the field than in the laboratory. No significant addition of organic carbon to soil from decomposing litters was evident in the present study. Eucalypt differed statistically from albizia and teak with respect to the bacterial pearl gram of litter, irrespective of the period of sampling or incubation condition. However, bacterial population did not vary significantly between albizia and teak litters. The number of fungi per gram of litter differed significantly between eucalypt and albizia, and that of actinomycetes between teak and eucalypt litters, both in the field and laboratory conditions. Between other pairs, the population and actinomycetes did not vary significantly. The CO2 evolution was positively correlated with number of fungi per gram of litter in albizia and teak in the field; it was not correlated with the population of bacteria and actinomycetes.",https://doi.org/10.1016/0378-1127(93)90115-4,https://www.sciencedirect.com/science/article/pii/0378112793901154,,,,1993,"Decomposition of leaf litter of albizia (Paraserianthes falcataria), eucalypt (Eucalyptus tereticornis) and teak (Tectona grandis) in Kerala, India",K.V. Sankaran,article,SANKARAN1993225,Forest Ecology and Management,1,56,0378-1127,,,
,,181-193,,,https://doi.org/10.1016/0034-6667(78)90043-X,https://www.sciencedirect.com/science/article/pii/003466677890043X,,,,1978,Aceraceae,G.C.S. Clarke and Marilyn R. Jones,article,CLARKE1978181,Review of Palaeobotany and Palynology,5,26,0034-6667,,,
,,369-377,,"The heat transfer in the rewetting of hot horizontal channels is investigated. The physical model assumes an inclined rewetting front advancing at a uniform velocity. Precursory cooling in the dry region is considered. Three-dimensional energy equations are solved numerically by a finite difference method. Further, the axial and circumferential temperature distributions are predicted. The influence of various parameters on the rewetting velocity is analyzed, as are the variations of the different heat transfer mechanisms, convection to the fluid and conduction in the three-dimensions, as a function of time.",https://doi.org/10.1016/0029-5493(80)90206-X,https://www.sciencedirect.com/science/article/pii/002954938090206X,,,,1980,Heat transfer during the rewetting of hot horizontal channels,Martha Salcudean and T.M. Bui,article,SALCUDEAN1980369,Nuclear Engineering and Design,2,59,0029-5493,,,
,,215-225,,"Summary
Background
Substantial physician workload and high costs are associated with the treatment of dyspepsia in primary health care. Despite the availability of consensus statements and guidelines, the most cost-effective empirical strategy for initial management of the condition remains to be determined. We compared step-up and step-down treatment strategies for initial management of patients with new onset dyspepsia in primary care.
Methods
Patients aged 18 years and older who consulted with their family doctor for new onset dyspepsia in the Netherlands were eligible for enrolment in this double-blind, randomised controlled trial. Between October, 2003, and January, 2006, 664 patients were randomly assigned to receive stepwise treatment with antacid, H2-receptor antagonist, and proton pump inhibitor (step-up; n=341), or these drugs in the reverse order (step-down; n=323), by use of a computer-generated sequence with blocks of six. Each step lasted 4 weeks and treatment only continued with the next step if symptoms persisted or relapsed within 4 weeks. Primary outcomes were symptom relief and cost-effectiveness of initial management at 6 months. Analysis was by intention to treat (ITT); the ITT population consisted of all patients with data for the primary outcome at 6 months. This trial is registered with ClinicalTrials.gov, number NCT00247715.
Findings
332 patients in the step-up, and 313 in the step-down group reached an endpoint with sufficient data for evaluation; the main reason for dropout was loss to follow-up. Treatment success after 6 months was achieved in 238 (72%) patients in the step-up group and 219 (70%) patients in the step-down group (odds ratio 0·92, 95% CI 0·7–1·3). The average medical costs were lower for patients in the step-up group than for those in the step-down group (€228 vs €245; p=0·0008), which was mainly because of costs of medication. One or more adverse drug events were reported by 94 (28%) patients in the step-up and 93 (29%) patients in the step-down group. All were minor events, including (other) dyspeptic symptoms, diarrhoea, constipation, and bad/dry taste.
Interpretation
Although treatment success with either step-up or step-down treatment is similar, the step-up strategy is more cost effective at 6 months for initial treatment of patients with new onset dyspeptic symptoms in primary care.
Funding
The Netherlands Organisation for Health Research and Development.",https://doi.org/10.1016/S0140-6736(09)60070-2,https://www.sciencedirect.com/science/article/pii/S0140673609600702,,,,2009,"Effect and cost-effectiveness of step-up versus step-down treatment with antacids, H2-receptor antagonists, and proton pump inhibitors in patients with new onset dyspepsia (DIAMOND study): a primary-care-based randomised controlled trial",Corine J {van Marrewijk} and Suhreta Mujakovic and Gerdine AJ Fransen and Mattijs E Numans and Niek J {de Wit} and Jean WM Muris and Martijn GH {van Oijen} and Jan BMJ Jansen and Diederik E Grobbee and J André Knottnerus and Robert JF Laheij,article,VANMARREWIJK2009215,The Lancet,9659,373,0140-6736,,,
,"Cloud computing, Cloud security monitoring, Hypervisor-based intrusion detection, Anomaly detection, Change detection, Multistage attacks",101646,,"Cloud computing is facing a multidimensional and rapidly evolving threat landscape, making intrusion detection more challenging. This paper introduces a new hypervisor-based cloud intrusion detection system (IDS) that uses online multivariate statistical change analysis to detect anomalous network behaviors. As a departure from the conventional monolithic network IDS feature model, we leverage the fact that a hypervisor consists of a collection of instances, to introduce an instance-oriented feature model that exploits the individual and correlated behaviors of instances to improve the detection capability. The proposed approach is evaluated by collecting and using a new cloud intrusion dataset that includes a wide variety of attack vectors.",https://doi.org/10.1016/j.cose.2019.101646,https://www.sciencedirect.com/science/article/pii/S0167404819301907,,,,2020,Hypervisor-based cloud intrusion detection through online multivariate statistical change tracking,Abdulaziz Aldribi and Issa Traoré and Belaid Moa and Onyekachi Nwamuo,article,ALDRIBI2020101646,Computers & Security,,88,0167-4048,,,
,"Maritime ship experiment, Collision prevention, Ship operator, Perceived ship collision risk, Maximum collision risk-bearing angle, Ship collision accident",107060,,"This study aims to elucidate the possible risk factors considering the point of view of a ship operator by identifying the maximum collision risk-bearing angle (MCRBA) and the distance at which the collision risk begins to increase significantly (DCRBIS), which are key factors affecting navigation safety in real maritime environments. Using two ships at sea in various vessel encounter situations (relative bearing angles of 000°, 045°, 090°, and 135°), the perceived ship collision risk (PSCR) was estimated by the ship operators. Then, the mean values of all the measured parameters were used to identify the bearing angle corresponding to the highest PSCR. The MCRBA was compared to the maximum frequency collision bearing angle (MFCBA) derived by investigating 200 reported ship collision cases in Korean waters. The highest experimental PSCR values were observed at a relative bearing angle of 135°, which corresponded to the results of collision case analyses stating that the MFCBA was equal to 112.5°–135°. Notably, the PSCR magnitude increased most significantly at a distance of 1.25–1 NM in experiments involving various vessel encounter situations. Collision risk factors such as the MCRBA and DCRBIS can thus be used in the development of collision prevention protocols for ship operators.",https://doi.org/10.1016/j.oceaneng.2020.107060,https://www.sciencedirect.com/science/article/pii/S0029801820301335,,,,2020,Identification of collision risk factors perceived by ship operators in a vessel encounter situation,Do-Hoon Kim,article,KIM2020107060,Ocean Engineering,,200,0029-8018,,,
,,922-943,,,https://doi.org/10.1016/S0958-1669(05)80131-4,https://www.sciencedirect.com/science/article/pii/S0958166905801314,,,,1991,Pharmaceutical applications,,article,1991922,Current Opinion in Biotechnology,6,2,0958-1669,,,
,,249-317,The Bamboos of the World,,https://doi.org/10.1016/B978-044450020-5/50007-1,https://www.sciencedirect.com/science/article/pii/B9780444500205500071,Amsterdam,Elsevier,978-0-444-50020-5,1999,SUBTRIBE BAMBUSINAE,D. OHRNBERGER,incollection,OHRNBERGER1999249,,,,,,D. OHRNBERGER,
,,239-247,,"Summary
The ultrastructure of a colourless amoeboid flagellate, Cercomonas sp. isolated from fresh water, is considered. This minute organism possesses two heterodynamic flagella. When moving it actively crawls along the substratum, persistently forming pseudopodia of various shape and size. The vesicular nucleus with a central nucleolus is located anteriorly, close the two kinetosomes. The system of kinetosome-derived microtubules forms a conical sheath around the nucleus. The Golgi apparatus, the endoplasmic reticulum, and mitochondria with tubular cristae have usual structure. A paranuclear body surrounded by a unit membrane is observed in the cells. The cytoplasm is filled with food vacuoles and drops of storage substances. Beneath the body surface, there are stinging organelles affecting bacteria. Peculiarities of the ultrastructure relate Cercomonas with the chrysophyte algae and myxomycetes.",https://doi.org/10.1016/S0003-9365(86)80045-8,https://www.sciencedirect.com/science/article/pii/S0003936586800458,,,,1986,"Ultrastructure of a Colourless Amoeboid Flagellate, Cercomonas sp.",>A.P. Mylnikov,article,MYLNIKOV1986239,Archiv für Protistenkunde,3,131,0003-9365,,,
,"Bacteria, Interstitial, Mangrove, Nutrient, Production, Sediment",201-223,,"Microbial productivity, nutrient chemistry and rates of nutrient regeneration were examined in muds of different mangrove forests within the Fly Delta, Papua New Guinea, to assess the effect of forest type on microbial and nutrient processes, and their interactions. Three major forest types were examined: Rhizophora-Bruguiera, Nypa and Avicennia-Sonneratia forests. For most variables, variations within a forest type were as great as, or greater than, differences between forest types. A high-intertidal Nypa site was most different in edaphic characteristics compared to five low-intertidal stations (two stations in each forest type) suggesting that differences among forest types in earlier studies were mainly a function of tidal elevation rather than species-specific ability of mangroves to influence redox and nutrient status. Dissolved inorganic nutrients were dominated by high (~ 200–500 μM) concentrations of silicates, but porewater phosphate levels were usually below detection limits (<0.02μM). Measured rates of nutrient regeneration were either slow into the sediment, or undetectable, despite a high concentration gradient for some solutes such as silicate. Rates of bacterial DNA and protein synthesis, and patterns of benthic primary production, indicate uptake of nutrients at the sediment-water interface by epibenthic microalgac and sequestering of porewater solutes by very active, subsurface bacterial communities. Rapid growth of these bacteria may be partially maintained by the decomposition and release of nutrients of mangrove roots and rhizomes, as suggested by the dominance of silicate in the porewater. Correlation analysis supports the notion of nutrient (mainly P) limitation of bacteria and microalgac in mangrove muds. It appears that a close microbe-nutricnt-planl connection serves as a mechanism to conserve scarce nutrients necessary for the existence of these tropical tidal forests.",https://doi.org/10.1016/0022-0981(93)90004-8,https://www.sciencedirect.com/science/article/pii/0022098193900048,,,,1993,The influence of forest type on microbial-nutrient relationships in tropical mangrove sediments,Daniel M. Alongi and Paul Christoffersen and Frank Tirendi,article,ALONGI1993201,Journal of Experimental Marine Biology and Ecology,2,171,0022-0981,,,
,"Intrusion detection, Class imbalance, K-nearest neighbor, Generative adversarial network, TACGAN",240-254,,"With the continuous emergence of various network attacks, it is becoming more and more important to ensure the security of the network. Intrusion detection, as one of the important technologies to ensure network security, has been widely studied. However, class imbalance leads to a challenging problem, that is, the normal data is much more than the attack data. Class imbalance will lead to the deviation of decision boundary, which makes higher value attack data classification error. In the face of imbalanced data, how to make the classification model classify more effectively is called imbalanced learning problem. In this study, we propose a tabular data sampling method to solve the imbalanced learning problem, which aims to balance the normal samples and attack samples. Firstly, for normal samples, on the premise of minimizing the loss of sample information, the K-nearest neighbor method is used for effective undersampling. Then, we design a tabular auxiliary classifier generative adversarial networks model (TACGAN) for attack sample oversampling. TACGAN model is an extension of ACGAN model. We add two loss functions in the generator to measure the information loss between real data and generated data, which makes TACGAN more suitable for the generation of tabular data. Finally, the normal data after undersampling and the attack data after oversampling are mixed to balance the data. We have carried out verification experiments on three real intrusion detection data sets. Experimental results show that the proposed method achieves excellent results in Accuracy, F1, AUC and Recall.",https://doi.org/10.1016/j.future.2022.01.026,https://www.sciencedirect.com/science/article/pii/S0167739X22000346,,,,2022,Imbalanced data classification: A KNN and generative adversarial networks-based hybrid approach for intrusion detection,Hongwei Ding and Leiyang Chen and Liang Dong and Zhongwang Fu and Xiaohui Cui,article,DING2022240,Future Generation Computer Systems,,131,0167-739X,,,
,"Optimal control, optimization, robots",311-315,,Optimal control of manipulation robots is considered. Problems of optimal control for robots are stated and solved by means of both analytical and numerical methods. Some optimal time motions of robots with two and three degrees of freedom are presented. Some of these regimes were realized experimentally for industrial robots. The obtained results show that optimal regimes require much less time than non-optimal “natural” ones. Practical applications of optimal regimes are discussed.,https://doi.org/10.1016/S1474-6670(17)60988-1,https://www.sciencedirect.com/science/article/pii/S1474667017609881,,,,1984,Optimal Control of Manipulation Robots,L.D. Akulenko and N.N. Bolotnik and F.L. Chernousko and A.A. Kaplunov,article,AKULENKO1984311,IFAC Proceedings Volumes,2,17,1474-6670,"9th IFAC World Congress: A Bridge Between Control Science and Technology, Budapest, Hungary, 2-6 July 1984",,
,,323-333,,"Two- and three-factor crosses with temperature-sensitive (ts) and syncytial plaque morphology (syn) mutants of herpes simplex type 1 virus have been used to study the possible role of syn-syn+ mixed plaque-forming virus in genetic recombination. Under the conditions of a standard genetic cross, recombinants first appear about 6 hr after infection, the time of formation of the first infectious progeny virus, and their frequency progressively rises until about 20 hr postinfection. During this period the frequency of mixed plaques remained constant at approximately 5%. The frequency of mixed plaques and recombinants were both increased several-fold when crosses were made in the presence of the DNA synthesis inhibitor 5-fluorodeoxyuridine (FUdR). In view of the genetic instability of the partially heterozygous genomes of mixed plaque forming virus this result is interpreted to mean that mixed plaques identify virus which is an intermediate in recombinant formation and that the molecular structure of their genome is probably that of a partial heteroduplex. Measurements of deoxynucleoside triphosphate pools showed that FUdR inhibited the large increase in the dTTP pool size which normally accompanies HSV-1 infection of BHK cells.",https://doi.org/10.1016/0042-6822(77)90007-1,https://www.sciencedirect.com/science/article/pii/0042682277900071,,,,1977,Heterozygosis and genetic recombination in herpes simplex type 1 virus,D.A. Ritchie and S. {Moira Brown} and J.H. Subak-Sharpe and A.T. Jamieson,article,RITCHIE1977323,Virology,2,82,0042-6822,,,
,,S151-S165,,,https://doi.org/10.1016/j.nmd.2020.08.001,https://www.sciencedirect.com/science/article/pii/S096089662030198X,,,,2020,Author index,,article,2020S151,Neuromuscular Disorders,,30,0960-8966,,,
,"Adaptive immunity, Allergic disease, IgE, Innate immunity, Mast cells",665-682,Comparative Biology of the Normal Lung (Second Edition),"Mast cells are well known as key effector cells of allergic disease, act as sentinels of innate immunity, and are regulators of adaptive immune responses. Phenotypic plasticity, characteristics and key locations of resident mast cells in a variety of host tissues contribute to the versatility of the mast cell response. While classically identified with IgE dependent allergy and innate immunity, mast cells are also known to play an indispensible role in modulating other effector cells, and delineating subsequent adverse pulmonary outcomes. The activation and function of mast cells is integral to the etiology of numerous lung pathophysiologies, exacerbation of pre-existing pulmonary conditions and detrimental toxicant exposures. Several therapeutics targeting mast cell activation and downstream effects of mediators have been developed to neutralize allergy and hypersensitivity. Advancements in mast cell biology have renewed focus on the importance of mast cells in pulmonary physiology and disease pathology.",https://doi.org/10.1016/B978-0-12-404577-4.00034-5,https://www.sciencedirect.com/science/article/pii/B9780124045774000345,San Diego,Academic Press,978-0-12-404577-4,2015,Chapter 34 - Pulmonary Mast Cells,Pranita Katwa and Jared M. Brown,incollection,KATWA2015665,,,,,,Richard A. Parent,Second Edition
,"ALCAN, tumor-specific gene, GPI-anchored protein, tumor antigen, tumor marker",235-243,,"In a search for novel genes expressed in human cancers, we identified one gene from an assembled expressed sequence tag database. Northern blot analysis revealed that the gene, termed alcan, was expressed in various types of human cancer cell lines and in the fetus, but not in normal tissues. The alcan gene is located on chromosome 6 and is encoded on a 246-amino-acid protein with weak homology to classical major histocompatibility complex class I. Its gene product, ALCAN, had hydrophobic amino acid clusters at both the N- and C-terminal regions and was predicted to be a glycosylphosphatidylinositol (GPI)-anchored membrane protein. Flow cytometric analysis revealed that ALCAN was detected on the surface of human cancer cells and on alcan-transfected CHO-K1 cells. ALCAN was also secreted from these cells, suggesting that some portion of the molecules was secreted by enzymatic cleavage by, for example, phospholipases. Mutational analysis of ALCAN suggested that the GPI-anchored position was the Ser216 residue. These findings indicate that ALCAN may be a potential target for cancer diagnosis or therapy.",https://doi.org/10.1006/bbrc.2001.5149,https://www.sciencedirect.com/science/article/pii/S0006291X01951496,,,,2001,A Novel Secreted Tumor Antigen with a Glycosylphosphatidylinositol-Anchored Structure Ubiquitously Expressed in Human Cancers,Haruo Onda and Shoichi Ohkubo and Yasushi Shintani and Kazuhiro Ogi and Kuniko Kikuchi and Hideyuki Tanaka and Koji Yamamoto and Isamu Tsuji and Yoshihiro Ishibashi and Takao Yamada and Chieko Kitada and Nobuhiro Suzuki and Hidekazu Sawada and Osamu Nishimura and Masahiko Fujino,article,ONDA2001235,Biochemical and Biophysical Research Communications,2,285,0006-291X,,,
,", Apocynaceae, cardiac glycoside, oleandrigenin β-gentiobiosyl-α--diginoside, digitoxigenin β-gentiobiosyl-α--oleandroside, adynerigenin, Δ-adynerigenin, Δ-neriagenin, 8β-hydroxydigitoxigenin, Δ-8β-hydroxydigitoxigenin.",2459-2463,,"Polar glycosides from the air-dried leaves were re-examined, and gentiobiosyl-nerigoside and gentiobiosylbeaumontoside isolated along with the major trioside, gentiobiosyl-oleandrin. Minor triosides also include glycosides of8β-hydroxy- and Δ16-8β-hydroxy-digitoxigenin, and Δ16-neriagenin, along with glycosides of known cardenolides, oleandrigenin, digitoxigenin, adynerigenin, neriagenin and their Δ16-derivatives.",https://doi.org/10.1016/0031-9422(92)83299-E,https://www.sciencedirect.com/science/article/pii/003194229283299E,,,,1992,Cardenolide triosides of oleander leaves,Fumiko Abe and Tatsuo Yamauchi,article,ABE19922459,Phytochemistry,7,31,0031-9422,The International Journal of Plant Biochemistry,,
,,137-142,,"The present work involves isolation of mango pectinesterase (PE) and polygalacturonase (PG), and investigating some of its characteristics, mainly with respect to heat-stability of the enzymes. Within a reaction time of 10 min, mango PE shows its maximal activity at pH 7.5 in a reaction mixture containing 1% citrus pectin and 0.1 or 0.2 m NaCl, at 55 °C. This enzyme possesses a Z value of 18.5 °C. Mango PG reveals its maximal activity in a reaction mixture containing 0.1% Na-polygalacturonate and 0.1 m NaCl. The reaction mixture was adjusted to pH 4.8 (McIlvaine buffer of 0.1 m) and 30–35 °C. Mango PG was less heat-stable than PE, with a Z value of 12.25 °C. The stepwise running of the inactivation diagrams of PE and PG emphasise the suggestion of the existence of more than one PE and more than one PG in mango enzyme extract.",https://doi.org/10.1016/0308-8146(95)90778-6,https://www.sciencedirect.com/science/article/pii/0308814695907786,,,,1995,Heat-inactivation of mango pectinesterase and polygalacturonase,Azza A.S. Labib and F.A. El-Ashwah and H.T. Omran and A. Askar,article,LABIB1995137,Food Chemistry,2,53,0308-8146,,,
,"Glyceroglycolipid, Liposome, Membrane surface, Glycolipid, Fluorescence anisotropy",44-51,,"To elucidate the importance of the headgroup structure of glycolipids in the physicochemical properties of liposomal membranes of glycolipids, two diglucosyldialkylglycerols containing an α(1′ → 4′) or a β(1′ → 4′) glucoside linkage, 1,2-dihexadecyl-O-β-d-maltosyl(1′ → 3)-rac-glycerol (MAL-DG) and 1,2-dihexadecyl-O-β-d-cellobiosyl(1′ → 3)-rac-glycerol (CEL-DG) were employed. The fluorescence spectra and steady-state fluorescence anisotropy of 1,6-diphenyl-1,3,5-hexatriene in the deep hydrophobic domain of these liposomal bilayers and dansylhexadecylamine in the vicinity of glycerol backbone were measured, respectively. Compared with dipalmitoylphosphatidylcholine (DPPC) liposomes, the phase-transition temperatures (Tc) of the present two glycolipid liposomes were about 11–15°C higher and the fluidity at the surface of these glycolipid liposome was considerably lower. This means that the interaction between neighboring diglucoside headgroups may be stronger than that between phosphatidylcholine headgroups. Fluorospectrometric and CPK model studies suggested that the structural difference in anomerization and epimerization of the disaccharide moiety of glyceroglycolipids is an important factor for determining the physicochemical properties of these glycolipid liposomes.",https://doi.org/10.1016/0005-2736(82)90212-7,https://www.sciencedirect.com/science/article/pii/0005273682902127,,,,1982,Liposomal membranes. XV: Importance of surface structure in liposomal membranes of glyceroglycolipids,Kiyoshi Iwamoto and Junzo Sunamoto and Keizo Inoue and Tamao Endo and Shoshichi Nojima,article,IWAMOTO198244,Biochimica et Biophysica Acta (BBA) - Biomembranes,1,691,0005-2736,,,
,,281-290,,"Production cost in the desalination plants remains to be a major constraint on the development and promotion of the water processing industry. Water is heavily subsidized in those countries where the only source of water for domestic supply is desalinated water. Searching for cost reduction measures, essentially involves analysis of the financing system under which a desalination plant is constructed, operated and maintained. In Bahrain, where natural water resources are extremely limited and fresh groundwater of requisite quality is becoming scarce, desalination of water is ranked as a must. The desalinated water is blended with groundwater to provide a domestic supply within the necessary quality limits. However, to keep pace with increasing demand and minimize the need to draw water from the aquifer, new desalination plants are required. In this paper the authors discuss the role of privatization as a financing alternative in the desalination industry in Bahrain, and its influence on the production cost. Available data from the existing operated plants in Bahrain throughout the past fifteen years are analyzed with a view to assert this possibility.",https://doi.org/10.1016/0011-9164(94)00092-1,https://www.sciencedirect.com/science/article/pii/0011916494000921,,,,1994,Privatization as a financing alternative for desalination plants in Bahrain,Ahmed Khater and Sami Dannish and Mohammed Al-Ansari,article,KHATER1994281,Desalination,1,97,0011-9164,Proceedings of the IDA and WRPC World Conference On Desalination and Water Treatment,,
,,25-33,,A modified kettle reboiler is planned to be used as an emergency condenser for high pressure steam in nuclear power plants. The condensing is achieved by the boiling-off of water at atmospheric pressure. The bubbles released at the tubular surface have a finite residence time in the liquid column above the tubular surface. This ‘bubble holdup’ increases the level of the two-phase boiling system. It is important to know the level change in order to determine the free space available for disengagement of the entrapped droplets and the capacity of the condenser to condense the high pressure steam. A solution to this problem is presented below alongwith an actual case study.,https://doi.org/10.1016/0094-4548(81)90004-7,https://www.sciencedirect.com/science/article/pii/0094454881900047,,,,1981,Transient swelling of liquid level during pool boiling in an emergency condenser,K.P. Singh and J.P. Gupta,article,SINGH198125,Letters in Heat and Mass Transfer,1,8,0094-4548,,,
,,115-124,,"A short-duration high-tooth-load test on case-hardened spur gears was run on an experimental gear rig with a view to comparing the performance of various condition monitoring techniques. The condition monitoring techniques used all relied on the detection of wear debris in the oil and included atomic absorption spectrometry, X-ray fluorescence, particle counting and ferrography. They all proved to be successful in signalling accelerated wear after 100 h of operation. Examination of the gears at the termination of the test indicated that the gears had worn by a combination of surface plastic deformation and pitting.",https://doi.org/10.1016/0043-1648(83)90317-4,https://www.sciencedirect.com/science/article/pii/0043164883903174,,,,1983,The condition monitoring of heavily loaded spur gears,M.L. Atkin and E.D. Doyle,article,ATKIN1983115,Wear,1,88,0043-1648,,,
,,213-225,,"The effect of ship motion, such as heaving and rolling, on the thermal-hydraulic behavior of marine reactors was investigated. The COBRA-IV-I CODE was modified to analyse the thermal-hydraulic performance on the critical heat flux under oscillating acceleration conditions. The critical heat flux in the code was verified experimentally using freon as a comparison. The Critical Heat Flux Ratio (CHFR) at the hottest channel of the PWR subchannel was analysed using the same code. A system code RETRAN-02/MOD2-GRAV was developed by improving RETRAN-02/MOD2 to simulate the thermal hydraulic transient under ship motion. It was verified by comparison using the experimental results of both two-phase natural circulation flow under heaving motion and single-phase natural circulation flow at an inclined attitude. The code was used to analyse reactor plant behavior in the nuclear ship Mutsu. Natural circulation flow during rolling motion was investigated experimentally. The characteristics of loop flow and core flow rates were clarified. The core flow rate correlated well with the Reynolds number of rolling motion.",https://doi.org/10.1016/0029-5493(90)90374-7,https://www.sciencedirect.com/science/article/pii/0029549390903747,,,,1990,Thermal-hydraulic behavior of a marine reactor during oscillations,I. Ishida and T. Kusunoki and H. Murata and T. Yokomura and M. Kobayashi and H. Nariai,article,ISHIDA1990213,Nuclear Engineering and Design,2,120,0029-5493,,,
,,137-140,,,https://doi.org/10.1016/0167-7799(88)90082-0,https://www.sciencedirect.com/science/article/pii/0167779988900820,,,,1988,Does the spontaneous adhesion of cultured plant cells to polymer surfaces have potential as an immobilization technique?,Frank Dicosmo and Peter J. Facchini and A.Wilhelm Neumann,article,DICOSMO1988137,Trends in Biotechnology,7,6,0167-7799,,,
,,211-214,,,https://doi.org/10.1016/0144-8617(94)90206-2,https://www.sciencedirect.com/science/article/pii/0144861794902062,,,,1994,Bibliography of carbohydrate polymers,,article,1994211,Carbohydrate Polymers,3,25,0144-8617,,,
,,217-233,,"Dorinnotheca streelii Fairon-Demaret, gen. et sp. nov. is described from three upper Famennian localities in Belgium. This new early seed plant bears cupules hanging singly at the tips of the slender ultimate axes of a pinnately branched system. Each cupule encloses a single, centrally located preovule with four free integumentary lobes. At the base of the fertile unit, the cupule segments are fused for a quarter of their total length; higher up they are free, recurved and highly dissected. The integumentary lobes appear joined to the fused part of the cupule segments. The preovule is sessile; at the apex, the nucellus shows a long, tubular, salpinx-like extension. This distinctive type of organisation is discussed in relation to the other Late Devonian preovulate structures from which it appears different.",https://doi.org/10.1016/0034-6667(95)00127-1,https://www.sciencedirect.com/science/article/pii/0034666795001271,,,,1996,"Dorinnotheca streelii Fairon-Demaret, gen. et sp. nov., a new early seed plant from the upper Famennian of Belgium",Muriel Fairon-Demaret,article,FAIRONDEMARET1996217,Review of Palaeobotany and Palynology,1,93,0034-6667,Maurice Streel,,
,,293-297,,,https://doi.org/10.1016/S0007-1536(64)80066-8,https://www.sciencedirect.com/science/article/pii/S0007153664800668,,,,1964,British records,,article,1964293,Transactions of the British Mycological Society,2,47,0007-1536,,,
,,141-152,,"A key for defining three developmental and five phenological stages of the sunflower has been developed and used in the study of development rate in twenty crops spanning a range of environments across northern New South Wales, Australia. Three heat sum models using different statistical methods for deriving base temperatures were tested. The base temperatures varied widely depending both on the development stage of the crop and on the statistical method of derivation. The base temperature models were found to be no more accurate for predicting development than a simple heat sum model. In general the most accurate method for predicting development was found to be a multiple regression model. This model incorporated temperature soil moisture and daylength effects during the vegetative growth stage, and temperature and soil moisture effects during the reproductive and maturation stages of growth. A test of this model against an independent set of seven crops from two widely contrasting environments confirmed the generality of this type of model for sunflower.",https://doi.org/10.1016/0378-4290(78)90017-5,https://www.sciencedirect.com/science/article/pii/0378429078900175,,,,1978,A systems approach to the adaptation of sunflower to new environments I. Phenology and development,W.K. Anderson and R.C.G. Smith and J.R. McWilliam,article,ANDERSON1978141,Field Crops Research,,1,0378-4290,,,
,"Collaborative intrusion prevention, Collaborative intrusion detection system (CIDS), Large-scale distributed attacks, Programmable network, Software-defined networks (SDN)",1-19,,"Coordinated intrusion, like DDoS, Worm outbreak and Botnet, is a major threat to network security nowadays and will continue to be a threat in the future. To ensure the Internet security, effective detection and mitigation for such attacks are indispensable. In this paper, we propose a novel collaborative intrusion prevention architecture, i.e. CIPA, aiming at confronting such coordinated intrusion behavior. CIPA is deployed as a virtual network of an artificial neural net over the substrate of networks. Taking advantage of the parallel and simple mathematical manipulation of neurons in a neural net, CIPA can disperse its lightweight computation power to the programmable switches of the substrate. Each programmable switch virtualizes one to several neurons. The whole neural net functions like an integrated IDS/IPS. This allows CIPA to detect distributed attacks on a global view. Meanwhile, it does not require high communication and computation overhead. It is scalable and robust. To validate CIPA, we have realized a prototype on Software-Defined Networks. We also conducted simulations and experiments. The results demonstrate that CIPA is effective.",https://doi.org/10.1016/j.cose.2015.11.008,https://www.sciencedirect.com/science/article/pii/S0167404815001856,,,,2016,CIPA: A collaborative intrusion prevention architecture for programmable network and SDN,Xiao-Fan Chen and Shun-Zheng Yu,article,CHEN20161,Computers & Security,,58,0167-4048,,,
,,11-16,,,https://doi.org/10.1078/143446103764928459,https://www.sciencedirect.com/science/article/pii/S1434461004701224,,,,2003,"Meeting Report: Xth International Conference on Harmful Algae, St. Pete Beach, Florida, October 21–25, 2002",Karen A. Steidinger,article,STEIDINGER200311,Protist,1,154,1434-4610,,,
,"Flexible manufacturing systems, Scheduling algorithms, Assembly robots, Discrete-event dynamic systems, Predictive control, Intelligent manufacturing systems, Agile manufacturing",194-199,,"Future production plants will see more and more the presence of humans actively collaborating with robots. Typical scenarios are those related to assembly lines. In such contexts the behaviour of humans is not controllable. Therefore the problem is to produce a scheduling for robotic activities accounting for the predicted human intentions. In this work we propose a scheduling strategy based on Time Petri Nets. The sequence of commands scheduled for the robot are executed exploiting the receding horizon principle. The developed approach is applied on a realistic use-case, in which one human operator and a dual-arm robot actively collaborate to perform the assembly of a real product.",https://doi.org/10.1016/j.ifacol.2018.08.257,https://www.sciencedirect.com/science/article/pii/S2405896318313818,,,,2018,Human-robot collaborative assembly: a use-case application,Andrea Casalino and Filippo Cividini and Andrea Maria Zanchettin and Luigi Piroddi and Paolo Rocco,article,CASALINO2018194,IFAC-PapersOnLine,11,51,2405-8963,16th IFAC Symposium on Information Control Problems in Manufacturing INCOM 2018,,
,"prolactin receptor, properdin, litter size, pig",1374-1378,,"This study is aimed at using the DNA mutations in the prolactin receptor (PRLR) and properdin (BF) genes to determine associations between the genotype and litter size in the Beijing Black pig population. A total of 321 Beijing Black pig sows were genotyped using the polymerase chain reaction-restriction fragment length polymorphism (PCR-RFLP) method, with the Alu I and Sma I for PRLR and BF genes, respectively. Two different alleles of PRLR and BF genes were identified: allele A (0.25) and B (0.75) of the PRLR gene, allele A (0.13) and B (0.86) of the BF gene. The association analysis between the genotypes and the litter size were estimated with the method of the general linear model. The analysis results of PRLR showed that in first parity, sows with genotype AA had a larger litter size than sows with genotype AB and BB, but the difference was statistically not significant. In later parities, statistically significant (P < 0.05) differences were seen between sows with genotypes AA and AB, and BB of the PRLR gene. The associated analysis results between genotypes and litter size (total number born, TNB, and number born alive, NBA) showed that there were no significant differences in the first parity sows with different genotypes of the BF gene, but significant differences appeared in NBA between the sows of genotypes AB and BB, in later parity, for which significantly higher values were observed in the offspring of heterozygotes. Considering the consistent genotypic effect on the litter size of both sows in first parity and later parity, it was concluded that the locus of the PRLR gene, digested with Alu I, could be the gene maker for the litter size in Beijing Black pigs.",https://doi.org/10.1016/S1671-2927(08)60187-X,https://www.sciencedirect.com/science/article/pii/S167129270860187X,,,,2008,Analysis of PRLR and BF Genotypes Associated with Litter Size in Beijing Black Pig Population,WANG Xing-ping and WANG Li-xian and LUO RENG Zhuo-ma and SUN Shi-duo,article,XINGPING20081374,Agricultural Sciences in China,11,7,1671-2927,,,
,,91-101,,"The Chilga lacustrine deposit from a small graben in the heart of the Northwestern Ethiopian Highlands (37°E, 12°N) is one of the ubiquitous intertrappean continental sedimentations on the Plateau. The basalt layer which makes the bottom of the basin has been dated as 8 Ma. The lacustrine sedimentation occurred contemporaneously with active volcanic phases in the region. Silicic aggregates are common in the cements and as important mineralogic constitutents of these phases whereas periods of calm sedimentation are characterized by thick lignite seams and the presence of authigenic minerals such as pyrite and vivianite. The sequence shows a general upward fining and evolution from shallow fluviatile to reduced lacustrine basin. The palynoflora from the sequence has a unique palaeofloral assemblage where the abundance of Guineo-Congolian-like pollen taxa, pteridophytes and absence of conifers imply a regional palaeoaltitude much lower than at present. The uplift of the Plateau at a rate of 0.1 mm yr−1 similarly suggests palaeotitudes of ca 900–1000 m.",https://doi.org/10.1016/0899-5362(87)90110-2,https://www.sciencedirect.com/science/article/pii/0899536287901102,,,,1987,"Limnogeologic studies on an intertrappean continental deposit from the northern Ethiopian Plateau (37°03′E, 12°25′N)",Kedamawit Yemane and Maurice Taieb and Hugues Faure,article,YEMANE198791,Journal of African Earth Sciences (1983),1,6,0731-7247,,,
,,251-253,,,https://doi.org/10.1016/0306-4492(81)90026-5,https://www.sciencedirect.com/science/article/pii/0306449281900265,,,,1981,Effects of hormones on the RNA-synthesis of Tetrahymena pyriformis,G. Csaba and L. Ubornyák,article,CSABA1981251,Comparative Biochemistry and Physiology Part C: Comparative Pharmacology,2,68,0306-4492,,,
,"BelB, BelW3, chlorophyll fluorescence, gas exchange, quenching analysis, stomatal conductance",845-853,,"Summary
The present paper reports on the characterisation of the photosynthetic responses to a single pulse of ozone (150 ppb for 5 hours) in the leaves of two tobacco cultivars displaying different degrees of sensitivity to O3 (BelB, O3-resistant and BelW3, O3-sensitive). In the BelW3 cultivars, O3 induced a decrease in the photosynthetic rate, but not in actual PSII efficiency at steady-state photosynthesis. The reduction state of QA did not change in these plants while a strong decrease in intrinsic PSII efficiency was observed. The quantum yield for photosynthetic CO2 assimilation decreased more than the actual PSII efficiency, suggesting the presence of a significant fraction of electron transport to molecular oxygen or the existence of some form of cyclic electron flow. O3-treated leaves reduced the excess of absorbed light (i.e. light that couldn't be used in photosynthesis) by dissipating a large part of the light absorbed by the PSII antenna as heath. In BelB, the CO2 assimilation rate did not change in the presence of the pollutant O3 and the only gas exchange parameter that changed was the stomatal conductance, which significantly increased. Some of the Chl fluorescence parameters changed after O3 fumigation, but returned to values similar to the controls when measured 24 hours after removing the stress. The only Chl fluorescence parameter that significantly increased during the recovery phase was the 1-qP",https://doi.org/10.1078/0176-1617-00519,https://www.sciencedirect.com/science/article/pii/S0176161704702990,,,,2002,Characterisation of the photosynthetic response of tobacco leaves to ozone: CO2 assimilation and chlorophyll fluorescence,Elena Degl'Innocenti and Lucia Guidi and Gian Franco Soldatini,article,DEGLINNOCENTI2002845,Journal of Plant Physiology,8,159,0176-1617,,,
,,323-329,,"The adsorption isotherm for porcine fibrinogen on silicone rubber is reported for fibrinogen adsorbing from a physiological buffer. The isotherm is found to have two plateaus as a function of solution concentration. The activity of fibrinogen adsorbed at different surface concentrations in promoting platelet adhesion is investigated by preadsorbing fibrinogen on the surface of the biomaterial and subsequently exposing it to fresh porcine blood, without any exposure to air. It is found that platelet adhesion increases with increasing concentration of preadsorbed fibrinogen until the surface concentration exceeds that in the first plateau. Higher surface concentrations of preadsorbed fibrinogen do not promote further platelet adhesion. This would indicate that the fibrinogen preadsorbed in the first plateau is conformationally changed sufficiently to promote platelet adhesion, but that in the second plateau is apparently not changed to the same extent.",https://doi.org/10.1016/0021-9797(86)90418-2,https://www.sciencedirect.com/science/article/pii/0021979786904182,,,,1986,Biological activity of fibrinogen adsorbed on synthetic materials,C.A Ward and D Stanga,article,WARD1986323,Journal of Colloid and Interface Science,2,114,0021-9797,,,
,"Tilia cordata Mill., Trunk wood, Lipase activity, Radial distribution",252-259,,"Summary
Milled sawdust of the trunkwood of Tilia cordataMill., exhibits lipolytic activity when incubated with emulsified olive oil. The lipase of the peripheral trunk zone shows optimal activity at a pH of 7.5 and between 37–45 °C. The lipase is neither inhibited nor activited by sodiumdesoxycholate. Lipase activity decreases towards the centre of the trunk. Washing the peripheral wood particles with water prior to incubation results in an increased lipolytic activity. The inhibtor extracted appears to be largely water insoluble in the older wood zones. In the water extracts, only traces of lipase activity are measurable. Most of the lipase seems to be tightly associated with the woody cell walls. The acidic value of the lipids extracted from the different radial wood zones suggests that only the peripheral trunkwood tissue exhibits high lipase activity.",https://doi.org/10.1016/S0044-328X(75)80021-3,https://www.sciencedirect.com/science/article/pii/S0044328X75800213,,,,1975,Lipase Activity in the Trunkwood of Tilia cor dataMill.,W. Höll,article,HOLL1975252,Zeitschrift für Pflanzenphysiologie,3,76,0044-328X,,,
,,269-277,,"Segregation of powder particles by tapping or vibration is a phenomenon caused by a sifting of fines toward the bottom of a container, and has been reported in the literature for systems with particle diameters in the range of 0.2 to 12 mm. Extrapolation of this effect to micrometer-sized particle systems, with and without the presence of agglomerates, was undertaken. The particle-size distribution were measured by instruments appropriate to each powder system. Five powders, with four different absolute densities (2.8 – 19.3 g/cm3) and with FSSS numbers from 0.9 to 8.0 were sudied. Jostling of powders in containers during transportation was simulated by controlled tapping of the powders in a demountable cylinder. Segregation did take place when a wide distribution was present, unless masked by the break-up of afflomerates and consequent generation of fines during tapping.",https://doi.org/10.1016/0032-5910(76)85013-9,https://www.sciencedirect.com/science/article/pii/0032591076850139,,,,1976,Particle segregation in fine powders by tapping as simulation of jostling during transportation,D.S. Parsons,article,PARSONS1976269,Powder Technology,2,13,0032-5910,,,
,"Leaf anatomy, Oxygen evolution, Photoacoustic(s), Photocalorimetry, Photosynthesis, Photosystem II, Structure—function",158-165,,"A photoacoustic instrument has been developed to measure photothermal signals and oxygen evolution at the microscopic level within leaves and leaf cross sections. The device utilizes lines of light, obtained from laser diodes, that are focussed on the sample and permit measurements with a spatial resolution of 40 μm. In cross sections of spinach leaves (700 μm thick) the profile for the photothermal signals is bell shaped and coincides closely with the chlorophyll content of the tissues. By contrast, the profile for oxygen evolution is relatively flat, suggesting uniform capacity for oxygen evolution in the mesophyll. Maximum values for relative quantum yield for oxygen evolution are found in palisade tissues near the adaxial leaf surface. The photoacoustic device shows that it is possible to collect thermal and oxygen signals from microscopic leaf samples and opens a new avenue for studies of leaf structure—function.",https://doi.org/10.1016/S1011-1344(99)00042-1,https://www.sciencedirect.com/science/article/pii/S1011134499000421,,,,1999,A photoacoustic spectrometer for measuring heat dissipation and oxygen quantum yield at the microscopic level within leaf tissues,Tao Han and Thomas C. Vogelmann,article,HAN1999158,Journal of Photochemistry and Photobiology B: Biology,2,48,1011-1344,,,
,,427-434,,,https://doi.org/10.1016/S0014-4894(56)80002-7,https://www.sciencedirect.com/science/article/pii/S0014489456800027,,,,1956,Permanently inserted plastic cannula for direct access to cecal contents of rats,Wesley J. Peterson,article,PETERSON1956427,Experimental Parasitology,5,5,0014-4894,,,
,"beta-mimetic, clenbuterol, fetal heart rate, maternal heart rate, maternal blood pressure, fetal breathing movements, fetal trunk movements, maternal blood glucose level",67-74,,"The effect of the beta-mimetic compound clenbuterol on maternal and fetal behavior was studied in 12 normal primigravidae between 35 and 38 wk of gestation. None of the subjects exhibited any signs of uterine activity. Following a control period of 60 min, oral intake of 100 μg of clenbuterol resulted in a maximum increase in maternal and fetal heart rate of 13 and 7%, respectively. Maternal systolic blood pressure showed a rise of 6%, whereas diastolic blood pressure demonstrated a drop of 8%. The percentage incidence of fetal breathing and trunk movements did not show any significant change following oral clenbuterol administration, indicating the absence of any major effect of this drug on the fetal central nervous system. Maternal blood glucose levels demonstrated a fairly constant pattern during the entire study period.",https://doi.org/10.1016/0028-2243(82)90002-8,https://www.sciencedirect.com/science/article/pii/0028224382900028,,,,1982,The effect of the beta-mimetic drug clenbuterol on maternal and fetal behavior,J.W. Wladimiroff and P.J. Roodenburg,article,WLADIMIROFF198267,European Journal of Obstetrics & Gynecology and Reproductive Biology,2,13,0301-2115,,,
,,237-242,,,https://doi.org/10.1016/0146-6410(85)90009-2,https://www.sciencedirect.com/science/article/pii/0146641085900092,,,,1985,Status report: electro-nuclear physics at NBS,Samuel Penner,article,PENNER1985237,Progress in Particle and Nuclear Physics,,13,0146-6410,,,
,"Security, Trustworthy computing, Identity and access management, Patents, Innovation, Vulnerabilities, Attacks",49-67,,"As the use of networked computers and digital data increase, so have the reports of data compromise and malicious cyber-attacks. Increased use and reliance on technologies complicate the process of providing information security. This expanding complexity in supplying data security requirements coupled with the increased recognition of the value of information, have led to the need to quickly advance the information security area. In this paper, we examine the maturation of the information security area by analyzing the innovation activity of one of the largest and most ubiquitous information technology companies, Microsoft. We conduct a textual analysis of their patent application activity in the information security domain since the early 2000's using a novel text analysis approach based on concepts from social network analysis and algorithmic classification. We map our analysis to focal areas in information security and examine it against Microsoft's own history, in order to determine the depth and breadth of Microsoft's innovations. Our analysis shows the relevance of using a network-based text analysis. Specifically, we find that Microsoft has increasingly emphasized topics that fall into the identity and access management area. We also show that Microsoft's innovations in information security showed tremendous growth after their Trustworthy Computing Initiative was announced. In addition, we are able to determine areas of focus that correspond to Microsoft's major vulnerabilities. These findings indicate that while Microsoft is still actively, albeit not always successfully, fighting vulnerabilities in their products, they are quite vigorously and broadly innovating in the information security area.",https://doi.org/10.1016/j.cose.2013.02.004,https://www.sciencedirect.com/science/article/pii/S0167404813000333,,,,2013,Using network-based text analysis to analyze trends in Microsoft's security innovations,Tabitha L. James and Lara Khansa and Deborah F. Cook and Olga Bruyaka and Kellie B. Keeling,article,JAMES201349,Computers & Security,,36,0167-4048,,,
,,3-30,A Study of Performance Measurement in the Outsourcing Decision,"Publisher Summary
This chapter identifies the limitations of the existing outsourcing literature and practices. This also outlines the requirements for an outsourcing framework. A clear appreciation of the objectives and risks of outsourcing is an essential pre-condition to the formation of suitable outsourcing performance measurements. According to a survey in 2006, the global business process outsourcing market was worth $48.4 billion for the first three quarters of 2006, representing a rise of 34% from the same period in 2005. Outsourcing can be employed to achieve performance improvements in cost, quality, service, and time-to-market. Examples of business services include computer services, professional services (legal, accountancy, market research, technical, engineering, advertising, human resources and consultancy), research and development (R&D), recruitment agencies and call centers. Between 1984 and 2001, the growth in the business services sector accounted for around one-third of the total output growth in the UK economy. A comprehensive survey of outsourcing in 2003 in the European banking industry by McKinsey, in collaboration with IBM and the EFMA, found that 44% of banks considered efficiency gains as the primary or even sole outsourcing objective. However, failure to place outsourcing within a strategic context will lead to a piecemeal approach based solely on attempts to reduce costs. Thus, a new focus on quality and customer relationships necessitates changes in policies, cultural values, work procedures and processes, relationship between departments and interactions between buyers and suppliers.",https://doi.org/10.1016/B978-1-85617-680-4.00002-7,https://www.sciencedirect.com/science/article/pii/B9781856176804000027,Oxford,CIMA Publishing,978-1-85617-680-4,2009,Chapter 2 - Literature Review,R. McIvor and P.K. Humphreys and A.P. Wall and A. McKittrick,incollection,MCIVOR20093,,,,,,R. McIvor and P.K. Humphreys and A.P. Wall and A. McKittrick,
,"battery aging management, electric vehicles, optimization",14199-14204,,"In this work, a closed-loop battery aging management strategy for electric vehicles is proposed. The aging management strategy, following the model predictive control rationale, optimizes aging and vehicle performance online. The proposed formulation is based on a closed-loop term which aims at tracking a user defined aging profile. A thorough simulation study validates the approach and verifies its robustness against model uncertainties and anomalous aging phenomena.",https://doi.org/10.1016/j.ifacol.2020.12.1051,https://www.sciencedirect.com/science/article/pii/S240589632031421X,,,,2020,Closed-loop Battery Aging Management for Electric Vehicles,Gabriele Pozzato and Matteo Corno,article,POZZATO202014199,IFAC-PapersOnLine,2,53,2405-8963,21st IFAC World Congress,,
,"Ascidiacea, Defense association, Epibacterial diversity, Epibiosis, Epibiotic bacteria",239-255,,"Interactions between epibiotic bacteria and organisms possibly play a central role in marine ecology. Despite its potential significance, this field has long time been neglected. For most aquatic taxa nothing is known about presence/absence of bacteria on their surface, much less about specific associations or potential interactions between epibiotically associated micro- and macroorganisms. Bahamian and Pacific ascidians, most of them colonial, were screened for the presence, abundance and diversity of epibiotic bacteria and macroepibionts. Only one species, Polyclinum planum, occasionally carried macroepibionts. All ascidian species exhibited varying densities of epibiotic bacteria on their surfaces. Average epibacterial abundance as assessed by plate counts on the 29 species ranged from 60 to 1.2 × 107/cm2. Significant differences in bacterial abundances were observed between species, families and geographical regions. On the family level, Polyclinidae were the most densely colonized. Bahamian species exhibited less dense epibacterial communities than Pacific species, a difference that may partly be caused by the absence of the heavily fouled Polyclinidae from the Bahamian collection. Diversity of culturable strains, evaluated for the Bahamian species only, was uniformly high on most species. I did not find any evidence for specific associations (as reflected by dominance of single strains) between culturable bacteria and ascidian species. Contrarily, direct observation by epifluorescence revealed the presence of an apparently dominant photosynthetic symbiont on several didemnid species. The presence of this symbiont correlated negatively with abundance and diversity of culturable epibionts. This negative correlation could reflect properties of the host's surface which selectively favor proliferation of the symbiont or antagonistic interactions between the symbionts and other potential bacterial colonizers.",https://doi.org/10.1016/0022-0981(95)00018-M,https://www.sciencedirect.com/science/article/pii/002209819500018M,,,,1995,Bacterial epibiosis on Bahamian and Pacific ascidians,Martin Wahl,article,WAHL1995239,Journal of Experimental Marine Biology and Ecology,2,191,0022-0981,,,
,"Trusted Cloud Computing, IaaS, vTPM, vDRTM, Remote Attestation, Trusted Virtual Domain",196-226,,"Cloud computing is no longer the future but the present. Security and trust are critical in cloud computing, but how can cloud service tenants trust cloud service providers to store all their private data on the cloud? Trusted computing is one of the new technologies in the last decade, and the integration between cloud computing and trusted computing can create a new architecture for infrastructure as a service that motivates more cloud service tenants to trust cloud service providers. This paper provides a survey and systematic literature review on the suggested architectures for this integration.",https://doi.org/10.1016/j.cose.2018.12.014,https://www.sciencedirect.com/science/article/pii/S0167404818302712,,,,2019,Trusted Cloud Computing Architectures for infrastructure as a service: Survey and systematic literature review,Fady {A. M. Ibrahim} and Elsayed E. Hemayed,article,AMIBRAHIM2019196,Computers & Security,,82,0167-4048,,,
,,1-45,Juniper® Networks Secure Access SSL VPN Configuration Guide,"Publisher Summary
This chapter discusses various aspects of firewall. A firewall is a chokepoint from one network to another network. Firewalls are also being used to create chokepoints between other networks in an enterprise environment. Various information security studies and surveys have found that the majority of attacks come from inside an organization. Hackers attempt to discover systems and gather information. In most cases, these attacks are used to gather information to set up an access or a Denial of Service (DOS) attack. Phishing, the new information gathering technique, is spreading and becoming increasingly sophisticated. Phishing e-mails either ask the victim to fill out a form or directs them to a Web page designed to look like a legitimate banking site. Application proxy firewalls are written to the specifications of the particular applications, and the selection of a particular application proxy is mostly determined by the type of application server being protected. Fine control of application proxies is lost in favor of better performance. It is suggested that stateful inspection gateways can be used internally to further protect subnets, and filter the information coming in from the Internet.",https://doi.org/10.1016/B978-159749200-3.00001-X,https://www.sciencedirect.com/science/article/pii/B978159749200300001X,Burlington,Syngress,978-1-59749-200-3,2007,Chapter 1 - Defining a Firewall,Rob Cameron and Neil R. Wyler,incollection,CAMERON20071,,,,,,Rob Cameron and Neil R. Wyler,
,"Cholinergic-dopaminergic interaction, Apomorphine, Striatum, rat, HA-966, DA feedback mechanism",245-250,,"The blocking effect of apomorphine on the rise in striatal dopamine (DA) content, induced by 1-hydroxy-3-amino-pyrrolidone-2 (HA-966) was taken as a measure for the intrastriatal feedback inhibition of DA synthesis. The effects of cholinergic drugs on this feedback system were assessed in order to verify the hypothesis that this mechanism is mediated via an intrastriatal cholinergic link. We presumed that DA receptors were located on a cholinergic neuron, while the cholinergic terminals in turn made direct or indirect axon-axonal contact with the dopaminergic nigro-striatal pathway (N.S.P.). Although cholinergic agents could modify the effect of HA-966 on striatal DA content, it proved to be impossible to counteract the blocking effect of apomorphine with cholinergic drugs as was to be expected. Therefore we concluded that the effect of apomorphine was not brought about in the way which had been postulated.",https://doi.org/10.1016/0014-2999(76)90132-1,https://www.sciencedirect.com/science/article/pii/0014299976901321,,,,1976,Absence of a ‘cholinergic link’ in the apomorphine-induced feedback inhibition of dopamine synthesis in rat striatum,Barbara J. {Van Zwieten-Boot} and Annelies Petri-Bot,article,VANZWIETENBOOT1976245,European Journal of Pharmacology,2,39,0014-2999,,,
,"Osmium, Iron",183-188,,"Reaction of (μ-H)Os3(CO)10(μ-COMe) with 1,1'-bis(diphenylphosphino)-ferrocene (dppf) produces (μ-H)Os3(CO)8(μ-COMe){μ-η2-(η5-C5H4PPh2)2Fe} (1) and (μ-H)2Os3(CO)7(μ-COMe){μ-η3-(η5-C5H3PPh2)Fe(η5-C5H4PPh2)} (2). Thermolysis of 1 leads quantitatively to 2. These compounds have been characterized by 1H, 31P, and 13C NMR, IR, and mass spectroscopies. Compound 2 crystallizes in space group P 21/c with a = 11.898(2), b = 21.266(3), c = 18.262(3) Å, β = 104.71(1)°, V = 4469(1) Å3, Z = 4, and RF = 0.029.",https://doi.org/10.1016/0022-328X(94)85024-0,https://www.sciencedirect.com/science/article/pii/0022328X94850240,,,,1994,"Ligand substitution reaction of (μ-H)Os3(CO)10(μ-COMe) with 1,1'-bis(diphenylphosphino) ferrocene",Wen-Yann Yeh and Sun-Bin Chen and Shie-Ming Peng and Gene-Hsiang Lee,article,YEH1994183,Journal of Organometallic Chemistry,2,481,0022-328X,,,
,,131-140,,"The chromatographic behavior of 48 alkaloids has been studied on Bio-Rad AG 1-X4, Cellex D and microcyrstalline cellulose, eluting with solutions of different pH but constant ionic strength (0.5). Many interesting separations were effected on both AG 1-X4 and Cellex D layers. The influence of pH on the chromatographic behaviour of alkaloids has been quantitatively studied and an equation was used that expresses the behaviour of the alkaloids on both AG 1-X4 (AcOt-) and microcrystalline cellulose layers. The non-applicability of this equation to Cellex D layers is discussed.",https://doi.org/10.1016/S0021-9673(00)83708-5,https://www.sciencedirect.com/science/article/pii/S0021967300837085,,,,1976,Chromatographic behaviour of alkaloids on thin layers of anion and cation exchangers: I. AG 1-X4 and Cellex D,L. Lepri and P.G. Desideri and M. Lepori,article,LEPRI1976131,Journal of Chromatography A,1,116,0021-9673,,,
,,263-275,,"The vegetational history of the south-central Mediterranean clearly reflects the major global climatic changes of the last four million years. A Mediterranean-type climate, characterized by strong seasonality and a dry summer, may have existed in this region during the early Pliocene. A short-term climatic cooling at approximately 3.2 Ma resulted in the temporary establishment of a humidity-demanding flora; the onset of major Northern Hemisphere glaciation at approximately 2.4 Ma initiated an alternation between humid (glacial) and dry (interglacial) conditions. Vegetational differences between this region and the north-west Mediterranean indicate that distinct latitudinal climatic gradients probably existed in the Mediterranean during the Pliocene-early Pleistocene.",https://doi.org/10.1016/0031-0182(89)90146-6,https://www.sciencedirect.com/science/article/pii/0031018289901466,,,,1989,Pliocene-pleistocene vegetational and climatic evolution of the south-central mediterranean,Remo Bertoldi and Domenico Rio and Robert Thunell,article,BERTOLDI1989263,"Palaeogeography, Palaeoclimatology, Palaeoecology",,72,0031-0182,XIIth INQUA Congress,,
Developments in Plant Genetics and Breeding,,433-448,"Chromosome Engineering in Plants: Genetics, Breeding, Evolution, Part A",,https://doi.org/10.1016/B978-0-444-88259-2.50025-4,https://www.sciencedirect.com/science/article/pii/B9780444882592500254,,Elsevier,,1991,21 - Intergeneric Hybrids involving the Genus Hordeum,GEORGE FEDAK,incollection,FEDAK1991433,,,2,0168-7972,,P.K. Gupta and T. Tsuchiya,
,,470-478,,"The involvement of pulsatile chemoattractant emission and signal relay in aggregation and multicellular morphogenesis of a variety of cellular slime mold species was investigated. The species differ from each other in the developmental stage when pulsatile signaling first becomes evident. In D. discoideum, D. mucoroides, and D. purpureum pulsatile signal emission starts in the preaggregative field. In D. vinaceo-fuscum, D. mexicanum, P. violaceum, and P. pallidum the aggregation centers shifts from continuous to pulsatile secretion of chemoattractant during the aggregation process. In D. minutum pulsatile signaling starts after the completion of aggregation and slightly before the onset of culmination. Tip formation is a consequence of continued attraction of amoebae inside the aggregate to the center of signal emission. The occurrence of pulsatile signaling at an early stage of development is correlated with the capacity of the tip (signaling center) to organize a relatively large number of cells into a single fruiting body. Several lines of evidence suggest that cAMP is probably involved in the coordination of morphogenetic movement in the multicellular stage of all investigated species.",https://doi.org/10.1016/0012-1606(84)90304-X,https://www.sciencedirect.com/science/article/pii/001216068490304X,,,,1984,The possible involvement of oscillatory cAMP signaling in multicellular morphogenesis of the cellular slime molds,Pauline Schaap and Mei Wang,article,SCHAAP1984470,Developmental Biology,2,105,0012-1606,,,
,,227-243,,,https://doi.org/10.1016/0144-8617(88)90005-7,https://www.sciencedirect.com/science/article/pii/0144861788900057,,,,1988,Bibliography on carbohydrate polymers,,article,1988227,Carbohydrate Polymers,3,8,0144-8617,,,
,,233-255,,"Ultrastructural and genetic investigations involving diverse species of plants have demonstrated that plastids may be transmitted either biparentally or maternally during sexual reproduction. In species in which plastid transmission is maternal, elimination of plastids from the paternal parent may occur in a number of ways: exclusion from the male gamete during spermatogenesis, loss from the motile sperm, exclusion during fertilization, or degradation within the zygote. These diverse ways in which maternal inheritance of plastids is achieved suggest that this inheritance pattern may have evolved independently many times in response to different selective pressures in different phyletic lineages.",https://doi.org/10.1016/0147-619X(80)90063-3,https://www.sciencedirect.com/science/article/pii/0147619X80900633,,,,1980,Elimination of plastids during spermatogenesis and fertilization in the plant kingdom,Barbara B. Sears,article,SEARS1980233,Plasmid,3,4,0147-619X,,,
,,233-238,,"Information System Planning (ISP) is a structured approach developed by IBM to assist organizations in establishing a plan to satisfy their short and long term information requirements. The ISP methodology was implemented at Tel-Aviv University. A comprehensive plan for the development of a Management Information System (MIS) was derived. This paper presents a review of the process by which the plan was obtained, a discussion of the methodology, and its ramifications.",https://doi.org/10.1016/0378-7206(81)90030-6,https://www.sciencedirect.com/science/article/pii/0378720681900306,,,,1981,Information System Planning: A case review,S. Gill,article,GILL1981233,Information & Management,5,4,0378-7206,,,
,,209-300,Handbook of Digital Forensics and Investigation,"Publisher Summary
This chapter provides technical methods and techniques to help practitioners extract and interpret data of investigative value from computers running Windows operating systems. An important aspect of conducting advanced forensic analysis is understanding the mechanisms underlying fundamental operations on Windows systems such as the boot process, file creation and deletion, and use of removable storage media. By understanding how to aggregate and correlate data on Windows systems, digital investigators are better able to get the “big picture” (such as an overall theory of user action and a timeline), as well as overcoming specific technical obstacles. It is not surprising that the majority of systems that digital investigators are called upon to examine run a Windows operating system. Whether investigating child pornography, intellectual property theft, or Internet Relay Chat (IRC) bot infection, it is a safe bet that knowledge of Windows operating systems, and its associated artifacts, will aid investigators in their task. It is important for forensic examiners to understand the Windows startup process for a number of reasons beyond simply interrupting the boot process to view and document the CMOS configuration. Ever since examiners figured out that there might be more to a file than meets the eye, they have been interested in Metadata, the information that describes or places data in context, without being part of the data that is the primary focus of the user. There are two types of metadata: file system metadata and application (or file) metadata.",https://doi.org/10.1016/B978-0-12-374267-4.00005-7,https://www.sciencedirect.com/science/article/pii/B9780123742674000057,San Diego,Academic Press,978-0-12-374267-4,2010,Chapter 5 - Windows Forensic Analysis,Ryan D. Pittman and Dave Shaver,incollection,PITTMAN2010209,,,,,,Eoghan Casey and Cory Altheide and Christopher Daywalt and Andrea {de Donno} and Dario Forte and James O. Holley and Andy Johnston and Ronald {van der Knijff} and Anthony Kokocinski and Paul H. Luehr and Terrance Maguire and Ryan D. Pittman and Curtis W. Rose and Joseph J. Schwerha and Dave Shaver and Jessica Reust Smith,
,"Bug handling process, Rapid release cycle, Feature freeze, Continuous software development, Software maintenance, Empirical software engineering",110882,,"Large software projects follow a continuous development process with regular releases during which bugs are handled. In recent years, many software projects shifted to rapid releases that reduce time-to-market and claim a faster delivery of fixed issues, but also have a shorter period to address bugs. To better understand the impact of rapid releases on bug handling activity, we empirically analyze successive releases of the Eclipse Core projects, focusing on the bug handling rates and durations as well as the feature freeze period. We study the impact of Eclipse’s transition from a yearly to quarterly release cycle. We confirm our findings through feedback received from five Eclipse Core maintainers. Among others, our results reveal that Eclipse’s bug handling process is becoming more stable over time, with a decreasing number of reported bugs before releases, an increasing bug fixing rate and an increasingly balanced bug handling workload before and after releases. The transition to a quarterly release cycle continued to improve bug handling. In addition, more effort is spent on bug fixing during the feature freeze period, while the bug handling rates do not differ between both periods.",https://doi.org/10.1016/j.jss.2020.110882,https://www.sciencedirect.com/science/article/pii/S0164121220302727,,,,2021,On the impact of release policies on bug handling activity: A case study of Eclipse,Zeinab {Abou Khalil} and Eleni Constantinou and Tom Mens and Laurence Duchien,article,ABOUKHALIL2021110882,Journal of Systems and Software,,173,0164-1212,,,
Physiological Ecology,,139-167,Carbon Dioxide and Environmental Stress,"Publisher Summary
This chapter describes the global impact of salinity and the consequences of elevated CO2 on plant growth and soil salinity. The cellular and whole plant mechanisms by which salinity affects growth are described, with emphasis on the mechanism by which elevated CO2 might interact with salinity. Much of the saline land in the world has been caused by human activities: by clearing, overgrazing, or the installation of irrigation schemes. The result of these activities is termed “secondary salinization.” The long-term productivity of the global agricultural system as a whole is declining, as is ecosystem stability. Rising CO2 levels could increase the productivity of cultivated species and natural vegetation on saline soils, but it may also increase soil salinity. Elevated CO2 can increase the growth rate of crops, pastures, and trees, but because it also increases their water use efficiency, it may alter the soil-plant water balance in a way that has adverse consequences for land with saline groundwater, where any factor that causes the water table to rise will increase the rate of salinization of the topsoil.",https://doi.org/10.1016/B978-012460370-7/50006-1,https://www.sciencedirect.com/science/article/pii/B9780124603707500061,San Diego,Academic Press,978-0-12-460370-7,1999,"5 - Interactions between Rising CO2, Soil Salinity, and Plant Growth",Rana Munns and Grant R. Cramer and Marilyn C. Ball,incollection,MUNNS1999139,,,,,,Yiqi Luo and Harold A. Mooney,
,"Foetal anomalies, Zygotes, Methyl methanesulphonate, Dimethyl sulphate, Diethyl sulphate",439-446,,"Exposure of mouse zygotes to ethylene oxide (EtO) or ethyl methanesulfonate (EMS) led to high incidences of fetal death and of certain classes of fetal malformations (Generoso et al., 1987, 1988; Rutledge and Generoso, 1989). These effects were not associated with induced chromosomal aberrations (Katoh et al., 1989) nor are they likely to be caused by gene mutations (Generoso et al., 1990). Nevertheless, the anomalies observed in these studies resemble the large class of stillbirths and sporadic defects in humans that are of unknown etiology, such as cleft palate, omphalocoel, clubfoot, hydrops and stillbirths (Czeizel, 1985; Oakley, 1986). Therefore, we continue to study the possible mechanisms relating to induction of these types of zygote-derived anomalies in mice. Effects of zygote exposure to the compounds methyl methanesulfonate (MMS), dimethyl sulfate (DMS), and diethyl sulfate (DES), which have similar DNA-binding properties as EtO and EMS, were studied. DMS and DES, but not MMS, induced effects that are similar to those induced by EtO and EMS. Thus, no site-specific alkylation product was identifiable as the critical target for these zygote-derived anomalies. We speculate that the developmental anomalies arose as a result of altered programming of gene expression during embryogenesis.",https://doi.org/10.1016/0027-5107(91)90200-8,https://www.sciencedirect.com/science/article/pii/0027510791902008,,,,1991,Developmental response of zygotes exposed to similar mutagens,W.M. Generoso and A.G. Shourbaji and W.W. Piegorsch and J.B. Bishop,article,GENEROSO1991439,Mutation Research/Fundamental and Molecular Mechanisms of Mutagenesis,1,250,0027-5107,,,
,"Failure detection, process models, estimation, chemical industries, observers, discrete observation systems",145-150,,"Traditional process monitoring techniques are unable to utilize the delayed, infrequent, and sometimes uncertain information available in many complex industrial processes. This paper presents the trajectory encoding method for process monitoring that is specifically designed to handle this type of information. Using a behavioral model specification of the range of admissible dynamic behaviors, a graphical representation of the system trajectories consistent with the process data is constructed on line as observations are received from the process. The monitor reports when the observations are no longer consistent with the behavioral model specification, giving timely fault-detection information to the operator. This paper describes the elements of the trajectory encoding method and its application to computer-controlled industrial processes.",https://doi.org/10.1016/S1474-6670(17)50231-1,https://www.sciencedirect.com/science/article/pii/S1474667017502311,,,,1992,On-Line Trajectory Encoding for Discrete-Observation Process Monitoring,L.E. Holloway and B.H. Krogh,article,HOLLOWAY1992145,IFAC Proceedings Volumes,4,25,1474-6670,"IFAC Symposium on On-line Fault Detection and Supervision in the Chemical Process Industries, Newark, Delaware, 22-24 April",,
,,105-113,,"Spore and pollen assemblages in Campanian to Paleocene nearshore marine to deltaic sediments of Seymour Island, Antarctica, are characterized by abundant podocarpaceous conifer pollen, diverse provincial angiosperm pollen and cryptogam spores of low diversity. These assemblages resemble coeval assemblages from New Zealand, southeastern Australia and southern South America. The palynoflora reflects primarily conifer-dominated rainforest growing in cool to warm temperate paleoclimates. The late Maastrichtian was a comparatively warm interval, with a humid equable paleoclimate. The Antarctic Peninsula cordillera probably supported altitudinally zoned plant associations and it is likely that climatic fluctuations during the Campanian to Paleocene resulted in altitudinal shifts of these vegetation zones.",https://doi.org/10.1016/0034-6667(90)90061-M,https://www.sciencedirect.com/science/article/pii/003466679090061M,,,,1990,"Campanian to paleocene spore and pollen assemblages of Seymour Island, Antarctica",Rosemary A. Askin,article,ASKIN1990105,Review of Palaeobotany and Palynology,1,65,0034-6667,Proceedings of the Seventh International Palynological Congress - Part II,,
,"real-time display, terrain data base, visualization",347-353,,"As part of a real-time control application, there is a need for a graphics display for data which is stored as a terrain data base. Due to space and cost limitations of the application, a system has been developed to work on a microcomputer system which includes transputers to allow parallel processing. This paper describes the data representation and manipulation which has been undertaken in order to provide a real-time graphical display. This data representation is suitable for use in a parallel processing environment.",https://doi.org/10.1016/0141-9331(91)90095-W,https://www.sciencedirect.com/science/article/pii/014193319190095W,,,,1991,Manipulation of terrain data for a real-time display application,JR Vaughan and GR Brookes and MA Fletcher and DPM Wills,article,VAUGHAN1991347,Microprocessors and Microsystems,7,15,0141-9331,,,
,"Oligosaccharide, Xyloglucan, Synthesis, X-ray structure",1-15,,"The disaccharides methyl 2-O-(α-l-fucopyranosyl)-β-d-galactopyranoside and methyl 2-O-(α-l-fucopyranosyl)-α-d-galactopyranoside have been synthesised using the assisted halide reaction of tri-O-benzyl-α-l-fucopyranosyl bromide with methyl 3,4,6-tri-O-benzyl-β-d-galactopyranoside and methyl 3,4,6-tri-O-benzyl-α-d-galactopyranoside to construct the interresidue glycosidic linkages. A crystal structure of methyl 2-O-(α-l-fucopyranosyl)-β-d-galactopyranoside was determined using Mo-Kα X-ray data at 183 K. The space group is P1 (No. 1) with the unit cell containing two molecules of the disaccharide with unique conformations and a water molecule. The structure was refined to R = 0.0566 for 2969 reflections. The l-fucopyranosyl and d-galactopyranosyl residues have the nominal 1C4 and 4C1 conformations, respectively. The interresidue torsion angles are comparable with those generated in a recent molecular modelling study.",https://doi.org/10.1016/S0008-6215(96)90160-3,https://www.sciencedirect.com/science/article/pii/S0008621596901603,,,,1996,Oligosaccharides related to xyloglucan: Synthesis and X-ray crystal structure of methyl 2-O-(α-l-fucopyranosyl)-β-d-galactopyranoside,Derek K. Watt and Donald J. Brasch and David S. Larsen and Laurence D. Melton and Jim Simpson,article,WATT19961,Carbohydrate Research,,285,0008-6215,,,
,"Arterial distensibility, Arterial compliance, Arterial stiffness, Hormone replacement therapy, Oestradiol, Women, Cardiovascular disease",149-157,,"A single centre randomised placebo-controlled trial was performed to assess the 2-year effects of hormone replacement therapy compared to placebo on mechanical arterial properties in 99 perimenopausal women recruited from the general population. The trial was double-blind with respect to a sequential combined regimen of oral 17β-oestradiol and desogestrel (17βE2-D) and the placebo group and open with respect to combination of conjugated equine oestrogens and norgestrel (CEE-N). At baseline, distensibility and compliance of the common carotid artery were measured non-invasively with B-mode ultrasound and a vessel wall movement detector system, and the distensibility coefficient (DC) and compliance coefficient (CC) were calculated. Measurements were repeated after 6 and 24 months. Change in DC and CC in treatment groups was compared to placebo. After 24 months, changes for 17βE2-D compared to placebo were −1.4×10−3/kPa (95% CI −4.4; 1.7, P=0.39) for DC and 0.26 mm2/kPa (95% CI −0.01; 0.53, P=0.07) for CC. Changes for CEE-N compared to placebo were 0.4×10−3/kPa (95% CI −1.0; 1.9, P=0.79) and 0.11 mm2/kPa (95% CI −0.14; 0.37, P=0.40). For systolic blood pressure (SBP), diastolic blood pressure (DBP) and arterial lumen diameter no changes were found. In this study no significant differences in changes in distensibility and compliance were found between perimenopausal women using 17βE2-D or CEE-N and women using placebo after 6 and 24 months.",https://doi.org/10.1016/S0021-9150(99)00438-4,https://www.sciencedirect.com/science/article/pii/S0021915099004384,,,,2000,The effect of hormone replacement therapy on arterial distensibility and compliance in perimenopausal women: a 2-year randomised trial,I.C.D Westendorp and M.J.J {de Kleijn} and M.L Bots and A.A.A Bak and J Planellas and H.J.T {Coelingh Bennink} and A Hofman and D.E Grobbee and J.C.M Witteman,article,WESTENDORP2000149,Atherosclerosis,1,152,0021-9150,,,
,,205-207,,,https://doi.org/10.1016/j.acalib.2014.01.008,https://www.sciencedirect.com/science/article/pii/S0099133314000093,,,,2014,Reviews and Analysis of Special Reports,Leslie Stebbins,article,STEBBINS2014205,The Journal of Academic Librarianship,2,40,0099-1333,,,
,"Self-managed networks, Autonomic control loop, 5G network, DDoS attack, Multi-tenancy, Self-protection",102416,,"There is a lack of effective security solutions that autonomously, without any human intervention, detect and mitigate DDoS cyber-attacks. The lack is exacerbated when the network to be protected is a 5G mobile network. 5G networks push multi-tenancy to the edge of the network. Both the 5G user mobility and multi-tenancy are challenges to be addressed by current security solutions. These challenges lead to an insufficient protection of 5G users, tenants and infrastructures. This research proposes a novel autonomic security system, including the design, implementation and empirical validation to demonstrate the efficient protection of the network against Distributed Denial of Service (DDoS) attacks by applying countermeasures decided on and taken by an autonomic system, instead of a human. The self-management architecture provides support for all the different phases involved in a DDoS attack, from the detection of an attack to its final mitigation, through making the appropriate autonomous decisions and enforcing actions. Empirical experiments have been performed to protect a 5G multi-tenant infrastructure against a User Datagram Protocol (UDP) flooding attack, as an example of an attack to validate the design and prototype of the proposed architecture. Scalability results show self-protection against DDoS attacks, without human intervention, in around one second for an attack of 256 simultaneous attackers with 100 Mbps bandwidth per attacker. Furthermore, results demonstrate the proposed approach is flow-, user- and tenant-aware, which allows applying different protection strategies within the infrastructure.",https://doi.org/10.1016/j.jnca.2019.102416,https://www.sciencedirect.com/science/article/pii/S1084804519302504,,,,2019,Autonomic protection of multi-tenant 5G mobile networks against UDP flooding DDoS attacks,Ana {Serrano Mamolar} and Pablo Salvá-García and Enrique Chirivella-Perez and Zeeshan Pervez and Jose M. {Alcaraz Calero} and Qi Wang,article,SERRANOMAMOLAR2019102416,Journal of Network and Computer Applications,,145,1084-8045,,,
,"Alzheimer disease, Convolutional neural network, Deep neural network, MRI, ResNet",105215,,"Early Alzheimer’s disease (EAD) diagnosis enables individuals to take preventative actions before irreversible brain damage occurs. Memory and thinking skills get worse in alzheimer disease, making it hard to do basic things. The abnormal buildup of amyloid and tau proteins in and around brain cells is thought to cause it. When amyloid builds up, it forms plaques around brain cells. Inside brain cells, tau tangles form when it accumulates. Healthy brain cells are damaged by the tangles and plagues, which causes them to shrink. The hippocampus, a part of the brain that aids in memory formation, appears to be the location of this damage. There are currently no methods that give the most accurate results and suggestions. With the methods we have now, alzheimer disease is not found early. So, we said that the Early Alzheimer’s disease - Deep Neural Network (EAD-DNN) method has found a way to predict alzheimer disease earlier. The Magnetic Resonance Imaging (MRI) dataset in the Comma Separated Value (CSV) format has been used by the EAD-DNN method. Convolutional Neural Network (CNN), the deep Residual Network (ResNet) has been used to train the MRI image dataset. This ResNet model can get more information from network levels with the help of Deep ResNet.The modified adam optimization has selected the best feature information from MRI scans of alzheimer patients and transferred it to another area while keeping the most important data. Using the EAD-DNN approach, a multi-class classification has been carried out. The extensive experiments show that the suggested method can achieve an accuracy rate of 98%.",https://doi.org/10.1016/j.bspc.2023.105215,https://www.sciencedirect.com/science/article/pii/S1746809423006481,,,,2023,EAD-DNN: Early Alzheimer's disease prediction using deep neural networks,Preethi Thangavel and Yuvaraj Natarajan and K.R. {Sri Preethaa},article,THANGAVEL2023105215,Biomedical Signal Processing and Control,,86,1746-8094,,,
,"Blockchain technology, Value driver, Value creation, Online community, Socio-technical approach",101563,,"There is growing recognition that blockchain technology has significant potential to alter how organizations and people work and communicate. However, theoretical guidance concerning how organizations leverage blockchain technology to enhance value creation for users is still limited. Grounded in the socio-technical perspective and leveraging the rich data obtained from case analyses of blockchain-enabled online communities, this paper develops a theoretical model to identify the core value drivers that blockchain enables for online communities. The core value drivers include: a reputation-value system, data ownership mechanisms, and verification & tracking mechanisms. Our findings suggest that these three value drivers enhance value creation of online communities by motivating participation and protecting contributions.",https://doi.org/10.1016/j.tele.2021.101563,https://www.sciencedirect.com/science/article/pii/S0736585321000022,,,,2021,Value drivers of blockchain technology: A case study of blockchain-enabled online community,Yujie Zheng and Wai Fong Boh,article,ZHENG2021101563,Telematics and Informatics,,58,0736-5853,,,
,"Information centric networks, DDoS, Packet logging, Path identifiers, Network security",102071,,"Information Centric Networks (ICNs) have emerged in recent years as a new networking paradigm for the next-generation Internet. The primary goal of these networks is to provide effective mechanisms for content distribution and retrieval based on in-network content caching. Several network architectures were proposed in recent years to realize this communication model. This include Named Data Networks (NDN) and Path-Identifier (PID) based ICN. This paper proposes LogDoS as a novel mechanism to address the problem of data flooding attacks in PID-based ICNs. The proposed LogDoS mechanism is a unique hybrid approach that combines the best of NDN networks and PID-based ICNs, and it is the first to employ Bloom-filter based logging approach in a novel way to filter attack traffic efficiently. In this context, we develop and model three versions of LogDoS with varying levels of storage overhead at LogDoS-enabled routers. Extensive simulation experiments show that LogDoS is very effective against DDoS attacks as it can filter more than 99.98% of attack traffic in different attack scenarios while incurring acceptable storage overhead.",https://doi.org/10.1016/j.cose.2020.102071,https://www.sciencedirect.com/science/article/pii/S0167404820303448,,,,2020,LogDoS: A Novel logging-based DDoS prevention mechanism in path identifier-Based information centric networks,Basheer Al-Duwairi and Öznur Özkasap and Ahmet Uysal and Ceren Kocaoğullar and Kaan Yildirim,article,ALDUWAIRI2020102071,Computers & Security,,99,0167-4048,,,
,"Robot Operating System, Package management, Software ecosystems",226-242,,"ROS, the Robot Operating System, offers a core set of software for operating robots that can be extended by creating or using existing packages, making it possible to write robotic software that can be reused on different hardware platforms. With thousands of packages available per stable distribution, encapsulating algorithms, sensor drivers, etc., it is the de facto middleware for robotics. Like any software ecosystem, ROS must evolve in order to keep meeting the requirements of its users. In practice, packages may end up being abandoned between releases: no one may be available to update a package, or newer packages offer similar functionality. As such, we wanted to identify and understand the evolution challenges faced by the ROS ecosystem. In this article, we report our findings after interviewing 19 ROS developers in depth, followed by a focus group (4 participants) and an online survey of 119 ROS community members. We specifically focused on the issues surrounding package reuse and how to contribute to existing packages. To conclude, we discuss the implications of our findings, and propose five recommendations for overcoming the identified issues, with the goal of improving the health of the ROS ecosystem.",https://doi.org/10.1016/j.jss.2019.02.024,https://www.sciencedirect.com/science/article/pii/S0164121219300342,,,,2019,The Robot Operating System: Package reuse and community dynamics,Pablo Estefo and Jocelyn Simmonds and Romain Robbes and Johan Fabry,article,ESTEFO2019226,Journal of Systems and Software,,151,0164-1212,,,
,"Complex software product line, Reverse engineering, Variability modelling, Extended feature models, Formal concept analysis, Pattern structures",341-360,,"Software product line engineering relies on systematic reuse and mass customisation to reduce the development time and cost of a software system family. The extractive adoption of a product line requires to extract variability information from the description of a collection of existing software systems to model their variability. With the increasing complexity of software systems, software product line engineering faces new challenges including variability extraction and modelling. Extensions of existing boolean variability models, such as multi-valued attributes or UML-like cardinalities, were proposed to enhance their expressiveness and support variability modelling in complex product lines. In this paper, we propose an approach to extract complex variability information, i.e., involving features as well as multi-valued attributes and cardinalities, in the form of logical relationships. This approach is based on Formal Concept Analysis and Pattern Structures, two mathematical frameworks for knowledge discovery that bring theoretical foundations to complex variability extraction algorithms. We present an application on product comparison matrices representing complex descriptions of software system families. We show that our method does not suffer from scalability issues and extracts all pertinent relationships, but that it also extracts numerous accidental relationships that need to be filtered.",https://doi.org/10.1016/j.jss.2019.06.002,https://www.sciencedirect.com/science/article/pii/S0164121219301311,,,,2019,Towards complex product line variability modelling: Mining relationships from non-boolean descriptions,Jessie Carbonnel and Marianne Huchard and Clémentine Nebut,article,CARBONNEL2019341,Journal of Systems and Software,,156,0164-1212,,,
,"IoT security, Deep neural network, CNN-BiLSTM model, Intrusion detection, Anomaly classification",100646,,"The paper introduces ACS-IoT, an Anomaly Classification System for IoT networks, structured as a two-tiered framework. In the first, it employs a decision tree classifier for anomaly detection. In the second, a CNN-BiLSTM model is utilized for more profound analysis and classification of anomaly types. To address data imbalance, SMOTE is used, and feature selection is enhanced with PSO. The approach showcases strong practical applicability in real-world industrial settings, achieving an accuracy of 88%, precision of 89%, recall of 88%, and F1-score of 88% for multi-class classification, surpassing other machine learning approaches by at least 6% in all metrics.",https://doi.org/10.1016/j.simpa.2024.100646,https://www.sciencedirect.com/science/article/pii/S2665963824000344,,,,2024,A two-tiered framework for anomaly classification in IoT networks utilizing CNN-BiLSTM model,Yue Guan and Morteza Noferesti and Naser Ezzati-Jivan,article,GUAN2024100646,Software Impacts,,20,2665-9638,,,
,"IoT botnet mitigation, Power-based botnet detection method, Convolutional neural network modeling",100103,,"Many IoT botnets that exploit vulnerabilities of IoT devices have emerged recently. After taking over control of IoT devices, the botnets generate tremendous traffic to attack target nodes. It is also a threat to the smart health area since they have used IoT devices more and more. To detect the malicious IoT botnets, many researchers have proposed botnet detection systems; however, these are not easily applicable to resource-constrained IoT devices. Moreover, since the botnet's early stage makes marginal differences in terms of traffic, it is hard to detect when they first attack the victim nodes. However, we observe that the IoT botnets generate distinguishable power consumption patterns. Thus, we aim to classify whether the IoT device is affected by malign behaviors through power consumption patterns so that we can protect the healthcare ecosystem from the malicious IoT botnets. We propose a CNN-based deep learning model that consists of a data processing module as well as an 8-layer CNN. Prior to applying the CNN model, we segment and normalize the collected power consumption data to help our CNN model to achieve higher accuracy. The 8-layer CNN classifies the processed data into four classes including a botnet class, which is our primary target. To demonstrate the performance, we run self-evaluation, cross-device-evaluation, leave-one-device-out, and leave-one-botnet-out tests on three common types of IoT devices, which are Security Camera, Router, and Voice Assistant devices. The self-tests achieve up to 96.5% classification accuracy whereas the cross-evaluation tests perform about 90% accuracy. Leave-one-out tests also introduce higher than 90% accuracy for botnet detection.",https://doi.org/10.1016/j.smhl.2019.100103,https://www.sciencedirect.com/science/article/pii/S2352648319300674,,,,2020,IoT botnet detection via power consumption modeling,Woosub Jung and Hongyang Zhao and Minglong Sun and Gang Zhou,article,JUNG2020100103,Smart Health,,15,2352-6483,,,
,"Kansei engineering, Automobile exterior, Text mining, Structural equation model, Deep learning",107913,,"New energy vehicles (NEVs) such as electronic cars represent a major trend in the automobile industry, where most their exterior designs still follow those of convention fuelled vehicles (FVs). It is important to investigate whether NEV users have unique requirements that differ from those of traditional users. Kansei engineering is a practical tool for perceptual demand analysis. However, the conventional method requires questionnaires or surveys to perform limited data collection. In this study, we utilised massive internet data to collect user Kansei requirements for NEV exterior design. The Scrapy crawler was adopted for data collection and a bidirectional long short-term memory, conditional random field, and multilayer perceptron framework was developed for text mining. To quantify design features and Kansei image scores, a hybrid Apriori  + structural equation model (SEM) system is proposed, where the data-driven Apriori algorithm can explore the hidden relationships in big user generated comments, while the SEM model captures the users’ behaviour and decision procedure so that to provide interpretable results. In addition, the association rules mined from user comments by Apriori can facilitate the specification of a complicated SEM model, substantially reducing the modelling and calibration effort. Goodness-of-fit results suggest that the proposed model outperforms conventional models. A case study on 1805 automobiles, 287 brands, and 369105 comments was conducted and the results suggest that some design features that would increase the Kansei image scores for conventional FVs may have the opposite effect on NEVs. Discussions on engineering and managerial insights are presented and the discovered rules and relationships are employed to develop a design-aided system.",https://doi.org/10.1016/j.cie.2021.107913,https://www.sciencedirect.com/science/article/pii/S0360835221008172,,,,2022,Kansei engineering for new energy vehicle exterior design: An internet big data mining approach,Xinjun Lai and Sheng Zhang and Ning Mao and Jianjun Liu and Qingxin Chen,article,LAI2022107913,Computers & Industrial Engineering,,165,0360-8352,,,
,"COVID-19, Machine learning, Artificial intelligence, Healthcare, Drug development, Predictive analysis",103751,,"COVID-19 was first discovered in December 2019 and has continued to rapidly spread across countries worldwide infecting thousands and millions of people. The virus is deadly, and people who are suffering from prior illnesses or are older than the age of 60 are at a higher risk of mortality. Medicine and Healthcare industries have surged towards finding a cure, and different policies have been amended to mitigate the spread of the virus. While Machine Learning (ML) methods have been widely used in other domains, there is now a high demand for ML-aided diagnosis systems for screening, tracking, predicting the spread of COVID-19 and finding a cure against it. In this paper, we present a journey of what role ML has played so far in combating the virus, mainly looking at it from a screening, forecasting, and vaccine perspective. We present a comprehensive survey of the ML algorithms and models that can be used on this expedition and aid with battling the virus.",https://doi.org/10.1016/j.jbi.2021.103751,https://www.sciencedirect.com/science/article/pii/S1532046421000800,,,,2021,"Machine learning research towards combating COVID-19: Virus detection, spread prevention, and medical assistance",Osama Shahid and Mohammad Nasajpour and Seyedamin Pouriyeh and Reza M. Parizi and Meng Han and Maria Valero and Fangyu Li and Mohammed Aledhari and Quan Z. Sheng,article,SHAHID2021103751,Journal of Biomedical Informatics,,117,1532-0464,,,
,"Dataset practices, Data curation, Online community, Metadata, Data seeking, Data sharing",101160,,"This study examined discussions of the r/Datasets community on Reddit. It identified three activities in which the community engaged: question answering, data sharing, and community building. Members of the community used 21 types of data and information sources in their activities. The findings of this research enhance our understanding of the activity structures, data and information sources used, and challenges and problems encountered when users search for, share, and make sense of datasets on the web, outside the traditional information and data ecosystems. Data librarians and curators can use the findings of this study in the design of their data management and reference services. The typology of data sources and the metadata model developed through this study can be used in annotating and categorizing data sources and informing the design of metadata schemas and vocabularies for datasets.",https://doi.org/10.1016/j.lisr.2022.101160,https://www.sciencedirect.com/science/article/pii/S0740818822000238,,,,2022,Seeking and sharing datasets in an online community of data enthusiasts,Besiki Stvilia and Leila Gibradze,article,STVILIA2022101160,Library & Information Science Research,3,44,0740-8188,,,
,"E-commerce, Commodity review, Sentiment analysis, the emotional correlation analysis model, SOM, User clustering",109035,,"Platform merchants mine user clusters and their characteristics to assist in precision marketing. In view of the information overload in e-commerce reviews, machine methods are needed to efficiently obtain clustering information from text. This study innovatively integrated the emotional correlation analysis model and Self-organizing Map (SOM) in application, to construct fine-grained user emotion vector based on review text and perform visual cluster analysis, which helped quickly mine user clustering and characteristics from review text. The result of empirical analysis based on real reviews of Amazon books showed that the proposed method had the average precision as 0.71, confirming that the clustering method integrating the emotional correlation analysis model and SOM could efficiently mine user groups and match appropriate marketing strategies, which will help platform merchants carry out precision marketing. The study makes contributions to the application and innovation of researches in the field of user clustering and e-commerce precision marketing.",https://doi.org/10.1016/j.compeleceng.2023.109035,https://www.sciencedirect.com/science/article/pii/S0045790623004597,,,,2024,Discovering e-commerce user groups from online comments: An emotional correlation analysis-based clustering method,Jia Ke and Ying Wang and Mingyue Fan and Xiaojun Chen and Wenlong Zhang and Jianping Gou,article,KE2024109035,Computers and Electrical Engineering,,113,0045-7906,,,
,"OS fingerprinting, Network monitoring, Network management, Cybersecurity, Machine learning, Survey",109782,,"Fingerprinting a host's operating system is a very common yet precarious task in network, asset, and vulnerability management. Estimating the operating system via network traffic analysis may leverage TCP/IP header parameters or complex analysis of hosts' behavior using machine learning. However, the existing approaches are becoming obsolete as network traffic evolves which makes the problem still open. This paper discusses various approaches to passive OS fingerprinting and their evolution in the past twenty years. We illustrate their usage, compare their results in an experiment, and list challenges faced by the current fingerprinting approaches. The hosts' differences in network stack settings were initially the most important information source for OS fingerprinting, which is now complemented by hosts' behavioral analysis and combined approaches backed by machine learning. The most impactful reasons for this evolution were the Internet-wide network traffic encryption and the general adoption of privacy-preserving concepts in application protocols. Other changes, such as the increasing proliferation of web applications on handheld devices, raised the need to identify these devices in the networks, for which we may use the techniques of OS fingerprinting.",https://doi.org/10.1016/j.comnet.2023.109782,https://www.sciencedirect.com/science/article/pii/S138912862300227X,,,,2023,Passive operating system fingerprinting revisited: Evaluation and current challenges,Martin Laštovička and Martin Husák and Petr Velan and Tomáš Jirsík and Pavel Čeleda,article,LASTOVICKA2023109782,Computer Networks,,229,1389-1286,,,
,"Personality traits, Large-scale distributed projects, Ecosystems, Apache, Big five, Five-Factor model, Open source software, Human aspects, Psychometric analysis, Computational personality detection",1-20,,"Context
Large-scale distributed projects are typically the results of collective efforts performed by multiple developers with heterogeneous personalities.
Objective
We aim to find evidence that personalities can explain developers’ behavior in large scale-distributed projects. For example, the propensity to trust others — a critical factor for the success of global software engineering — has been found to influence positively the result of code reviews in distributed projects.
Method
In this paper, we perform a quantitative analysis of ecosystem-level data from the code commits and email messages contributed by the developers working on the Apache Software Foundation (ASF) projects, as representative of large scale-distributed projects.
Results
We find that there are three common types of personality profiles among Apache developers, characterized in particular by their level of Agreeableness and Neuroticism. We also confirm that developers’ personality is stable over time. Moreover, personality traits do not vary with their role, membership, and extent of contribution to the projects. We also find evidence that more open developers are more likely to make contributors to Apache projects.
Conclusion
Overall, our findings reinforce the need for future studies on human factors in software engineering to use psychometric tools to control for differences in developers’ personalities.",https://doi.org/10.1016/j.infsof.2019.05.012,https://www.sciencedirect.com/science/article/pii/S0950584918301216,,,,2019,"A large-scale, in-depth analysis of developers’ personalities in the Apache ecosystem",Fabio Calefato and Filippo Lanubile and Bogdan Vasilescu,article,CALEFATO20191,Information and Software Technology,,114,0950-5849,,,
,"Working from home, WFH, Telework, COVID-19, Software engineering, Case study, Empirical study",111509,,"The COVID-19 outbreak has admittedly caused interruptions to production, transportation, and mobility, therefore, having a significant impact on the global supply and demand chain’s well-functioning. But what happened to companies developing digital services, such as software? How has the enforced Working-From-Home (WFH) mode impacted their ability to deliver software, if at all? This article shares our findings from monitoring the WFH during 2020 in an international software company with engineers located in Sweden, the USA, and the UK. We analyzed different aspects of productivity, such as developer job satisfaction and well-being, activity, communication and collaboration, efficiency and flow based on the archives of commit data, calendar invites, Slack communication, the internal reports of WFH experiences, and 30 interviews carried out in April/May and September 2020. We add more objective evidence to the existing COVID-19 studies the vast majority of which are based on self-reported productivity from the early months of the pandemic. We find that engineers continue committing code and carrying out their daily duties, as their routines adjust to “the new norm”. Our key message is that software engineers can work from home and quickly adjust their tactical approaches to the changes of unprecedented scale. Further, WFH has its benefits, including better work-life balance, improved flow, and improved quality of distributed meetings and events. Yet, WFH is not challenge free: not everybody feels equally productive working from home, work hours for many increased, while physical activity, socialization, pairing and opportunities to connect to unfamiliar colleagues decreased. Information sharing and meeting patterns also changed. Finally, experiences gained during the pandemic will have a lasting impact on the future of the workplace. The results of an internal company-wide survey suggest that only 9% of engineers will return to work in the office full time. Our article concludes with the InterSoft’s strategy for work from anywhere (WFX), and a list of useful adjustments for a better WFH.",https://doi.org/10.1016/j.jss.2022.111509,https://www.sciencedirect.com/science/article/pii/S0164121222001856,,,,2023,From forced Working-From-Home to voluntary working-from-anywhere: Two revolutions in telework,Darja Šmite and Nils Brede Moe and Eriks Klotins and Javier Gonzalez-Huerta,article,SMITE2023111509,Journal of Systems and Software,,195,0164-1212,,,
,"IoT botnet, IoT security, Static malware detection, PSI-rooted subgraph, Machine learning, Deep learning",128-138,,"It is obvious that IoT devices are widely used more and more in many areas. However, due to limited resources (e.g., memory, CPU), the security mechanisms on many IoT devices such as IP-Camera, router are low. Therefore, botnets are an emerging threat to compromise IoT devices recently. To tackle this, a novel method for IoT botnets detection plays a crucial role. In this paper, we have some contributions for IoT botnet detection: first, we present a novel high-level PSI-rooted subgraph-based feature for the detection of IoT botnets; second, we generate a limited number of features that have precise behavioral descriptions, which require smaller space and reduce processing time; third, The evaluation results show the effectiveness and robustness of PSI-rooted subgraph-based features, as with five machine classifiers consisting of Random Forest, Decision Tree, Bagging, k-Nearest Neighbor, and Support Vector Machine, each classifier achieves more than 97% detection rate and low time-consuming. Moreover, compared to other work, our proposed method obtains better performance. Finally, we publicize all our materials on Github, which will benefit future research (e.g., IoT botnet detection approach).",https://doi.org/10.1016/j.icte.2019.12.001,https://www.sciencedirect.com/science/article/pii/S2405959519304412,,,,2020,PSI-rooted subgraph: A novel feature for IoT botnet detection using classifier algorithms,Huy-Trung Nguyen and Quoc-Dung Ngo and Doan-Hieu Nguyen and Van-Hoang Le,article,NGUYEN2020128,ICT Express,2,6,2405-9595,,,
,"Robotics, Robot Operating System, ROS 2, Robotic manipulation, Mobile robots, Robot control, Remote teaching",279-284,,"This paper presents the use of ROS 2 as a support platform for the Dynamics and Control of Robots course at the School of Engineering of the Universidade Federal do Rio Grande do Sul, Brazil. The organization of the course is presented and the autonomous activities performed by students at home using ROS 2 are described in detail, including some pitfalls that should be avoided. The results show that ROS 2 is mature enough for production use, at least in an academic environment and that students are able to use sophisticated robotic tools even in undergraduate courses.",https://doi.org/10.1016/j.ifacol.2022.09.292,https://www.sciencedirect.com/science/article/pii/S2405896322015348,,,,2022,Remote Teaching of Dynamics and Control of Robots Using ROS 2,Walter Fetter Lages,article,LAGES2022279,IFAC-PapersOnLine,17,55,2405-8963,13th IFAC Symposium on Advances in Control Education ACE 2022,,
,"Network intrusion detection system (NIDS), Multistage AI-based NIDS, Malicious packet classifier, Anomaly detector, Novelty detector, Sequential deep neural networks, One-shot learning, Transfer learning",103928,,"Ensuring the security and integrity of computer and network systems is of utmost importance in today’s digital landscape. Network intrusion detection systems (NIDS) play a critical role in continuously monitoring network traffic and identifying unauthorized or potentially malicious activities that could compromise the confidentiality, availability, and integrity of these systems. However, traditional NIDS face a daunting challenge in effectively adapting to the evolving tactics of cyber attackers. To address this challenge, we propose a multistage artificial intelligence enabled framework for intrusion detection in network traffic, capable of handling zero-day, out-of-distribution, and adversarial evasion attacks. Our framework comprises three sequential deep neural network (DNN) architectures: one for the classifier and two for specific autoencoders, designed to effectively detect both known attack patterns and novel, previously unseen samples. We introduce an innovative transfer learning technique where specific combinations of neurons and layers in the DNN architectures are frozen during one-shot learning to enhance the framework’s robustness to novel attacks. To validate the effectiveness of our framework, we conducted extensive experimentation using publicly available benchmark intrusion detection data sets. Leveraging the one-shot learning approach in the transfer learning component of the framework, we demonstrate continuous improvement in detection accuracy for both known and novel network traffic patterns. The results demonstrate the effectiveness of the multiple stages in the framework by achieving, on average, 98.5% accuracy in detecting various attacks.",https://doi.org/10.1016/j.cose.2024.103928,https://www.sciencedirect.com/science/article/pii/S0167404824002311,,,,2024,A sequential deep learning framework for a robust and resilient network intrusion detection system,Soumyadeep Hore and Jalal Ghadermazi and Ankit Shah and Nathaniel D. Bastian,article,HORE2024103928,Computers & Security,,144,0167-4048,,,
,"Networked robotic systems, Multi-agent systems, Consensus, Decentralized control, Decentralized Control and Systems",11436-11443,,"We consider task allocation for multi-object transport using a multi-robot system, in which each robot selects one object among multiple objects with different and unknown weights. The existing centralized methods assume the number of robots and tasks to be fixed, which is inapplicable to scenarios that differ from the learning environment. Meanwhile, the existing distributed methods limit the minimum number of robots and tasks to a constant value, making them applicable to various numbers of robots and tasks. However, they cannot transport an object whose weight exceeds the load capacity of robots observing the object. To make it applicable to various numbers of robots and objects with different and unknown weights, we propose a framework using multi-agent reinforcement learning for task allocation. First, we introduce a structured policy model consisting of 1) predesigned dynamic task priorities with global communication and 2) a neural network-based distributed policy model that determines the timing for coordination. The distributed policy builds consensus on the high-priority object under local observations and selects cooperative or independent actions. Then, the policy is optimized by multi-agent reinforcement learning through trial and error. This structured policy of local learning and global communication makes our framework applicable to various numbers of robots and objects with different and unknown weights, as demonstrated by simulations.",https://doi.org/10.1016/j.ifacol.2023.10.431,https://www.sciencedirect.com/science/article/pii/S240589632300798X,,,,2023,"Learning Locally, Communicating Globally: Reinforcement Learning of Multi-robot Task Allocation for Cooperative Transport",Kazuki Shibata and Tomohiko Jimbo and Tadashi Odashima and Keisuke Takeshita and Takamitsu Matsubara,article,SHIBATA202311436,IFAC-PapersOnLine,2,56,2405-8963,22nd IFAC World Congress,,
,"Online social networks, Automatic content moderator, Adversarial machine learning, Hate speech, Cybersecurity, Instagram, Obfuscation techniques",100252,,"Nowadays, people generate and share massive amounts of content on online platforms (e.g., social networks, blogs). In 2021, the 1.9 billion daily active Facebook users posted around 150 thousand photos every minute. Content moderators constantly monitor these online platforms to prevent the spreading of inappropriate content (e.g., hate speech, nudity images). Based on deep learning (DL) advances, Automatic Content Moderators (ACM) help human moderators handle high data volume. Despite their advantages, attackers can exploit weaknesses of DL components (e.g., preprocessing, model) to affect their performance. Therefore, an attacker can leverage such techniques to spread inappropriate content by evading ACM. In this work, we analyzed 4600 potentially toxic Instagram posts, and we discovered that 44% of them adopt obfuscations that might undermine ACM. As these posts are reminiscent of captchas (i.e., not understandable by automated mechanisms), we coin this threat as Captcha Attack (CAPA). Our contributions start by proposing a CAPA taxonomy to better understand how ACM is vulnerable to obfuscation attacks. We then focus on the broad sub-category of CAPA using textual Captcha Challenges, namely CC-CAPA, and we empirically demonstrate that it evades real-world ACM (i.e., Amazon, Google, Microsoft) with 100% accuracy. Our investigation revealed that ACM failures are caused by the OCR text extraction phase. The training of OCRs to withstand such obfuscation is therefore crucial, but huge amounts of data are required. Thus, we investigate methods to identify CC-CAPA samples from large sets of data (originated by three OSN – Pinterest, Twitter, Yahoo-Flickr), and we empirically demonstrate that supervised techniques identify target styles of samples almost perfectly. Unsupervised solutions, on the other hand, represent a solid methodology for inspecting uncommon data to detect new obfuscation techniques.",https://doi.org/10.1016/j.osnem.2023.100252,https://www.sciencedirect.com/science/article/pii/S2468696423000113,,,,2023,Turning captchas against humanity: Captcha-based attacks in online social media,Mauro Conti and Luca Pajola and Pier Paolo Tricomi,article,CONTI2023100252,Online Social Networks and Media,,36,2468-6964,,,
,"Covid-19 pandemic, Sociome, Conversation, Emotion classification, Emotion shift",102918,,"This paper proposes a new deep learning approach to better understand how optimistic and pessimistic feelings are conveyed in Twitter conversations about COVID-19. A pre-trained transformer embedding is used to extract the semantic features and several network architectures are compared. Model performance is evaluated on two new, publicly available Twitter corpora of crisis-related posts. The best performing pessimism and optimism detection models are based on bidirectional long- and short-term memory networks. Experimental results on four periods of the COVID-19 pandemic show how the proposed approach can model optimism and pessimism in the context of a health crisis. There is a total of 150,503 tweets and 51,319 unique users. Conversations are characterised in terms of emotional signals and shifts to unravel empathy and support mechanisms. Conversations with stronger pessimistic signals denoted little emotional shift (i.e. 62.21% of these conversations experienced almost no change in emotion). In turn, only 10.42% of the conversations laying more on the optimistic side maintained the mood. User emotional volatility is further linked with social influence.",https://doi.org/10.1016/j.ipm.2022.102918,https://www.sciencedirect.com/science/article/pii/S0306457322000437,,,,2022,Optimism and pessimism analysis using deep learning on COVID-19 related twitter conversations,Guillermo Blanco and Anália Lourenço,article,BLANCO2022102918,Information Processing & Management,3,59,0306-4573,,,
,"Denial of service, Data breach, Security, Privacy, Trust, Insider threat",100507,,"Printing over a network and calling over VoIP technology are routine at present. This article investigates to what extent these services can be attacked using freeware in the real world if they are not configured securely. In finding out that attacks of high impact, termed the Printjack and Phonejack families, could be mounted at least from insiders, the article also observes that secure configurations do not appear to be widely adopted. Users with the necessary skills may put existing security measures in place with printers, but would need novel measures, which the article prototypes, with phones in order for a pair of peers to call each other securely and without trusting anyone else, including sysadmins.",https://doi.org/10.1016/j.iot.2022.100507,https://www.sciencedirect.com/science/article/pii/S2542660522000130,,,,2022,Multi-service threats: Attacking and protecting network printers and VoIP phones alike,Giampaolo Bella and Pietro Biondi and Stefano Bognanni,article,BELLA2022100507,Internet of Things,,18,2542-6605,,,
,"Blockchain, Cryptocurrency, Ethereum",200894,,This paper examines the Ethereum network in the context of an investigation. The validation of data sources is achieved through different client software on both the Ropsten network and the live blockchain. New scenarios are also used test common patterns in order to track for start and end points for Ethereum and ERC20 tokens.,https://doi.org/10.1016/j.fsidi.2019.200894,https://www.sciencedirect.com/science/article/pii/S1742287618302263,,,,2020,Scenario-based creation and digital investigation of ethereum ERC20 tokens,Simon F. Dyson and William J. Buchanan and Liam Bell,article,DYSON2020200894,Forensic Science International: Digital Investigation,,32,2666-2817,,,
,"Feature correspondence, Attention network, Graph matching, Graph learning",109059,,"In recent years, powered by the learned discriminative representation via graph neural network (GNN) models, deep graph matching methods have made great progresses in the task of matching semantic features. However, these methods usually rely on heuristically generated graph patterns, which may introduce unreliable relationships to hurt the matching performance. In this paper, we propose a joint graph learning and matching network, named GLAM, to explore reliable graph structures for boosting graph matching. GLAM adopts a pure attention-based framework for both graph learning and graph matching. Specifically, it employs two types of attention mechanisms, self-attention and cross-attention for the task. The self-attention discovers the relationships between features to further update feature representations over the learnt structures; and the cross-attention computes cross-graph correlations between the two feature sets to be matched for feature reconstruction. Moreover, the final matching solution is directly derived from the output of the cross-attention layer, without employing a specific matching decision module. The proposed method is evaluated on three popular visual matching benchmarks (Pascal VOC, Willow Object and SPair-71k), and it outperforms previous state-of-the-art graph matching methods on all benchmarks. Furthermore, the graph patterns learnt by our model are validated to be able to remarkably enhance previous deep graph matching methods by replacing their handcrafted graph structures with the learnt ones.",https://doi.org/10.1016/j.patcog.2022.109059,https://www.sciencedirect.com/science/article/pii/S0031320322005398,,,,2023,Joint Graph Learning and Matching for Semantic Feature Correspondence,He Liu and Tao Wang and Yidong Li and Congyan Lang and Yi Jin and Haibin Ling,article,LIU2023109059,Pattern Recognition,,134,0031-3203,,,
,"Large language models, Air transportation, Review, Challenges",100024,,"In the past decade, Artificial Intelligence (AI) has contributed to the improvement of various aviation aspects, including flight plan optimization, the development of autonomous systems, performing predictive analytics, as well as in passenger / crew assistance systems. The latest AI technology to potentially revolutionize air transportation are so-called Large Language Models (LLMs), which have an outstanding ability to process and generate human-like text. The application areas for LLMs cover nearly all aspects of air transportation, through language processing, content generation, and problem solving. In this study, we discuss the potential of this impact with two major contributions. First, we have performed an experimental evaluation of twelve commonly-used LLMs concerning their performance of air transportation related subjects, covering fact retrieval, complex reasoning abilities, and explanation tasks. Second, we have performed a survey among graduate students at Beihang University, a leading aviation university in China, to explore the experiences and uses of LLMs. We believe that our study makes a significant contribution towards the dissemination and application of LLMs in the air transportation domain.",https://doi.org/10.1016/j.jatrs.2024.100024,https://www.sciencedirect.com/science/article/pii/S2941198X24000356,,,,2024,Large language models for air transportation: A critical review,Yucheng Liu,article,LIU2024100024,Journal of the Air Transport Research Society,,2,2941-198X,,,
,"In vivo cardiomyofiber strains, Cardiac kinematics, Model based image analysis, Analytical phantom",101932,,"Since heart contraction results from the electrically activated contraction of millions of cardiomyocytes, a measure of cardiomyocyte shortening mechanistically underlies cardiac contraction. In this work we aim to measure preferential aggregate cardiomyocyte (“myofiber”) strains based on Magnetic Resonance Imaging (MRI) data acquired to measure both voxel-wise displacements through systole and myofiber orientation. In order to reduce the effect of experimental noise on the computed myofiber strains, we recast the strains calculation as the solution of a boundary value problem (BVP). This approach does not require a calibrated material model, and consequently is independent of specific myocardial material properties. The solution to this auxiliary BVP is the displacement field corresponding to assigned values of myofiber strains. The actual myofiber strains are then determined by minimizing the difference between computed and measured displacements. The approach is validated using an analytical phantom, for which the ground-truth solution is known. The method is applied to compute myofiber strains using in vivo displacement and myofiber MRI data acquired in a mid-ventricular left ventricle section in N=8 swine subjects. The proposed method shows a more physiological distribution of myofiber strains compared to standard approaches that directly differentiate the displacement field.",https://doi.org/10.1016/j.media.2020.101932,https://www.sciencedirect.com/science/article/pii/S1361841520302966,,,,2021,Estimating cardiomyofiber strain in vivo by solving a computational model,Luigi E. Perotti and Ilya A. Verzhbinsky and Kévin Moulin and Tyler E. Cork and Michael Loecher and Daniel Balzani and Daniel B. Ennis,article,PEROTTI2021101932,Medical Image Analysis,,68,1361-8415,,,
,"Data acquisition, Framework, Experiment automation, Firmware development, Scientific software",111588,,"The LabBot Framework project is intended to implement control of experiment and data acquisition without writing special platform codes, while achieving industrial-grade results. The Framework is intended for fast and advanced development of controlling and data acquisition software for laboratory-scale experimental setups; more sophisticated software for middle-scale laboratory equipment; industrial-grade software for self-made commercial instrumentation developed by small- and middle-scale companies. The paper presents review of the Framework top-level architecture and its implementation addressing development of ITER Divertor Thomson Scattering (DTS) diagnostic. The first examples of the Framework implementation include the set-ups for vacuum heating testbench; RF cleaning of diagnostic mirrors as well as DTS equipment, which must be controlled by the ITER CODAC system.",https://doi.org/10.1016/j.fusengdes.2020.111588,https://www.sciencedirect.com/science/article/pii/S0920379620301368,,,,2020,Framework for software development of laboratory equipment and setups integrated into large scale DAQ systems (LabBot),Alexandr Chernakov and Nikita Zhiltsov and Vasiliy Senitchenkov and Nikita Babinov and Alexander Bazhenov and Ivan Bukreev and Paul Chernakov and Anton Chernakov and Anastasia Chironova and Artem Dmitriev and Denis Elets and Nikita Ermakov and Igor Khodunov and Alexander Koval and Gleb Kurskiev and Andrei Litvinov and Alina Mitrofanova and Alexander Mokeev and Eugene Mukhin and Alexey Razdobarin and Dmitry Samsonov and Leonid Snigirev and Valeri Solovei and Ivan Tereschenko and Sergei Tolstyakov and Lidia Varshavchik and Paul Zatylkin,article,CHERNAKOV2020111588,Fusion Engineering and Design,,156,0920-3796,,,
,"Legal documents, Official gazettes, Natural Language Processing, Classification, Named Entity Recognition",127064,,"Official gazettes are documents published by governments to publicize their actions, spanning long periods of time and making an important transparency mechanism. These documents have information on laws, contracts, and bidding processes, as well as on civil servants and their careers in public service. Automatic information extraction of these documents may contribute to public transparency, with two tasks being especially useful: the classification of the different segments of these documents, the so called acts; and the Named Entity Recognition (NER) within the acts. The variety of official gazettes and their patterns brings up the necessity of constructing different tools for specific gazettes. In this paper, we propose DODFMiner, a command-line interface tool to classify acts and extract named entities from the Official Gazette of the Federal District. The tool follows a 3-step approach: the pre-processing of the input data; text classification using rule-based systems with regular expressions; and NER with Machine Learning algorithms. It allows users to input JSON files and receive CSV as output, providing information that allows users to track government procurements through years, contracts duration and total amount, among others. We also propose a set of experiments to support the choice of models included in the tool, covering the classification and NER steps. Text classification achieved a mean F1-score of 0.778, while to the NER, we compared 3 different architectures, CRF with a mean F1-score of 0.851, CNN-biLSTM-CRF with 0.787 and CNN-CNN-LSTM with 0.841.",https://doi.org/10.1016/j.neucom.2023.127064,https://www.sciencedirect.com/science/article/pii/S0925231223011876,,,,2024,DODFMiner: An automated tool for Named Entity Recognition from Official Gazettes,Gabriel M.C. Guimarães and Felipe X.B. {da Silva} and Andrei L. Queiroz and Ricardo M. Marcacini and Thiago P. Faleiros and Vinicius R.P. Borges and Luís P.F. Garcia,article,GUIMARAES2024127064,Neurocomputing,,568,0925-2312,,,
,"DevOps, Extreme Programming, Object, Object-Oriented Programming, Procedural languages, Spiral Model, Systems Development Life Cycle, Waterfall Model",459-508,CISSP® Study Guide (Fourth Edition),"This chapter introduces Domain 8 of the CISSP®, Software Development Security. The most important aspects of this domain are related to managing the development of software and applications. Approaches to software development that attempt to reduce the likelihood of defects or flaws are a key topic in this domain. In particular, the Waterfall, Spiral, and Rapid Application Development (RAD) models of software development are considered. Another significant portion of this chapter is dedicated to understanding the principles of Object-Oriented programming and design. A basic discussion of several types of software vulnerabilities and the issues surrounding disclosure of the vulnerabilities are also a topic for this domain. Finally, databases, being a key component of many applications, are considered.",https://doi.org/10.1016/B978-0-443-18734-6.00008-8,https://www.sciencedirect.com/science/article/pii/B9780443187346000088,,Syngress,978-0-443-18734-6,2023,Chapter 9 - Domain 8: Software Development Security,Eric Conrad and Seth Misenar and Joshua Feldman,incollection,CONRAD2023459,,,,,,Eric Conrad and Seth Misenar and Joshua Feldman,Fourth Edition
,"Efficient annotation, Weak supervised learning, Segmentation, Deep learning, Cerebrovascular tree",102263,,"Deep learning techniques for 3D brain vessel image segmentation have not been as successful as in the segmentation of other organs and tissues. This can be explained by two factors. First, deep learning techniques tend to show poor performances at the segmentation of relatively small objects compared to the size of the full image. Second, due to the complexity of vascular trees and the small size of vessels, it is challenging to obtain the amount of annotated training data typically needed by deep learning methods. To address these problems, we propose a novel annotation-efficient deep learning vessel segmentation framework. The framework avoids pixel-wise annotations, only requiring weak patch-level labels to discriminate between vessel and non-vessel 2D patches in the training set, in a setup similar to the CAPTCHAs used to differentiate humans from bots in web applications. The user-provided weak annotations are used for two tasks: (1) to synthesize pixel-wise pseudo-labels for vessels and background in each patch, which are used to train a segmentation network, and (2) to train a classifier network. The classifier network allows to generate additional weak patch labels, further reducing the annotation burden, and it acts as a second opinion for poor quality images. We use this framework for the segmentation of the cerebrovascular tree in Time-of-Flight angiography (TOF) and Susceptibility-Weighted Images (SWI). The results show that the framework achieves state-of-the-art accuracy, while reducing the annotation time by ∼77% w.r.t. learning-based segmentation methods using pixel-wise labels for training.",https://doi.org/10.1016/j.media.2021.102263,https://www.sciencedirect.com/science/article/pii/S136184152100308X,,,,2022,Vessel-CAPTCHA: An efficient learning framework for vessel annotation and segmentation,Vien Ngoc Dang and Francesco Galati and Rosa Cortese and Giuseppe {Di Giacomo} and Viola Marconetto and Prateek Mathur and Karim Lekadir and Marco Lorenzi and Ferran Prados and Maria A. Zuluaga,article,DANG2022102263,Medical Image Analysis,,75,1361-8415,,,
,"Convolutional neural networks, computer vision, agricultural robotics, edge computing",24-29,,"Strawberry production in open-field conditions requires a lot of human labor, which is increasingly difficult to recruit. A robotic solution could potentially operate in the field around the clock with minimal supervision. For strawberry farmers, automation of harvesting would eliminate the personnel risk and provide security for operations in the long term. A robot which would be capable of replacing physical human labor in horticultural production requires an accurate and fast perception system. In this paper, we focus on the task of detecting of garden strawberries to guide the picking by a strawberry harvesting robot. We have developed a real-time implementation of strawberry and peduncle detection system that runs on an edge device. This paper outlines the vision system requirements, hardware selection, model selection, training process and results. After consideration of the overall requirements of the system, we decided to use YOLOv5 to detect both the berries and peduncles for the picking system. Training data was collected and annotated, and the detection model was trained. The network had 91.5% average precision (AP) for detecting strawberries and an 43.6% AP for detecting peduncles. One of the reasons for performance discrepancy was the difficulty to detect peduncles from afar. Overall, the vision algorithm reached the performance that was required to guide the robot to a strawberry and detect the corresponding strawberry-peduncle pairs. However, for densely clustered berries the method often failed to detect the correct peduncle and needs to be improved.",https://doi.org/10.1016/j.ifacol.2022.11.109,https://www.sciencedirect.com/science/article/pii/S2405896322027422,,,,2022,Real-Time CNN-based Computer Vision System for Open-Field Strawberry Harvesting Robot,Madis Lemsalu and Victor Bloch and Juha Backman and Matti Pastell,article,LEMSALU202224,IFAC-PapersOnLine,32,55,2405-8963,"7th IFAC Conference on Sensing, Control and Automation Technologies for Agriculture AGRICONTROL 2022",,
,"Internet of things (IoT), Large-scale attacks, Machine learning, Deep learning",100365,,"With the continuous expansion and evolution of IoT applications, attacks on those IoT applications continue to grow rapidly. In this systematic literature review (SLR) paper, our goal is to provide a research asset to researchers on recent research trends in IoT security. As the main driver of our SLR paper, we proposed six research questions related to IoT security and machine learning. This extensive literature survey on the most recent publications in IoT security identified a few key research trends that will drive future research in this field. With the rapid growth of large scale IoT attacks, it is important to develop models that can integrate state of the art techniques and technologies from big data and machine learning. Accuracy and efficiency are key quality factors in finding the best algorithms and models to detect IoT attacks in real or near real-time",https://doi.org/10.1016/j.iot.2021.100365,https://www.sciencedirect.com/science/article/pii/S2542660521000093,,,,2021,Machine learning approaches to IoT security: A systematic literature review ,Rasheed Ahmad and Izzat Alsmadi,article,AHMAD2021100365,Internet of Things,,14,2542-6605,,,
,"Data science, Cyber forensics, Internet-of-things, IoT Security, Internet measurements",101707,,"The insecurity of the Internet-of-Things (IoT) paradigm continues to wreak havoc in consumer and critical infrastructures. The highly heterogeneous nature of IoT devices and their widespread deployments has led to the rise of several key security and measurement-based challenges, significantly crippling the process of collecting, analyzing and correlating IoT-centric data. To this end, this paper explores macroscopic, passive empirical data to shed light on this evolving threat phenomena. The proposed work aims to classify and infer Internet-scale compromised IoT devices by solely observing one-way network traffic, while also uncovering, reporting and thoroughly analyzing “in the wild” IoT botnets. To prepare a relevant dataset, a novel probabilistic model is developed to cleanse unrelated traffic by removing noise samples (i.e., misconfigured network traffic). Subsequently, several shallow and deep learning models are evaluated in an effort to train an effective multi-window convolutional neural network. By leveraging active and passing measurements when generating the training dataset, the neural network aims to accurately identify compromised IoT devices. Consequently, to infer orchestrated and unsolicited activities that have been generated by well-coordinated IoT botnets, hierarchical agglomerative clustering is employed by scrutinizing a set of innovative and efficient network feature sets. Analyzing 3.6 TB of recently captured darknet traffic revealed a momentous 440,000 compromised IoT devices and generated evidence-based artifacts related to 350 IoT botnets. Moreover, by conducting thorough analysis of such inferred campaigns, we reveal their scanning behaviors, packet inter-arrival times, employed rates and geo-distributions. Although several campaigns exhibit significant differences in these aspects, some are more distinguishable; by being limited to specific geo-locations or by executing scans on random ports besides their core targets. While many of the inferred botnets belong to previously documented campaigns such as Hide and Seek, Hajime and Fbot, newly discovered events portray the evolving nature of such IoT threat phenomena by demonstrating growing cryptojacking capabilities or by targeting industrial control services. To motivate empirical (and operational) IoT cyber security initiatives as well as aid in reproducibility of the obtained results, we make the source codes of all the developed methods and techniques available to the research community at large.",https://doi.org/10.1016/j.cose.2019.101707,https://www.sciencedirect.com/science/article/pii/S0167404819302445,,,,2020,"On data-driven curation, learning, and analysis for inferring evolving internet-of-Things (IoT) botnets in the wild",Morteza {Safaei Pour} and Antonio Mangino and Kurt Friday and Matthias Rathbun and Elias Bou-Harb and Farkhund Iqbal and Sagar Samtani and Jorge Crichigno and Nasir Ghani,article,SAFAEIPOUR2020101707,Computers & Security,,91,0167-4048,,,
,"Domain Generation Algorithm (DGA), Natural Language Processing (NLP), Machine learning, Data, Network security",105400,,"In computer security, botnets still represent a significant cyber threat. Concealing techniques such as the dynamic addressing and the domain generation algorithms (DGAs) require an improved and more effective detection process. To this extent, this data descriptor presents a collection of over 30 million manually-labeled algorithmically generated domain names decorated with a feature set ready-to-use for machine learning (ML) analysis. This proposed dataset has been co-submitted with the research article ”UMUDGA: a dataset for profiling DGA-based botnet” [1], and it aims to enable researchers to move forward the data collection, organization, and pre-processing phases, eventually enabling them to focus on the analysis and the production of ML-powered solutions for network intrusion detection. In this research, we selected 50 among the most notorious malware variants to be as exhaustive as possible. Inhere, each family is available both as a list of domains (generated by executing the malware DGAs in a controlled environment with fixed parameters) and as a collection of features (generated by extracting a combination of statistical and natural language processing metrics).",https://doi.org/10.1016/j.dib.2020.105400,https://www.sciencedirect.com/science/article/pii/S2352340920302948,,,,2020,UMUDGA: A dataset for profiling algorithmically generated domain names in botnet detection,Mattia Zago and Manuel {Gil Pérez} and Gregorio {Martínez Pérez},article,ZAGO2020105400,Data in Brief,,30,2352-3409,,,
,,13-19,,"It seems that as fast as we develop defences for our networks and computing devices we also introduce new products with new flaws that criminals and others can exploit. The Internet of Things (IoT) is a case in point. In the rush to connect everything from dolls to CCTV systems to the Internet, security seems to get overlooked, making us all vulnerable. In this interview with penetration tester Ken Munro, a partner at Pen Test Partners, we discover how the most seemingly innocuous product can be turned into a cyber weapon.",https://doi.org/10.1016/S1353-4858(17)30104-6,https://www.sciencedirect.com/science/article/pii/S1353485817301046,,,,2017,Weaponising the Internet of Things,Steve Mansfield-Devine,article,MANSFIELDDEVINE201713,Network Security,10,2017,1353-4858,,,
,"Course project effort, Student performance, Student satisfaction, Software engineering skills, Project challenges",111156,,"Given the inclusion of (often team-based) course projects in tertiary software engineering education, it is necessary to investigate software engineering curricula and students’ experiences while undergoing their software engineering training. Previous research efforts have not sufficiently explored students perceptions around the commitment and adequacy of effort spent on software engineering projects, their project performance and skills that are developed during course projects. This gap in skills awareness includes those that are necessary, anticipated and learned, and the challenges to student project success, which may predict project performance. Such insights could inform curricula design, theory and practice, in terms of improving post-study software development success. We conducted a survey involving undergraduate across four universities in New Zealand and Cyprus to explore these issues, where extensive deductive and inductive analyses were performed. Among our findings we observe that students’ commitment of effort on software engineering project seems appropriate. Students are more satisfied with their team’s collaboration performance than technical contributions, but we found that junior students seemed to struggle with teamwork. Further, we observe that the software students developed were of higher quality if they had worked in project teams previously, had stronger technical skills and were involved in timely meetings. This study singles out mechanisms for informing good estimation of effort, mentoring technical competencies and suitable coaching for enhancing project success and student learning.",https://doi.org/10.1016/j.jss.2021.111156,https://www.sciencedirect.com/science/article/pii/S0164121221002466,,,,2022,"Understanding students’ software development projects: Effort, performance, satisfaction, skills and their relation to the adequacy of outcomes developed",Sherlock A. Licorish and Matthias Galster and Georgia M. Kapitsaki and Amjed Tahir,article,LICORISH2022111156,Journal of Systems and Software,,186,0164-1212,,,
,"Side channel attack, GPU, WebGL, Differential Privacy",100135,,"In the past few years, graphics processing units (GPUs) have become an indispensable part of modern computer systems, not only for graphics rendering but also for intensive parallel computing. Given that many tasks running on GPUs contain sensitive information, security concerns have been raised, especially about potential GPU information leakage. Previous works have shown such concerns by showing that attackers can use GPU memory allocations or performance counters to measure victim side effects. However, such an attack has a critical drawback that it requires a victim to install desktop applications or mobile apps yielding it uneasy to be deployed in the real world. In this paper, we solve this drawback by proposing a novel GPU-based side-channel Geo-Privacy inference attack on the WebGL framework, namely, GLINT (stands for Geo-Location Inference Attack). GLINT merely utilizes a lightweight browser extension to measure the time elapsed to render a sequence of frames on well-known map websites, e.g., Google Maps, or Baidu Maps. The measured stream of time series is then employed to infer geologically privacy-sensitive information, such as a search on a specific location. Upon retrieving the stream, we propose a novel online segmentation algorithm for streaming data to determine the start and end points of privacy-sensitive time series. We then combine the DTW algorithm and KNN algorithm on these series to conclude the final inference on a user’s geo-location privacy. We conducted real-world experiments to testify our attack. The experiments show that GeoInfer can correctly infer more than 83% of user searches regardless of the locations and map websites, meaning that our Geo-Privacy inference attack is accurate, practical, and robust. To counter this attack, we implemented a defense strategy based on Differential Privacy to hinder obtaining accurate rendering data. We found that this defense mechanism managed to reduce the average accuracy of the attack model by more than 70%, indicating that the attack was no longer effective. We have fully implemented GLINT and open-sourced it for future follow-up research.",https://doi.org/10.1016/j.hcc.2023.100135,https://www.sciencedirect.com/science/article/pii/S2667295223000338,,,,2023,A novel GPU based Geo-Location Inference Attack on WebGL framework,Weixian Mai and Yinhao Xiao,article,MAI2023100135,High-Confidence Computing,4,3,2667-2952,,,
,"Text preprocessing, Natural Language Processing, Fake news, SVM, Bayes, Transformers, Deep learning, LSTM, Convolutional neural networks",102342,,"With the advent of the modern pre-trained Transformers, the text preprocessing has started to be neglected and not specifically addressed in recent NLP literature. However, both from a linguistic and from a computer science point of view, we believe that even when using modern Transformers, text preprocessing can significantly impact on the performance of a classification model. We want to investigate and compare, through this study, how preprocessing impacts on the Text Classification (TC) performance of modern and traditional classification models. We report and discuss the preprocessing techniques found in the literature and their most recent variants or applications to address TC tasks in different domains. In order to assess how much the preprocessing affects classification performance, we apply the three top referenced preprocessing techniques (alone or in combination) to four publicly available datasets from different domains. Then, nine machine learning models – including modern Transformers – get the preprocessed text as input. The results presented show that an educated choice on the text preprocessing strategy to employ should be based on the task as well as on the model considered. Outcomes in this survey show that choosing the best preprocessing technique – in place of the worst – can significantly improve accuracy on the classification (up to 25%, as in the case of an XLNet on the IMDB dataset). In some cases, by means of a suitable preprocessing strategy, even a simple Naïve Bayes classifier proved to outperform (i.e., by 2% in accuracy) the best performing Transformer. We found that Transformers and traditional models exhibit a higher impact of the preprocessing on the TC performance. Our main findings are: (1) also on modern pre-trained language models, preprocessing can affect performance, depending on the datasets and on the preprocessing technique or combination of techniques used, (2) in some cases, using a proper preprocessing strategy, simple models can outperform Transformers on TC tasks, (3) similar classes of models exhibit similar level of sensitivity to text preprocessing.",https://doi.org/10.1016/j.is.2023.102342,https://www.sciencedirect.com/science/article/pii/S0306437923001783,,,,2024,Is text preprocessing still worth the time? A comparative survey on the influence of popular preprocessing methods on Transformers and traditional classifiers,Marco Siino and Ilenia Tinnirello and Marco {La Cascia},article,SIINO2024102342,Information Systems,,121,0306-4379,,,
,"Continuous integration, Build prediction, Multi-Objective optimization, Search-Based software engineering, Machine learning",106392,,"Context: Continuous Integration (CI) is a common practice in modern software development and it is increasingly adopted in the open-source as well as the software industry markets. CI aims at supporting developers in integrating code changes constantly and quickly through an automated build process. However, in such context, the build process is typically time and resource-consuming which requires a high maintenance effort to avoid build failure. Objective: The goal of this study is to introduce an automated approach to cut the expenses of CI build time and provide support tools to developers by predicting the CI build outcome. Method: In this paper, we address problem of CI build failure by introducing a novel search-based approach based on Multi-Objective Genetic Programming (MOGP) to build a CI build failure prediction model. Our approach aims at finding the best combination of CI built features and their appropriate threshold values, based on two conflicting objective functions to deal with both failed and passed builds. Results: We evaluated our approach on a benchmark of 56,019 builds from 10 large-scale and long-lived software projects that use the Travis CI build system. The statistical results reveal that our approach outperforms the state-of-the-art techniques based on machine learning by providing a better balance between both failed and passed builds. Furthermore, we use the generated prediction rules to investigate which factors impact the CI build results, and found that features related to (1) specific statistics about the project such as team size, (2) last build information in the current build and (3) the types of changed files are the most influential to indicate the potential failure of a given build. Conclusion: This paper proposes a multi-objective search-based approach for the problem of CI build failure prediction. The performances of the models developed using our MOGP approach were statistically better than models developed using machine learning techniques. The experimental results show that our approach can effectively reduce both false negative rate and false positive rate of CI build failures in highly imbalanced datasets.",https://doi.org/10.1016/j.infsof.2020.106392,https://www.sciencedirect.com/science/article/pii/S0950584920301579,,,,2020,Predicting continuous integration build failures using evolutionary search,Islem Saidani and Ali Ouni and Moataz Chouchen and Mohamed Wiem Mkaouer,article,SAIDANI2020106392,Information and Software Technology,,128,0950-5849,,,
,"Biomedical and medical image processing and systems, Bio-signals analysis and interpretation, Bioinformatics, Human centred automation",6477-6483,,"Microscopy has been a key tool involved in many discoveries in the life sciences over the past centuries. In the last 30 years in particular, enormous progress has been made in developing this measurement technique further to make researchers working with it more effective. To combine gains in reproducibility and efficiency resulting from these advancements in different research areas, we present for the first time a unified and comprehensive concept for an end-to-end automated microscopy workflow. To this end, we employ both robotic and computational methods as well as holotomography microscopy. Considering the physical preparation and cleanup of a measurement, the image acquisition, and the management and analysis of the resulting data, we give a fine-grained workflow description. We present the robotic system to perform the manual process steps and a Python package to standardize the resulting proprietary image (meta)data. For the other tasks, we identify suitable open-source tools to execute them and apply them to our setup. The choice of holotomography as a suitable microscopy technique to realize this workflow is elucidated. We envision that the adoption of an automated workflow paves the way toward a future life science laboratory where microscopy-based research is carried out more efficiently and reproducibly than in the past.",https://doi.org/10.1016/j.ifacol.2023.10.862,https://www.sciencedirect.com/science/article/pii/S2405896323012429,,,,2023,Towards End-to-End Automated Microscopy Control using Holotomography: Workflow Design and Data Management,Henning Zwirnmann and Dennis Knobbe and Sami Haddadin,article,ZWIRNMANN20236477,IFAC-PapersOnLine,2,56,2405-8963,22nd IFAC World Congress,,
,"Subject librarians, Artificial intelligence generated content, Interpretive phenomenological analysis, Technology acceptance model, Influencing factor",e29584,,"To explore the factors affecting the use of artificial intelligence generated content (AIGC) by subject librarians through understanding their perceptions of AIGC. Interpretive phenomenological analysis (IPA) and technology acceptance model (TAM) were used in semi-structured interviews to explore the external variables of perceived ease of use and perceived usability of AIGC application in subject librarians. The perceptions of subject librarians towards AIGC included performance, risk perceptions, ability enhancement, and affective attitude. Attentions were paid to AIGC's performances in providing customized services, optimizing collection resources and improving cost efficiency. The risk perception involved technical stability, data security, user acceptance and occupational risk, the ability enhancement involved the improvement of personal literacy, innovative ability, and self-confidence through the use of AIGC technology, and the affective attitudes included not only excitement and anticipation for the technical potential of AIGC, but also concerns and skepticism about it, and critical attitudes toward its application in academic settings and the ethical issues it may raise. TAM analysis on the factors affecting the use of AIGC by subject librarians indicates that the external influencing factors of perceived ease of use include personal literacy, innovative ability, self-confidence enhancement and affective attitude; the external influencing factors of perceived usability include precise service, collection resource optimization, cost-effectiveness, technological risk, user acceptance and occupational risk. These factors constitute a theoretical framework for understanding and promoting the acceptance and effective use of AIGC by subject librarians. TAM analysis combined with IPA exploration on the external variables of perceived ease of use and perceived usability of AIGC application can identify the key factors affecting subject librarians' perceptions of AIGC, propose strategies for optimizing librarians' roles, enhancing information recognition ability and privacy protection, thus providing guidance for effective use of AIGC in library.",https://doi.org/10.1016/j.heliyon.2024.e29584,https://www.sciencedirect.com/science/article/pii/S2405844024056159,,,,2024,Factors affecting the use of artificial intelligence generated content by subject librarians: A qualitative study,Xiaowen Yang and Jingjing Ding and Haibo Chen and Hanzhen Ji,article,YANG2024e29584,Heliyon,8,10,2405-8440,,,
,"Customer Complaint Handling System, Customer Temperament, Data Mining, Correspondence Analysis, Interactive marketing",102520,,"One of the most significant sources of information from customers is customer complaints. Successful and effective complaint management can end complaint crises and ensure client loyalty, which is a sign of great service performance. In this paper, we proposed a novel customer temperament-centered and e-CCH system-based data collection and data mining method titled “3D” model for customer complaint data analysis. Three phases are (1) Development and launch of e-Customer Complaint Handling system, (2) Data collection and transfer of learning by e-Customer Complaint Handling system, and (3) Data mining by e-Customer Complaint Handling system. An advanced electronic Customer Complaint Handling System called the e-CCH system was then developed and launched. This system adapts the seasonal associations model based on Hippocrates's customer temperament theory to the whole stages of customer complaint reporting and handling. With this system, we conducted a dataset collection work from restaurant chains of two brands over four years. As a result, we collect thousands of real-world temperament-centred customer complaint cases by four years to form the one-of-a-kind CCH dataset. This one-of-a-kind CCH dataset was open-sourced with detailed customer complaint attributes and heuristic decision-making for valuable industrial handling manner. After further analysis of this dataset, we found that customers with different temperament types tend to have different types of complaints. In addition, adapting the temperament theory to the e-CCH system can classify customer types better and provide personalized solutions. To our best knowledge, this rich and the one-of-a-kind CCH dataset reported in this paper is the first comprehensive study of customer complaint handling in an industrial service management context. Meanwhile, data mining with cross analysis and correspondence analysis and an ChatGPT experiment for transfer of learning based on this yearly and one-of-a-kind industrial customer complaint dataset was analyzed and discussed. In addition, how this dataset may contribute to more realistic complaint-handling theoretic studies for better service failure recovery and interactive marketing is discussed in-depth.",https://doi.org/10.1016/j.aei.2024.102520,https://www.sciencedirect.com/science/article/pii/S147403462400168X,,,,2024,"Data Collection, data mining and transfer of learning based on customer temperament-centered complaint handling system and one-of-a-kind complaint handling dataset",Ching-Hung Lee and Xuejiao Zhao,article,LEE2024102520,Advanced Engineering Informatics,,60,1474-0346,,,
,"Information Security, APT, unknown domain, attack detection, attack monitoring",316-323,,"The increasing coverage of Internet has created opportunities and advantages for different aspects of society. However, there come new threats and challenges to information security. One of the typical types of attacks that has increasingly occurred is the APT attack (Advanced Persistent Threat). APT is dangerous with clear purposes. APT attacks employ different sophisticated methods and techniques attacking targets in order to steal confidential and sensitive information. In the past, hackers attacked information systems with personal and financial motives. However, there are nowadays other motives such as political ones and they are potentially backed by governments or nations. Nations that own advanced technologies such as United States, India, Russia, UK are also suffering from special purpose attacks. APT is an advanced type of attacks that consists of many stages and concrete strategies. Besides, techniques and technologies employed in APT attack are usually new and developed by hackers in order to break through the monitoring of security software. However, APT is normally implemented through concrete steps and stages. If one of the steps or stages fails, the entire APT attack will fail. This paper presents a method of detecting APT attacks based on monitoring accesses to unknown domains. This detection method results into high effectiveness in the initial stage of APT attacks.",https://doi.org/10.1016/j.procs.2019.02.058,https://www.sciencedirect.com/science/article/pii/S1877050919304041,,,,2019,A Method of Monitoring and Detecting APT Attacks Based on Unknown Domains,Do Xuan Cho and Ha Hai Nam,article,CHO2019316,Procedia Computer Science,,150,1877-0509,"Proceedings of the 13th International Symposium “Intelligent Systems 2018” (INTELS’18), 22-24 October, 2018, St. Petersburg, Russia",,
,"Botnet, Botnet detection, DNS-based Botnet detection, Network Security, DGA",28-52,,"Cybercrimes are evolving on a regular basis and as such these crimes are becoming a greater threat day by day. Earlier these threats were very general and unorganized. In the last decade, these attacks have become highly sophisticated in nature. This higher level of coordination is possible mainly due to botnets, which are clusters of infected hosts controlled remotely by an attacker (botmaster). The number of infected machines is continuously rising, thereby resulting in botnets with over a million infected machines. This powerful capability gives the botmaster a lethal weapon to launch various security attacks. As a result, botnet detection techniques received greater research focus. The Domain Name System (DNS) is a large scale distributed database on the Internet, which is being abused as a botnet communication channel. While there are numerous survey and review papers on botnet detection, there are two survey papers on DNS-based botnet detection which are neither comprehensive nor take into consideration various parameters vital for effective comparison. This survey presents a new classification for DNS-based botnet detection techniques and provides a deep analysis of each technique within the category.",https://doi.org/10.1016/j.cose.2019.05.019,https://www.sciencedirect.com/science/article/pii/S0167404819301117,,,,2019,Issues and challenges in DNS based botnet detection: A survey,Manmeet Singh and Maninder Singh and Sanmeet Kaur,article,SINGH201928,Computers & Security,,86,0167-4048,,,
,"Morality, Markets, Deontology, Consequentialism, Otree, Online experiment",101577,,"This paper investigates the impact of markets on moral reasoning. Whereas the current literature focuses on morally relevant decisions that arise in markets, little is known about whether the exposition to markets shapes subsequent moral reasoning. To close this gap, we run a large-scale online experiment with 3 conditions: In Baseline, participants make a choice in a moral dilemma. In the other two conditions, participants are exposed to either a Non-market or Market environment, before facing the identical choice in the moral dilemma. We hypothesize that being exposed to Market induces cost-benefit considerations, which translate into modified reasoning in the subsequent moral dilemma. Compared to the baseline distribution, we indeed find a substantial effect in Market. However, similar choices can be observed in Non-market. We discuss potential explanations for these results, and suggest avenues for future research.",https://doi.org/10.1016/j.socec.2020.101577,https://www.sciencedirect.com/science/article/pii/S221480431930535X,,,,2020,The impact of markets on moral reasoning: Evidence from an online experiment,Jonas Gehrlein and Ann-Kathrin Crede and Nana Adrian,article,GEHRLEIN2020101577,Journal of Behavioral and Experimental Economics,,87,2214-8043,,,
,"Polyurethane, Kinetics, Raspberry pi, Foam, Adiabatic temperature rise",e00365,,"Adiabatic temperature rise is an important method for determining isocyanate conversion in polyurethane foam reactions as well as many other exothermic chemical reactions. Adiabatic temperature rise can be used in conjunction with change in height and mass measurements to gain understanding into the blowing and gelling reactions that occur during polyurethane foaming as well as give important information on cell morphology. FoamPi is an open-source Raspberry Pi device for monitoring polyurethane foaming reactions. The device effectively monitors temperature rise, change in foam height as well as changes in the mass during the reaction. Three Python scripts are also presented. The first logs raw data during the reaction. The second corrects temperature data such that it can be used in adiabatic temperature rise reactions for calculating isocyanate conversion; additionally this script reduces noise in all the data and removes erroneous readings. The final script extracts important information from the corrected data such as maximum temperature change and maximum height change as well as the time to reach these points. Commercial examples of such equipment exist however the price (>£10000) of these equipment make these systems inaccessible for many research laboratories. The FoamPi build presented is inexpensive (£350) and test examples are shown here to indicate the reproducibility of results as well as precision of the FoamPi.",https://doi.org/10.1016/j.ohx.2022.e00365,https://www.sciencedirect.com/science/article/pii/S2468067222001109,,,,2022,FoamPi: An open-source raspberry Pi based apparatus for monitoring polyurethane foam reactions,Harry C. Wright and Duncan D. Cameron and Anthony J. Ryan,article,WRIGHT2022e00365,HardwareX,,12,2468-0672,,,
,"Blockchain, IA, IoT, Security countermeasures, Security vulnerabilities",100888,,"The current advances in the Internet of Things (IoT) and the solutions being offered by this technology have accounted IoT among the top ten technologies that will transform the global economy by 2030. IoT is a state-of-the-art paradigm that has developed traditional living into a high-tech lifestyle. The current study aims to provide a comprehensive review and analysis of the existing cybersecurity attacks and vulnerabilities in IoT, offering suitable countermeasures with a focus on describing the impact of emerging technologies on IoT devices and protocol layers. The main vulnerabilities across different layers of the IoT reference model are discussed and categorized, and suitable countermeasures (such as separating IT and IoT network traffic, enhancing physical security, implementing encryption and secure messaging protocols, etc.) are suggested. In addition, the hardware, communication, application, web, and cloud vulnerabilities are introduced, then the corresponding safeguards and protections are presented. Furthermore, Information Assurance (IA) has been deliberately defined and the adoption of the NIST framework and IA model is recommended as a metric to ensure security for IoT solutions considering the five pillars of availability, integrity, authentication, confidentiality, and non-repudiation. Finally, Blockchain technology, known for its use in securing cryptocurrencies, is suggested to facilitate secure data exchange, identification, authentication, and communication for IoT devices by various avenues including ensuring the integrity of sensor data, eliminating the need for intermediaries, reducing costs, and enabling direct addressability of IoT devices.",https://doi.org/10.1016/j.iot.2023.100888,https://www.sciencedirect.com/science/article/pii/S2542660523002111,,,,2023,A review of the security vulnerabilities and countermeasures in the Internet of Things solutions: A bright future for the Blockchain,Hossein Pourrahmani and Adel Yavarinasab and Amir Mahdi Hosseini Monazzah and Jan {Van herle},article,POURRAHMANI2023100888,Internet of Things,,23,2542-6605,,,
,", , , , Reproduction, Body condition, Gastrointestinal nematodes",221-231,,"Parasites can impact wildlife populations through their effects on host fitness and survival. The life history strategies of a parasite species can dictate the mechanisms and timing through which it influences the host. However, unravelling this species-specific effect is difficult as parasites generally occur as part of a broader community of co-infecting parasites. Here, we use a unique study system to explore how life histories of different abomasal nematode species may influence host fitness. We examined abomasal nematodes in two adjacent, but isolated, West Greenland caribou (Rangifer tarandus groenlandicus) populations. One herd of caribou were naturally infected with Ostertagia gruehneri, a common and dominant summer nematode of Rangifer sspp., and the other with Marshallagia marshalli (abundant; winter) and Teladorsagia boreoarcticus (less abundant; summer), allowing us to determine if these nematode species have differing effects on host fitness. Using a Partial Least Squares Path Modelling approach, we found that in the caribou infected with O. gruehneri, higher infection intensity was associated with lower body condition, and that animals with lower body condition were less likely to be pregnant. In caribou infected with M. marshalli and T. boreoarcticus, we found that only M. marshalli infection intensity was negatively related to body condition and pregnancy, but that caribou with a calf at heel were more likely to have higher infection intensities of both nematode species. The differing effects of abomasal nematode species on caribou health outcomes in these herds may be due to parasite species-specific seasonal patterns which influence both transmission dynamics and when the parasites have the greatest impact on host condition. These results highlight the importance of considering parasite life history when testing associations between parasitic infection and host fitness.",https://doi.org/10.1016/j.ijpara.2023.01.001,https://www.sciencedirect.com/science/article/pii/S0020751923000334,,,,2023,Life history matters: Differential effects of abomasal parasites on caribou fitness,Eleanor R Dickinson and Karin Orsel and Christine Cuyler and Susan J Kutz,article,DICKINSON2023221,International Journal for Parasitology,4,53,0020-7519,,,
,"Anomaly detection, Software-Defined Networking (SDN), Deep ensemble learning, Autoencoders, Probabilistic Neural Networks (PNNs), Internet of Thing (IoT)",100391,,"Internet of Things (IoT) devices are inherently vulnerable due to insecure design, implementation, and configuration. Aggressive behavior changes, due to increased attacker’s sophistication, and the heterogeneity of the data in IoT have proven that securing IoT devices trigger multiple challenges. It includes complex and dynamic attack detection, data imbalance, data heterogeneity, real-time response, and prediction capability. Most researchers are not focusing on the class imbalance, dynamic attack detection, and data heterogeneity problems together in Software-Defined Networking (SDN) enabled IoT anomaly detection. Thus, to address these challenging tasks, we propose DeL-IoT, a deep ensemble learning framework for IoT anomaly detection and prediction using SDN, having three primary modules including anomaly detection, intelligent flow management, and device status forecasting. The DeL-IoT employs deep and stacked autoencoders to extract handy features for stacking into an ensemble learning model. This framework yields efficient detection of anomalies, manages flows dynamically, and forecasts both short and long-term device status for early action. We validate the proposed DeL-IoT framework with testbed and benchmark datasets. We demonstrate that in even a 1% imbalanced dataset, the performance of our proposed method, deep feature extraction with a deep ensemble learning model, is around 3% better than the single model. The extensive experimental results show that our models have a better and more reliable performance than the competing models showcased in the relevant related work.",https://doi.org/10.1016/j.iot.2021.100391,https://www.sciencedirect.com/science/article/pii/S2542660521000354,,,,2021,DeL-IoT: A deep ensemble learning approach to uncover anomalies in IoT,Enkhtur Tsogbaatar and Monowar H. Bhuyan and Yuzo Taenaka and Doudou Fall and Khishigjargal Gonchigsumlaa and Erik Elmroth and Youki Kadobayashi,article,TSOGBAATAR2021100391,Internet of Things,,14,2542-6605,,,
,"Machine Learning, Natural Language Processing, Education, Twitter, Sentiment Analysis, fastText, TensorFlow, Scikit-Learn",394-399,,"This paper presents an interesting use case for learning as well as teaching basics of Machine Learning systems. Starting from a brief historical outline of the ML, the authors propose and compare a set of popular ML libraries in an interesting exemplary implementation, to present their usability. The paper also describes text classification methods, the aim of which is to distinguish positive and negative labels of particular messages within the Twitter social network. The study is summarized by a brief comparison of the quality of the classification of the libraries and methods used, as an assessment of their suitability. Final thoughts on the importance of teaching ML are included.",https://doi.org/10.1016/j.ifacol.2019.12.692,https://www.sciencedirect.com/science/article/pii/S2405896319326412,,,,2019,Classification of user attitudes in Twitter -beginners guide to selected Machine Learning libraries,Marta Sokolowska and Maciej Mazurek and Marcin Majer and Michal Podpora,article,SOKOLOWSKA2019394,IFAC-PapersOnLine,27,52,2405-8963,16th IFAC Conference on Programmable Devices and Embedded Systems PDES 2019,,
,"Ultra-high energy, Neutrinos, Neutrino telescope, Simulation, Tau regeneration, Open source",108422,,"In the past decade IceCube's observations have revealed a flux of astrophysical neutrinos extending to 107GeV. The forthcoming generation of neutrino observatories promises to grant further insight into the high-energy neutrino sky, with sensitivity reaching energies up to 1012GeV. At such high energies, a new set of effects becomes relevant, which was not accounted for in the last generation of neutrino propagation software. Thus, it is important to develop new simulations which efficiently and accurately model lepton behavior at this scale. We present TauRunner, a Python-based package that propagates neutral and charged leptons. TauRunner supports propagation between 10GeV and 1012GeV. The package accounts for all relevant secondary neutrinos produced in charged-current tau neutrino interactions. Additionally, tau energy losses of taus produced in neutrino interactions are taken into account, and treated stochastically. Finally, TauRunner is broadly adaptable to divers experimental setups, allowing for user-specified trajectories and propagation media, neutrino cross sections, and initial spectra.
Program summary
Program title: TauRunner CPC Library link to program files: https://doi.org/10.17632/82nyd9skhj.1 Developer's repository link: https://github.com/icecube/TauRunner Licensing provisions: GNU General Public License 3 Programming language: Python Nature of problem: Propagation of ultra-high energy neutrinos in dense media accounting for various effects associated with ντ and τ± energy losses. Solution method: Monte Carlo methods.",https://doi.org/10.1016/j.cpc.2022.108422,https://www.sciencedirect.com/science/article/pii/S0010465522001412,,,,2022,TauRunner: A public Python program to propagate neutral and charged leptons,Ibrahim Safa and Jeffrey Lazar and Alex Pizzuto and Oswaldo Vasquez and Carlos A. Argüelles and Justin Vandenbroucke,article,SAFA2022108422,Computer Physics Communications,,278,0010-4655,,,
,"Malware, Domain Generation Algorithms, Botnets, DNS, Algorithmically Generated Domain",103135,,"A crucial technical challenge for cybercriminals is to keep control over the potentially millions of infected devices that build up their botnets, without compromising the robustness of their attacks. A single, fixed C&C server, for example, can be trivially detected either by binary or traffic analysis and immediately sink-holed or taken-down by security researchers or law enforcement. Botnets often use Domain Generation Algorithms (DGAs), primarily to evade take-down attempts. DGAs can enlarge the lifespan of a malware campaign, thus potentially enhancing its profitability. They can also contribute to hindering attack accountability. In this work, we introduce HYDRAS, the most comprehensive and representative dataset of Algorithmically-Generated Domains (AGD) available to date. The dataset contains more than 100 DGA families, including both real-world and adversarially designed ones. We analyse the dataset and discuss the possibility of differentiating between benign requests (to real domains) and malicious ones (to AGDs) in real-time. The simultaneous study of so many families and variants introduces several challenges; nonetheless, it alleviates biases found in previous literature employing small datasets which are frequently overfitted, exploiting characteristic features of particular families that do not generalise well. We thoroughly compare our approach with the current state-of-the-art and highlight some methodological shortcomings in the actual state of practice. The outcomes obtained show that our proposed approach significantly outperforms the current state-of-the-art in terms of both classification performance and efficiency.",https://doi.org/10.1016/j.jnca.2021.103135,https://www.sciencedirect.com/science/article/pii/S1084804521001545,,,,2021,Intercepting Hail Hydra: Real-time detection of Algorithmically Generated Domains,Fran Casino and Nikolaos Lykousas and Ivan Homoliak and Constantinos Patsakis and Julio Hernandez-Castro,article,CASINO2021103135,Journal of Network and Computer Applications,,190,1084-8045,,,
,"Auction, Bayesian game, Critical value condition, DDoS attack, Differential payment, Marginal utility",193-204,,"DDoS attack is one of the most powerful cyber-weapons as it does not wait for a specific server configuration or particular network state to attack or to disrupt any operation of the target machine. Further, it does not require any huge investment and can cause enormous reputational and financial loss to the organization. Additionally, the uneven distribution of resources and incentives on Internet has paved an easy path for attackers to take the repercussions of DDoS attack to a challenging level. Malicious users cannot be assumed to obey network protocols or algorithms. In fact, they tried to take advantage of their knowledge about network to disrupt other users and to gain a maximum share of resources. Therefore, in this paper, we propose a Bayesian game theory-based solution to empower service provider to maximize the social welfare by employing incentives and pricing rules on the users of a network. The service provider and legitimate users are assumed to observe the network for a long time and gain probabilistic knowledge about another user being malicious or not. This probabilistic knowledge is utilized by the service provider and legitimate users to amend their actions to counteract malicious users present in the network. Considering these assumptions and facts, we propose Bayesian pricing and auction mechanism to achieve Bayesian Nash Equilibrium points in different scenarios where probabilistic information proves beneficial for legitimate users and service provider. Further, we propose a reputation assessment and updating mechanism where payment and participation parameters are considered to quantify user’s reliability. Extensive experimentation has been carried out using MatLab. We consider the rate of social welfare degradation and variation in user’s utility as parameters to validate the proposed model.",https://doi.org/10.1016/j.future.2020.11.027,https://www.sciencedirect.com/science/article/pii/S0167739X20330600,,,,2021,A reputation score policy and Bayesian game theory based incentivized mechanism for DDoS attacks mitigation and cyber defense,Amrita Dahiya and Brij B. Gupta,article,DAHIYA2021193,Future Generation Computer Systems,,117,0167-739X,,,
,"Web crawler detection, Reinforcement learning, Feature selection, Crawler diversity, Crawler dynamics",115-128,,"Crawler detection is always an important research topic in network security. With the development of web technology, crawlers are constantly updating and changing, and their types are becoming diverse. The diversity and dynamics of crawlers pose significant challenges for feature applicability and model robustness. Existing crawler detection methods can only detect a limited number of crawlers by predefined rules and can not cover all types of crawlers; worse, they can be completely invalidated by the emergence of new types of crawlers. In this paper, we propose a reinforcement learning based web crawler detection method for diversity and dynamics (WC3D), which is composed of a feature selector and a session classifier. The feature selector selects the appropriate feature set for different types of crawlers with deep deterministic policy gradient. The session classifier makes crawler detection and provides rewards to the feature selector. The two modules are trained jointly to optimize the feature selection and session classification processes. Extensive experiments demonstrate the existence of crawler diversity and that the proposed method is still highly robust against the new type of crawlers and achieves state-of-the-art performance even without considering the dynamics of the crawlers.",https://doi.org/10.1016/j.neucom.2022.11.059,https://www.sciencedirect.com/science/article/pii/S0925231222014473,,,,2023,Reinforcement learning based web crawler detection for diversity and dynamics,Yang Gao and Zunlei Feng and Xiaoyang Wang and Mingli Song and Xingen Wang and Xinyu Wang and Chun Chen,article,GAO2023115,Neurocomputing,,520,0925-2312,,,
,"Bug priority change, Open source software, Empirical study",112019,,"In issue tracking systems, each bug is assigned a priority level (e.g., Blocker, Critical, Major, Minor, or Trivial in JIRA from highest to lowest), which indicates the urgency level of the bug. In this sense, understanding bug priority changes helps to arrange the work schedule of participants reasonably, and facilitates a better analysis and resolution of bugs. According to the data extracted from JIRA deployed by Apache, a proportion of bugs in each project underwent priority changes after such bugs were reported, which brings uncertainty to the bug fixing process. However, there is a lack of in-depth investigation on the phenomenon of bug priority changes, which may negatively impact the bug fixing process. Thus, we conducted a quantitative empirical study on bugs with priority changes through analyzing 32 non-trivial Apache open source software projects. The results show that: (1) 8.3% of the bugs in the selected projects underwent priority changes; (2) the median priority change time interval is merely a few days for most (28 out of 32) projects, and half (50. 7%) of bug priority changes occurred before bugs were handled; (3) for all selected projects, 87.9% of the bugs with priority changes underwent only one priority change, most priority changes tend to shift the priority to its adjacent priority, and a higher priority has a greater probability to undergo priority change; (4) bugs that require bug-fixing changes of higher complexity or that have more comments are likely to undergo priority changes; and (5) priorities of bugs reported or allocated by a few specific participants are more likely to be modified, and maximally only one participant in each project tends to modify priorities.",https://doi.org/10.1016/j.jss.2024.112019,https://www.sciencedirect.com/science/article/pii/S0164121224000621,,,,2024,Bug priority change: An empirical study on Apache projects,Zengyang Li and Guangzong Cai and Qinyi Yu and Peng Liang and Ran Mo and Hui Liu,article,LI2024112019,Journal of Systems and Software,,212,0164-1212,,,
,"Internet of things (IoT) networks, Distributed Denial of Service (DDoS) attack, Consumer IoT (CIoT) devices, Machine learning algorithms, Botnet, IoT security",107726,,"From smart home to industrial automation to smart power grid, IoT- based solutions penetrate into every working field. These devices expand the attack surface and turned out to be an easy target for the attacker as resource constraint nature hinders the integration of heavy security solutions. Because IoT devices are less secured and operate mostly in unattended scenario, they perfectly justify the requirements of attacker to form botnet army to trigger Denial of Service attack on massive scale. Therefore, this paper presents a Machine Learning-based attack detection approach to identify the attack traffic in Consumer IoT (CIoT). This approach operates on local IoT network-specific attributes to empower low-cost machine learning classifiers to detect attack, at the local router. The experimental outcomes unveiled that the proposed approach achieved the highest accuracy of 0.99 which confirms that it is robust and reliable in IoT networks.",https://doi.org/10.1016/j.compeleceng.2022.107726,https://www.sciencedirect.com/science/article/pii/S0045790622000404,,,,2022,Smart defense against distributed Denial of service attack in IoT networks using supervised learning classifiers,B.B. Gupta and Pooja Chaudhary and Xiaojun Chang and Nadia Nedjah,article,GUPTA2022107726,Computers & Electrical Engineering,,98,0045-7906,,,
,"Crowdfunding, User-centered innovation, Design thinking",102-113,,"User-centered innovation has attracted considerable interest for exploiting emerging business ideas. We suggest a novel framework for discovering emerging business ideas and their combination with user-centered innovation in the software industry based on design thinking processes. We apply topic modeling to projects on Kickstarter which is one of the largest crowdfunding platforms in the world. We adopt conjoint analysis to find which topics are most preferred upon the platform in terms of the amount of funding that they have received. From our findings, the convergence of smart assistant services with various domains, such as tutoring mathematics and seeking job opportunities, is recommended as an emerging idea for software businesses. We also find that the ideas preferred in the US are different from those preferred in other countries. Our findings can be exploited effectively for decision support in establishing a new business model. Finally, this study contributes to discovering emerging business ideas by connecting user-centered innovation with a design thinking perspective.",https://doi.org/10.1016/j.dss.2018.10.013,https://www.sciencedirect.com/science/article/pii/S0167923618301702,,,,2019,Discovering emerging business ideas based on crowdfunded software projects,Won Sang Lee and So Young Sohn,article,LEE2019102,Decision Support Systems,,116,0167-9236,,,
,"Vaccine hesitancy, Health communication, Social media, Network analysis",100019,,"In recent years, vaccination rates in the Netherlands have declined slightly, but steadily. The Dutch National Institute for Public Health and the Environment (RIVM) commissioned a Committee for Vaccine Willingness (VWC) to study the societal context of the decline. One of the societal contexts is the Internet, where audiences discuss vaccination and refer to sources of health-related information of varying quality. Working for the VWC, we have explored the Dutch vaccination debate on Twitter in order to: (1) identify online communities in the vaccination debate, (2) identify vaccine-related narratives; and (3) understand how the online communities interact with each other. We identified seven different communities, including (public) health professionals, writers and journalists, anti-establishment, and international vaccination advocates. The debate is spearheaded by the writers & journalists community, while the health- and anti-establishment communities try to influence it. The health community circulates facts, figures and scientific studies, while negative messages about vaccination – either from a homeopathy or conspiracy perspective – are most prevalent in the anti-establishment. The facts and figures shared by the health community hardly reach other communities, whereas the myths introduced by the anti-establishment do spill over to other communities. Our study provides further evidence that negative perceptions about vaccination might be rooted in a wider sentiment of distrust of traditional institutions. We argue that Dutch health organizations should try to address questions, doubts, and worries among the general audience more actively, and present scientific information in a simpler and more attractive way.",https://doi.org/10.1016/j.jvacx.2019.100019,https://www.sciencedirect.com/science/article/pii/S2590136219300208,,,,2019,"Mapping the Dutch vaccination debate on Twitter: Identifying communities, narratives, and interactions",Roel O. Lutkenhaus and Jeroen Jansz and Martine P.A. Bouman,article,LUTKENHAUS2019100019,Vaccine: X,,1,2590-1362,,,
,"Logging, Software evolution, Software repository mining, Software transformation, Degree of interest",102724,,"Logging—used for system events and security breaches to describe more informational yet essential aspects of software features—is pervasive. Given the high transactionality of today's software, logging effectiveness can be reduced by information overload. Log levels help alleviate this problem by correlating a priority to logs that can be later filtered. As software evolves, however, levels of logs documenting surrounding feature implementations may also require modification as features once deemed important may have decreased in urgency and vice-versa. We present an automated approach that assists developers in evolving levels of such (feature) logs. The approach, based on mining Git histories and manipulating a degree of interest (DOI) model,1 transforms source code to revitalize feature log levels based on the “interestingness” of the surrounding code. Built upon JGit and Mylyn, the approach is implemented as an Eclipse IDE plug-in and evaluated on 18 Java projects with ∼3 million lines of code and ∼4K log statements. Our tool successfully analyzes 99.22% of logging statements, increases log level distributions by ∼20%, and increases the focus of logs in bug fix contexts ∼83% of the time. Moreover, pull (patch) requests were integrated into large and popular open-source projects. The results indicate that the approach is promising in assisting developers in evolving feature log levels.",https://doi.org/10.1016/j.scico.2021.102724,https://www.sciencedirect.com/science/article/pii/S0167642321001179,,,,2022,Automated evolution of feature logging statement levels using Git histories and degree of interest,Yiming Tang and Allan Spektor and Raffi Khatchadourian and Mehdi Bagherzadeh,article,TANG2022102724,Science of Computer Programming,,214,0167-6423,,,
,"Mars, Global DTM, CTX, HiRISE, CASP-GO, Clouds computing",30-58,,"Digital Terrain Model (DTM) creation is essential to improving our understanding of the formation processes of the Martian surface. Although there have been previous demonstrations of open-source or commercial planetary 3D reconstruction software, planetary scientists are still struggling with creating good quality DTMs that meet their science needs, especially when there is a requirement to produce a large number of high quality DTMs using “free” software. In this paper, we describe a new open source system to overcome many of these obstacles by demonstrating results in the context of issues found from experience with several planetary DTM pipelines. We introduce a new fully automated multi-resolution DTM processing chain for NASA Mars Reconnaissance Orbiter (MRO) Context Camera (CTX) and High Resolution Imaging Science Experiment (HiRISE) stereo processing, called the Co-registration Ames Stereo Pipeline (ASP) Gotcha Optimised (CASP-GO), based on the open source NASA ASP. CASP-GO employs tie-point based multi-resolution image co-registration, and Gotcha sub-pixel refinement and densification. CASP-GO pipeline is used to produce planet-wide CTX and HiRISE DTMs that guarantee global geo-referencing compliance with respect to High Resolution Stereo Colour imaging (HRSC), and thence to the Mars Orbiter Laser Altimeter (MOLA); providing refined stereo matching completeness and accuracy. All software and good quality products introduced in this paper are being made open-source to the planetary science community through collaboration with NASA Ames, United States Geological Survey (USGS) and the Jet Propulsion Laboratory (JPL), Advanced Multi-Mission Operations System (AMMOS) Planetary Data System (PDS) Pipeline Service (APPS-PDS4), as well as browseable and visualisable through the iMars web based Geographic Information System (webGIS) system.",https://doi.org/10.1016/j.pss.2018.02.012,https://www.sciencedirect.com/science/article/pii/S0032063317303252,,,,2018,Massive stereo-based DTM production for Mars on cloud computers,Y. Tao and J.-P. Muller and P. Sidiropoulos and Si-Ting Xiong and A.R.D. Putri and S.H.G. Walter and J. Veitch-Michaelis and V. Yershov,article,TAO201830,Planetary and Space Science,,154,0032-0633,,,
,"Incivility, Big data, Political participation, Political advertising",368-377,,"Using the 2012 presidential election as a case study, this work set out to understand the relationship between negative political advertising and political incivility on Twitter. Drawing on the stimulation hypothesis and the notion that communication with dissimilar others can encourage incivility, it was predicted that (1) heightened levels of negative campaign advertising would be associated with increased citizen activity on Twitter, (2) increased citizen activity would predict online incivility, and (3) that increases in citizen activity would facilitate a positive indirect relationship between negative advertising volume and citizen incivility. This theoretical model was tested using data collected from over 140,000 individual Twitter users located in 206 Designated Market Areas. The results supported the proposed model. Additional analyses further suggested that the relationship between negative political advertising and citizen incivility was conditioned by contextual levels of economic status. These results are discussed in the context of political advertising and democratic deliberation.",https://doi.org/10.1016/j.chb.2016.11.034,https://www.sciencedirect.com/science/article/pii/S0747563216307750,,,,2017,Does negative campaign advertising stimulate uncivil communication on social media? Measuring audience response using big data,Toby Hopp and Chris J. Vargo,article,HOPP2017368,Computers in Human Behavior,,68,0747-5632,,,
,"Botnet, DDoS, Command Control server, Tactics",103768,,"Mobile malware is a malicious code specifically designed to target mobile devices to perform multiple types of fraud. The number of attacks reported each day is increasing constantly and is causing an impact not only at the end-user level but also at the network operator level. Malware like FluBot contributes to identity theft and data loss but also enables remote Command & Control (C2) operations, which can instrument infected devices to conduct Distributed Denial of Service (DDoS) attacks. Current mobile device-installed solutions are not effective, as the end user can ignore security warnings or install malicious software. This article designs and evaluates MONDEO-Tactics5G - a multistage botnet detection mechanism that does not require software installation on end-user devices, together with tactics for 5G network operators to manage infected devices. We conducted an evaluation that demonstrates high accuracy in detecting FluBot malware, and in the different adaptation strategies to reduce the risk of DDoS while minimising the impact on the clients' satisfaction by avoiding disrupting established sessions.",https://doi.org/10.1016/j.cose.2024.103768,https://www.sciencedirect.com/science/article/pii/S0167404824000695,,,,2024,MONDEO-Tactics5G: Multistage botnet detection and tactics for 5G/6G networks,Bruno Sousa and Duarte Dias and Nuno Antunes and Javier Cámara and Ryan Wagner and Bradley Schmerl and David Garlan and Pedro Fidalgo,article,SOUSA2024103768,Computers & Security,,140,0167-4048,,,
,"Intrinsic antibiotic resistance, Outer membrane permeability, Cationic antimicrobial peptides, Enterobacter cloacae complex, Neonatal sepsis, KexD",108-121,,"ABSTRACT
Objectives
A concern with the ESKAPE pathogen, Enterobacter bugandensis, and other species of the Enterobacter cloacae complex, is the frequent appearance of multidrug resistance against last-resort antibiotics, such as polymyxins.
Methods
Here, we investigated the responses to polymyxin B (PMB) in two PMB-resistant E. bugandensis clinical isolates by global transcriptomics and deletion mutagenesis.
Results
In both isolates, the genes of the CrrAB-regulated operon, including crrC and kexD, displayed the highest levels of upregulation in response to PMB. ∆crrC and ∆kexD mutants became highly susceptible to PMB and lost the heteroresistant phenotype. Conversely, heterologous expression of CrrC and KexD proteins increased PMB resistance in a sensitive Enterobacter ludwigii clinical isolate and in the Escherichia coli K12 strain, W3110. The efflux pump, AcrABTolC, and the two component regulators, PhoPQ and CrrAB, also contributed to PMB resistance and heteroresistance. Additionally, the lipid A modification with 4-L-aminoarabinose (L-Ara4N), mediated by the arnBCADTEF operon, was critical to determine PMB resistance. Biochemical experiments, supported by mass spectrometry and structural modelling, indicated that CrrC is an inner membrane protein that interacts with the membrane domain of the KexD pump. Similar interactions were modeled for AcrB and AcrD efflux pumps.
Conclusion
Our results support a model where drug efflux potentiated by CrrC interaction with membrane domains of major efflux pumps combined with resistance to PMB entry by the L-Ara4N lipid A modification, under the control of PhoPQ and CrrAB, confers the bacterium high-level resistance and heteroresistance to PMB.",https://doi.org/10.1016/j.jgar.2024.03.012,https://www.sciencedirect.com/science/article/pii/S2213716524000626,,,,2024,Drug efflux and lipid A modification by 4-L-aminoarabinose are key mechanisms of polymyxin B resistance in the sepsis pathogen Enterobacter bugandensis,Inmaculada García-Romero and Mugdha Srivastava and Julia Monjarás-Feria and Samuel O. Korankye and Lewis MacDonald and Nichollas E. Scott and Miguel A. Valvano,article,GARCIAROMERO2024108,Journal of Global Antimicrobial Resistance,,37,2213-7165,,,
,"Smart cities, Network datasets, Cybersecurity applications, Machine learning, Edge, Software-Defined Network (SDN), Network Function Virtualization (NFV), Service Orchestration (SO)",102994,,"While there has been a significant interest in understanding the cyber threat landscape of Internet of Things (IoT) networks, and the design of Artificial Intelligence (AI)-based security approaches, there is a lack of distributed architecture led to generating heterogeneous datasets that contain the actual behaviors of real-world IoT networks and complex cyber threat scenarios to evaluate the credibility of the new systems. This paper presents a novel testbed architecture of IoT network which can be used to evaluate Artificial Intelligence (AI)-based security applications. The platform NSX vCloud NFV was employed to facilitate the execution of Software-Defined Network (SDN), Network Function Virtualization (NFV) and Service Orchestration (SO) to offer dynamic testbed networks, which allow the interaction of edge, fog and cloud tiers. While deploying the architecture, real-world normal and attack scenarios are executed to collect labeled datasets. The generated datasets are named ‘TON_IoT’, as they comprise heterogeneous data sources collected from telemetry datasets of IoT services, Windows and Linux-based datasets, and datasets of network traffic. The TON_IoT network dataset is validated using four machine learning-based intrusion detection algorithms of Gradient Boosting Machine, Random Forest, Naive Bayes, and Deep Neural Networks, revealing a high performance of detection accuracy using the set of training and testing. A comparative summary of the TON_IoT network dataset and other competing network datasets demonstrates its diverse legitimate and anomalous patterns that can be used to better validate new AI-based security solutions. The architecture and datasets can be publicly accessed from TON_IOT Datasets (2020).",https://doi.org/10.1016/j.scs.2021.102994,https://www.sciencedirect.com/science/article/pii/S2210670721002808,,,,2021,A new distributed architecture for evaluating AI-based security systems at the edge: Network TON_IoT datasets,Nour Moustafa,article,MOUSTAFA2021102994,Sustainable Cities and Society,,72,2210-6707,,,
,"Adaptive gamification, Collaborative systems, Systematic mapping",100333,,"Mass collaboration mediated by technology is now commonplace (Wikipedia, Quora, TripAdvisor). Online, mass collaboration is also present in science in the form of Citizen Science. These collaboration models, which have a large community of contributors coordinated to pursue a common goal, are known as Collaborative systems. This article introduces a study of the published research on the application of adaptive gamification to collaborative systems. The study focuses on works that explicitly discuss an approach of personalization or adaptation of the gamification elements in this type of system. It employs a systematic mapping design in which a categorical structure for classifying the research results is proposed based on the topics that emerged from the papers review. The main contributions of this paper are a formalization of the adaptation strategies and the proposal of a new taxonomy for gamification elements adaptation. The results evidence the lack of research literature in the study of adapting gamification in the field of collaborative systems. Considering the underlying cultural diversity in those projects, the adaptability of gamification design and strategies is a promissory research field.",https://doi.org/10.1016/j.cosrev.2020.100333,https://www.sciencedirect.com/science/article/pii/S1574013720304330,,,,2021,"Adaptive gamification in Collaborative systems, a systematic mapping study",María {Dalponte Ayastuy} and Diego Torres and Alejandro Fernández,article,DALPONTEAYASTUY2021100333,Computer Science Review,,39,1574-0137,,,
,"COVID-19 propagation, Human mobility, Power law scaling, Allometric model, Scalefree dynamics",122-133,,"We analyzed the number of cumulative positive cases of COVID-19 as a function of time in countries around the World. We tracked the increase in cases from the onset of the pandemic in each region for up to 150 days. We found that in 81 out of 146 regions the trajectory was described with a power-law function for up to 30 days. We also detected scale-free properties in the majority of sub-regions in Australia, Canada, China, and the United States (US). We developed an allometric model that was capable of fitting the initial phase of the pandemic and was the best predictor for the propagation of the illness for up to 100 days. We then determined that the power-law COVID-19 exponent correlated with measurements of human mobility. The COVID-19 exponent correlated with the magnitude of air passengers per country. This correlation persisted when we analyzed the number of air passengers per US states, and even per US metropolitan areas. Furthermore, the COVID-19 exponent correlated with the number of vehicle miles traveled in the US. Together, air and vehicular travel explained 70% of the variability of the COVID-19 exponent. Taken together, our results suggest that the scale-free propagation of the virus is present at multiple geographical scales and is correlated with human mobility. We conclude that models of disease transmission should integrate scale-free dynamics as part of the modeling strategy and not only as an emergent phenomenological property.",https://doi.org/10.1016/j.idm.2021.12.003,https://www.sciencedirect.com/science/article/pii/S2468042721000841,,,,2022,The allometric propagation of COVID-19 is explained by human travel,Rohisha Tuladhar and Paolo Grigolini and Fidel Santamaria,article,TULADHAR2022122,Infectious Disease Modelling,1,7,2468-0427,,,
,,11021-11031,,"ABSTRACT
Nanotechnology governance, particularly in relation to human and environmental concerns, remains a contested domain. In recent years, the creation of both a risk governance framework and council has been actively pursued. Part of the function of a governance framework is the communication to external stakeholders. Existing descriptions on the public perceptions of nanotechnology are generally positive with the attendant economic and societal benefits being forefront in that thinking. Debates on nanomaterials' risk tend to be dominated by expert groupings while the general public is largely unaware of the potential hazards. Communicating via social media has become an integral part of everyday life facilitating public connectedness around specific topics that was not feasible in the pre-digital age. When civilian passive stakeholders become active their frustration can quickly coalesce into a campaign of resistance, and once an issue starts to develop into a campaign it is difficult to ease the momentum. Simmering discussions with moderate local attention can gain international exposure resulting in pressure and it can, in some cases, quickly precipitate legislative action and/or economic consequences. This paper highlights the potential of such a runaway, twitterstorm. We conducted a sentiment analysis of tweets since 2006 focusing on silver, titanium and carbon-based nanomaterials. We further examined the sentiment expressed following the decision by the European Food Safety Authority (EFSA) to phase out the food additive titanium dioxide (E 171). Our analysis shows an engaged, attentive public, alert to announcements from industry and regulatory bodies. We demonstrate that risk governance frameworks, particularly the communication aspect of those structures must include a social media blueprint to counter misinformation and alleviate the potential impact of a social media induced regulatory and economic reaction.",https://doi.org/10.1039/d1ra09383e,https://www.sciencedirect.com/science/article/pii/S2046206922006313,,,,2022,The risk perception of nanotechnology: evidence from twitter,Finbarr Murphy and Ainaz Alavi and Martin Mullins and Irini Furxhi and Arash Kia and Myles Kingston,article,MURPHY202211021,RSC Advances,18,12,2046-2069,,,
,,7-13,,"In mid-October, a distributed denial of service (DDoS) attack hit the headlines in a big way. Targeting DNS service provider Dyn, it rendered a significant portion of the Internet inoperable and left many high-profile web services unreachable for several hours. But while this was arguably the most visible DDoS attack in history, it's only one among many. In this interview, Paul Nicholson, responsible for global product marketing and strategy at A10 Networks, talks about how DDoS is becoming an ever-growing threat and what organisations can do about it. We’ve just witnessed the biggest distributed denial of service (DDoS) attacks in history, which turned seemingly harmless devices such as video recorders into cyber-weapons. With both the scale and frequency of attacks increasing, many organisations are left wondering how they can protect themselves and how those defences should be deployed, whether on-premise or in the cloud. In this interview with Paul Nicholson of A10 Networks, we examine how DDoS is becoming an ever-growing threat and what organisations can do about it.",https://doi.org/10.1016/S1353-4858(16)30104-0,https://www.sciencedirect.com/science/article/pii/S1353485816301040,,,,2016,DDoS goes mainstream: how headline-grabbing attacks could make this threat an organisation's biggest nightmare,Steve Mansfield-Devine,article,MANSFIELDDEVINE20167,Network Security,11,2016,1353-4858,,,
,"Cyber Physical System, Medical Cyber Physical System, Smart Devices, Cyber Security in E-healthcare, Issues, Challenges in MCPS",647-655,,"In the previous decade, many technologies have attracted attention from several research communities. Internet of Things (IoT) is main invention of the recent/ past decade. When these smart devices or internet connected devices are interact together, then they create a cyber infrastructure. These cyber infrastructures face several serious concerns privacy, trust, security, etc. These smart devices make an automatic environment (executed without the intervention of a human) in applications likedefense, manufacturing, e-healthcare, etc. In e-healthcare, these devices built the structure of Medical Cyber Physical System (MCPS). MCPS are facing several critical issues and challenges in current era, i.e., several attacks, issues and challenges which we require to overcome in current and next decade to provide efficient and reliable service to patients. MCPS is need of smart healthcare and require attention from several research communities towards its raised issue. Hence, this article provides a detailed study about CPS, MCPS, mitigated attacks on same architecture (CPS and MCPS), issues and challenges in CPS/ MCPS, including several research gaps in CPS/ MCPS (with opportunities for future researchers).",https://doi.org/10.1016/j.procs.2020.01.059,https://www.sciencedirect.com/science/article/pii/S1877050920300673,,,,2019,Medical Cyber Physical Systems and Its Issues,Meghna Manoj Nair and Amit Kumar Tyagi and Richa Goyal,article,NAIR2019647,Procedia Computer Science,,165,1877-0509,"2nd International Conference on Recent Trends in Advanced Computing ICRTAC -DISRUP - TIV INNOVATION , 2019 November 11-12, 2019",,
,"Hydrodynamics, Supersaturation, Crystal morphology, Porosity reduction",103885,,"The naturally occurring bio-geochemical microbial-induced calcium carbonate precipitation (MICP) process is an eco-friendly technology for rehabilitating construction materials, reinforcement of soils and sand, heavy metals immobilization and sealing subsurface leakage pathways. We report pore-scale spatiotemporal dynamics of the MICP process in porous media, relevant for reduced environmental risk by leakage during CO2 geological storage. Effects of hydrodynamics and supersaturation on the MICP with Sporosarcina pasteurii stains were studied using a high-pressure, rock-on-a-chip microfluidic device. Bacterial cell numbers and variation in cementation concentration controlled the crystal size and pore-scale distribution by influencing the local supersaturation. Local pore structure determined crystal nucleation, where low velocity regions tended to nucleate more crystals. CaCO3 crystallization was observed at subsurface pressure (100 barg) with a reduced sealing performance due to the low microbial activity from elevated pressure. We identify that hydrodynamics and supersaturation determine crystal nucleation and growth in porous systems, providing important experimental evidence for subsurface environmental applications and validation of upscaled MICP models.",https://doi.org/10.1016/j.ijggc.2023.103885,https://www.sciencedirect.com/science/article/pii/S1750583623000555,,,,2023,Pore-scale spatiotemporal dynamics of microbial-induced calcium carbonate growth and distribution in porous media,Na Liu and Malin Haugen and Benyamine Benali and David Landa-Marbán and Martin A. Fernø,article,LIU2023103885,International Journal of Greenhouse Gas Control,,125,1750-5836,,,
,"Arterial input function, Quantitative perfusion, Dynamic contrast enhanced MRI, Colorectal cancer, Segmentation",116-123,,Development of a deterministic algorithm for automated detection of the Arterial Input Function (AIF) in DCE-MRI of colorectal cancer. Using a filter pipeline to determine the AIF region of interest. Comparison to algorithms from literature with mean squared error and quantitative perfusion parameter Ktrans. The AIF found by our algorithm has a lower mean squared error (0.0022 ± 0.0021) in reference to the manual annotation than comparable algorithms. The error of Ktrans (21.52 ± 17.2%) is lower than that of other algorithms. Our algorithm generates reproducible results and thus supports a robust and comparable perfusion analysis.,https://doi.org/10.1016/j.mri.2020.09.009,https://www.sciencedirect.com/science/article/pii/S0730725X20302423,,,,2021,Deterministic Arterial Input Function selection in DCE-MRI for automation of quantitative perfusion calculation of colorectal cancer,Christian Tönnes and Sonja Janssen and Alena-Kathrin Golla and Tanja Uhrig and Khanlian Chung and Lothar R. Schad and Frank Gerrit Zöllner,article,TONNES2021116,Magnetic Resonance Imaging,,75,0730-725X,,,
,"Social networks, User characteristics, Twitter, Theory of planned behavior, Subjective norm, Following to follower",674-687,,"In this paper we study a dozen of rumors on Twitter to find new insights in user characteristics and macro patterns in the process of rumor spreading. The collection and curation of data has left us with 12 rumor datasets out of 56,852 tweets from 43,919 users. The analysis over data shows users with lower ratio of following-to-follower are more probable to spark the rumor diffusion while users with the higher ratio are those who keep the flame alive. Furthermore, most users participate in the process of rumor spreading only once which implies the nature of rumor spreading is not a recurrent activity. However, among those users who engage with multi posts, the extreme change of state from rumor spreader to anti-rumor spreader happens to users with higher ratio of following-to-follower. We discuss these findings by employing the theory of planned behavior. Finally, analyzing the process of rumor spreading at the macro level revealed the existence of two distinctive patterns. Further investigations showed the extent of time gap between the beginning of rumor and anti-rumor diffusion plays the major role in emerging of these patterns. This phenomenon is explained by the shift in subjective norm toward rumors on social media.",https://doi.org/10.1016/j.comcom.2020.07.017,https://www.sciencedirect.com/science/article/pii/S0140366420304060,,,,2020,The characteristics of rumor spreaders on Twitter: A quantitative analysis on real data,Amirhosein Bodaghi and Jonice Oliveira,article,BODAGHI2020674,Computer Communications,,160,0140-3664,,,
,"altmetrics, alternative metrics, social media, research evaluation, research ­impact, social networks.",127-136,Managing Scientific Information and Research Data,"Scholars are communicating in many different spheres today, using social media, mobile technology, and cloud computing. Until now, research has been evaluated using citation metrics such as the impact factor (IF) and h-index. As scholarly communication has shifted now mostly to online, other methods are needed to bring attention to research and measure its impact. Altmetrics, a new field that is creating and using such alternative metrics, takes into account not just citation counts of articles published in peer-reviewed journals. It involves collecting information from different sources and measuring interest in articles, people, journals, datasets, presentations, and other artifacts by monitoring views, downloads, “likes,” and mentions in social networks and the news media. Researchers engaging in social networks now rely on recommendations from their peers about newly published articles. Altmetrics tools allow them to see what others are reading, saving, and commenting on. This chapter presents an overview of the area of altmetrics and discusses how it is affecting the dissemination of scientific information and its evaluation.",https://doi.org/10.1016/B978-0-08-100195-0.00014-7,https://www.sciencedirect.com/science/article/pii/B9780081001950000147,,Chandos Publishing,978-0-08-100195-0,2015,14 - Measuring attention: social media and altmetrics,Svetla Baykoucheva,incollection,BAYKOUCHEVA2015127,,,,,,Svetla Baykoucheva,
,"Initial coin offerings, Cryptocurrency, Heterogeneous knowledge, Text analytics",113574,,"Initial coin offering (ICO) is a new financing method that has been widely used in cryptocurrency projects. However, it has been reported that nearly 30% of cryptocurrency projects fail during ICO, indicating an important gap in research and an opportunity for more advanced research on ICO project assessment. This study reveals that previous studies primarily used project-related factors to predict ICO success while neglecting social factors such as team information and expert evaluation. Inspired by the knowledge-based theory (KBT) of the firm, we set out to examine the impact of heterogeneous team knowledge and expert evaluation on ICO success. One primary contribution of this study is the design of novel knowledge measures based on KBT. In addition, we propose a deep-learning model – an attention-based bidirectional recurrent neural network (A-BiRNN) – to automatically extract features from online comments. We validate the proposed model on a real-world dataset, and experiments show that the accuracy of the proposed prediction model outperforms those of existing models by more than 6%, highlighting the effectiveness of the proposed approach in predicting ICO success. This study's results provide useful ideas for both investors and ICO platforms to assess the quality of cryptocurrency projects, thus improving information symmetry in ICO markets. Also, this study demonstrates the value of applying KBT in assessing firm performance in ICO markets. The generalized value of the proposed approach should be tested in more business contexts, such as crowdfunding and peer-to-peer (P2P) lending.",https://doi.org/10.1016/j.dss.2021.113574,https://www.sciencedirect.com/science/article/pii/S0167923621000841,,,,2021,Prediction of initial coin offering success based on team knowledge and expert evaluation,Wei Xu and Ting Wang and Runyu Chen and J. Leon Zhao,article,XU2021113574,Decision Support Systems,,147,0167-9236,,,
,"COVID-19, Influenza, Respiratory syncytial virus, Compartmental model, Forecasting, Scenario Planning, Pipeline, Open-source Software",100753,,"The COVID-19 pandemic led to an unprecedented demand for projections of disease burden and healthcare utilization under scenarios ranging from unmitigated spread to strict social distancing policies. In response, members of the Johns Hopkins Infectious Disease Dynamics Group developed flepiMoP (formerly called the COVID Scenario Modeling Pipeline), a comprehensive open-source software pipeline designed for creating and simulating compartmental models of infectious disease transmission and inferring parameters through these models. The framework has been used extensively to produce short-term forecasts and longer-term scenario projections of COVID-19 at the state and county level in the US, for COVID-19 in other countries at various geographic scales, and more recently for seasonal influenza. In this paper, we highlight how the flepiMoP has evolved throughout the COVID-19 pandemic to address changing epidemiological dynamics, new interventions, and shifts in policy-relevant model outputs. As the framework has reached a mature state, we provide a detailed overview of flepiMoP’s key features and remaining limitations, thereby distributing flepiMoP and its documentation as a flexible and powerful tool for researchers and public health professionals to rapidly build and deploy large-scale complex infectious disease models for any pathogen and demographic setup.",https://doi.org/10.1016/j.epidem.2024.100753,https://www.sciencedirect.com/science/article/pii/S1755436524000148,,,,2024,flepiMoP: The evolution of a flexible infectious disease modeling pipeline during the COVID-19 pandemic,Joseph C. Lemaitre and Sara L. Loo and Joshua Kaminsky and Elizabeth C. Lee and Clifton McKee and Claire Smith and Sung-mok Jung and Koji Sato and Erica Carcelen and Alison Hill and Justin Lessler and Shaun Truelove,article,LEMAITRE2024100753,Epidemics,,47,1755-4365,,,
,"5G, Denial of service, Intrusion detection systems, Source-side detection, Knowledge acquisition",114-131,,"This paper introduces a novel approach for detecting the participation of a protected network device in flooding-based Distributed Denial of Service attacks. With this purpose, the traffic flows are inspected at source-side looking for discordant behaviors. In contrast to most previous solutions, the proposal assumes the non-stationarity and heterogeneity inherent in the emergent communication environment. In particular, the approach takes advantage of the monitorization and knowledge acquisition capabilities implemented in the SELFNET (H2020-ICT-2014-2/671672) project, which facilitates its implementation as a self-organizing solution on 5G mobile networks. Monitorization, feature extraction and knowledge acquisition tasks are carried out on centralized control plane, hence the proposed architecture minimizes the impact on operational performance and prompts the end-points mobility. The preliminary results observed when considering different metrics, adjustment parameters, and a dataset with traffic observed in 61 real devices proven efficiency when distinguishing normal activities from DDoS behaviors of different intensity. With an optimal granularity selection, the highest AUC reached values close to 1.0 when measured under the most intense attacks, hence demonstrating optimal TPR and FPR relationships by adapting to the instantiated use cases.",https://doi.org/10.1016/j.jnca.2019.02.030,https://www.sciencedirect.com/science/article/pii/S108480451930089X,,,,2019,Traffic-flow analysis for source-side DDoS recognition on 5G environments,Marco Antonio {Sotelo Monge} and Andrés {Herranz González} and Borja {Lorenzo Fernández} and Diego {Maestre Vidal} and Guillermo {Rius García} and Jorge {Maestre Vidal},article,SOTELOMONGE2019114,Journal of Network and Computer Applications,,136,1084-8045,,,
,"Generative adversarial networks (GANs), Societal impacts, Algorithmic bias, Data augmentation, Social media",103652,,"In this paper, we show that popular Generative Adversarial Network (GAN) variants exacerbate biases along the axes of gender and skin tone in the generated data. The use of synthetic data generated by GANs is widely used for a variety of tasks ranging from data augmentation to stylizing images. While practitioners celebrate this method as an economical way to obtain synthetic data to train data-hungry machine learning models or provide new features to users of mobile applications, it is unclear whether they recognize the perils of such techniques when applied to real world datasets biased along latent dimensions. Although one expects GANs to replicate the distribution of the original data, in real-world settings with limited data and finite network capacity, GANs suffer from mode collapse. First, we show readily-accessible GAN variants such as DCGANs ‘imagine’ faces of synthetic engineering professors that have masculine facial features and fair skin tones. When using popular GAN architectures that attempt to address mode-collapse, we observe that these variants either provide a false sense of security or suffer from other inherent limitations due to their design choice. Second, we show that a conditional GAN variant transforms input images of female and nonwhite faces to have more masculine features and lighter skin when asked to generate faces of engineering professors. Worse yet, prevalent filters on Snapchat end up consistently lightening the skin tones in people of color when trying to make face images appear more feminine. Thus, our study is meant to serve as a cautionary tale for practitioners and educate them about the side-effect of bias amplification when applying GAN-based techniques.",https://doi.org/10.1016/j.artint.2021.103652,https://www.sciencedirect.com/science/article/pii/S0004370221002034,,,,2022,Imperfect ImaGANation: Implications of GANs exacerbating biases on facial data augmentation and snapchat face lenses,Niharika Jain and Alberto Olmo and Sailik Sengupta and Lydia Manikonda and Subbarao Kambhampati,article,JAIN2022103652,Artificial Intelligence,,304,0004-3702,,,
,"Cryptocurrency, Pump and dump, Fraud, Social media, Finance",115284,,"The cryptocurrency market has gained significant traction in the last decade, becoming an alternative finance platform to traditional stock market trading. Despite its rapid evolution, legal regulations have not yet caught up to the cryptocurrency market’s progress, attracting the attention of scammers looking to exploit legal loopholes for profits. Pump-and-dump schemes, a well-worn fraud device, has regained relevance in this new territory. In a typical pump-and-dump scheme, scammers organize and leverage media channels to artificially inflate the price of an alternative cryptocurrency, only to quickly sell them to profit off unsuspecting buyers. The disruptive nature of pump-and-dump schemes necessitates a system to reliably forecast pump targets and the magnitude of its success. In this paper, we propose an approach to predict the target cryptocurrency for each pump before its announcement using market and social media signals using Neural Network-based architectures while offering interpretable insights into their black-box nature. Additionally, we construct models that are capable of forecasting the highest price induced by the pump after the cryptocurrency’s identity is revealed within 6.1% error margin. We examine the optimal temporal windows and describe the limitations of social data to predict the manipulations in cryptocurrency trade. Our experimental results serve as proof of a feasible forecasting expert system for identifying cryptocurrency pump-and-dump frauds using publicly available data.",https://doi.org/10.1016/j.eswa.2021.115284,https://www.sciencedirect.com/science/article/pii/S0957417421007156,,,,2021,Detecting cryptocurrency pump-and-dump frauds using market and social signals,Huy Nghiem and Goran Muric and Fred Morstatter and Emilio Ferrara,article,NGHIEM2021115284,Expert Systems with Applications,,182,0957-4174,,,
,"Denial of service attack, IoT botnet, Software defined networks, Smart contract, Blockchain, DDoS attacks, Internet service provider",96-112,,"With the proliferation of new technologies such as the Internet of Things (IoT) and Software-Defined Networking (SDN) in recent years, the Distributed Denial of Service (DDoS) attack vector has broadened and opened new opportunities for more sophisticated DDoS attacks on the targeted victims. The new attack vector includes unsecured and vulnerable IoT devices connected to the internet, and denial of service vulnerabilities like southbound channel saturation in the SDN architecture. Given the high-volume and pervasive nature of these attacks, it is beneficial for stakeholders to collaborate in detecting and mitigating the denial of service attacks promptly. Blockchain technology is considered to improve the security aspects owing to the decentralized design, secured distributed storage, and privacy. A thorough exploration and classification of blockchain techniques used for DDoS attack mitigation are not explored in the prior art. This paper reviews and categorizes state-of-the-art DDoS mitigation solutions based on blockchain technology. The DDoS mitigation techniques are classified based on the solution deployment location i.e. network-based, near attacker location, near victim location, and hybrid solutions in the network architecture with emphasis on the IoT and SDN architectures. Additionally, based on our study, the research challenges and future directions to implement the blockchain based DDoS mitigation solutions are discussed.",https://doi.org/10.1016/j.comcom.2022.10.026,https://www.sciencedirect.com/science/article/pii/S0140366422004145,,,,2023,"A survey on Blockchain solutions in DDoS attacks mitigation: Techniques, open challenges and future directions",Rajasekhar Chaganti and Bharat Bhushan and Vinayakumar Ravi,article,CHAGANTI202396,Computer Communications,,197,0140-3664,,,
,"Social media, Rumor popularity, Misinformation analysis",122791,,"Malicious online rumors with high popularity, if left undetected, can spread very quickly with damaging societal implications. The development of reliable computational methods for early prediction of the popularity of false rumors is very much needed, as a complement to related work on automated rumor detection and fact-checking. Besides, detecting false rumors with higher popularity in the early stage allows social media platforms to timely deliver fact-checking information to end users. To this end, we (1) propose a new regression task to predict the future popularity of false rumors given both post and user-level information; (2) introduce a new publicly available dataset in Chinese that includes 19,256 false rumor cases from Weibo, the corresponding profile information of the original spreaders and a rumor popularity score as a function of the shares, replies and reports it has received; (3) develop a new open-source domain adapted pre-trained language model, i.e., BERT-Weibo-Rumor and evaluate its performance against several supervised classifiers using post and user-level information. Our best performing model (KG-Fusion) achieves the lowest RMSE score (1.54) and highest Pearson’s r (0.636), outperforming competitive baselines by leveraging textual information from both the post and the user profile. Our analysis unveils that popular rumors consist of more conjunctions and punctuation marks, while less popular rumors contain more words related to the social context and personal pronouns. Our dataset is publicly available: https://github.com/YIDAMU/Weibo_Rumor_Popularity.",https://doi.org/10.1016/j.eswa.2023.122791,https://www.sciencedirect.com/science/article/pii/S0957417423032931,,,,2024,Predicting and analyzing the popularity of false rumors in Weibo,Yida Mu and Pu Niu and Kalina Bontcheva and Nikolaos Aletras,article,MU2024122791,Expert Systems with Applications,,243,0957-4174,,,
,,155-159,Altmetrics for Information Professionals,,https://doi.org/10.1016/B978-0-08-100273-5.09988-9,https://www.sciencedirect.com/science/article/pii/B9780081002735099889,,Chandos Publishing,978-0-08-100273-5,2016,Index,,incollection,2016155,,,,,,Kim Holmberg,
,"Online social networks, Fake news classification, Fake news identification techniques",101571,,"The explosion of online social networks in recent decades has significantly improved in which the way individuals communicate with one another. People trust social networks bluntly without knowing the origin and genuinity of the information passed through these networks. Sometimes, unreliable information on online social networks misleads the viewers, and it brings unremovable stains to humanity. Online social networks transform even the original information of the government, which create confusion among the people and people loses confidence over the government. Various types of research have been conducted to identify fake news with high efficiency. In this survey, we describe the basic theories of fake news, investigate and analyze the perspective on fake news, attribute misleading information, an in-depth analysis of disinformation, and methods that have been established for detection. To our knowledge, this research article will assist in facilitating collaborative activities among technical experts, political campaigns, online purchases, and other disciplines that are being used to investigate fake messages.",https://doi.org/10.1016/j.jksuci.2023.101571,https://www.sciencedirect.com/science/article/pii/S1319157823001258,,,,2023,"A comprehensive survey of fake news in social networks: Attributes, features, and detection approaches",Medeswara Rao Kondamudi and Somya Ranjan Sahoo and Lokesh Chouhan and Nandakishor Yadav,article,KONDAMUDI2023101571,Journal of King Saud University - Computer and Information Sciences,6,35,1319-1578,,,
,"ChatGPT, GPT-4, GPT-3.5, GPT performance, GPT limitations, OpenAI, NLP, Computer programming",e21624,,"Since the release of ChatGPT, numerous studies have highlighted the remarkable performance of ChatGPT, which often rivals or even surpasses human capabilities in various tasks and domains. However, this paper presents a contrasting perspective by demonstrating an instance where human performance excels in typical tasks suited for ChatGPT, specifically in the domain of computer programming. We utilize the IEEExtreme Challenge competition as a benchmark—a prestigious, annual international programming contest encompassing a wide range of problems with different complexities. To conduct a thorough evaluation, we selected and executed a diverse set of 102 challenges, drawn from five distinct IEEExtreme editions, using three major programming languages: Python, Java, and C++. Our empirical analysis provides evidence that contrary to popular belief, human programmers maintain a competitive edge over ChatGPT in certain aspects of problem-solving within the programming context. In fact, we found that the average score obtained by ChatGPT on the set of IEEExtreme programming problems is 3.9 to 5.8 times lower than the average human score, depending on the programming language. This paper elaborates on these findings, offering critical insights into the limitations and potential areas of improvement for AI-based language models like ChatGPT.",https://doi.org/10.1016/j.heliyon.2023.e21624,https://www.sciencedirect.com/science/article/pii/S2405844023088321,,,,2023,Humans are still better than ChatGPT: Case of the IEEEXtreme competition,Anis Koubaa and Basit Qureshi and Adel Ammar and Zahid Khan and Wadii Boulila and Lahouari Ghouti,article,KOUBAA2023e21624,Heliyon,11,9,2405-8440,,,
,"Process synthesis, Distillation sequences, Process optimization, Mixed-integer linear programming",108549,,"Distillation energy consumption dominates the process industry; hence, the selection of the distillation sequence will substantially affect the separation energy consumption. We propose a framework for the automatic synthesis and optimization of distillation sequences by integrating the Aspen Plus with the MATLAB programming platform. The framework combines the concept of binary trees in data structures and uses a preorder traversal algorithm to generate a network superstructure in the simulator. In the next step, it automatically formulates and solves a mixed-integer linear programming model based on calculation results; finally, the distillation model is optimized using an improved quadratic interpolation algorithm. Two case studies for C5 alkane and dimethyl carbonate separation showed that the optimal solution obtained by the framework reduced the total annual costs by 13.18 % and 2.88 %, respectively, compared with the processes without systematic optimization. The framework also allowed screening out promising alternatives by rapid evaluation of different process routes.",https://doi.org/10.1016/j.compchemeng.2023.108549,https://www.sciencedirect.com/science/article/pii/S0098135423004192,,,,2024,An automatic distillation sequence synthesis framework based on a preorder traversal algorithm,Anqing Wang and Alexander Guzman-Urbina and Hajime Ohno and Yasuhiro Fukushima,article,WANG2024108549,Computers & Chemical Engineering,,181,0098-1354,,,
,"Modern code review, Software verification, Software quality, Systematic literature review",110951,,"Context:
Modern Code Review (MCR) is a widely known practice of software quality assurance. However, the existing body of knowledge of MCR is currently not understood as a whole.
Objective:
Our goal is to identify the state of the art on MCR, providing a structured overview and an in-depth analysis of the research done in this field.
Methods:
We performed a systematic literature review, selecting publications from four digital libraries.
Results:
A total of 139 papers were selected and analyzed in three main categories. Foundational studies are those that analyze existing or collected data from the adoption of MCR. Proposals consist of techniques and tools to support MCR, while evaluations are studies to assess an approach or compare a set of them.
Conclusion:
The most represented category is foundational studies, mainly aiming to understand the motivations for adopting MCR, its challenges and benefits, and which influence factors lead to which MCR outcomes. The most common types of proposals are code reviewer recommender and support to code checking. Evaluations of MCR-supporting approaches have been done mostly offline, without involving human subjects. Five main research gaps have been identified, which point out directions for future work in the area.",https://doi.org/10.1016/j.jss.2021.110951,https://www.sciencedirect.com/science/article/pii/S0164121221000480,,,,2021,A systematic literature review and taxonomy of modern code review,Nicole Davila and Ingrid Nunes,article,DAVILA2021110951,Journal of Systems and Software,,177,0164-1212,,,
,"Prototyping, Makerspaces, Arduino",634-638,,"In early stages of product development, prototyping is an invaluable tool which allows designers to generate learnings and uncover unknown challenges which can be used to further construct design requirements. While generous use of prototyping early in the design process might reduce the risk of premature design decisions, it also demands significant investments in terms of resources such as time, material, and skills. Tools that allow designers to rapidly implement and test new functionalities are therefore desired. With wirelessly communicating products having become ubiquitous in modern society, designers should be comfortable designing products utilizing these technologies. In this paper we present an Arduino library, named TrollBOT, that facilitates rapid implementation of wireless communication between two or more Arduinos. The Arduinos form nodes in a tree topology using inexpensive nRF24-based radio transceivers. The library is constructed in such a way that a minimal amount of new language syntax must be learned. All nodes can be programmed from a single master node in an intuitive manner, significantly reducing the amount of code that needs to be written as compared to similar existing solutions.",https://doi.org/10.1016/j.procir.2020.03.111,https://www.sciencedirect.com/science/article/pii/S2212827120308763,,,,2020,TrollBOT: A Spontaneous Networking Tool Facilitating Rapid Prototyping of Wirelessly Communicating Products,Torjus Steffensen and Sampsa Kohtala and Håvard Vestad and Martin Steinert,article,STEFFENSEN2020634,Procedia CIRP,,91,2212-8271,Enhancing design through the 4th Industrial Revolution Thinking,,
,"Software architecture knowledge, Knowledge management systems, Decision-making, Human aspects",111560,,"Cobbler’s children do not wear shoes. Software engineers build sophisticated software but we often cannot find the needed information and knowledge for ourselves. Issues are the amount of development information that can be captured, organizing that information to make them useable for other developers as well as human decision-making issues. Current architectural knowledge management systems cannot handle these issues properly. In this paper, we outline a research agenda for intelligent tools to support the knowledge management and decision making of architects. The research agenda consists of a vision and research challenges on the way to realize this vision. We call our vision on-demand architectural knowledge systems (ODAKS). Based on literature review, analysis, and synthesis of past research works, we derive our vision of ODAKS as decision-making companions to architects. ODAKS organize and provide relevant information and knowledge to the architect through an assistive conversation. ODAKS use probing to understand the architects’ goals and their questions, they suggest relevant knowledge and present reflective hints to mitigate human decision-making issues, such as cognitive bias, cognitive limitations, as well as design process aspects, such as problem-solution co-evolution and the balance between intuitive and rational decision-making. We present the main features of ODAKS, investigate current potential technologies for the implementation of ODAKS and discuss the main research challenges.",https://doi.org/10.1016/j.jss.2022.111560,https://www.sciencedirect.com/science/article/pii/S0164121222002369,,,,2023,The vision of on-demand architectural knowledge systems as a decision-making companion,Maryam Razavian and Barbara Paech and Antony Tang,article,RAZAVIAN2023111560,Journal of Systems and Software,,198,0164-1212,,,
,"Attention dynamics, Repost network, Online social network, Hot search list",128724,,"To understand the emergence of hashtag popularity in online social networking complex systems, we study the largest Chinese microblogging site Sina Weibo, which has a Hot Search List (HSL) showing in real time the ranking of the 50 most popular hashtags based on search activity. We investigate the prehistory of successful hashtags from 17 July 2020 to 17 September 2020 by mapping out the related interaction network preceding the selection to HSL. We have found that the circadian activity pattern has an impact on the time needed to get to the HSL. When analyzing this time we distinguish two extreme categories: (a) “Born in Rome”, which means hashtags are mostly first created by superhubs or reach superhubs at an early stage during their propagation and thus gain immediate wide attention from the broad public, and (b) “Sleeping Beauty”, meaning the hashtags gain little attention at the beginning and reach system-wide popularity after a considerable time lag. The evolution of the repost networks of successful hashtags before getting to the HSL show two types of growth patterns: “smooth” and “stepwise”. The former is usually dominated by a superhub and the latter results from consecutive waves of contributions of smaller hubs. The repost networks of unsuccessful hashtags exhibit a simple evolution pattern.",https://doi.org/10.1016/j.physa.2023.128724,https://www.sciencedirect.com/science/article/pii/S0378437123002790,,,,2023,“Born in Rome” or “Sleeping Beauty”: Emergence of hashtag popularity on the Chinese microblog Sina Weibo,Hao Cui and János Kertész,article,CUI2023128724,Physica A: Statistical Mechanics and its Applications,,619,0378-4371,,,
,"Security, Door lock, Multifactor authentication, Biometric verification, Keypad, Gsm lock",7973-7979,,"Security has become very important, but along with that, people also need a system that is not very expensive and can be customized to meet our needs. As conventional door locks can be easily opened, this makes people vulnerable to security threats. This study attempts a comparative analysis of pre-existing researches, made in the field of security control system developed and improvised over the span of time with multifactor authentication technique’s evolvement. The components, hardware complications, work efficiency and algorithms used in each of the model is drawn as a comparison to other to provide an idea of systematic development in this regard. With each passing day, security systems are advancing and new technology is being developed. Security systems or door locking mechanics have evolved from metallic door locks of primitive type keys, to advanced controlling structure with up to four or five step authentications to ensure utmost safety.",https://doi.org/10.1016/j.matpr.2021.02.708,https://www.sciencedirect.com/science/article/pii/S2214785321018617,,,,2021,Multifactor door locking systems: A review,Yashraj Motwani and Saambhavi Seth and Devang Dixit and A. Bagubali and R. Rajesh,article,MOTWANI20217973,Materials Today: Proceedings,,46,2214-7853,"3rd International Conference on Materials, Manufacturing and Modelling",,
,"Availability, Data collection, Dataset, Origin, Experiment generated, User generated, Repository",S94-S105,,"This paper targets two main goals. First, we want to provide an overview of available datasets that can be used by researchers and where to find them. Second, we want to stress the importance of sharing datasets to allow researchers to replicate results and improve the state of the art. To answer the first goal, we analyzed 715 peer-reviewed research articles from 2010 to 2015 with focus and relevance to digital forensics to see what datasets are available and focused on three major aspects: (1) the origin of the dataset (e.g., real world vs. synthetic), (2) if datasets were released by researchers and (3) the types of datasets that exist. Additionally, we broadened our results to include the outcome of online search results. We also discuss what we think is missing. Overall, our results show that the majority of datasets are experiment generated (56.4%) followed by real world data (36.7%). On the other hand, 54.4% of the articles use existing datasets while the rest created their own. In the latter case, only 3.8% actually released their datasets. Finally, we conclude that there are many datasets for use out there but finding them can be challenging.",https://doi.org/10.1016/j.diin.2017.06.004,https://www.sciencedirect.com/science/article/pii/S1742287617301913,,,,2017,Availability of datasets for digital forensics – And what is missing,Cinthya Grajeda and Frank Breitinger and Ibrahim Baggili,article,GRAJEDA2017S94,Digital Investigation,,22,1742-2876,,,
Advances in Computers,"Robots Exclusion Protocol, Internet Archive, JSONP, Hypercat, Meta crawling, HTML crawling, Mobile crawlers, Bloom filter, Resource Description Framework, Search engine optimization",77-100,A Deep Dive into NoSQL Databases: The Use Cases and Applications,"With the advent of Web technology, the Web is full of unstructured data called Big Data. However, these data are not easy to collect, access, and process at large scale. Web Crawling is an optimization problem. Site-specific crawling of various social media platforms, e-Commerce websites, Blogs, News websites, and Forums is a requirement for various business organizations to answer a search quarry from webpages. Indexing of huge number of webpage requires a cluster with several petabytes of usable disk. Since the NoSQL databases are highly scalable, use of NoSQL database for storing the Crawler data is increasing along with the growing popularity of NoSQL databases. This chapter discusses about the application of NoSQL database in Web Crawler application to store the data collected by the Web Crawler.",https://doi.org/10.1016/bs.adcom.2017.08.001,https://www.sciencedirect.com/science/article/pii/S0065245817300323,,Elsevier,,2018,Chapter Three - NoSQL Web Crawler Application,Ganesh Chandra Deka,incollection,DEKA201877,,,109,0065-2458,,Pethuru Raj and Ganesh Chandra Deka,
,"Ontology evolution, Materialisation, Evolution impact, Ontology change",100658,,"Ontologies are becoming a key component of numerous applications and research fields. But knowledge captured within ontologies is not static. Some ontology updates potentially have a wide ranging impact; others only affect very localised parts of the ontology and their applications. Investigating the impact of the evolution gives us insight into the editing behaviour but also signals ontology engineers and users how the ontology evolution is affecting other applications. However, such research is in its infancy. Hence, we need to investigate the evolution itself and its impact on the simplest of applications: the materialisation. In this work, we define impact measures that capture the effect of changes on the materialisation. In the future, the impact measures introduced in this work can be used to investigate how aware the ontology editors are about consequences of changes. By introducing five different measures, which focus either on the change in the materialisation with respect to the size or on the number of changes applied, we are able to quantify the consequences of ontology changes. To see these measures in action, we investigate the evolution and its impact on materialisation for nine open biomedical ontologies, most of which adhere to the EL++ description logic. Our results show that these ontologies evolve at varying paces but no statistically significant difference between the ontologies with respect to their evolution could be identified. We identify three types of ontologies based on the types of complex changes which are applied to them throughout their evolution. The impact on the materialisation is the same for the investigated ontologies, bringing us to the conclusion that the effect of changes on the materialisation can be generalised to other similar ontologies. Further, we found that the materialised concept inclusion axioms experience most of the impact induced by changes to the class inheritance of the ontology and other changes only marginally touch the materialisation.",https://doi.org/10.1016/j.websem.2021.100658,https://www.sciencedirect.com/science/article/pii/S1570826821000330,,,,2021,Beware of the hierarchy — An analysis of ontology evolution and the materialisation impact for biomedical ontologies,Romana Pernisch and Daniele Dell’Aglio and Abraham Bernstein,article,PERNISCH2021100658,Journal of Web Semantics,,70,1570-8268,,,
,"Artificial Intelligence, Chatbot, Deep Learning, Machine Learning, Mental health",100198,,"Increased screen time may cause significant health impacts, including harmful effects on mental health. Studies on the association between technological obsessions and their influence on health have been conducted using Deep Learning (DL) and Machine Learning (ML) techniques. The deployment of chatbots in different industries has been proven as a game-changer. We study conversational Artificial Intelligence (AI) systems enabling operators to conduct conversations with machines that resemble those with humans. We design and develop two retrieval-based and generative-based chatbots, each with six designs. Among the retrieval-based chatbots, Vanilla Recurrent Neural Network (RNN) has an accuracy of 83.22%, Long Short Term Memory (LSTM) is 89.87% accurate, Bidirectional LSTM (Bi-LSTM) is 91.57% accurate, Gated Recurrent Unit (GRU) is 65.57% accurate, and Convolution Neural Network (CNN) is 82.33% accurate. In comparison, generative-based chatbots have encoder–decoder designs that are 94.45% accurate. The most significant distinction is that while generative-based chatbots can generate new text, retrieval-based chatbots are restricted to responding to inputs that match the best of the outputs they already know.",https://doi.org/10.1016/j.health.2023.100198,https://www.sciencedirect.com/science/article/pii/S2772442523000655,,,,2023,A comparative study of retrieval-based and generative-based chatbots using Deep Learning and Machine Learning,Sumit Pandey and Srishti Sharma,article,PANDEY2023100198,Healthcare Analytics,,3,2772-4425,,,
,"Indicators of Compromise, IOC, Cyber Threat Intelligence, RSS, Twitter, Telegram",74-89,,"To adapt to a constantly evolving landscape of cyber threats, organizations actively need to collect Indicators of Compromise (IOCs), i.e., forensic artifacts that signal that a host or network might have been compromised. IOCs can be collected through open-source and commercial structured IOC feeds. But, they can also be extracted from a myriad of unstructured threat reports written in natural language and distributed using a wide array of sources such as blogs and social media. There exist multiple indicator extraction tools that can identify IOCs in natural language reports. But, it is hard to compare their accuracy due to the difficulty of building large ground truth datasets. This work presents a novel majority vote methodology for comparing the accuracy of indicator extraction tools, which does not require a manually-built ground truth. We implement our methodology into GoodFATR, an automated platform for collecting threat reports from a wealth of sources, extracting IOCs from the collected reports using multiple tools, and comparing their accuracy. GoodFATR supports 6 threat report sources: RSS, Twitter, Telegram, Malpedia, APTnotes, and ChainSmith. GoodFATR continuously monitors the sources, downloads new threat reports, extracts 41 indicator types from the collected reports, and filters non-malicious indicators to output the IOCs. We run GoodFATR over 15 months to collect 472,891 reports from the 6 sources; extract 978,151 indicators from the reports; and identify 618,217 IOCs. We analyze the collected data to identify the top IOC contributors and the IOC class distribution. We apply GoodFATR to compare the IOC extraction accuracy of 7 popular open-source tools with GoodFATR’s own indicator extraction module.",https://doi.org/10.1016/j.future.2023.02.012,https://www.sciencedirect.com/science/article/pii/S0167739X23000535,,,,2023,The Rise of GoodFATR: A Novel Accuracy Comparison Methodology for Indicator Extraction Tools,Juan Caballero and Gibran Gomez and Srdjan Matic and Gustavo Sánchez and Silvia Sebastián and Arturo Villacañas,article,CABALLERO202374,Future Generation Computer Systems,,144,0167-739X,,,
,"Lexicons, Machine Learning, Twitter, Data Streams, Sentiment Analysis",165-172,,"Due to the massive amount of data being generated on the platform, Twitter has been the subject of numerous sentiment analysis studies. Such social network services generate massive unstructured data streams which make working with them very challenging. The aim of this study is to reliably analyze the sentiment of trending tweets in the Twitter API data stream using a combination of different algorithms to achieve a consensus. The methods we implemented include Support-Vector Machine, Naive Bayes, Textblob, and Lexicon Approach. The hypothesis is that using these methods together would enable us to get more accurate results. Using a labeled dataset to test our model, the results show that the combination of these four algorithms all together performed best with an overall accuracy of 68.29%. We conclude that our combination method of analysis is suitable and fast enough for our data stream and also accurate for analyzing sentiment.",https://doi.org/10.1016/j.procs.2022.07.023,https://www.sciencedirect.com/science/article/pii/S1877050922006287,,,,2022,Live Sentiment Analysis Using Multiple Machine Learning and Text Processing Algorithms,Andrew Motz and Elizabeth Ranta and Adan Sierra Calderon and Quin Adam and Fadi Alzhouri and Dariush Ebrahimi,article,MOTZ2022165,Procedia Computer Science,,203,1877-0509,"17th International Conference on Future Networks and Communications / 19th International Conference on Mobile Systems and Pervasive Computing / 12th International Conference on Sustainable Energy Information Technology (FNC/MobiSPC/SEIT 2022), August 9-11, 2022, Niagara Falls, Ontario, Canada",,
,"Blockchain, Marketing, Blockchain applications, Blockchain in marketing",100023,,"Given the emerging nature of integrating Blockchain Technology (BCT) into several business fields concerning the interaction between companies and their customers, this study aims to investigate the applications of BCT in marketing through an accurate procedure of locating, selecting and analyzing existing companies using BCT in marketing. A sample that consists of 800 companies was identified using web-scraping methods. The data set was collected from initial coin offerings (ICO) websites as well as from an existing, older landscape of applications. The data set was then intensively analyzed in order to be categorized into five fields of marketing technology. Advertising and ecommerce outgrew the other fields of social & relationship, content & experience and data in absolute numbers, revealing the focus of practitioners in the past as well as gaps for the future. The authors provided future directions for researchers on and development of tools to systematically generate knowledge and improve the application of BCT and the work of practitioners in marketing.",https://doi.org/10.1016/j.bcra.2021.100023,https://www.sciencedirect.com/science/article/pii/S209672092100018X,,,,2021,Applications of Blockchain Technology in marketing—A systematic review of marketing technology companies,Valerio Stallone and Martin Wetzels and Michael Klaas,article,STALLONE2021100023,Blockchain: Research and Applications,3,2,2096-7209,,,
,"IoT, Firmware attack, XSS, Brute Force, Cross-site scripting, UPnP, IDS",100443,,"Smart home devices have brought in a disruptive, revolutionary Internet-based ecosystem that enhanced our daily lives but has pushed private data from inside our homes to external public sources. Threats and attacks mounted against IoT deployments have only increased in recent times. There have been several proposals to secure home automation environments, but there is no full protection against Cybersecurity threats for our home IoT platforms. This research investigates attack attempts on smart home environments, focusing on firmware, brute force, and DoS attacks on the Internet of Things (IoT) network which were successful in bringing down the device in less than a minute. Weak passwords were cracked using Brute Force techniques related to HTTP, SSH, Telnet, and FTP protocols, and an unknown service port to reveal backdoor access. Cross-site scripting vulnerability was detected on IoT devices that could allow running malicious scripts on the devices. The authors also exploited the unknown services to reveal backdoors and access sensitive device details and potentially exploited them to add new ports or rules to turn the IoT devices into a router to attack other devices. To detect and mitigate such attacks, the authors present an IoT-based intrusion detection and prevention system to secure smart home network devices. The authors compared the proposed framework with other similar research based on Precision, Accuracy, F-measure, and Recall. The proposed model outperforms all the other known models reporting a high of 95% for identifying malicious attack packets, while others reported 58% and 71% detection percentage.",https://doi.org/10.1016/j.eij.2024.100443,https://www.sciencedirect.com/science/article/pii/S1110866524000069,,,,2024,Fortifying home IoT security: A framework for comprehensive examination of vulnerabilities and intrusion detection strategies for smart cities,Akashdeep Bhardwaj and Salil Bharany and Anas W. Abulfaraj and Ashraf {Osman Ibrahim} and Wamda Nagmeldin,article,BHARDWAJ2024100443,Egyptian Informatics Journal,,25,1110-8665,,,
,"LCA, BIM, Design decision support, Early design stages",100263,,"To meet the European climate goals in the building sector, a holistic optimization of embodied greenhouse gas (GHG) emissions using the method of life cycle assessments (LCA) are necessary. The early design stages have high impact on the final performance of the buildings and are characterized by high uncertainty due to the lack of information and not yet taken decisions. Furthermore, most current LCA approaches based on Building Information Models (BIM) require high expertise and experience in both BIM and LCA and do not follow an intuitive visualization approach for other stakeholders and non-experts. This paper presents a novel design-decision-making approach for reducing embodied GHG emissions by interactive, model-based visualizations of uncertain LCA results. The proposed workflow is based on open BIM data formats, such as Industry Foundation Classes (IFC) and BIM Collaboration Format (BCF), and is developed for decision support for non-LCA experts in the early design stages. With the help of a user study, the prototypical implementation is tested by 103 participants with different levels of experience in BIM and LCA based on a case study. We evaluate the proposed approach regarding the support of open BIM data formats, different LCA visualization strategies, and the intuitiveness of different approaches to visualizing uncertain LCA results. The user study results show a broad acceptance and need for open BIM data formats and model-based LCA visualization but less for visualizing uncertainties, which needs further research. In conclusion, this interactive, model-based visualization approach using color coding supports non-LCA experts in the design decision-making process in early design stages.",https://doi.org/10.1016/j.dibe.2023.100263,https://www.sciencedirect.com/science/article/pii/S266616592300145X,,,,2023,BIM4EarlyLCA: An interactive visualization approach for early design support based on uncertain LCA results using open BIM,Kasimir Forth and Alexander Hollberg and André Borrmann,article,FORTH2023100263,Developments in the Built Environment,,16,2666-1659,,,
,"Disinformation, Conspiracy theory, Anti-vaccination, Anti-5G, Social network analysis, COVID-19, Social movements, Twitter, Public health, Trust in government",100174,,"The COVID-19 pandemic caused high uncertainty regarding appropriate treatments and public policy reactions. This uncertainty provided a perfect breeding ground for spreading conspiratorial anti-science narratives based on disinformation. Disinformation on public health may alter the population’s hesitance to vaccinations, counted among the ten most severe threats to global public health by the United Nations. We understand conspiracy narratives as a combination of disinformation, misinformation, and rumour that are especially effective in drawing people to believe in post-factual claims and form disinformed social movements. Conspiracy narratives provide a pseudo-epistemic background for disinformed social movements that allow for self-identification and cognitive certainty in a rapidly changing information environment. This study monitors two established conspiracy narratives and their communities on Twitter, the anti-vaccination and anti-5G communities, before and during the first UK lockdown. The study finds that, despite content moderation efforts by Twitter, conspiracy groups were able to proliferate their networks and influence broader public discourses on Twitter, such as #Lockdown in the United Kingdom.",https://doi.org/10.1016/j.osnem.2021.100174,https://www.sciencedirect.com/science/article/pii/S2468696421000550,,,,2021,Disinformed social movements: A large-scale mapping of conspiracy narratives as online harms during the COVID-19 pandemic,Philipp Darius and Michael Urquhart,article,DARIUS2021100174,Online Social Networks and Media,,26,2468-6964,,,
,,417-497,,,https://doi.org/10.1016/0306-4573(84)90072-4,https://www.sciencedirect.com/science/article/pii/0306457384900724,,,,1984,Selected bibliography on information theory applications to information science and related subject areas,Pranas Zunde,article,ZUNDE1984417,Information Processing & Management,3,20,0306-4573,Special Issue Information Theory Applications to Problems of Information Science,,
,,305-412,,"The results of statistical model calculations of (n,γ), (n,p), and (n,α) cross sections and reaction-rate factors are presented in tabular form for over 500 target nuclei in the range 36 ≤ Z ≤ 83 (krypton to bismuth). Included in these tables is information on (i) the reaction cross section as a function of energy for the exoergic channel in the range 0.01 ≤ E(MeV) ≤ 3.0; (ii) the thermally averaged reaction-rate factor, NA〈σv〉 and the nuclear partition function G(T) for temperatures in the range 108 ≤ T(oK) ≤ 3 × 109; (iii) analytic fits to the reaction-rate factors and partition functions as functions of temperature; and (iv) nuclear level-density parameters and formulas for their extrapolation. Two types of reaction-rate factors have been computed. One, which may be called the “laboratory rate factor,” is based on the assumption that the target nuclei occupy only their ground states. The other, which shall be termed the “stellar rate factor,” is based on the more realistic assumption that the target nuclei occupy a thermal distribution of excited states at temperature T. A brief discussion of theory and instructions for usage of the tables are included. New fitting forms for statistical-model thermonuclear reaction rates are presented and justified.",https://doi.org/10.1016/0092-640X(76)90011-5,https://www.sciencedirect.com/science/article/pii/0092640X76900115,,,,1976,Tables of thermonuclear-reaction-rate data for neutron-induced reactions on heavy nuclei,J.A. Holmes and S.E. Woosley and William A. Fowler and B.A. Zimmerman,article,HOLMES1976305,Atomic Data and Nuclear Data Tables,4,18,0092-640X,,,
,,51-294,,,https://doi.org/10.1016/0370-2693(82)91296-5,https://www.sciencedirect.com/science/article/pii/0370269382912965,,,,1982,Data card listings,,article,198251,Physics Letters B,,111,0370-2693,,,
,,103-321,,,https://doi.org/10.1016/0043-1354(67)90037-1,https://www.sciencedirect.com/science/article/pii/0043135467900371,,,,1967,Contents of volumes,,article,1967103,Water Research,,1-25,0043-1354,,,
ACM Monograph Series,,51-396,Mathematical Software,"Publisher Summary
This chapter focuses on the Taylor series method for the solution of systems of ordinary differential equations, which is one of the oldest and most reliable procedures for integrating systems of differential equations. The method can be formulated in general for differential systems that are reducible to rational form. In addition, it can be programmed as a general purpose algorithm that requires no previous manipulations on the differential system, accepting only the defining system as input. Experience over a wide range of problems and required accuracies have indicated that it does not suffer from numerical instability. It is a flexible, variable-step method that produces a piecewise polynomial solution, valid throughout the entire domain of integration. In many problems, it can attain a significantly greater maximum accuracy than the Runge–Kutta–Gill method, and it proceeds with unusually large step lengths. Throughout a wide range of accuracy, the Bulrisch–Stoer method often requires five times the amount of computing time taken by the Taylor series method.",https://doi.org/10.1016/B978-0-12-587250-8.50012-6,https://www.sciencedirect.com/science/article/pii/B9780125872508500126,,Academic Press,,1971,CHAPTER 5 - THE PAPERS,,incollection,197151,,,,05724252,,JOHN R. RICE,
,,101-861,European Miniature Electronic Components and Assemblies Data 1965–66: Including Six-Language Glossaries of Electronic Component and Microelectronics Terms,,https://doi.org/10.1016/B978-0-08-011151-3.50019-3,https://www.sciencedirect.com/science/article/pii/B9780080111513500193,,Pergamon,978-0-08-011151-3,1965,GERMAN MINIATURE ELECTRONIC COMPONENTS AND ASSEMBLIES,,incollection,1965101,,,,,,G.W.A. DUMMER and J. MACKENZIE ROBERTSON,
,,172-284,,,https://doi.org/10.1016/0022-328X(95)80002-6,https://www.sciencedirect.com/science/article/pii/0022328X95800026,,,,1995,Cumulative indexes of volumes 450–505: Volume contents,,article,1995172,Journal of Organometallic Chemistry,2,505,0022-328X,,,
,,507-660,,,https://doi.org/10.1016/S0090-3752(75)80014-7,https://www.sciencedirect.com/science/article/pii/S0090375275800147,,,,1975,Key numbers and key words,,article,1975507,Nuclear Data Sheets,4,16,0090-3752,,,
,,143-487,Encyclopedia of Language & Linguistics (Second Edition),,https://doi.org/10.1016/B0-08-044854-2/09090-8,https://www.sciencedirect.com/science/article/pii/B0080448542090908,Oxford,Elsevier,978-0-08-044854-1,2006,List of Languages,,incollection,2006143,,,,,,Keith Brown,Second Edition
,,672,,,https://doi.org/10.1016/S0015-6264(65)80261-9,https://www.sciencedirect.com/science/article/pii/S0015626465802619,,,,1965,"883. Will no one crack this egg?: Szepsenwol, J. (1965). The carcinogenic effect of egg yolk in mice of the C57 Bl. strain. Proc. Am. Ass. Cancer Res.6, 63",,article,1965672,Food and Cosmetics Toxicology,,3,0015-6264,,,
,,1-760,,,https://doi.org/10.1016/S0021-9673(01)95161-1,https://www.sciencedirect.com/science/article/pii/S0021967301951611,,,,1976,Bibliography of liquid column chromatography 1971–1973 and survey of applications,,article,19761,Journal of Chromatography A,,6,0021-9673,,,
,,107-322,Components and Sub-Assemblies,,https://doi.org/10.1016/B978-1-85617-175-5.50006-2,https://www.sciencedirect.com/science/article/pii/B9781856171755500062,Oxford,Elsevier,978-1-85617-175-5,1993,"Section 2 - Directory of agents and representatives, country by country",,incollection,1993107,,,,,,C.G. Wedgwood,
,,1-369,,,https://doi.org/10.1016/0022-2860(93)85034-R,https://www.sciencedirect.com/science/article/pii/002228609385034R,,,,1993,Bibliography,,article,19931,Journal of Molecular Structure,,290,0022-2860,,,
,,1089-1272,,,https://doi.org/10.1016/S0016-5085(79)80259-0,https://www.sciencedirect.com/science/article/pii/S0016508579802590,,,,1979,Abstracts of Papers Submitted to the American Gastroenterological Association,,article,19791089,Gastroenterology,"5, Part 2",76,0016-5085,80th Annual Meeting of the American Gastroentrological Association,,
,"Internet of Things, Computational linguistic, Artificial Intelligence, First order logic, Cognitive architectures, Meta-reasoning",104269,,"In the last decade, the market of Internet of Things has become quite disruptive, together with commercial clouds providing connection between every sort of devices and the global network, supported by vocal assistants. On the other hands, such commercial products are limited to work on limited domains, although easily scalable, without aspiring to higher level of reasoning in the field of Decisions Making. In this work, we show a way towards the design of an architecture for building cognitive agents leveraging Natural Language Processing. Such agents will be not based on clouds and do not require any semantic training, plus they will be able of deduction on facts and rules in First Order Logic inferred directly from Natural Language. After the description of the architecture and its underlying components, a case-study is provided to show the effectiveness in cases of direct commands and routines, subordinated also by a Meta-Reasoning in a conceptual space, parsing the utterances with promising real-time performances.",https://doi.org/10.1016/j.engappai.2021.104269,https://www.sciencedirect.com/science/article/pii/S0952197621001160,,,,2021,"Caspar: Towards decision making helpers agents for IoT, based on natural language and first order logic reasoning",Carmelo Fabio Longo and Francesco Longo and Corrado Santoro,article,LONGO2021104269,Engineering Applications of Artificial Intelligence,,104,0952-1976,,,
,"Conversational agent, Generative artificial intelligence, Generative AI, ChatGPT, Large language models",102642,,"Transformative artificially intelligent tools, such as ChatGPT, designed to generate sophisticated text indistinguishable from that produced by a human, are applicable across a wide range of contexts. The technology presents opportunities as well as, often ethical and legal, challenges, and has the potential for both positive and negative impacts for organisations, society, and individuals. Offering multi-disciplinary insight into some of these, this article brings together 43 contributions from experts in fields such as computer science, marketing, information systems, education, policy, hospitality and tourism, management, publishing, and nursing. The contributors acknowledge ChatGPT’s capabilities to enhance productivity and suggest that it is likely to offer significant gains in the banking, hospitality and tourism, and information technology industries, and enhance business activities, such as management and marketing. Nevertheless, they also consider its limitations, disruptions to practices, threats to privacy and security, and consequences of biases, misuse, and misinformation. However, opinion is split on whether ChatGPT’s use should be restricted or legislated. Drawing on these contributions, the article identifies questions requiring further research across three thematic areas: knowledge, transparency, and ethics; digital transformation of organisations and societies; and teaching, learning, and scholarly research. The avenues for further research include: identifying skills, resources, and capabilities needed to handle generative AI; examining biases of generative AI attributable to training datasets and processes; exploring business and societal contexts best suited for generative AI implementation; determining optimal combinations of human and generative AI for various tasks; identifying ways to assess accuracy of text produced by generative AI; and uncovering the ethical and legal issues in using generative AI across different contexts.",https://doi.org/10.1016/j.ijinfomgt.2023.102642,https://www.sciencedirect.com/science/article/pii/S0268401223000233,,,,2023,"Opinion Paper: “So what if ChatGPT wrote it?” Multidisciplinary perspectives on opportunities, challenges and implications of generative conversational AI for research, practice and policy",Yogesh K. Dwivedi and Nir Kshetri and Laurie Hughes and Emma Louise Slade and Anand Jeyaraj and Arpan Kumar Kar and Abdullah M. Baabdullah and Alex Koohang and Vishnupriya Raghavan and Manju Ahuja and Hanaa Albanna and Mousa Ahmad Albashrawi and Adil S. Al-Busaidi and Janarthanan Balakrishnan and Yves Barlette and Sriparna Basu and Indranil Bose and Laurence Brooks and Dimitrios Buhalis and Lemuria Carter and Soumyadeb Chowdhury and Tom Crick and Scott W. Cunningham and Gareth H. Davies and Robert M. Davison and Rahul Dé and Denis Dennehy and Yanqing Duan and Rameshwar Dubey and Rohita Dwivedi and John S. Edwards and Carlos Flavián and Robin Gauld and Varun Grover and Mei-Chih Hu and Marijn Janssen and Paul Jones and Iris Junglas and Sangeeta Khorana and Sascha Kraus and Kai R. Larsen and Paul Latreille and Sven Laumer and F. Tegwen Malik and Abbas Mardani and Marcello Mariani and Sunil Mithas and Emmanuel Mogaji and Jeretta Horn Nord and Siobhan O’Connor and Fevzi Okumus and Margherita Pagani and Neeraj Pandey and Savvas Papagiannidis and Ilias O. Pappas and Nishith Pathak and Jan Pries-Heje and Ramakrishnan Raman and Nripendra P. Rana and Sven-Volker Rehm and Samuel Ribeiro-Navarrete and Alexander Richter and Frantz Rowe and Suprateek Sarker and Bernd Carsten Stahl and Manoj Kumar Tiwari and Wil {van der Aalst} and Viswanath Venkatesh and Giampaolo Viglia and Michael Wade and Paul Walton and Jochen Wirtz and Ryan Wright,article,DWIVEDI2023102642,International Journal of Information Management,,71,0268-4012,,,
,"Malware detection, Obfuscated malware, Ensemble learning, Stacking, Deep learning, Pearson correlation coefficient",200283,,"Since the advent of malware, it has reached a toll in this world that exchanges billions of data daily. Millions of people are victims of it, and the numbers are not decreasing as the year goes by. Malware is of various types in which obfuscation is a special kind. Obfuscated malware detection is necessary as it is not usually detectable and is prevalent in the real world. Although numerous works have already been done in this field so far, most of these works still need to catch up at some points, considering the scope of exploration through recent extensions. In addition to that, the application of a hybrid classification model is yet to be popularized in this field. Thus, in this paper, a novel hybrid classification model named, MalHyStack, has been proposed for detecting such obfuscated malware within the network. This proposed working model is built incorporating a stacked ensemble learning scheme, where conventional machine learning algorithms namely, Extremely Randomized Trees Classifier (ExtraTrees), Extreme Gradient Boosting (XgBoost) Classifier, and Random Forest are used in the first layer which is then followed by a deep learning layer in the second stage. Before utilizing the classification model for malware detection, an optimum subset of features has been selected using Pearson correlation analysis which improved the accuracy of the model by more than 2 % for multiclass classification. It also reduces time complexity by approximately two and three times for binary and multiclass classification, respectively. For evaluating the performance of the proposed model, a recently published balanced dataset named CIC-MalMem-2022 has been used. Utilizing this dataset, the overall experimental results of the proposed model represent a superior performance when compared to the existing classification models.",https://doi.org/10.1016/j.iswa.2023.200283,https://www.sciencedirect.com/science/article/pii/S2667305323001084,,,,2023,MalHyStack: A hybrid stacked ensemble learning framework with feature engineering schemes for obfuscated malware analysis,Kowshik Sankar Roy and Tanim Ahmed and Pritom Biswas Udas and Md. Ebtidaul Karim and Sourav Majumdar,article,ROY2023200283,Intelligent Systems with Applications,,20,2667-3053,,,
,"Cognitive development, Educational robotics, Selective trust, Human-robot interaction",105814,,"We expect children to learn new words, skills, and ideas from various technologies. When learning from humans, children prefer people who are reliable and trustworthy, yet children also forgive people's occasional mistakes. Are the dynamics of children learning from technologies, which can also be unreliable, similar to learning from humans? We tackle this question by focusing on early childhood, an age at which children are expected to master foundational academic skills. In this project, 168 4–7-year-old children (Study 1) and 168 adults (Study 2) played a word-guessing game with either a human or robot. The partner first gave a sequence of correct answers, but then followed this with a sequence of wrong answers, with a reaction following each one. Reactions varied by condition, either expressing an accident, an accident marked with an apology, or an unhelpful intention. We found that older children were less trusting than both younger children and adults and were even more skeptical after errors. Trust decreased most rapidly when errors were intentional, but only children (and especially older children) outright rejected help from intentionally unhelpful partners. As an exception to this general trend, older children maintained their trust for longer when a robot (but not a human) apologized for its mistake. Our work suggests that educational technology design cannot be one size fits all but rather must account for developmental changes in children's learning goals.",https://doi.org/10.1016/j.cognition.2024.105814,https://www.sciencedirect.com/science/article/pii/S0010027724001008,,,,2024,School-age children are more skeptical of inaccurate robots than adults,Teresa Flanagan and Nicholas C. Georgiou and Brian Scassellati and Tamar Kushnir,article,FLANAGAN2024105814,Cognition,,249,0010-0277,,,
,"Ransomware, Malware, Access control, Ransomware mitigation, Intrusion prevention",103160,,"The advancement of modern Operating Systems (OSs), and the popularity of personal computing devices with Internet connectivity, have facilitated the proliferation of ransomware attacks. Ransomware has evolved from executable programs encrypting user files, to novel attack vectors including fileless command scripts, information exfiltration and human-operated ransomware. Many anti-ransomware studies have been published, but many of them assumed newer ransomware variants only performed file encryption, were similar to existing variants, and often did not consider those novel attack vectors. We have defined an updated ransomware threat model to include those novel attack vectors, and redefined false positives and false negatives in the context of ransomware mitigation. We proposed to apply both program-centric and user-centric access control to combat ransomware, but only delegate access control decisions that users are capable of making to users, while enforcing non-negotiable access control decisions by OS and software developers. We have designed a Staged Event-Driven Access Control (SEDAC) approach to incorporate both program-centric and user-centric access control measures, and demonstrated a prototype on Windows OS. Our prototype was able to intercept more types of ransomware attack vectors than existing proposals. We hope to convince OS and software architects to incorporate our design to better combat ransomware.",https://doi.org/10.1016/j.cose.2023.103160,https://www.sciencedirect.com/science/article/pii/S0167404823000706,,,,2023,Applying staged event-driven access control to combat ransomware,Timothy McIntosh and A.S.M. Kayes and Yi-Ping Phoebe Chen and Alex Ng and Paul Watters,article,MCINTOSH2023103160,Computers & Security,,128,0167-4048,,,
,"Extreme Programming, Object, Object-Oriented Programming, Procedural languages, Spiral Model, Systems Development Life Cycle, Waterfall Model",429-477,CISSP Study Guide (Third Edition),"Chapter 9 introduces Domain 8 of the CISSP, Software Development Security. The most important aspects of this domain are related to managing the development of software and applications. Approaches to software development that attempt to reduce the likelihood of defects or flaws are a key topic in this domain. In particular, the Waterfall, Spiral, and Rapid Application Development (RAD) models of the software development are considered. Another significant portion of this chapter is dedicated to understanding the principles of Object Oriented programming and design. A basic discussion of several types of software vulnerabilities and the issues surrounding disclosure of the vulnerabilities are also a topic for this domain. Finally, databases, being a key component of many applications, are considered.",https://doi.org/10.1016/B978-0-12-802437-9.00009-6,https://www.sciencedirect.com/science/article/pii/B9780128024379000096,Boston,Syngress,978-0-12-802437-9,2016,"Chapter 9 - Domain 8: Software Development Security (Understanding, Applying, and Enforcing Software Security)",Eric Conrad and Seth Misenar and Joshua Feldman,incollection,CONRAD2016429,,,,,,Eric Conrad and Seth Misenar and Joshua Feldman,Third Edition
,"GUI testing, GUI-based testing, Software testing, Code review, Modern code review, Guidelines, Practices",107299,,"Context:
Review of software artifacts, such as source or test code, is a common practice in industrial practice. However, although review guidelines are available for source and low-level test code, for GUI-based testing artifacts, such guidelines are missing.
Objective:
The goal of this work is to define a set of guidelines from literature about production and test code, that can be mapped to GUI-based testing artifacts.
Method:
A systematic literature review is conducted, using white and gray literature to identify guidelines for source and test code. These synthesized guidelines are then mapped, through examples, to create actionable, and applicable, guidelines for GUI-based testing artifacts.
Results:
The results of the study are 33 guidelines, summarized in nine guideline categories, that are successfully mapped as applicable to GUI-based testing artifacts. Of the collected literature, only 10 sources contained test-specific code review guidelines. These guideline categories are: perform automated checks, use checklists, provide context information, utilize metrics, ensure readability, visualize changes, reduce complexity, check conformity with the requirements and follow design principles and patterns.
Conclusion:
This pivotal set of guidelines provides an industrial contribution in filling the gap of general guidelines for review of GUI-based testing artifacts. Additionally, this work highlights, from an academic perspective, the need for future research in this area to also develop guidelines for other specific aspects of GUI-based testing practice, and to take into account other facets of the review process not covered by this work, such as reviewer selection.",https://doi.org/10.1016/j.infsof.2023.107299,https://www.sciencedirect.com/science/article/pii/S0950584923001532,,,,2023,Code review guidelines for GUI-based testing artifacts,Andreas Bauer and Riccardo Coppola and Emil Alégroth and Tony Gorschek,article,BAUER2023107299,Information and Software Technology,,163,0950-5849,,,
,"Software Defined Networking, Attack detection and mitigation, Network security, Middlebox management, Traffic management, Policy management, Traffic engineering, Smart grid security",89-108,,"Software Defined Networking (SDN) has emerged as a new networking paradigm for managing different kinds of networks ranging from enterprise to home network through software enabled control. The logically centralized control plane and programmability offers a great opportunity to improve network security, like implementing new mechanisms to detect and mitigate various threats, as well as enables deploying security as a service on the SDN controller. Due to the increasing and fast development of SDN, this paper provides an extensive survey on the application of SDN on enhancing the security of computer networks. In particular, we survey recent research studies that focus on applying SDN for network security including attack detection and mitigation, traffic monitoring and engineering, configuration and policy management, service chaining, and middlebox deployment, in addition to smart grid security. We further identify some challenges and promising future directions on SDN security, compatibility and scalability issues that should be addressed in this field.",https://doi.org/10.1016/j.jnca.2019.01.019,https://www.sciencedirect.com/science/article/pii/S108480451930027X,,,,2019,The application of Software Defined Networking on securing computer networks: A survey,Rishikesh Sahay and Weizhi Meng and Christian D. Jensen,article,SAHAY201989,Journal of Network and Computer Applications,,131,1084-8045,,,
,"automatic text mining, web crawlers, text classification, intelligent transportation systems, machine learning, tf-idf, n-gram, naïve Bayes algorithm, linear classifier, sentiment analysis",626-635,,"The paper addresses the task of analyzing traffic safety in the Northwestern Federal District according to the reviews published in the Web. To accomplish the task, the authors developed a system of automatic review classification based on a sentiment classifier. They analyzed open source libraries for data mining, developed a web crawler using Scrapy framework, written in Python 3, and collected reviews. They also considered the methods of text vectorization and lemmatization and their application in the Scikit-Learn library: Bag-of-Words, N-gram, CountVectorizer, and TF-IDF Vectorizer. For the purpose of classification, the authors used the naïve Bayes algorithm and a linear classifier model with stochastic gradient descent optimization. A base of tagged Twitter reviews was used as a training set. The classifier was trained using cross-validation and ShuffleSplit strategies. The authors also tested and compared the classification results for different classifiers. As a result of validation, the best model was determined. The developed system was applied to analyze the quality of roads in the Northwestern Federal District. Based on the outcome, the roads were marked-up in color to illustrate the results of the research.",https://doi.org/10.1016/j.trpro.2020.10.074,https://www.sciencedirect.com/science/article/pii/S2352146520308255,,,,2020,Traffic safety evaluation in Northwestern Federal District using sentiment analysis of Internet users’ reviews,Yaroslav Seliverstov and Svyatoslav Seliverstov and Igor Malygin and Oleg Korolev,article,SELIVERSTOV2020626,Transportation Research Procedia,,50,2352-1465,XIV International Conference on Organization and Traffic Safety Management in Large Cities (OTS-2020),,
Intelligent Data-Centric Systems,"Explainable artificial intelligence, Interpretable machine learning, Machine learning model, User interface",295-310,Innovations in Artificial Intelligence and Human-Computer Interaction in the Digital Era,"Artificial intelligence–based systems are developed and successfully used for applications like home appliances, defense systems, virtual assistance, robotics, self-driving vehicles, and many more. Their success lies in accurate and timely decision-making ability. But the other side of these systems is a lack of transparency that can be described as black box. Due to the opaque nature of existing artificial intelligence systems, researchers are not able to interpret the decisions that have been derived from given input situations. The lack of openness not only causes the end users to resist trusting the system but also tends to make it difficult for machine learning engineers to detect and mitigate the fault in case of failure in deriving desired output. The solution is to open the black box working nature of the system and provide required explanations as well interpretations to making the whole processes humanly understandable and meaningful. This chapter focuses on the need for explainable artificially intelligent systems, present paradigms that exist to achieve it, along with various forms of explanations expected by different stakeholders and challenges in the field of making transparent systems in the direction of trustworthy human–computer interaction.",https://doi.org/10.1016/B978-0-323-99891-8.00006-1,https://www.sciencedirect.com/science/article/pii/B9780323998918000061,,Academic Press,978-0-323-99891-8,2023,Chapter 11 - Challenges and future work directions in artificial intelligence with human-computer interaction,Mahesh H. Panchal and Shaileshkumar D. Panchal,incollection,PANCHAL2023295,,,,,,Surbhi {Bhatia Khan} and Suyel Namasudra and Swati Chandna and Arwa Mashat and Fatos Xhafa,
,"Blockchain platforms, Cryptocurrency, User-generated content provisioning, Token supply mechanism, Coarsened exact matching",103989,,"This study investigates the impact of cryptocurrency rewards and token prices on user-generated content (UGC) provision by content creators on a blockchain-based platform. Analyzing data from the Steemit platform, we find that although an increase in total reward value incentivizes UGC contributions, the rise in token prices alone does not lead to a surge in UGC. Instead, token prices have a mediating role in the relationship between total rewards earned by content creators and the volume of UGC they produce. Furthermore, we observe that an increase in UGC does not lead to a corresponding rise in the platform's market capitalization, as increased website traffic intensifies competition for rewards from a constant pool, suggesting that heightened user engagement does not translate to enhanced market capitalization. These findings imply that carefully designed reward mechanisms are crucial for sustaining user engagement and content creation amidst market fluctuations. Our study underscores the importance of a comprehensive approach to incentivizing user participation and ensuring platform growth, as a mere increase in token prices may not guarantee sustained engagement or an associated increase in market capitalization.",https://doi.org/10.1016/j.im.2024.103989,https://www.sciencedirect.com/science/article/pii/S0378720624000715,,,,2024,Do cryptocurrency rewards improve platform valuations?,Hemang Subramanian and Florent Rouxelin,article,SUBRAMANIAN2024103989,Information & Management,6,61,0378-7206,,,
Intelligence-Based Medicine: Subspecialty Series,,481-501,Intelligence-Based Cardiology and Cardiac Surgery,,https://doi.org/10.1016/B978-0-323-90534-3.17001-5,https://www.sciencedirect.com/science/article/pii/B9780323905343170015,,Academic Press,978-0-323-90534-3,2024,Glossary,,incollection,2024481,,,,,,Anthony C. Chang and Alfonso Limon,
,"Anomaly detection, Machine Learning, Internet of Things (IoT), Smart home, Cybersecurity, Cyber attacks, Systematic literature review (SLR)",100792,,"Smart homes, leveraging IoT technology to interconnect various devices and appliances to the internet, enable remote monitoring, automation, and control. However, collecting sensitive personal and business data assets renders smart homes a target for cyberattacks. Anomaly detection is a promising approach for identifying malicious behavior in smart homes. Yet, the current literature primarily discusses IoT-related cyberattacks and gives limited attention to detecting anomalies specific to the smart home context. Furthermore, there is a lack of datasets that accurately represent the complexity inherent in a smart home environment in terms of users with varying levels of expertise and diverse, evolving types of devices. Therefore, this paper presents a systematic literature review (SLR) that focuses on using anomaly detection to identify cyberattacks in smart home environments. The SLR includes an adapted taxonomy that classifies existing anomaly detection methods and a critical analysis of the current state of knowledge and future research challenges. Our findings show a growing interest in detecting cyberattacks with anomaly-based models in smart homes using centralized and network-based features. Ensemble and deep learning techniques are popular methods for detecting these anomalies. However, the limited diversity of cyberattacks in existing datasets and the absence of comprehensive datasets representing the complexity of smart home environments call for further research to improve the generalizability of detection models.",https://doi.org/10.1016/j.iot.2023.100792,https://www.sciencedirect.com/science/article/pii/S2542660523001154,,,,2023,Anomaly-based cyberattacks detection for smart homes: A systematic literature review,Juan Ignacio Iturbe Araya and Helena Rifà-Pous,article,ARAYA2023100792,Internet of Things,,22,2542-6605,,,
,"Network security, Tsallis entropy, DDoS attack",79-87,,"Distributed Denial-of-Service attacks have been a challenge to cyberspace, as the attackers send a large number of attack packets similar to the normal traffic, to throttle legitimate flows. These attacks intentionally disrupt the services offered by the systems resulting in heavy cost. A flash crowd or flash event is an unexpected surge in the number of visitors to a particular website resulting in a sudden increase in server load. Flash crowds, which are legitimate flows, are difficult to be discriminated from Distributed Denial-of-Service attacks that are illicit flows. Effective and accurate detection of Distributed Denial of Service attacks still remains a challenge due to the difficulty in its detection and the false alerts generated in the case of flash crowds. There is a trade off between detection rate and false positive rate. This work deals with an efficient and early detection of distributed denial of service attacks and discriminates flash crowd by considering two network traffic parameters such as packet size and destination IP address. Using these traffic features two attributes are computed and its generalized entropies are calculated. The threshold is computed using the mean value of network attributes to detect the attacks. Threshold updater can automatically adjust the threshold values according to the changes in the channel conditions. The data sets used to evaluate the performance of the proposed approach are the MIT Lincoln Laboratory DARPA data set and a data set generated in a University network. Experimental results show this research approach achieves higher detection rate and lower false positives in a much reduced processing time as compared to the existing methods.",https://doi.org/10.1016/j.jpdc.2021.02.019,https://www.sciencedirect.com/science/article/pii/S074373152100040X,,,,2021,Discriminating flash crowds from DDoS attacks using efficient thresholding algorithm,Jisa David and Ciza Thomas,article,DAVID202179,Journal of Parallel and Distributed Computing,,152,0743-7315,,,
,"Network intrusion detection, Deep learning, Class imbalance, Gaussian mixture model, Convolutional neural network",107315,,"Network Intrusion Detection System (NIDS) is a key security device in modern networks to detect malicious activities. However, the problem of imbalanced class associated with intrusion detection dataset limits the classifier’s performance for minority classes. To improve the detection rate of minority classes while ensuring efficiency, we propose a novel class imbalance processing technology for large-scale dataset, referred to as SGM, which combines Synthetic Minority Over-Sampling Technique (SMOTE) and under-sampling for clustering based on Gaussian Mixture Model (GMM). We then design a flow-based intrusion detection model, SGM-CNN, which integrates imbalanced class processing with convolutional neural network, and investigate the impact of different numbers of convolution kernels and different learning rates on model performance. The advantages of the proposed model are verified using the UNSW-NB15 and CICIDS2017 datasets. The experimental results show that i) for binary classification and multiclass classification on the UNSW-NB15 dataset, SGM-CNN achieves a detection rate of 99.74% and 96.54%, respectively; ii) for 15-class classification on the CICIDS2017 dataset, it achieves a detection rate of 99.85%. We compare five imbalanced processing methods and two classification algorithms, and conclude that SGM-CNN provides an effective solution to imbalanced intrusion detection and outperforms the state-of-the-art intrusion detection methods.",https://doi.org/10.1016/j.comnet.2020.107315,https://www.sciencedirect.com/science/article/pii/S1389128620300712,,,,2020,An effective convolutional neural network based on SMOTE and Gaussian mixture model for intrusion detection in imbalanced dataset,Hongpo Zhang and Lulu Huang and Chase Q. Wu and Zhanbo Li,article,ZHANG2020107315,Computer Networks,,177,1389-1286,,,
,"Spoken dialogue systems, Automatic speech recognition, End of turn detection, Natural language processing, Neural networks",104189,,"An End-Of-Turn Detection Module (EOTD-M) is an essential component of automatic Spoken Dialogue Systems. The capability of correctly detecting whether a user’s utterance has ended or not improves the accuracy in interpreting the meaning of the message and decreases the latency in the answer. Usually, in dialogue systems, an EOTD-M is coupled with an Automatic Speech Recognition Module (ASR-M) to transmit complete utterances to the Natural Language Understanding unit. Mistakes in the ASR-M transcription can have a strong effect on the performance of the EOTD-M. The actual extent of this effect depends on the particular combination of ASR-M transcription errors and the sentence featurization techniques implemented as part of the EOTD-M. In this paper we investigate this important relationship for an EOTD-M based on semantic information and particular characteristics of the speakers (speech profiles). We introduce an Automatic Speech Recognition Simulator (ASR-SIM) that models different types of semantic mistakes in the ASR-M transcription as well as different speech profiles. We use the simulator to evaluate the sensitivity to ASR-M mistakes of a Long Short-Term Memory network classifier trained in EOTD with different featurization techniques. Our experiments reveal the different ways in which the performance of the model is influenced by the ASR-M errors. We corroborate that not only is the ASR-SIM useful to estimate the performance of an EOTD-M in customized noisy scenarios, but it can also be used to generate training datasets with the expected error rates of real working conditions, which leads to better performance.",https://doi.org/10.1016/j.engappai.2021.104189,https://www.sciencedirect.com/science/article/pii/S0952197621000361,,,,2021,Analysis of the sensitivity of the End-Of-Turn Detection task to errors generated by the Automatic Speech Recognition process,César Montenegro and Roberto Santana and Jose A. Lozano,article,MONTENEGRO2021104189,Engineering Applications of Artificial Intelligence,,100,0952-1976,,,
,"Keystroke dynamics, Keyboard, USB, Malicious, Malware, Concealment, Authentication, Supply chain attack",240-269,,"Concealing malicious components within widely used USB peripherals has become a popular attack vector utilizing social engineering techniques and exploiting users’ trust in USB devices. This vector enables the attacker to easily penetrate an organization's computers even when the target is secured or in an air-gapped network. Such malicious concealment can be done as part of a supply chain attack or during the device manufacturing process. In cases where the device allows the user to update its firmware, a supply chain attack may involve changing just the device's firmware, thus compromising the device without the need for concealment. A compromised device can impersonate other devices like keyboards in order to send malicious keystrokes to the computer. However, the keystrokes generated maliciously do not match human keystroke characteristics, and therefore they can be easily detected by security tools that are designed to continuously verify the user's identity based on his/her keystroke dynamics. In this paper, we present Malboard, a sophisticated attack based on designated hardware concealment, which automatically generates keystrokes that have the attacked user's behavioral characteristics; in this attack these keystrokes are injected into the computer in the form of malicious commands and thus can evade existing detection mechanisms designed to continuously verify the user's identity based on keystroke dynamics. We implemented this novel attack and evaluated its performance on 30 subjects performing three different keystroke tasks; we evaluated the attack against three existing detection mechanisms, and the results show that our attack managed to evade detection in 83–100% of the cases, depending on the detection tools in place. Malboard was proven to be effective in two scenarios: either by a remote attacker using wireless communication to communicate with Malboard or by an inside attacker (malicious employee) that physically operates and uses Malboard. In addition, in order to address the evasion gap, we developed three different modules aimed at detecting keystroke injection attacks in general, and particularly, the more sophisticated Malboard attack. Our proposed detection modules are trusted and secured, because they are based on three side-channel resources which originate from the interaction between the keyboard, user, and attacked host. These side-channel resources include (1) the keyboard's power consumption, (2) the keystrokes’ sound, and (3) the user's behavior associated with his/her ability to respond to displayed textual typographical errors. Our results showed that each of the proposed detection modules is capable of detecting the Malboard attack in 100% of the cases, with no misses and no false positives; using them together as an ensemble detection framework will assure that an organization is immune to the Malboard attack in particular and other keystroke injection attacks in general.",https://doi.org/10.1016/j.cose.2019.05.008,https://www.sciencedirect.com/science/article/pii/S0167404818309957,,,,2019,Malboard: A novel user keystroke impersonation attack and trusted detection framework based on side-channel analysis,Nitzan Farhi and Nir Nissim and Yuval Elovici,article,FARHI2019240,Computers & Security,,85,0167-4048,,,
,"Dataset, Crop, Computer vision, Precision agriculture, Robotics, Data sharing, Images",105760,,"Computer vision technologies have attracted significant interest in precision agriculture in recent years. At the core of robotics and artificial intelligence, computer vision enables various tasks from planting to harvesting in the crop production cycle to be performed automatically and efficiently. However, the scarcity of public image datasets remains a crucial bottleneck for fast prototyping and evaluation of computer vision and machine learning algorithms for the targeted tasks. Since 2015, a number of image datasets have been established and made publicly available to alleviate this bottleneck. Despite this progress, a dedicated survey on these datasets is still lacking. To fill this gap, this paper makes the first comprehensive but not exhaustive review of the public image datasets collected under field conditions for facilitating precision agriculture, which include 15 datasets on weed control, 10 datasets on fruit detection, and 9 datasets on miscellaneous applications. We survey the main characteristics and applications of these datasets, and discuss the key considerations for creating high-quality public image datasets. This survey paper will be valuable for the research community on the selection of suitable image datasets for algorithm development and identification of where creation of new image datasets is needed to support precision agriculture.",https://doi.org/10.1016/j.compag.2020.105760,https://www.sciencedirect.com/science/article/pii/S0168169920312709,,,,2020,A survey of public datasets for computer vision tasks in precision agriculture,Yuzhen Lu and Sierra Young,article,LU2020105760,Computers and Electronics in Agriculture,,178,0168-1699,,,
,"Blockchain, Smart contracts, P2P, Consensus, Ledger, Testing, Verification, Validation, Simulation, Benchmarking, Software testing, Security testing, Performance testing, System under test, Formal verification, Platform testing",100492,,"As blockchain technology is gaining popularity in industry and society, solutions for Verification and Validation (V&V) of blockchain-based software applications (BC-Apps) have started gaining equal attention. To ensure that BC-Apps are properly developed before deployment, it is paramount to apply systematic V&V to verify their functional and non-functional requirements. While existing research aims at addressing the challenges of engineering BC-Apps by providing testing techniques and tools, blockchain-based software development is still an emerging research discipline, and therefore, best practices and tools for the V&V of BC-Apps are not yet sufficiently developed. In this paper, we provide a comprehensive survey on V&V solutions for BC-Apps. Specifically, using a layered approach, we synthesize V&V tools and techniques addressing different components at various layers of the BC-App stack, as well as across the whole stack. Next, we provide a discussion on the challenges associated with BC-App V&V, and summarize a set of future research directions based on the challenges and gaps identified in existing research work. Our study aims to highlight the importance of BC-App V&V and pave the way for a disciplined, testable, and verifiable BC development.",https://doi.org/10.1016/j.cosrev.2022.100492,https://www.sciencedirect.com/science/article/pii/S1574013722000314,,,,2022,"Blockchain verification and validation: Techniques, challenges, and research directions",Dusica Marijan and Chhagan Lal,article,MARIJAN2022100492,Computer Science Review,,45,1574-0137,,,
,"HIP, CAPTCHA, Machine learning, Gender classification, Side-channel attack",744-756,,"Human Interactive Proofs (HIPs 11Human Interaction Proof, or also Human Interactive Proof. or CAPTCHAs 22Completely Automated Public Turing test to tell Computers and Humans Apart.) have become a first-level security measure on the Internet to avoid automatic attacks or minimize their effects. All the most widespread, successful or interesting CAPTCHA designs put to scrutiny have been successfully broken. Many of these attacks have been side-channel attacks. New designs are proposed to tackle these security problems while improving the human interface. FunCAPTCHA is the first commercial implementation of a gender classification CAPTCHA, with reported improvements in conversion rates. This article finds weaknesses in the security of FunCAPTCHA and uses simple machine learning (ML) analysis to test them. It shows a side-channel attack that leverages these flaws and successfully solves FunCAPTCHA on 90% of occasions without using meaningful image analysis. This simple yet effective security analysis can be applied with minor modifications to other HIPs proposals, allowing to check whether they leak enough information that would in turn allow for simple side-channel attacks.",https://doi.org/10.1016/j.cose.2017.05.005,https://www.sciencedirect.com/science/article/pii/S0167404817301128,,,,2017,Using machine learning to identify common flaws in CAPTCHA design: FunCAPTCHA case analysis,Carlos Javier Hernández-Castro and María D. R-Moreno and David F. Barrero and Stuart Gibson,article,HERNANDEZCASTRO2017744,Computers & Security,,70,0167-4048,,,
,"BDI Agents, Robotics, UAVs, ROS, Jason",10000-10005,,"This paper proposes and evaluates an embedded architecture aimed to promote the utilization of cognitive agents in cooperation with the Robotic Operating System (ROS), serving as an alternative for programming intelligent robots. It promotes the programming abstraction level in two directions. The first direction regards using cognitive agents facilities for programming the robots intelligence, consisting of its perceptions and related actions. The second direction exploits the facilities of using ROS layers for programming the robot interaction with its sensors and actuators. The paper reports experiments of using agents to command simulated UAVs while measuring performance metrics that allowed us to evaluate the benefits of the proposed architecture.",https://doi.org/10.1016/j.ifacol.2020.12.2718,https://www.sciencedirect.com/science/article/pii/S2405896320334819,,,,2020,Embedded Architecture Composed of Cognitive Agents and ROS for Programming Intelligent Robots,Gustavo R. Silva and Leandro B. Becker and Jomi F. Hübner,article,SILVA202010000,IFAC-PapersOnLine,2,53,2405-8963,21st IFAC World Congress,,
,"General data protection regulation, Controller, Joint controller, Household exception, Virtual assistant, Google assistant",105689,,"This article provides an overview and critical examination of the rules for determining who qualifies as controller or joint controller under the General Data Protection Regulation. Using Google Assistant – an artificial intelligence-driven virtual assistant – as a case study, we argue that these rules are overreaching and difficult to apply in the present-day information society and Internet of Things environments. First, as a consequence of recent developments in case law and supervisory guidance, these rules lead to a complex and ambiguous test to determine (joint) control. Second, due to advances in technological applications and business models, it is increasingly challenging to apply such rules to contemporary processing operations. In particular, as illustrated by the Google Assistant, individuals will likely be qualified as joint controllers, together with Google and also third-party developers, for at least the collection and possible transmission of other individuals’ personal data via the virtual assistant. Third, we identify follow-on issues relating to the apportionment of responsibilities between joint controllers and the effective and complete protection of data subjects. We conclude by questioning whether the framework for determining who qualifies as controller or joint controller is future-proof and normatively desirable.",https://doi.org/10.1016/j.clsr.2022.105689,https://www.sciencedirect.com/science/article/pii/S026736492200036X,,,,2022,A Matter of (Joint) control? Virtual assistants and the general data protection regulation,Jurriaan {van Mil} and João Pedro Quintais,article,VANMIL2022105689,Computer Law & Security Review,,45,0267-3649,,,
,"Nontarget analysis, Disinfection byproducts, Ultrahigh-resolution mass spectrometry, Dissolved organic matter, Compounds of emerging concerns",120694,,"Halogenated organic compounds (HOCs), widely present in various environments, are generally formed by natural processes (e.g., photochemical halogenation) and anthropogenic activities (e.g., water disinfection and anthropogenic discharge of HOCs), posing health and environmental risks. Therefore, in-depth knowledge of the molecular composition, transformation, and fate of HOCs is crucial to regulate and reduce their formation. Because of the extremely complex nature of HOCs and their precursors, the molecular composition of HOCs remains largely unknown. The Fourier transform ion cyclotron resonance mass spectrometry (FT-ICR MS) offers the most powerful resolution and mass accuracy for the simultaneous molecular-level characterization of HOCs and their precursors. However, there is still a paucity of reviews regarding the comprehensive characterization of HOCs by FT-ICR MS. Based on the FT-ICR MS, the formation mechanism, sample pretreatment, and analysis methods were summarized for two typical HOCs classes, namely halogenated disinfection byproducts and per- and polyfluoroalkyl substances in this review. Moreover, we have highlighted data analysis methods and some typical applications of HOCs using FT-ICR MS and proposed suggestions for current issues. This review will deepen our understanding of the chemical characterization of HOCs and their formation mechanisms and transformation at the molecular level in aquatic systems, facilitating the application of the state-of-the-art FT-ICR MS in environmental and geochemical research.",https://doi.org/10.1016/j.watres.2023.120694,https://www.sciencedirect.com/science/article/pii/S004313542301134X,,,,2023,Characterization of halogenated organic compounds by the Fourier transform ion cyclotron resonance mass spectrometry: A critical review,Shixi Wu and Manabu Fujii and Xin Yang and Qing-Long Fu,article,WU2023120694,Water Research,,246,0043-1354,,,
,"Building information modelling, Concurrent engineering, Design collaboration, Knowledge graphs, Semantic enrichment",101711,,"The technological tools people use for designing buildings have progressed from drawings to descriptive geometry, and from computer-aided drafting and design (CAD) to building information modelling (BIM). Yet despite their use of state-of-the-art BIM technology, the multidisciplinary teams that design modern buildings still face numerous challenges. Building models lack sufficient semantic content to properly express design intent, concurrent design is difficult due to the need for operators to maintain model consistency and integrity manually, managing design variations is cumbersome due to the packaging of information in files, and collaboration requires making-do with imperfect interoperability between application software. In response, we propose a ‘Cloud BIM’ (CBIM) approach to building modelling that seeks to automate maintenance of consistency across federated discipline-specific models by enriching models with semantic information that encapsulates design intent. The approach requires a new ontology to represent knowledge about the relationships between building model objects within and across disciplines. Discipline-specific building models are stored together with their data schema in knowledge graphs, and linked using objects and relationships from the CBIM ontology. The links are established using artificially intelligent semantic enrichment methods that recognize patterns of location, geometry, topology and more. Software methods that operate along CBIM relationship chains can detect inconsistencies that arise across disciplines and act to inform users, propose meaningful corrections, and apply them if approved. Future CBIM systems may provide designers with the functionality for collaborative multidisciplinary design by maintaining model consistency and managing versioning at the object level.",https://doi.org/10.1016/j.aei.2022.101711,https://www.sciencedirect.com/science/article/pii/S1474034622001690,,,,2022,Toward artificially intelligent cloud-based building information modelling for collaborative multidisciplinary design,Rafael Sacks and Zijian Wang and Boyuan Ouyang and Duygu Utkucu and Siyu Chen,article,SACKS2022101711,Advanced Engineering Informatics,,53,1474-0346,,,
," bioprinting, Robotic bioprinting platform, Path planning algorithm",e00139,,"The aim of this work is to design a robotic bioprinting platform able to fabricate a three-dimensional structure onto irregular surfaces. With respect to the limitations of current in vitro bioprinting approach, widely used in scaffold-based tissue engineering – handling difficulty, risk of contamination, shape not matching with the defect site – this robotic bioprinter can offer an innovative solution allowing in situ bioprinting, a direct dispensing of biological materials onto and into the damaged site. The robotic platform was developed starting from the 5 degrees-of-freedom open source MOVEO robot from BCN3D. The hardware and the software of the original project were re-engineered to control the robot using LinuxCNC, a path planning algorithm was developed in Matlab®, and the end-effector was equipped with a pneumatic extruder. The algorithm automatically projects any generic printing pattern on the surface on which the scaffold will be 3D bioprinted. For each point, the algorithm calculates the joint angles to keep the end effector always perpendicular to the surface. A g-code file is then exported to Linux CNC adding parameters to control the air pressure and the printing speed. The robotic platform was tested to evaluate its performances. Resolution (~200 ​μm) and repeatability were estimated and preliminary in situ bioprinting tests were performed onto different irregular surfaces, including a physiologically relevant bone model.",https://doi.org/10.1016/j.bprint.2021.e00139,https://www.sciencedirect.com/science/article/pii/S2405886621000129,,,,2021,Robotic platform and path planning algorithm for in situ bioprinting,Gabriele Maria Fortunato and Gabriele Rossi and Amedeo Franco Bonatti and Aurora {De Acutis} and Christian Mendoza-Buenrostro and Giovanni Vozzi and Carmelo {De Maria},article,FORTUNATO2021e00139,Bioprinting,,22,2405-8866,,,
,"Computer science, Network, Network topology",103217,,"Summary
Link prediction is a paradigmatic problem in network science, which aims at estimating the existence likelihoods of nonobserved links, based on known topology. After a brief introduction of the standard problem and evaluation metrics of link prediction, this review will summarize representative progresses about local similarity indices, link predictability, network embedding, matrix completion, ensemble learning, and some others, mainly extracted from related publications in the last decade. Finally, this review will outline some long-standing challenges for future studies.",https://doi.org/10.1016/j.isci.2021.103217,https://www.sciencedirect.com/science/article/pii/S2589004221011858,,,,2021,Progresses and challenges in link prediction,Tao Zhou,article,ZHOU2021103217,iScience,11,24,2589-0042,,,
,"DDoS, Attack detection, Mitigation, Fog computing, VNF",51-62,,"Distributed denial of service (DDoS) cyber-attack poses a severe threat to the industrial Internet of Things (IIoT) operation due to the security vulnerabilities resulted from increased connectivity and openness, and the large number of deployed low computation power devices. This paper applies Fog computing concept in DDoS mitigation by allocating traffic monitoring and analysis work close to local devices, and, on the other hand, coordinating and consolidating work to cloud central servers so as to achieve fast response while at low false alarm rate. The mitigation scheme consists of real-time traffic filtering via field firewall devices, which are able to reversely filter the signature botnet attack packets; offline specification based traffic analysis via virtualized network functions (VNFs) in the local servers; and centralized coordination via cloud server, which consolidates and correlates the information from the distributed local servers to make a more accurate decision. The proposed scheme is tested in an industrial control system testbed and the experiments evaluate the detection time and rate for two types of DDoS attacks and demonstrate the effectiveness of the scheme.",https://doi.org/10.1016/j.cose.2019.04.017,https://www.sciencedirect.com/science/article/pii/S0167404818311349,,,,2019,A fog computing based approach to DDoS mitigation in IIoT systems,Luying Zhou and Huaqun Guo and Gelei Deng,article,ZHOU201951,Computers & Security,,85,0167-4048,,,
,"Blockchain, Alternative financing solutions, Initial coin offerings, Asymmetrical information",101966,,"This article analyzes the main problems and the solutions adopted in the market for Initial Coin Offerings (ICO), to anticipate the future of this market and determine implications for issuers, investors and regulators. ICOs represent an alternative and innovative financing solution that has experienced spectacular growth and notoriety in recent years. ICOs rely on Blockchain protocols and the ICO market is, therefore, characterized as decentralized, disintermediated and unregulated. Our results show that although the ICO market is innovative, it already displays many of the problems of traditional financial markets, and that these problems were at the genesis of the last financial crisis. Our analysis of the problems and solutions adopted shows a tension between what the Blockchain technology offers, and the problems associated with the financing of innovation. Considering the problems and solutions adopted, we no longer expect the ICO market to be characterized as disintermediated, unregulated or even decentralized in the near future. Furthermore, it is a real possibility that ICOs may end up being a progressor model eventually replaced by similar but more specialized financing models, some of which may already exist. With respect to the particular solutions of the ICO market, while some represent the realization of the potential of Blockchain, others such as forks have important Governance implications with the potential to create as many problems as the ones they address.",https://doi.org/10.1016/j.irfa.2021.101966,https://www.sciencedirect.com/science/article/pii/S1057521921002842,,,,2022,Challenges of the market for initial coin offerings,Pablo {de Andrés} and David Arroyo and Ricardo Correia and Alvaro Rezola,article,DEANDRES2022101966,International Review of Financial Analysis,,79,1057-5219,,,
,"Mobile robots, Path planning, Deep reinforcement learning, Deep Q-Learning, Dueling neural network, ROS",111503,,"Path planning is a key requirement for mobile robots employed for different tasks such as rescue or transport missions. Conventional methods such as A* or Dijkstra to tackle path planning problem need a premise map of the robot's environment. Nowadays, dynamic path planning is a popular research topic, which drives mobile robots without prior static requirements. Deep reinforcement learning (DRL), which is another popular research area, is being harnessed to solve dynamic path planning problem by the researchers. In this study, Deep Q-Networks, which is a subdomain of DRL are opted to solve dynamic path planning problem. We first employ well known techniques Double Deep Q-Networks (D2QN) and Dueling Double Deep Q-Networks (D3QN) to train a model which can drive a mobile robot in environments with static and dynamic obstacles within 3 different configurations. Then we propose D3QN with Prioritized Experience Replay (PER) extension in order to further optimize the DRL model. We created a test bed to measure the performance of the DRL models against 99 randomly generated goal locations. According to our experiments, D3QN-PER method performs better than D2QN and D3QN in terms of path length and travel time to the goal without any collisions. Robot Operating System and Gazebo simulation environment is utilized to realize the training and testing environments, thus, the trained DRL models can be deployed to any ROS compatible robot seamlessly.",https://doi.org/10.1016/j.asoc.2024.111503,https://www.sciencedirect.com/science/article/pii/S1568494624002771,,,,2024,Dynamic path planning via Dueling Double Deep Q-Network (D3QN) with prioritized experience replay,Mehmet Gök,article,GOK2024111503,Applied Soft Computing,,158,1568-4946,,,
,"Decentralization, Immutable, Independence, Interoperability, Privacy, Protection, Trustless, Web3, Web3+, Web3.0",553-581,Handbook of Digital Currency (Second Edition),"The Internet has undergone numerous changes since its emergence in 1969 and has now become an indispensable aspect of modern life. With the introduction of the World Wide Web by Tim Berners-Lee, the Internet has transformed into a tool for sharing and accessing vast amounts of information. As the Internet evolves toward its third iteration, Web3+ offers a decentralized solution that empowers users and returns control over the Internet to them. With the rise of cryptocurrency and blockchain, Web3+ focuses on data ownership and protection, making the Internet more secure and fair for everyone. In this article, we will explore the differences between Web 1.0, Web 2.0, Web 3.0, Web3, and Web3+ and how they shape the future of the Internet.",https://doi.org/10.1016/B978-0-323-98973-2.00052-6,https://www.sciencedirect.com/science/article/pii/B9780323989732000526,San Diego,Academic Press,978-0-323-98973-2,2024,"Chapter 28 - Understanding the Evolution of the Internet: Web 1.0 to Web3.0, Web3, and Web 3+∗∗The article is written with the help of ChatGPT to enhance the writing style. ChatGPT also assisted the author in verification of some information.",Zheng JinCheng and David Lee Kuo Chuen,incollection,JINCHENG2024553,,,,,,David {Lee Kuo Chuen},Second Edition
,"Model driven engineering, Software engineering, Artificial intelligence, Machine learning, Systematic literature review",107423,,"Context:
Machine Learning (ML) has become widely adopted as a component in many modern software applications. Due to the large volumes of data available, organizations want to increasingly leverage their data to extract meaningful insights and enhance business profitability. ML components enable predictive capabilities, anomaly detection, recommendation, accurate image and text processing, and informed decision-making. However, developing systems with ML components is not trivial; it requires time, effort, knowledge, and expertise in ML, data processing, and software engineering. There have been several studies on the use of model-driven engineering (MDE) techniques to address these challenges when developing traditional software and cyber–physical systems. Recently, there has been a growing interest in applying MDE for systems with ML components.
Objective:
The goal of this study is to further explore the promising intersection of MDE with ML (MDE4ML) through a systematic literature review (SLR). Through this SLR, we wanted to analyze existing studies, including their motivations, MDE solutions, evaluation techniques, key benefits and limitations.
Method:
Our SLR is conducted following the well-established guidelines by Kitchenham. We started by devising a protocol and systematically searching seven databases, which resulted in 3934 papers. After iterative filtering, we selected 46 highly relevant primary studies for data extraction, synthesis, and reporting.
Results:
We analyzed selected studies with respect to several areas of interest and identified the following: (1) the key motivations behind using MDE4ML; (2) a variety of MDE solutions applied, such as modeling languages, model transformations, tool support, targeted ML aspects, contributions and more; (3) the evaluation techniques and metrics used; and (4) the limitations and directions for future work. We also discuss the gaps in existing literature and provide recommendations for future research.
Conclusion:
This SLR highlights current trends, gaps and future research directions in the field of MDE4ML, benefiting both researchers and practitioners.",https://doi.org/10.1016/j.infsof.2024.107423,https://www.sciencedirect.com/science/article/pii/S0950584924000284,,,,2024,Model driven engineering for machine learning components: A systematic literature review,Hira Naveed and Chetan Arora and Hourieh Khalajzadeh and John Grundy and Omar Haggag,article,NAVEED2024107423,Information and Software Technology,,169,0950-5849,,,
,"Public health, Trust in science, Trust in health authorities, Information-seeking responses and reliance, Epidemics, Infectious disease outbreaks, Pandemics",100721,,"Research suggests trust in experts and authorities are important correlates of compliance with public health measures during infectious disease outbreaks. Empirical evidence on the dynamics of reliance on scientists and public health authorities during the early phases of an epidemic outbreak is limited. We examine these processes during the COVID-19 outbreak in Italy by leveraging data from Twitter and two online surveys, including a survey experiment. We find that reliance on experts followed a curvilinear path. Both Twitter and survey data showed initial increases in information-seeking from expert sources in the three weeks after the detection of the first case. Consistent with these increases, knowledge about health information linked to COVID-19 and support for containment measures was widespread, and better knowledge was associated with stronger support for containment policies. Both knowledge and containment support were positively associated with trust in science and public health authorities. However, in the third week after the outbreak, we detected a slowdown in responsiveness to experts. These processes were corroborated with a survey experiment, which showed that those holding incorrect beliefs about COVID-19 gave no greater – or even lower – importance to information when its source was stated as coming from experts than when the source was unstated. Our results suggest weakened trust in public health authorities with prolonged exposure to the epidemic as a potential mechanism for this effect. Weakened responsiveness to expert sources may increase susceptibility to misinformation and our results call for efforts to sustain trust in adapting public health response.",https://doi.org/10.1016/j.ssmph.2020.100721,https://www.sciencedirect.com/science/article/pii/S235282732030358X,,,,2021,Reliance on scientists and experts during an epidemic: Evidence from the COVID-19 outbreak in Italy,Pietro Battiston and Ridhi Kashyap and Valentina Rotondi,article,BATTISTON2021100721,SSM - Population Health,,13,2352-8273,,,
,"Internet energy consumption, CO emission, Online advertising, Invalid traffic",177-200,,"There are no commonly agreed ways to assess the total energy consumption of the Internet. Estimating the Internet's energy footprint is challenging because of the interconnectedness associated with even seemingly simple aspects of energy consumption. The first contribution of this paper is a common modular and layered framework, which allows researchers to assess both energy consumption and CO2e emissions of any Internet service. The framework allows assessing the energy consumption depending on the research scope and specific system boundaries. Further, the proposed framework allows researchers without domain expertise to make such an assessment by using intermediate results as data sources, while analyzing the related uncertainties. The second contribution is an estimate of the energy consumption and CO2e emissions of online advertising by utilizing our proposed framework. The third contribution is an assessment of the energy consumption of invalid traffic associated with online advertising. The second and third contributions are used to validate the first. The online advertising ecosystem resides in the core of the Internet, and it is the sole source of funding for many online services. Therefore, it is an essential factor in the analysis of the Internet's energy footprint. As a result, in 2016, online advertising consumed 20–282 TWh of energy. In the same year, the total infrastructure consumption ranged from 791 to 1334 TWh. With extrapolated 2016 input factor values without uncertainties, online advertising consumed 106 TWh of energy and the infrastructure 1059 TWh. With the emission factor of 0.5656 kg CO2e/kWh, we calculated the carbon emissions of online advertising, and found it produces 60 Mt CO2e (between 12 and 159 Mt of CO2e when considering uncertainty). The share of fraudulent online advertising traffic was 13.87 Mt of CO2e emissions (between 2.65 and 36.78 Mt of CO2e when considering uncertainty). The global impact of online advertising is multidimensional. Online advertising affects the environment by consuming significant amounts of energy, leading to the production CO2e emissions. Hundreds of billions of ad dollars are exchanged yearly, placing online advertising in a significant role economically. It has become an important and acknowledged component of the online-bound society, largely due to its integration with the Internet and the amount of revenue generated through it.",https://doi.org/10.1016/j.eiar.2018.08.004,https://www.sciencedirect.com/science/article/pii/S0195925517303505,,,,2018,Environmental impact assessment of online advertising,M. Pärssinen and M. Kotila and R. Cuevas and A. Phansalkar and J. Manner,article,PARSSINEN2018177,Environmental Impact Assessment Review,,73,0195-9255,,,
,"Malware detection, Semantic information, Heterogeneous subgraph, Deep learning, Graph convolutional network",103846,,"As the most popular mobile platform, Android has become the major attack target of malware, and thus there is an urgent need to effectively thwart them. Recently, the graph-based technique has been a promising solution for malware detection, which highly depends on graph structures to capture behaviors separating the malware from the benign apps. However, existing graph-based malware detection approaches still suffer from high computation cost in constructing or updating a graph for APK under detection, high false negative and false positive. To cope with these issues, we propose a novel global heterogeneous graph-based Android malware detection approach, named GHGDroid. A global heterogeneous graph (GHG) with a good updatability is first built on large-scale Android applications to characterize complex relationships among APKs and sensitive APIs. And then, using the GHG, a multi-layer graph convolutional network based embedding method is proposed to learn APK embeddings for well capturing behaviors that can separate malware from benign. Finally, using APK embeddings as well their labels, a malware classifier is trained. Experiments on real-world Android applications show that GHGDroid achieves 99.17 % F1-score, which outperforms the state-of-the-art approaches. Moreover, GHGDroid spends about 8 s on detecting an APK, which shows that it has a good potential as a practical tool for the Android malware detection task.",https://doi.org/10.1016/j.cose.2024.103846,https://www.sciencedirect.com/science/article/pii/S0167404824001470,,,,2024,GHGDroid: Global heterogeneous graph-based android malware detection,Lina Shen and Mengqi Fang and Jian Xu,article,SHEN2024103846,Computers & Security,,141,0167-4048,,,
,"IoT botnet, Adaptive learning, Ensemble learning, Online learning",84-95,,"With the number of Internet of Things (IoT) devices proliferating, the traffic volume of IoT-based attacks has shown a gradually increasing trend. The IoT botnet attack, which aims to commit real, efficient, and profitable cybercrimes, has become one of the most severe IoT threats. Applying traditional techniques to IoT is difficult due to its particular characteristics, such as resource-constrained devices, massive volumes of data, and real-time requirements. In this paper, we explore an adaptive online learning strategy for real-time IoT botnet attack detection. Furthermore, we operate the proposed adaptive strategy in conjunction with online ensemble learning. To evaluate the proposed strategy, we use real IoT traffic data, including benign traffic data and botnet traffic data infected by Mirai. In real-time IoT botnet attack detection, our experimental results demonstrate that the proposed adaptive online learning strategy achieves remarkable performance.",https://doi.org/10.1016/j.ins.2021.05.076,https://www.sciencedirect.com/science/article/pii/S0020025521005697,,,,2021,Adaptive online learning for IoT botnet detection,Zhou Shao and Sha Yuan and Yongli Wang,article,SHAO202184,Information Sciences,,574,0020-0255,,,
,"Internet of Things, Fog computing, Intrusion detection and prevention",109154,,"Currently, the Internet of Things is spreading in all areas that apply computing resources. An important ally of the IoT is fog computing. It extends cloud computing and services to the edge of the network. Smart environments are becoming real and possible through IoT and fog computing. However, they are not free from security threats and vulnerabilities. This makes special security techniques indispensable. Security is one of the biggest challenges to ensuring an optimal IoT and Fog environment. Combined with the significant damage generated by application attacks, this fact creates the need to focus efforts in this area. This need can be proven through existing reviews of the state-of-the-art that pointed out several open aspects that need greater research effort. In this way, this article presents a Systematic Literature Review (SLR) considering the context of intrusion detection and prevention in environments based on fog computing and IoT. This review addresses more than 100 studies that were included after undergoing an extensive inclusion/exclusion process with well-defined criteria. From these studies, information was extracted to build a view of the current state-of-the-art and answer the research questions of this study. In this way, we identify the state-of-the-art, open questions and possibilities for future research.",https://doi.org/10.1016/j.comnet.2022.109154,https://www.sciencedirect.com/science/article/pii/S1389128622002651,,,,2022,Intrusion detection and prevention in fog based IoT environments: A systematic literature review,Cristiano Antonio {de Souza} and Carlos Becker Westphall and Renato Bobsin Machado and Leandro Loffi and Carla Merkle Westphall and Guilherme Arthur Geronimo,article,DESOUZA2022109154,Computer Networks,,214,1389-1286,,,
,"Big data, Outdoor recreation, Social media, Mobile device data, Machine learning, Novel data",100668,,"With researchers increasingly interested in big data research, this conceptual paper describes how large datasets, secondary data, and associated analysis techniques can be used to understand outdoor recreation. Some types of large, secondary datasets that have been increasingly used in outdoor recreation research include social media, mobile device data, and trip reports or online reviews. First, we give a brief overview of big data terms and outline the steps involved in conducting big data research. In doing so, we describe data sources and analysis techniques relevant for outdoor recreation, and review how they have been applied in previous published works. We then describe opportunities, limitations, and considerations of using big data. Finally, we outline several questions researchers may consider when designing, conducting, reporting, and reviewing outdoor recreation research using big data. Overall, big data approaches can expand our understanding of outdoor recreation and, by addressing key questions, may help researchers harness the strengths of big data while ensuring quality and integrity.",https://doi.org/10.1016/j.jort.2023.100668,https://www.sciencedirect.com/science/article/pii/S2213078023000658,,,,2023,"What is “big data” and how should we use it? The role of large datasets, secondary data, and associated analysis techniques in outdoor recreation research",Dani T. Dagan and Emily J. Wilkins,article,DAGAN2023100668,Journal of Outdoor Recreation and Tourism,,44,2213-0780,Social media and other user created content for outdoor recreation and nature-based tourism research,,
,"Engineering, Energy engineering, Social sciences, Research methodology social sciences",106166,,"Summary
Geoengineering techniques such as solar radiation management (SRM) could be part of a future technology portfolio to limit global temperature change. However, there is public opposition to research and deployment of SRM technologies. We use 814,924 English-language tweets containing #geoengineering globally over 13 years (2009–2021) to explore public emotions, perceptions, and attitudes toward SRM using natural language processing, deep learning, and network analysis. We find that specific conspiracy theories influence public reactions toward geoengineering, especially regarding “chemtrails” (whereby airplanes allegedly spray poison or modify weather through contrails). Furthermore, conspiracies tend to spillover, shaping regional debates in the UK, USA, India, and Sweden and connecting with broader political considerations. We also find that positive emotions rise on both the global and country scales following events related to SRM governance, and negative and neutral emotions increase following SRM projects and announcements of experiments. Finally, we also find that online toxicity shapes the breadth of spillover effects, further influencing anti-SRM views.",https://doi.org/10.1016/j.isci.2023.106166,https://www.sciencedirect.com/science/article/pii/S2589004223002432,,,,2023,Conspiracy spillovers and geoengineering,Ramit Debnath and David M. Reiner and Benjamin K. Sovacool and Finn Müller-Hansen and Tim Repke and R. Michael Alvarez and Shaun D. Fitzgerald,article,DEBNATH2023106166,iScience,3,26,2589-0042,,,
,"Building energy system, Building load prediction, Building energy forecasting, Machine learning, Feature engineering, Data engineering",116452,,"The surge of machine learning and increasing data accessibility in buildings provide great opportunities for applying machine learning to building energy system modeling and analysis. Building load prediction is one of the most critical components for many building control and analytics activities, as well as grid-interactive and energy efficiency building operation. While a large number of research papers exist on the topic of machine-learning-based building load prediction, a comprehensive review from the perspective of machine learning is missing. In this paper, we review the application of machine learning techniques in building load prediction under the organization and logic of the machine learning, which is to perform tasks T using Performance measure P and based on learning from Experience E. Firstly, we review the applications of building load prediction model (task T). Then, we review the modeling algorithms that improve machine learning performance and accuracy (performance P). Throughout the papers, we also review the literature from the data perspective for modeling (experience E), including data engineering from the sensor level to data level, pre-processing, feature extraction and selection. Finally, we conclude with a discussion of well-studied and relatively unexplored fields for future research reference. We also identify the gaps in current machine learning application and predict for future trends and development.",https://doi.org/10.1016/j.apenergy.2021.116452,https://www.sciencedirect.com/science/article/pii/S0306261921000209,,,,2021,A review of machine learning in building load prediction,Liang Zhang and Jin Wen and Yanfei Li and Jianli Chen and Yunyang Ye and Yangyang Fu and William Livingood,article,ZHANG2021116452,Applied Energy,,285,0306-2619,,,
,"Cancer, Chemotherapy, Social media, Twitter, Side effect, Deep learning",92-100,,"Objective
Twitter has become one of the most popular social media platforms that offers real-world insights to healthy behaviors. The purpose of this study was to assess and compare perceptions about chemotherapy of patients and health-care providers through analysis of chemo-related tweets.
Materials and methods
Cancer-related Twitter accounts and their tweets were obtained through using Tweepy (Python library). Multiple text classification algorithms were tested to identify the models with best performance in classifying the accounts into individual and organization. Chemotherapy-specific tweets were extracted from historical tweetset, and the content of these tweets was analyzed using topic model, sentiment analysis and word co-occurrence network.
Results
Using the description in Twitter users’ profiles, the accounts related with cancer were collected and coded as individual or organization. We employed Long Short Term Memory (LSTM) network with GloVe word embeddings to identify the user into individuals and organizations with accuracy of 85.2%. 13, 273 and 14,051 publicly available chemotherapy-related tweets were retrieved from individuals and organizations, respectively. The content of the chemo-related tweets was analyzed by text mining approaches. The tweets from individual accounts pertained to personal chemotherapy experience and emotions. In contrast with the personal users, professional accounts had a higher proportion of neutral tweets about side effects. The information about the assessment of response to chemotherapy was deficient from organizations on Twitter.
Discussion
Examining chemotherapy discussions on Twitter provide new lens into content and behavioral patterns associated with treatments for cancer patients. The methodology described herein allowed us to collect relatively large number of health-related tweets over a greater time period and exploit the potential power of social media, which provide comprehensive view on patients’ perceptions of chemotherapy.
Conclusion
This study sheds light on using Twitter data as a valuable healthcare data source for helping oncologists (organizations) in understanding patients’ experiences while undergoing chemotherapy, in developing personalize therapy plans, and a supplement to the clinical electronic medical records (EMRs).",https://doi.org/10.1016/j.ijmedinf.2018.10.002,https://www.sciencedirect.com/science/article/pii/S1386505618304325,,,,2018,Utilizing Twitter data for analysis of chemotherapy,Ling Zhang and Magie Hall and Dhundy Bastola,article,ZHANG201892,International Journal of Medical Informatics,,120,1386-5056,,,
,"Mobile Robots, Multisensor Integration, Simultaneous Localization, Mapping, Robotics, Sensors, Cameras, Encoders, Embedded systems",323-328,,"The goal of this paper is to present a concept and implementation of an Environment Detection System. The system is supposed to collect data from sensors attached to the mobile robot and then enhance the map of the environment by this information. Moreover, the data can be processed to get valuable information about the environment or its change. The open-source implementation of the system is written for Robot Operating System. Thus, the system can handle data from different sensors using a unified way. It is possible by employing the messaging mechanism implemented in the Robot Operating System. Another contribution of this paper are records of our testing runs with a 6WD mobile robot equipped by multiple sensors, which can be used as a dataset for SLAM and Environment Detection System implementations.",https://doi.org/10.1016/j.ifacol.2019.12.681,https://www.sciencedirect.com/science/article/pii/S2405896319326308,,,,2019,Environment detection system for localization and mapping purposes,P. Neduchal and L. Bureš and M. Železný,article,NEDUCHAL2019323,IFAC-PapersOnLine,27,52,2405-8963,16th IFAC Conference on Programmable Devices and Embedded Systems PDES 2019,,
,"Emerging technologies, Network-level security and protection, Network communications, Network Protocols, Protection mechanisms, Quality analysis and evaluation, System issues, Security and Privacy Protection, Authentication, Communications Applications, Virtual reality, Security and Protection, Artificial, augmented, and virtual realities, Invasive software (viruses, worms, Trojan horses), Unauthorized access (hacking, phreaking)",102923,,"The allure of the metaverse along with Virtual Reality (VR) technologies and speed at which they are deployed may shift focus away from security and privacy fundamentals. In this work we employ classic exploitation techniques against cutting edge devices to obtain equally novel results. The unique features of the Virtual Reality landscape set the stage for our primary account of a new attack, the Man-in-the-Room (MitR). This attack, realized from a vulnerable social networking application led to both worming and botnet capabilities being adapted for VR with potential critical impacts affecting millions of users. Our work improves the state-of-the-art in Virtual Reality (VR) security and socio-technical research in VR. It shares several analytical and attacking tools, example exploits, evaluation dataset, and vulnerability signatures with the scientific and professional communities to ensure secure VR software development. The presented results demonstrate the detection and prevention of VR vulnerabilities, and raise questions in the law and policy domains pertaining to VR security and privacy.",https://doi.org/10.1016/j.cose.2022.102923,https://www.sciencedirect.com/science/article/pii/S0167404822003157,,,,2023,Rise of the Metaverse’s Immersive Virtual Reality Malware and the Man-in-the-Room Attack & Defenses,Martin Vondráček and Ibrahim Baggili and Peter Casey and Mehdi Mekni,article,VONDRACEK2023102923,Computers & Security,,127,0167-4048,,,
,"Information credibility evaluation, Fake news detection, Adversarial networks, Reinforcement learning",453-473,,"A series of deep learning approaches extract a large number of credibility features to detect fake news on the Internet. However, these extracted features still suffer from many irrelevant and noisy features that restrict severely the performance of the approaches. In this paper, we propose a novel model based on Adversarial Networks and inspirited by the Shared-Private model (ANSP), which aims at reducing common, irrelevant features from the extracted features for information credibility evaluation. Specifically, ANSP involves two tasks: one is to prevent the binary classification of true and false information for capturing common features relying on adversarial networks guided by reinforcement learning. Another extracts credibility features (henceforth, private features) from multiple types of credibility information and compares with the common features through two strategies, i.e., orthogonality constraints and KL-divergence for making the private features more differential. Experiments first on two six-label LIAR and Weibo datasets demonstrate that ANSP achieves state-of-the-art performance, boosting the accuracy by 2.1%, 3.1%, respectively and then on four-label Twitter16 validate the robustness of the model with 1.8% performance improvements.",https://doi.org/10.1016/j.ins.2019.12.040,https://www.sciencedirect.com/science/article/pii/S002002551931151X,,,,2020,Discovering differential features: Adversarial learning for information credibility evaluation,Lianwei Wu and Yuan Rao and Ambreen Nazir and Haolin Jin,article,WU2020453,Information Sciences,,516,0020-0255,,,
,"Social accountability, Social media, Panama papers, Big data and quantitative methods, Accounting interventions",38-53,,"The potential of social media to disseminate, aggregate, channel and democratize social accountability processes has encouraged a variety of organizations to actively promote and champion such initiatives. These initiatives typically envision a three step social accountability process where, for example, the publication of previously-private financial information about the inappropriate wealth accumulation activities of politicians and their business allies (step #1), combined with social media dissemination and discussion of these activities (step #2), can result in an accountability conversation that spills out of the medium and that sometimes results in positive social change (step #3). The current study examines Twitter reactions to the International Consortium of Investigative Journalist’s (ICIJ) publication of the Panama Papers. The analysis illustrates that there was a Twitter reaction: furthermore, that there were different styles of response and that certain styles were more likely to elicit an audience reaction, especially if the tweeter was a journalist or organization. While the provided analysis focuses on step #2 within the social accountability process, the results imply that publicly-interested accounting academics qua activists can facilitate social accountability by helping to make previously-private financial information public and by cultivating sympathetic individuals within the traditional media as well as within organizations that are active on social media.",https://doi.org/10.1016/j.cpa.2019.04.003,https://www.sciencedirect.com/science/article/pii/S1045235418302314,,,,2019,Twitter and social accountability: Reactions to the Panama Papers,Dean Neu and Greg Saxton and Abu Rahaman and Jeffery Everett,article,NEU201938,Critical Perspectives on Accounting,,61,1045-2354,,,
,"Machine Learning, Metabolic Engineering, Synthetic Biology, Deep Learning",34-60,,"Machine learning provides researchers a unique opportunity to make metabolic engineering more predictable. In this review, we offer an introduction to this discipline in terms that are relatable to metabolic engineers, as well as providing in-depth illustrative examples leveraging omics data and improving production. We also include practical advice for the practitioner in terms of data management, algorithm libraries, computational resources, and important non-technical issues. A variety of applications ranging from pathway construction and optimization, to genetic editing optimization, cell factory testing, and production scale-up are discussed. Moreover, the promising relationship between machine learning and mechanistic models is thoroughly reviewed. Finally, the future perspectives and most promising directions for this combination of disciplines are examined.",https://doi.org/10.1016/j.ymben.2020.10.005,https://www.sciencedirect.com/science/article/pii/S109671762030166X,,,,2021,Machine learning for metabolic engineering: A review,Christopher E. Lawson and Jose Manuel Martí and Tijana Radivojevic and Sai Vamshi R. Jonnalagadda and Reinhard Gentz and Nathan J. Hillson and Sean Peisert and Joonhoon Kim and Blake A. Simmons and Christopher J. Petzold and Steven W. Singer and Aindrila Mukhopadhyay and Deepti Tanjore and Joshua G. Dunn and Hector {Garcia Martin},article,LAWSON202134,Metabolic Engineering,,63,1096-7176,Tools and Strategies of Metabolic Engineering,,
,,207-221,Eleventh Hour CISSP® (Third Edition),,https://doi.org/10.1016/B978-0-12-811248-9.09992-7,https://www.sciencedirect.com/science/article/pii/B9780128112489099927,,Syngress,978-0-12-811248-9,2017,Index,,incollection,2017207,,,,,,Eric Conrad and Seth Misenar and Joshua Feldman,Third Edition
,"Cyber security, Cloud computing, Machine learning, Deep learning, Recurrent neural network",102662,,"The reliability of Internet of Things (IoT) connected devices is heavily dependent on the security model employed to protect user data and prevent devices from engaging in malicious activity. Existing approaches for detecting phishing, distributed denial of service (DDoS), and Botnet attacks often focus on either the device or the back-end. In this paper, we propose a cloud-based distributed deep learning framework for phishing and Botnet attack detection and mitigation. The model comprises two key security mechanisms working cooperatively, namely: (1) a Distributed Convolutional Neural Network (DCNN) model embedded as an IoT device micro-security add-on for detecting phishing and application layer DDoS attacks; and (2) a cloud-based temporal Long-Short Term Memory (LSTM) network model hosted on the back-end for detecting Botnet attacks, and ingest CNN embeddings to detect distributed phishing attacks across multiple IoT devices. The distributed CNN model, embedded into a ML engine in the client's IoT device, allows us to detect and defend the IoT device from phishing attacks at the point of origin. We create a dataset consisting of both phishing and non-phishing URLs to train the proposed CNN add-on security model, and select the N_BaIoT dataset for training the back-end LSTM model. The joint training method minimizes communication and resource requirements for attack detection, and maximizes the usefulness of extracted features. In addition, an aggregation of schemes allows the automatic fusion of multiple requests to improve the overall performance of the system. Our experiments show that the IoT micro-security add-on running the proposed CNN model is capable of detecting phishing attacks with an accuracy of 94.3% and a F-1 score of 93.58%. Using the back-end LSTM model, the model detects Botnet attacks with an accuracy of 94.80% using all malicious data points in the used dataset. Thus, the findings demonstrate that the proposed approach is capable of detecting attacks, both at device and at the back-end level, in a distributed fashion.",https://doi.org/10.1016/j.jnca.2020.102662,https://www.sciencedirect.com/science/article/pii/S1084804520301363,,,,2020,Detecting Internet of Things attacks using distributed deep learning,Gonzalo {De La Torre Parra} and Paul Rad and Kim-Kwang Raymond Choo and Nicole Beebe,article,DELATORREPARRA2020102662,Journal of Network and Computer Applications,,163,1084-8045,,,
,"India stack, Digital public infrastructure, Digital transformation, Aadhaar, Unified payments interface",105947,,"India is going through a transformative phase in its digital journey. A large part of this is enfolding in the field of digital public infrastructures as the ‘India Stack’ branded suite of technological solutions permeates through areas like digital identity, instant payments, digital commerce, and consent management. The paper traces the socio-technical imaginaries that have fueled India's digital transformation strategy and how India Stack acquired its central place in that scheme. Drawing upon India's performance on global ICT-related indices and the OECD's Good Practice Principles for Public Service Design and Delivery, the paper also examines how the country is faring in translating its visions of digital transformation into outcomes. It identifies reliance on coercive digital adoption strategies, lack of participative decision-making, and insufficient accountability safeguards as some of the fault lines in India's path to fair and equitable digital transformation.",https://doi.org/10.1016/j.clsr.2024.105947,https://www.sciencedirect.com/science/article/pii/S0267364924000141,,,,2024,Stack is the New Black?: Evolution and Outcomes of the ‘India-Stackification’ Process,Smriti Parsheera,article,PARSHEERA2024105947,Computer Law & Security Review,,52,0267-3649,,,
,"Digital innovation, Socio-technical artifact, Design science research, Information systems scalability",103263,,"We posit that design science enables the creation of in-class introductory college courses that can scale to large numbers of students, under resource constraints. We build on the centrality of human interactions in learning environments and conceptualize a college course as a socio-technical (ST) artifact. Grounded in the intervention theory, we draw meta-requirements guiding the design of college courses that leverage IT to scale, while maintaining the centrality of the professor’s role. We use the design-build-evaluate cycle to instantiate the ST artifact and demonstrate its feasibility using evaluation episodes as prescribed by the Framework for Evaluation in Design Science Research.",https://doi.org/10.1016/j.im.2019.103263,https://www.sciencedirect.com/science/article/pii/S0378720619300394,,,,2020,Designing scalability in required in-class introductory college courses,Gabriele Piccoli and Marcin Łukasz Bartosiak and Biagio Palese and Joaquin Rodriguez,article,PICCOLI2020103263,Information & Management,8,57,0378-7206,,,
,"AI assurance, AI explainability, detecting bias, natural language processing, large language models",371-427,AI Assurance,"AI methods are becoming more common in the field of economics, but these models must be bias-free, fair, and explainable. In other words, we need AI assurance. Economic forecasting has benefited from machine learning techniques, such as neural networks, to increase model performance, but these AI techniques must be audited, accountable, and interpretable to be useful for economic policymaking. The rise of natural language processing and large language models has created new challenges for economic policymaking institutions, which need to be aware of AI assurance and how to harness them safely.",https://doi.org/10.1016/B978-0-32-391919-7.00025-1,https://www.sciencedirect.com/science/article/pii/B9780323919197000251,,Academic Press,978-0-323-91919-7,2023,11 - Assuring AI methods for economic policymaking,Anderson Monken and William Ampeh and Flora Haberkorn and Uma Krishnaswamy and Feras A. Batarseh,incollection,MONKEN2023371,,,,,,Feras A. Batarseh and Laura J. Freeman,
,"Open-domain dialogue generation, Teamwork generation framework, Semantics extractor, Conversation model",108376,,"Many existing conversation models that are based on the encoder–decoder framework incorporate complex encoders. These powerful encoders serve to enrich the context vectors, so that the generated responses are more diverse and informative. However, these approaches face two potential challenges. First, the high complexity of the encoder means relative simplicity of the decoder. There is a danger that the decoder becomes too simple to effectively capture previously generated information. As a result, the decoder may produce duplicated and self-contradicting responses. Second, by having a complex encoder, the model may generate incoherent responses because the complex context vectors may deviate from the true semantics of context. In this work, we propose a conversation model named “THINK” (Teamwork generation Hover around Impressive Noticeable Keywords) that is equipped with a complex decoder to avoid generating duplicated and self-contradicting responses. The model also simplifies the context vectors and increases the coherence of generated responses in a reasonable way. For this model, we propose Teamwork generation framework and Semantics extractor. Compared with other baselines, both automatic and human evaluation showed the advantages of our model.",https://doi.org/10.1016/j.knosys.2022.108376,https://www.sciencedirect.com/science/article/pii/S0950705122001423,,,,2022,THINK: A novel conversation model for generating grammatically correct and coherent responses,Bin Sun and Shaoxiong Feng and Yiwei Li and Jiamou Liu and Kan Li,article,SUN2022108376,Knowledge-Based Systems,,242,0950-7051,,,
,"Blockchain, Bitcoin, Ethereum, Hyperledger, Algorand, Ripple, IOTA, Tangle, Smart contracts, Hashing, Security, Cryptography, Trust, Attacks, Vulnerabilities, Consensus",183-195,,"Distributed ledgers stimulate innovative services and enabled new applications in several domains, creating new concepts for trust and regulation. However, this backbone that is enabling novelties and abridging businesses comes with drawbacks and security flaws. In this paper, we evaluate several Distributed Ledger Technologies (DLTs) features depicting the Bitcoin, Ripple, Ethereum, Hyperledger, Algorand and IOTA networks. We focus on their security challenges and expose numerous threats and vulnerabilities. For instance, we have simulated a few of their possible attacks proving them non-immune. In the other hand, we show a few of their malicious use cases. Meticulously presenting DLTs menaces and flaws, we are not involved in preferring any specific DLT network.",https://doi.org/10.1016/j.future.2020.06.044,https://www.sciencedirect.com/science/article/pii/S0167739X17330650,,,,2020,On distributed ledgers security and illegal uses,Joanna Moubarak and Maroun Chamoun and Eric Filiol,article,MOUBARAK2020183,Future Generation Computer Systems,,113,0167-739X,,,
,"Nighttime lights imagery, Twitter, Socioeconomic factors, Location-based social media, The United States",1-10,,"Nighttime lights (NTL) imagery is one of the most commonly used tools to quantitatively study socioeconomic systems over large areas. In this study we aim to use location-based social media big data to challenge the primacy of NTL imagery on estimating socioeconomic factors. Geo-tagged tweets posted in the contiguous United States in 2013 were retrieved to produce a tweet image with the same spatial resolution of the NTL imagery (i.e., 0.00833° × 0.00833°). Sum tweet (the total number of tweets) and sum light (summed DN value of the NTL image) of each state or county were obtained from the tweets and the NTL images, respectively, to estimate three important socioeconomic factors: personal income, electric power consumption, and fossil fuel carbon dioxide emissions. Results show that sum tweet is a better measure of personal income and electric power consumption while carbon dioxide emissions can be more accurately estimated by sum light. We further exploited that African-Americans adults are more likely than White seniors to post geotagged tweets in the US, yet did not find any significant correlations between proportions of the subpopulations and the estimation accuracy of the socioeconomic factors. Existence of saturated pixels and blooming effects and failure to remove gas flaring reduce quality of NTL imagery in estimating socioeconomic factors, however, such problems are nonexistent in the tweet images. This study reveals that the number of geo-tagged tweets has great potential to be deemed as a substitute of brightness of NTL to assess socioeconomic factors over large geographic areas.",https://doi.org/10.1016/j.isprsjprs.2018.08.018,https://www.sciencedirect.com/science/article/pii/S0924271618302375,,,,2018,Tweets or nighttime lights: Comparison for preeminence in estimating socioeconomic factors,Naizhuo Zhao and Guofeng Cao and Wei Zhang and Eric L. Samson,article,ZHAO20181,ISPRS Journal of Photogrammetry and Remote Sensing,,146,0924-2716,,,
,"Data flow diagram, Access control, Information flow",111138,,"The security of software-intensive systems is frequently attacked. High fines or loss in reputation are potential consequences of not maintaining confidentiality, which is an important security objective. Detecting confidentiality issues in early software designs enables cost-efficient fixes. A Data Flow Diagram (DFD) is a modeling notation, which focuses on essential, functional aspects of such early software designs. Existing confidentiality analyses on DFDs support either information flow control or access control, which are the most common confidentiality mechanisms. Combining both mechanisms can be beneficial but existing DFD analyses do not support this. This lack of expressiveness requires designers to switch modeling languages to consider both mechanisms, which can lead to inconsistencies. In this article, we present an extended DFD syntax that supports modeling both, information flow and access control, in the same language. This improves expressiveness compared to related work and avoids inconsistencies. We define the semantics of extended DFDs by clauses in first-order logic. A logic program made of these clauses enables the automated detection of confidentiality violations by querying it. We evaluate the expressiveness of the syntax in a case study. We attempt to model nine information flow cases and six access control cases. We successfully modeled fourteen out of these fifteen cases, which indicates good expressiveness. We evaluate the reusability of models when switching confidentiality mechanisms by comparing the cases that share the same system design, which are three pairs of cases. We successfully show improved reusability compared to the state of the art. We evaluated the accuracy of confidentiality analyses by executing them for the fourteen cases that we could model. We experienced good accuracy.",https://doi.org/10.1016/j.jss.2021.111138,https://www.sciencedirect.com/science/article/pii/S0164121221002351,,,,2022,Detecting violations of access control and information flow policies in data flow diagrams,Stephan Seifermann and Robert Heinrich and Dominik Werle and Ralf Reussner,article,SEIFERMANN2022111138,Journal of Systems and Software,,184,0164-1212,,,
,"IoT-Fog networks, Data security, Intrusion Detection System (IDS), Received Signal Strength (RSS), Rate Limiting (RL)",103778,,"The Internet of Things (IoT) has recently received a lot of attention from the information and communication technology community. It has turned out to be a crucial development for harnessing the incredible power of wireless media in the real world. The nature of IoT-Fog networks requires the use of defense techniques who are light and mobile-aware. The edge resources in such a distributed environment are open to various safety hazards. DDoS UDP flooding attacks are the most frequent threats to edge resources in IoT-Fog networks. It is crucial for sabotaging fog gateways and can overcome traditional data filtering techniques. This paper introduces M-RL, a lightweight intrusion detection system with mobility awareness that can detect DDoS UDP flooding attacks while taking into account adversarial IoT devices that engage in IP spoofing. To this end, this paper analyzes the malicious behaviors that result in anonymity against Rate Limiting and Received Signal Strength (RSS)-based approaches, combines their advantages, and addresses their vulnerabilities. We test our method in different contexts to achieve that goal, and we find that it may decrease the accuracy of the RL, RSS, and RSS-RL methods to 70%, 48.9%, and 64.3%, respectively. The outcomes demonstrate the proposed approach's resistance to software-based source address forgery, impersonation, and signal modification. It offers more than 99% accuracy and supports node mobility. In this case, the best possible accuracy of the previous methods is 77%.",https://doi.org/10.1016/j.cose.2024.103778,https://www.sciencedirect.com/science/article/pii/S0167404824000798,,,,2024,M-RL: A mobility and impersonation-aware IDS for DDoS UDP flooding attacks in IoT-Fog networks,Saeed Javanmardi and Meysam Ghahramani and Mohammad Shojafar and Mamoun Alazab and Antonio M. Caruso,article,JAVANMARDI2024103778,Computers & Security,,140,0167-4048,,,
,"Memory forensics, Keystroke loggers, Malware detection, Emulation, Incident response, Reverse engineering",101872,,"Advances in malware development have led to the widespread use of attacker toolkits that do not leave any trace in the local filesystem. This negatively impacts traditional investigative procedures that rely on filesystem analysis to reconstruct attacker activities. As a solution, memory forensics has replaced filesystem analysis in these scenarios. Unfortunately, existing memory forensics tools leave many capabilities inaccessible to all but the most experienced investigators, who are well versed in operating systems internals and reverse engineering. The goal of the research described in this paper is to make investigation of one of the greatest threats that organizations face, userland keyloggers, less error-prone and less dependent on manual reverse engineering. To accomplish this, we have added significant new capabilities to HookTracer, which is an engine capable of emulating code discovered in a physical memory captures and recording all actions taken by the emulated code. Based on this work, we present new memory forensics capabilities, embodied in a new Volatility plugin, hooktracer_messagehooks, that uses Hooktracer to automatically decide whether a hook in memory is associated with a malicious keylogger or benign software. We also include a detailed case study that illustrates our technique’s ability to successfully analyze very sophisticated keyloggers, such as Turla.",https://doi.org/10.1016/j.cose.2020.101872,https://www.sciencedirect.com/science/article/pii/S0167404820301450,,,,2020,Hooktracer: Automatic Detection and Analysis of Keystroke Loggers Using Memory Forensics,Andrew Case and Ryan D. Maggio and Md Firoz-Ul-Amin and Mohammad M. Jalalzai and Aisha Ali-Gombe and Mingxuan Sun and Golden G. Richard,article,CASE2020101872,Computers & Security,,96,0167-4048,,,
,"Large language models, LLMs, GPT-3, ChatGPT, GPT-4, Transformers, LLM survey",100048,,"Large language models (LLMs) are a special class of pretrained language models (PLMs) obtained by scaling model size, pretraining corpus and computation. LLMs, because of their large size and pretraining on large volumes of text data, exhibit special abilities which allow them to achieve remarkable performances without any task-specific training in many of the natural language processing tasks. The era of LLMs started with OpenAI’s GPT-3 model, and the popularity of LLMs has increased exponentially after the introduction of models like ChatGPT and GPT4. We refer to GPT-3 and its successor OpenAI models, including ChatGPT and GPT4, as GPT-3 family large language models (GLLMs). With the ever-rising popularity of GLLMs, especially in the research community, there is a strong need for a comprehensive survey which summarizes the recent research progress in multiple dimensions and can guide the research community with insightful future research directions. We start the survey paper with foundation concepts like transformers, transfer learning, self-supervised learning, pretrained language models and large language models. We then present a brief overview of GLLMs and discuss the performances of GLLMs in various downstream tasks, specific domains and multiple languages. We also discuss the data labelling and data augmentation abilities of GLLMs, the robustness of GLLMs, the effectiveness of GLLMs as evaluators, and finally, conclude with multiple insightful future research directions. To summarize, this comprehensive survey paper will serve as a good resource for both academic and industry people to stay updated with the latest research related to GLLMs.",https://doi.org/10.1016/j.nlp.2023.100048,https://www.sciencedirect.com/science/article/pii/S2949719123000456,,,,2024,A survey of GPT-3 family large language models including ChatGPT and GPT-4,Katikapalli Subramanyam Kalyan,article,KALYAN2024100048,Natural Language Processing Journal,,6,2949-7191,,,
,"Analytical derivatives, algorithmic differentiation, robot manipulators, optimal control, predictive control",78-83,,"In the context of nonlinear model predictive control (NMPC) for robot manipulators, we address the problem of enabling the mixed and transparent use of algorithmic differentiation (AD) and efficient analytical derivatives of rigid-body dynamics (RBD) to decrease the solution time of the subjacent optimal control problem (OCP). Efficient functions for RBD and their analytical derivatives are made available to the numerical optimization framework CasADi by overloading the operators in the implementations made by the RBD library Pinocchio and adding a derivative-overloading feature to CasADi. A comparison between analytical derivatives and AD is made based on their influence on the solution time of the OCP, showing the benefits of using analytical derivatives for RBD in optimal control of robot manipulators.",https://doi.org/10.1016/j.ifacol.2021.11.156,https://www.sciencedirect.com/science/article/pii/S240589632102200X,,,,2021,"Mixed Use of Analytical Derivatives and Algorithmic Differentiation for NMPC of Robot Manipulators⁎⁎The authors would like to thank Flanders Make SBO MULTIROB: “Rigorous approach for programming and optimal control of multi-robot systems”, FWO project G0A6917N of the Research Foundation - Flanders (FWO - Flanders), and KU Leuven-BOF PFV/10/002 Centre of Excellence: Optimization in Engineering (OPTEC) for supporting this research.",Alejandro Astudillo and Justin Carpentier and Joris Gillis and Goele Pipeleers and Jan Swevers,article,ASTUDILLO202178,IFAC-PapersOnLine,20,54,2405-8963,"Modeling, Estimation and Control Conference MECC 2021",,
,,455-479,Intelligence-Based Medicine,,https://doi.org/10.1016/B978-0-12-823337-5.00024-X,https://www.sciencedirect.com/science/article/pii/B978012823337500024X,,Academic Press,978-0-12-823337-5,2020,Glossary,,incollection,2020455,,,,,,Anthony C. Chang,
,"Modern code review, Software quality, Code reviewers recommendation, Search-based software engineering",106908,,"Contemporary software development is distributed and characterized by high dynamics with continuous and frequent changes to fix defects, add new user requirements or adapt to other environmental changes. To manage such changes and ensure software quality, modern code review is broadly adopted as a common and effective practice. Yet several open-source as well as commercial software projects have adopted peer code review as a crucial practice to ensure the quality of their software products using modern tool-based code review. Nevertheless, the selection of peer reviewers is still merely a manual and hard task especially with the growing size of distributed development teams. Indeed, it has been proven that inappropriate peer reviewers selection can consume more time and effort from both developers and reviewers and increase the development costs and time to market. To address this problem, we introduce a multi-objective search-based approach, named WhoReview, to find the optimal set of peer reviewers for code changes. We use the Indicator-Based Evolutionary Algorithm (IBEA) to find the best set of code reviewers that are (1) most experienced with the code change to be reviewed, while (2) considering their current workload, i.e., the number of open code reviews they are working on. We conduct an empirical study on 4 long-lived open source software projects to evaluate our approach. The obtained results show that WhoReview outperforms state-of-the-art approach by an average precision of 68% and recall of 77%. Moreover, we deployed our approach in an industrial context and evaluated it qualitatively from developers perspective. Results show the effectiveness of our approach with a high acceptance ratio in identifying relevant reviewers.",https://doi.org/10.1016/j.asoc.2020.106908,https://www.sciencedirect.com/science/article/pii/S1568494620308462,,,,2021,WhoReview: A multi-objective search-based approach for code reviewers recommendation in modern code review,Moataz Chouchen and Ali Ouni and Mohamed Wiem Mkaouer and Raula Gaikovina Kula and Katsuro Inoue,article,CHOUCHEN2021106908,Applied Soft Computing,,100,1568-4946,,,
Intelligent Data-Centric Systems,"Artificial intelligence, autonomous vehicles, facial recognition, AI writing assistant, AI image generator, human needs",259-278,Ethics in Online AI-based Systems,"While advancing artificial intelligence (AI) applications have brought ease and benefit to human life in meeting our physical needs, it is less obvious how they would impact psychological needs. This study analyzes three emerging technologies—autonomous vehicles; facial recognition systems; and AI writing or image generators—from the perspective of six fundamental human needs; certainty, variety, significance, connection, growth, and contribution. Our core human needs can greatly influence the acceptability, feasibility, and utility of these technologies. A prognosis of the human needs implications of AI can help algorithm designers, policymakers, regulators, and end users mitigate the risks and accentuate its benefits.",https://doi.org/10.1016/B978-0-443-18851-0.00004-4,https://www.sciencedirect.com/science/article/pii/B9780443188510000044,,Academic Press,978-0-443-18851-0,2024,Chapter 13 - Artificial intelligence and basic human needs: the shadow aspects of emerging technology,Tay Keong Tan,incollection,TAN2024259,,,,,,Santi Caballé and Joan Casas-Roma and Jordi Conesa,
,"Flaky tests, Non-deterministic tests, Test bugs, Software testing, Multivocal review",111837,,"Flaky tests (tests with non-deterministic outcomes) pose a major challenge for software testing. They are known to cause significant issues, such as reducing the effectiveness and efficiency of testing and delaying software releases. In recent years, there has been an increased interest in flaky tests, with research focusing on different aspects of flakiness, such as identifying causes, detection methods and mitigation strategies. Test flakiness has also become a key discussion point for practitioners (in blog posts, technical magazines, etc.) as the impact of flaky tests is felt across the industry. This paper presents a multivocal review that investigates how flaky tests, as a topic, have been addressed in both research and practice. Out of 560 articles we reviewed, we identified and analysed a total of 200 articles that are focused on flaky tests (composed of 109 academic and 91 grey literature articles/posts) and structured the body of relevant research and knowledge using four different dimensions: causes, detection, impact and responses. For each of those dimensions, we provide categorization and classify existing research, discussions, methods and tools With this, we provide a comprehensive and current snapshot of existing thinking on test flakiness, covering both academic views and industrial practices, and identify limitations and opportunities for future research.",https://doi.org/10.1016/j.jss.2023.111837,https://www.sciencedirect.com/science/article/pii/S0164121223002327,,,,2023,"Test flakiness’ causes, detection, impact and responses: A multivocal review",Amjed Tahir and Shawn Rasheed and Jens Dietrich and Negar Hashemi and Lu Zhang,article,TAHIR2023111837,Journal of Systems and Software,,206,0164-1212,,,
,"Denial of service, Web server, Defense, Enlargement, Availability",103363,,"Denial-of-Service (DoS) attacks are becoming increasingly common and undermine the availability of widely used web servers. Even if DoS attacks cannot be rendered completely harmless, ready-to-use defense modules and solutions to mitigate their effect are highly beneficial for site administrators. Unfortunately, there is a lack of measurement studies that explore the pros and cons of common DoS web server defense modules in order to understand their limitations and to drive practitioners’ choices. This paper presents an empirical study of the ubiquitous Apache web server, with an assessment of two well-known pluggable defense modules and an enlargement technique that provides the server with additional resources. Measurements are based on a mixture of flooding and slow DoS attacks. The experimentation shows that, in spite of the large availability of pluggable security modules that can be usefully deployed in practice, there is not a bulletproof defense solution to mitigate the DoS attacks in hand. The findings of our analysis can be useful to support the deployment of proper defense mechanisms, as well as the development of robust and effective solutions for DoS protection.",https://doi.org/10.1016/j.jnca.2022.103363,https://www.sciencedirect.com/science/article/pii/S1084804522000303,,,,2022,No more DoS? An empirical study on defense techniques for web server Denial of Service mitigation,Marta Catillo and Antonio Pecchia and Umberto Villano,article,CATILLO2022103363,Journal of Network and Computer Applications,,202,1084-8045,,,
,,3536-3543.e6,,"Summary
Bilateral symmetry defines much of the animal kingdom and is crucial for numerous functions of bilaterian organisms. Genetic approaches have discovered highly conserved patterning networks that establish bilateral symmetry in early embryos,1 but how this symmetry is maintained throughout subsequent morphogenetic events remains largely unknown.2 Here we show that the terminal patterning system—which relies on Ras/ERK signaling through activation of the Torso receptor by its ligand Trunk3—is critical for preserving bilateral symmetry during Drosophila body axis elongation, a process driven by cell rearrangements in the two identical lateral regions of the embryo and specified by the dorsal-ventral and anterior-posterior patterning systems.4 We demonstrate that fluctuating asymmetries in this rapid convergent-extension process are attenuated in normal embryos over time, possibly through noise-dissipating forces from the posterior midgut invagination and movement. However, when Torso signaling is attenuated via mutation of Trunk or RNAi directed against downstream Ras/ERK pathway components, body axis elongation results in a characteristic corkscrew phenotype,5 which reflects dramatic reorganization of global tissue flow and is incompatible with viability. Our results reveal a new function downstream of the Drosophila terminal patterning system in potentially active control of bilateral symmetry and should motivate systematic search for similar symmetry-preserving regulatory mechanisms in other bilaterians.",https://doi.org/10.1016/j.cub.2023.07.050,https://www.sciencedirect.com/science/article/pii/S0960982223009892,,,,2023,Maintaining symmetry during body axis elongation,Celia M. Smits and Sayantan Dutta and Vishank Jain-Sharma and Sebastian J. Streichan and Stanislav Y. Shvartsman,article,SMITS20233536,Current Biology,16,33,0960-9822,,,
,"Fake news, Inconsistency graph, Energy flow",101985,,"Recently, the term “fake news” has been broadly and extensively utilized for disinformation, misinformation, hoaxes, propaganda, satire, rumors, click-bait, and junk news. It has become a serious problem around the world. We present a new system, FaNDS, that detects fake news efficiently. The system is based on several concepts used in some previous works but in a different context. There are two main concepts: an Inconsistency Graph and Energy Flow. The Inconsistency Graph contains news items as nodes and inconsistent opinions between them for edges. Energy Flow assigns each node an initial energy and then some energy is propagated along the edges until the energy distribution on all nodes converges. To illustrate FaNDS we use the original data from the Fake News Challenge (FNC-1). First, the data has to be reconstructed in order to generate the Inconsistency Graph. The graph contains various subgraphs with well-defined shapes that represent different types of connections between the news items. Then the Energy Flow method is applied. The nodes with high energy are the candidates for being fake news. In our experiments, all these were indeed fake news as we checked each using several reliable web sites. We compared FaNDS to several other fake news detection methods and found it to be more sensitive in discovering fake news items.",https://doi.org/10.1016/j.datak.2022.101985,https://www.sciencedirect.com/science/article/pii/S0169023X22000040,,,,2022,FaNDS: Fake News Detection System using energy flow,Jiawei Xu and Vladimir Zadorozhny and Danchen Zhang and John Grant,article,XU2022101985,Data & Knowledge Engineering,,139,0169-023X,,,
,"Jargons identification, Information security, Feature engineering, Word embedding, Transfer learning, Vectors projection",103033,,"When cybercriminals communicate with their customers in underground markets, they tend to use secure and customizable instant messaging (IM) software, i.e. Telegram. It is a popular IM software with over 700 million monthly active users (MAU) up to June 2022. In recent years, more and more dark jargons (i.e. an innocent-looking replacement of sensitive terms) appear frequently on Telegram. Therefore, jargons identification is one of the most significant research perspectives to track online underground markets and cybercrimes. This paper proposes a novel Chinese Jargons Identification Framework (CJI-Framework) to identify dark jargons. Firstly, we collect chat history from Telegram groups that are related to the underground market and construct the corpus TUMCC (Telegram Underground Market Chinese Corpus), which is the first Chinese corpus in jargons identification research field. Secondly, we extract seven brand-new features which can be classified into three categories: Vectors-based Features (VF), Lexical analysis-based Features (LF), and Dictionary analysis-based Features (DF), to identify Chinese dark jargons from commonly-used words. Based on these features, we then run a statistical outlier detection to decide whether a word is a jargon. Furthermore, we employ a word vector projection method and a transfer learning method to improve the effect of the framework. Experimental results show that CJI-Framework achieves a remarkable performance with an F1-score of 89.66%. After adaptation for English, it performs better than state-of-the-art English jargons identification method as well. Our built corpus and code have been publicly released to facilitate the reproduction and extension of our work.",https://doi.org/10.1016/j.ipm.2022.103033,https://www.sciencedirect.com/science/article/pii/S030645732200142X,,,,2022,Identification of Chinese dark jargons in Telegram underground markets using context-oriented and linguistic features,Yiwei Hou and Hailin Wang and Haizhou Wang,article,HOU2022103033,Information Processing & Management,5,59,0306-4573,,,
,"Domain Generation Algorithm, Command, Control server, Network Security, Machine Learning",403-412,,"Command and control(C&C) servers are being more frequently used in cyberattacks in recent years. A malware-infected machine is controlled and directed by an attacker using a command-and-control server in order to steal data from the network. To hide their servers, attackers commonly employ a domain generation algorithm that generates domain names for them by concatenating words from word lists. Some of the algorithmically-generated domain names are used to connect to the C&C server. With the emergence of sophisticated domain generation algorithms, detecting such domains has become a challenge, which in turn poses a severe danger to computer networks. In this paper, we are proposing a concept called centrality, which is used as one of the features to analyze the words in the domain names generated by the domain generation algorithm malware. For classification, we are using Naïve Bayes, KNN, SVM, Decision Trees, Random Forest and logistic regression. Experimental results showed that Random Forest gave the highest classification accuracy rate of 88.64% and Naive Bayes gave the lowest accuracy of 44.32%.",https://doi.org/10.1016/j.procs.2022.12.042,https://www.sciencedirect.com/science/article/pii/S1877050922021135,,,,2022,A model to detect domain names generated by DGA malware,T Divya and P.P Amritha and Sangeetha Viswanathan,article,DIVYA2022403,Procedia Computer Science,,215,1877-0509,4th International Conference on Innovative Data Communication Technology and Application,,
,"COVID-19, Digital health, Audio processing, Computational paralinguistics",108289,,"The Coronavirus (COVID-19) pandemic impelled several research efforts, from collecting COVID-19 patients’ data to screening them for virus detection. Some COVID-19 symptoms are related to the functioning of the respiratory system that influences speech production; this suggests research on identifying markers of COVID-19 in speech and other human generated audio signals. In this article, we give an overview of research on human audio signals using ‘Artificial Intelligence’ techniques to screen, diagnose, monitor, and spread the awareness about COVID-19. This overview will be useful for developing automated systems that can help in the context of COVID-19, using non-obtrusive and easy to use bio-signals conveyed in human non-speech and speech audio productions.",https://doi.org/10.1016/j.patcog.2021.108289,https://www.sciencedirect.com/science/article/pii/S0031320321004696,,,,2022,AI-Based human audio processing for COVID-19: A comprehensive overview,Gauri Deshpande and Anton Batliner and Björn W. Schuller,article,DESHPANDE2022108289,Pattern Recognition,,122,0031-3203,,,
,"Open source MATLAB/GNU Octave, Discontinuous Galerkin method, Vectorization, Coupled modeling, Shallow–water equations, Cahn–Hilliard equation",3-41,,"The present work documents the current state of development for our MATLAB/GNU Octave-based open source toolbox FESTUNG (Finite Element Simulation Toolbox for UNstructured Grids). The goal of this project is to design a user-friendly, research-oriented, yet computationally efficient software tool for solving partial differential equations (PDEs). Since the release of its first version, FESTUNG has been actively used for research and teaching purposes such as the design of novel algorithms and discretization schemes, benchmark studies, or just providing students with an easy-to-learn software package to study advanced numerical techniques and good programming practices. For spatial discretization, the package employs various discontinuous Galerkin (DG) methods, while different explicit, implicit, or semi-implicit Runge–Kutta schemes can be used for time stepping. The current publication discusses the most important aspects of our toolbox such as the code design concepts and various discretization procedures illustrated in some detail using a standard advection–diffusion–reaction equation. Moreover, we present selected applications already supported in FESTUNG including solvers for the two-dimensional shallow-water equations, the Cahn–Hilliard equation, and a coupled multi-physics model of free surface/subsurface flow.",https://doi.org/10.1016/j.camwa.2020.08.018,https://www.sciencedirect.com/science/article/pii/S0898122120303254,,,,2021,"FESTUNG 1.0: Overview, usage, and example applications of the MATLAB/GNU Octave toolbox for discontinuous Galerkin methods",Balthasar Reuter and Hennes Hajduk and Andreas Rupp and Florian Frank and Vadym Aizinger and Peter Knabner,article,REUTER20213,Computers & Mathematics with Applications,,81,0898-1221,Development and Application of Open-source Software for Problems with Numerical PDEs,,
,"DGA, Ensemble Learning, PRNG, Malware",1129-1136,,"Domain Generation Algorithms are the new source of mediators which will provide the attackers an intelligent way of avoiding detection at the host level. Typically, before the existence of DGA, the malware was having a hardcoded command and control (C&C) IP address. That hardcoded mechanism is prone to detection and thus how DGA came into existence. Domain Generation Algorithms use the traditional cryptographic principles of Pseudo-random number generators (PRNGs) to generate a list of domain names to which malware communicates. In this paper, we constructed a list of 44 features (lexical+statistical) from domain names and used the ensemble approaches like C5.0, Random Forest, Gradient Boosting and CART to classify DGA domain names. C5.0 stands out as the best one with an accuracy value of 0.9704.",https://doi.org/10.1016/j.procs.2020.04.121,https://www.sciencedirect.com/science/article/pii/S1877050920310991,,,,2020,An Ensemble Approach For Algorithmically Generated Domain Name Detection Using Statistical And Lexical Analysis,P. Mohan Anand and T. Gireesh Kumar and P.V. Sai Charan,article,ANAND20201129,Procedia Computer Science,,171,1877-0509,Third International Conference on Computing and Network Communications (CoCoNet'19),,
,"leader social media, Social media, Leadership, Twitter, Facebook",101580,,"The proliferation of digital data has opened the door for a 21st-century social science that explores human relationships on an unprecedented scale. A particular area of interest is that of leader social media (SM) usage. As studies on leader SM usage have grown dramatically in the past several years, we take stock of the extant literature across various research disciplines. Within this manuscript, we contextualize leader SM usage and demonstrate how it compares to analogous concepts. We subsequently abridge relevant findings and reflect on methodological and theoretical components of the research studies identified in this review. Further, we outline the nature of SM data and provide practical recommendations for leadership scholars to capitalize on this rich data source in their investigations. We also offer a theoretical framework and summary of how scholars have studied leader SM usage. Specifically, this review article synthesizes the current literature while also elevating the academic rigor of leader SM research.",https://doi.org/10.1016/j.leaqua.2021.101580,https://www.sciencedirect.com/science/article/pii/S1048984321000850,,,,2022,"Tweet, like, subscribe! Understanding leadership through social media use",Michael J. Matthews and Samuel H. Matthews and Dawei(David) Wang and Thomas K. Kelemen,article,MATTHEWS2022101580,The Leadership Quarterly,1,33,1048-9843,The Leadership Quarterly Yearly Review (LQYR) for 2022,,
,"Cybersecurity, Artificial intelligence, Machine learning, Deep learning, Cyber-threat, Botnets, Intrusion detection, Spam filtering, Encrypted traffic analysis",109032,,"As the number of Internet-connected systems rises, cyber analysts find it increasingly difficult to effectively monitor the produced volume of data, its velocity and diversity. Signature-based cybersecurity strategies are unlikely to achieve the required performance for detecting new attack vectors. Moreover, technological advances enable attackers to develop sophisticated attack strategies that can avoid detection by current security systems. As the cyber-threat landscape worsens, we need advanced tools and technologies to detect, investigate, and make quick decisions regarding emerging attacks and threats. Applications of artificial intelligence (AI) have the potential to analyze and automatically classify vast amounts of Internet traffic. AI-based solutions that automate the detection of attacks and tackle complex cybersecurity problems are gaining increasing attention. This paper comprehensively presents the promising applications of deep learning, a subfield of AI based on multiple layers of artificial neural networks, in a wide variety of security tasks. Before critically and comparatively surveying state-of-the-art solutions from the literature, we discuss the key characteristics of representative deep learning architectures employed in cybersecurity applications, we introduce the emerging trends in deep learning, and we provide an overview of necessary resources like a generic framework and suitable datasets. We identify the limitations of the reviewed works, and we bring forth a vision of the current challenges of the area, providing valuable insights and good practices for researchers and developers working on related problems. Finally, we uncover current pain points and outline directions for future research to address them.",https://doi.org/10.1016/j.comnet.2022.109032,https://www.sciencedirect.com/science/article/pii/S1389128622001864,,,,2022,"A survey on deep learning for cybersecurity: Progress, challenges, and opportunities",Mayra Macas and Chunming Wu and Walter Fuertes,article,MACAS2022109032,Computer Networks,,212,1389-1286,,,
,"Behavioral biometrics, Keystroke dynamics, Multi-user model, X-means",106982,,"In recent years, keystroke dynamics has gained popularity as a reliable means of verifying user identity in remote systems. Due to its high performance in verification and the fact that it does not require additional effort from the user, keystroke dynamics has become one of the most preferred second factor of authentication. Despite its prominence, it has one major limitation: keystroke dynamics algorithms are good at fitting a model to one user and one user only. When such algorithms try to fit a model to more than one user, the verification accuracy decreases dramatically. However, in real-world applications it is common practice for two or more users to use the same credentials, such as in shared bank accounts, shared social media profiles, and shared streaming licenses which allow multiple users in one account. In these cases, keystroke dynamics solutions become unreliable. To address this limitation, we propose a method that can leverage existing keystroke dynamics algorithms to automatically determine the number of users sharing the account and accurately support accounts that are shared with multiple users. We evaluate our method using eight state-of-the-art keystroke dynamics algorithms and three public datasets, with up to five different users in one model, achieving an average improvement in verification of 9.2% for the AUC and 8.6% for the EER in the multi-user cases, with just a negligible reduction of 0.2% for the AUC and 0.3% for the EER in the one-user cases.",https://doi.org/10.1016/j.knosys.2021.106982,https://www.sciencedirect.com/science/article/pii/S0950705121002458,,,,2021,Supporting unknown number of users in keystroke dynamics models,Itay Hazan and Oded Margalit and Lior Rokach,article,HAZAN2021106982,Knowledge-Based Systems,,221,0950-7051,,,
,"Bayesian inference, Hamiltonian Monte Carlo, Gaussian mixture models",25-30,,"This paper considers the problem of estimating linear dynamic system models when the observations are corrupted by random disturbances with nonstandard distributions. The paper is particularly motivated by applications where sensor imperfections involve significant contribution of outliers or wrap-around issues resulting in multi-modal distributions such as commonly encountered in robotics applications. As will be illustrated, these nonstandard measurement errors can dramatically compromise the effectiveness of standard estimation methods, while a computational Bayesian approach developed here is demonstrated to be equally effective as standard methods in standard measurement noise scenarios, but dramatically more effective in nonstandard measurement noise distribution scenarios.",https://doi.org/10.1016/j.ifacol.2018.09.085,https://www.sciencedirect.com/science/article/pii/S2405896318317452,,,,2018,"Sparse Bayesian ARX models with flexible noise distributions⁎⁎This work was supported by the Australian Research Council Discovery Project DP140104350. The EEG data was kindly provided by Eline Borch Petersen and Thomas Lunner at Eriksholm Research Centre, Oticon A/S, Denmark.",Johan Dahlin and Adrian Wills and Brett Ninness,article,DAHLIN201825,IFAC-PapersOnLine,15,51,2405-8963,18th IFAC Symposium on System Identification SYSID 2018,,
,"Machine learning, Cloud security, DDoS Attack, DoS attack, Industry 4.0, Early detection, Botnet, Feature transformation, Classification",107955,,"ABSTRACT
Recent advancements in artificial intelligence and machine learning technologies have laid the flagstone for the fourth industrial revolution, Industry 4.0. The industry 4.0 is at a very high momentum when compared to previous revolutions witnessed by humans in a way which was never anticipated. Cyber Physical Systems and Cloud computing are the basis for Industry 4.0. An ongoing research challenge in cloud computing is the immediate need to address security and data availability challenges coined in modern networking environments. For instance, DDoS attacks in cloud are continuously throwing new challenges to network community which makes detection of these attacks, an ongoing research challenge with respect to cloud security. At the outset, the research reported in this work has addressed three important contributions (i) A new gaussian based traffic attribute-pattern similarity function for evolutionary feature clustering to achieve feature transformation-based dimensionality reduction, (ii) A Gaussian based network traffic similarity function for similarity computation between network traffic instances and (iii) A machine learning model SWASTHIKA which uses feature transformation traffic for detection of low rate and high-rate network attacks. For experimental study, the most recent benchmark dataset namely IoT DoS and DDoS attack dataset available at IEEE Dataport is considered as this dataset has highly non-linear traffic instances which are like the real-world traffic. The performance evaluation of the proposed machine learning model SWASTHIKA is done by considering various classifier evaluation parameters such as accuracy, precision, detection rate, and F-Score. The experiment results proved that the attack detection rate of SWASTHIKA is significantly better compared to state of art machine learning classifiers.",https://doi.org/10.1016/j.compeleceng.2022.107955,https://www.sciencedirect.com/science/article/pii/S0045790622002324,,,,2022,A Feature Similarity Machine Learning Model for DDoS Attack Detection in Modern Network Environments for Industry 4.0,Swathi Sambangi and Lakshmeeswari Gondi and Shadi Aljawarneh,article,SAMBANGI2022107955,Computers and Electrical Engineering,,100,0045-7906,,,
,"Reconnaissance, OSINT, footprinting, DNS, human recon, whois",31-106,Penetration Tester's Open Source Toolkit (Fourth Edition),This chapter covers information gathering by focusing on reconnaissance and learning as much about a target as possible before you actually interact with it. This is typically a very stealthy part of penetration testing and is the first step in gathering the information that you need to move forward with testing.,https://doi.org/10.1016/B978-0-12-802149-1.00002-6,https://www.sciencedirect.com/science/article/pii/B9780128021491000026,Boston,Syngress,978-0-12-802149-1,2017,Chapter 2 - Reconnaissance,Jeremy Faircloth,incollection,FAIRCLOTH201731,,,,,,Jeremy Faircloth,Fourth Edition
,"IoT security, Markov-chain, Anomaly detection, Blockchain, Collaborative security",75-97,,"Due to their rapid growth and deployment, the Internet of things (IoT) have become a central aspect of our daily lives. Unfortunately, IoT devices tend to have many vulnerabilities which can be exploited by an attacker. Unsupervised techniques, such as anomaly detection, can be used to secure these devices in a plug-and-protect manner. However, anomaly detection models must be trained for a long time in order to capture all benign behaviors. Furthermore, the anomaly detection model is vulnerable to adversarial attacks since, during the training phase, all observations are assumed to be benign. In this paper, we propose (1) a novel approach for anomaly detection and (2) a lightweight framework that utilizes the blockchain to ensemble an anomaly detection model in a distributed environment. Blockchain framework incrementally updates a trusted anomaly detection model via self-attestation and consensus among the IoT devices. We evaluate our method on a distributed IoT simulation platform, which consists of 48 Raspberry Pis. The simulation demonstrates how the approach can enhance the security of each device and the security of the network as a whole.",https://doi.org/10.1016/j.jpdc.2020.06.008,https://www.sciencedirect.com/science/article/pii/S0743731520303154,,,,2020,Lightweight collaborative anomaly detection for the IoT using blockchain,Yisroel Mirsky and Tomer Golomb and Yuval Elovici,article,MIRSKY202075,Journal of Parallel and Distributed Computing,,145,0743-7315,,,
,"Lake temperature, Lake warming, Stratification, Mixing, Numerical model, Open source",125874,,"Lake temperature responses to climate forcing are of interest on account of the important linkages between water temperature and ecosystem processes. This paper describes a new 1-dimensional (1D) numerical model code and its application to investigations of multi-scale linkages between the vertical temperature structure and meteorological forcing. UCLAKE is implemented as highly portable open-source software, based on computationally efficient algorithms, and able to resolve sub-daily (e.g., hourly) dynamics while retaining the efficiency to simulate multi-decadal time scales. A UCLAKE model is calibrated and validated against thermistor profile time series for a small upland lake in North Wales, UK. Some of the challenges in 1D model calibration are explored and a sensitivity analysis reveals a dependence of optimal parameter set values on water column depth and time. An exploratory 52-year hindcast simulation demonstrates the computational efficiency of UCLAKE for multi-decadal studies of trends in lake temperature that vary with depth. A supplementary application of UCLAKE to Windermere, in the English Lake District, demonstrates its performance for larger and deeper lakes.",https://doi.org/10.1016/j.limno.2021.125874,https://www.sciencedirect.com/science/article/pii/S0075951121000268,,,,2021,Simulating seasonal to multi-decadal variation in lake thermal response to meteorological forcing using the UCLAKE 1-dimensional model code,Luis A. Morales-Marín and Jon R. French and Helene Burningham and Chris Evans and Annette Burden,article,MORALESMARIN2021125874,Limnologica,,88,0075-9511,,,
,"Unsupervised definition embeddings, Semantic features of glosses, Context words, Auto-encoding models, Natural language processing",111883,,"For both humans and machines to acquire vocabulary, it is effective to learn words from context while using dictionaries as an auxiliary tool. It has been shown in previous linguistic studies that for humans, glossing either target words to be learned or words comprising context is an effective approach. For machines, however, previous NLP studies are mainly focused on the former. In this paper, we investigate the potentiality of context words-glossed setting. During pre-training BERT, to infuse context words with semantic features of glosses, we propose DG embeddings — the unsupervised definition embeddings learned from dictionaries and glossaries. To employ unsupervised learning is inspired by a real-world scenario of dictionary use called headword search. This can also prevent a technical duplicate from happening, as learning words from context is already based on auto-encoding models with self-supervised learning. BERT-base is used for evaluation, and we refer to BERT-base with DG embeddings as DG-BERT. According to our experimental results, compared to the vanilla BERT, DG-BERT shows the following strengths: faster pre-training convergence, noticeable improvements on various downstream tasks, a better grasp of figurative semantics, more accurate self-attention for collocation of phrases, and higher sensitivity to context words for target-word predictions in psycholinguistic diagnostics.",https://doi.org/10.1016/j.knosys.2024.111883,https://www.sciencedirect.com/science/article/pii/S0950705124005173,,,,2024,DG Embeddings: The unsupervised definition embeddings learned from dictionary and glossary to gloss context words of Cloze task,Xiaodong Liu and Rafal Rzepka and Kenji Araki,article,LIU2024111883,Knowledge-Based Systems,,296,0950-7051,,,
,"Minimum description length, Short text messages, Semantic indexing, Text categorization, Machine learning",314-325,,"The popularity and reach of short text messages commonly used in electronic communication have led spammers to use them to propagate undesired content. This is often composed by misleading information, advertisements, viruses, and malwares that can be harmful and annoying to users. The dynamic nature of spam messages demands for knowledge-based systems with online learning and, therefore, the most traditional text categorization techniques can not be used. In this study, we introduce the MDLText, a text classifier based on the minimum description length principle, to the context of filtering undesired short text messages. The proposed approach supports incremental learning and, therefore, its predictive model is scalable and can adapt to continuously evolving spamming techniques. It is also fast, with computational cost increasing linearly with the number of samples and features, which is very desirable for expert systems applied to real-time electronic communication. In addition to the dynamic nature of these messages, they are also short and usually poorly written, rife with slangs, symbols, and abbreviations that difficult text representation, learning, and filtering. In this scenario, we also investigated the benefits of using text normalization and semantic indexing techniques. We showed these techniques can improve the text content quality and, consequently, enhance the performance of the expert systems for spamming detection. Based on these findings, we propose a new hybrid ensemble approach that combines the predictions obtained by the classifiers using the original text samples along with their variations created by applying text normalization and semantic indexing techniques. It has the advantages of being independent of the classification method and the results indicated it is efficient to filter undesired short text messages.",https://doi.org/10.1016/j.eswa.2017.04.055,https://www.sciencedirect.com/science/article/pii/S0957417417303056,,,,2017,Towards filtering undesired short text messages using an online learning approach with semantic indexing,Renato M. Silva and Tulio C. Alberto and Tiago A. Almeida and Akebo Yamakami,article,SILVA2017314,Expert Systems with Applications,,83,0957-4174,,,
,"Industrial megaprojects, Knowledge representation, Project analytics, Risk analysis, Ontology, Semantic web",101164,,"The fourth industrial revolution has affected most industries, including construction and those within the delivery chain of megaprojects. These major paradigm shifts, however, did not considerably improve the track record in predicting project outcomes and estimating required resources. One reason is the lack of unified data definitions and expandable knowledge representation across project lifecycle to represent megaprojects for analytics. This paper proposes and evaluates a unified ontology for project knowledge representation that facilitates data collection, processing, and utilization for industrial megaprojects through their lifecycle. The proposed Uniform Project Ontology, or UPonto, provides a data infrastructure for project analytics by enabling logical deductions and inferences, and flexible expansion and partitioning of the data utilizing linked data and the semantic web. The ontology facilitates cost normalization processes, temporal queries, and graph queries using SPARQL, while defining universal semantics for a wide range of project risk factors and characteristics based on comprehensive research of the empirical project risk and success literature augmented by practical considerations gained through expert consultations. UPonto forms the basis for a project knowledge graph to utilize unstructured data; it as well provides semantic definitions for smart IoT agents to consume project risk data and knowledge.",https://doi.org/10.1016/j.aei.2020.101164,https://www.sciencedirect.com/science/article/pii/S147403462030135X,,,,2020,Ontology-based knowledge representation for industrial megaprojects analytics using linked data and the semantic web,Pouya Zangeneh and Brenda McCabe,article,ZANGENEH2020101164,Advanced Engineering Informatics,,46,1474-0346,,,
,"Cloud computing, Network intrusion detection system, Deep Neural Network, Genetic algorithm, Simulated Annealing Algorithm, CICIDS dataset 2017, NSL-KDD dataset, CIDDS-001 dataset",291-317,,"The appealing features of Cloud Computing continue to fuel its adoption and its integration in many sectors such industry, governments, education and entertainment. Nevertheless, uploading sensitive data to public cloud storage services poses security risks such as integrity, availability and confidentiality to organizations. Moreover, the open and distributed (decentralized) structure of the cloud has resulted this class of computing, prone to cyber attackers and intruders. Thereby, it is imperative to develop an anomaly network intrusion system to detect and prevent both inside and outside assaults in cloud environment with high detection precision and low false warnings. In this work, we propose an intelligent approach to build automatically an efficient and effective Deep Neural Network (DNN) based anomaly Network IDS using a hybrid optimization framework (IGASAA) based on Improved Genetic Algorithm (IGA) and Simulated Annealing Algorithm (SAA). The IDS resulted is called “MLIDS” (Machine Learning based Intrusion Detection System). Genetic Algorithm (GA) is improved through optimization strategies, namely Parallel Processing and Fitness Value Hashing, which reduce execution time, convergence time and save processing power. Moreover, SAA was incorporated to IGA with the aim to optimize its heuristic search. Our approach consists of using IGASAA in order to search the optimal or near-optimal combination of most relevant values of the parameters included in construction of DNN based IDS or impacting its performance, like feature selection, data normalization, architecture of DNN, activation function, learning rate and Momentum term, which ensure high detection rate, high accuracy and low false alarm rate. For simulation and validation of the proposed method, CloudSim 4.0 simulator platform and three benchmark IDS datasets were used, namely CICIDS2017, NSL-KDD version 2015 and CIDDS-001. The implementation results of our model demonstrate its ability to detect intrusions with high detection accuracy and low false alarm rate, and indicate its superiority in comparison with state-of-the-art methods.",https://doi.org/10.1016/j.cose.2019.06.013,https://www.sciencedirect.com/science/article/pii/S0167404819301221,,,,2019,Intelligent approach to build a Deep Neural Network based IDS for cloud environment using combination of machine learning algorithms,Zouhair Chiba and Noreddine Abghour and Khalid Moussaid and Amina {El omri} and Mohamed Rida,article,CHIBA2019291,Computers & Security,,86,0167-4048,,,
,"Dialogue act, Deep learning, LSTM, Word embeddings, Word2vec",175-193,,"Dialogue act recognition is an important component of a large number of natural language processing pipelines. Many research works have been carried out in this area, but relatively few investigate deep neural networks and word embeddings. This is surprising, given that both of these techniques have proven exceptionally good in most other language-related domains. We propose in this work a new deep neural network that explores recurrent models to capture word sequences within sentences, and further study the impact of pretrained word embeddings. We validate this model on three languages: English, French and Czech. The performance of the proposed approach is consistent across these languages and it is comparable to the state-of-the-art results in English. More importantly, we confirm that deep neural networks indeed outperform a Maximum Entropy classifier, which was expected. However, and this is more surprising, we also found that standard word2vec embeddings do not seem to bring valuable information for this task and the proposed model, whatever the size of the training corpus is. We thus further analyse the resulting embeddings and conclude that a possible explanation may be related to the mismatch between the type of lexical-semantic information captured by the word2vec embeddings, and the kind of relations between words that is the most useful for the dialogue act recognition task.",https://doi.org/10.1016/j.csl.2017.07.009,https://www.sciencedirect.com/science/article/pii/S0885230816300456,,,,2018,On the effects of using word2vec representations in neural networks for dialogue act recognition,Christophe Cerisara and Pavel Král and Ladislav Lenc,article,CERISARA2018175,Computer Speech & Language,,47,0885-2308,,,
,,100313,,,https://doi.org/10.1016/j.fsisyn.2022.100313,https://www.sciencedirect.com/science/article/pii/S2589871X22000985,,,,2023,Interpol review of digital evidence for 2019–2022,Paul Reedy,article,REEDY2023100313,Forensic Science International: Synergy,,6,2589-871X,,,
,"Neural network, MNIST, CIFAR10, Splitting, Nesterov, Dynamical system",178-190,,"In the following paper we present a new type of optimization algorithms adapted for neural network training. These algorithms are based upon sequential operator splitting technique for some associated dynamical systems. Furthermore, we investigate through numerical simulations the empirical rate of convergence of these iterative schemes toward a local minimum of the loss function, with some suitable choices of the underlying hyper-parameters. We validate the convergence of these optimizers using the results of the accuracy and of the loss function on the MNIST, MNIST-Fashion and CIFAR 10 classification datasets.",https://doi.org/10.1016/j.neunet.2020.03.018,https://www.sciencedirect.com/science/article/pii/S0893608020300952,,,,2020,New optimization algorithms for neural network training using operator splitting techniques,Cristian Daniel Alecsa and Titus Pinţa and Imre Boros,article,ALECSA2020178,Neural Networks,,126,0893-6080,,,
,"Digital media, Misinformation, Diffusion, Networks, Relational niche, COVID-19",103004,,"This study explores why some fake news publishers are able to propagate misinformation while others receive little attention on social media. Using COVID-19 vaccine tweets as a case study, this study combined the relational niche framework with pooled and multilevel models that address the unobserved heterogeneity. The results showed that, as expected, ties to accounts with more followers were associated with more fake news tweets, retweets, and likes. However, more surprisingly, embedding with fake news publishers had an inverted U-shaped association with diffusion, whereas social proximity to mainstream media was positively associated. Although the effect of influential users is in line with opinion leader theory, the newly-identified effects of social proximity to reliable sources and embeddedness suggest that the key to fake news virality is to earn greater organizational status and modest, not overly, echo chambers. This study highlights the potential of dynamic media networks to shape the misinformation market.",https://doi.org/10.1016/j.ssresearch.2024.103004,https://www.sciencedirect.com/science/article/pii/S0049089X24000267,,,,2024,Fake news virality: Relational niches and the diffusion of COVID-19 vaccine misinformation,Chen-Shuo Hong,article,HONG2024103004,Social Science Research,,120,0049-089X,,,
,"Semantic localisation, Indoor localisation, Patterns, Movements, Time-series, Pattern syntax, Mobility",101946,,"While UbiComp research has steadily improved the performance of localisation systems, the analysis of such datasets remains largely unaddressed. In this paper, we present a tool to facilitate querying and analysis of localisation time-series with a focus on semantic localisation. Drawing on well-established models to represent movement and mobility, we first develop a query language for localisation datasets. We then develop a software library in R that implements this querying. We use case studies to demonstrate how our programming tool can be used to query localisation datasets. Our work addresses an important gap in localisation research, by providing a flexible tool that can model and analyse localisation data programmatically and in real time.",https://doi.org/10.1016/j.pmcj.2024.101946,https://www.sciencedirect.com/science/article/pii/S1574119224000725,,,,2024,A toolkit for localisation queries,Gabriele Marini and Jorge Goncalves and Eduardo Velloso and Raja Jurdak and Vassilis Kostakos,article,MARINI2024101946,Pervasive and Mobile Computing,,103,1574-1192,,,
Translational and Applied Genomics,"Reproducibility, Replication, Rigor, Genomic research, Experimental methodology, Ethical legal social implications, ELSI, Data availability, Open science",3-22,Rigor and Reproducibility in Genetics and Genomics,"The scientific method is the fundamental framework used to make observations, identify and address unanswered questions, and interpret outcomes against the context of existing knowledge and predictions. As scientific investigations become increasingly complex and are conducted with rapidly evolving technologies, a high degree of rigor is necessary to develop and conduct experiments while also ensuring the ability to reliably reproduce results. This introductory chapter provides a brief overview of the scientific method and highlights the challenges of rigor and reproducibility in present-day genetic and biomedical research. Furthermore, this chapter demonstrates how these challenges have impacted public discourse and trust in scientific—particularly biomedical—research. Finally, suggestions for addressing these challenges are presented, including the use of “open science” to redefine research parameters and encourage collaboration.",https://doi.org/10.1016/B978-0-12-817218-6.00012-7,https://www.sciencedirect.com/science/article/pii/B9780128172186000127,,Academic Press,978-0-12-817218-6,2024,Chapter 1 - Rigor and reproducibility in genetic research and the effects on scientific reporting and public discourse,Monika H.M. Schmidt and Douglas F. Dluzen,incollection,SCHMIDT20243,,,,,,Douglas F. Dluzen and Monika H.M. Schmidt,
,"Malware Analysis, Malware Persistence, Incident Response",88-97,,"In the public imagination Cybersecurity is very much about malware, even though malware constitutes only part of all the threats faced by Cybersecurity experts. However, malware is still one of the best methods to gain persistent access and control of a target system. Malware is often combined with a well socially-engineered phishing attack that deceives a user to gain a foothold on a system. Once the attakcer gains a beachhead in the victim’s network, it may be used to download additional payloads and exploit vulnerabilities, to gain more control and access within a network. Using malware as their foothold, attackers are able to to conduct reconnaissance, gather intelligence (e.g., exfiltration of intellectual property) or simply inflict damage or extortion (e.g., ransomware). All of this has to be done in a way that allows an attacker to retain access for as long as possible; the ability to do so is called persistence, and this paper examines the different techniques used by malware to accomplish persistence in an ever evolving landscape.",https://doi.org/10.1016/j.procs.2020.08.010,https://www.sciencedirect.com/science/article/pii/S1877050920318342,,,,2020,Malware Persistence Mechanisms,Zane Gittins and Michael Soltys,article,GITTINS202088,Procedia Computer Science,,176,1877-0509,Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 24th International Conference KES2020,,
,"Co-oriented Scansis (CoS) model, Crisis communication, Situational Crisis Communication Theory (SCCT), AI crisis, Scansis, Moral outrage",102360,,"This study presents the Co-oriented Scansis (CoS) model, which provides a comprehensive understanding of scansis—a recently identified crisis type integrated into the Situational Crisis Communication Theory (SCCT). Using a crisis case of Scatter Lab, a South Korean AI company, as a model case, the study applies the CoS model to analyze the perceptions and meta-perceptions of both the organization and the public regarding the crisis. The data collection involved three official statements released by Scatter Lab and an analysis of 365 reviews from the Google Play users' reviews page of Science of Love—the app used by Scatter Lab to collect intimate conversations between romantic partners. The findings highlight the utility of the CoS model in explaining how Scatter Lab's AI crisis evolved into a scansis. Specifically, the organization's failure to accurately comprehend the public's perception of the crisis (second level co-orientation) and the resulting discrepancy between the organization and the public's perceptions (third level co-orientation) contributed to moral outrage, ultimately leading to a scansis. The study concludes by discussing the theoretical contributions of the CoS model and its practical implications for crisis management.",https://doi.org/10.1016/j.pubrev.2023.102360,https://www.sciencedirect.com/science/article/pii/S0363811123000759,,,,2023,"Introducing the Co-oriented Scansis (CoS) model: A case of chatbot, Lee-Luda",Heesoo Jang and Suman Lee,article,JANG2023102360,Public Relations Review,4,49,0363-8111,,,
,"Web of Things, Internet of Things, Web of Things Discovery, Semantic Interoperability, Semantic Web, Ontology",997-1006,,"Buildings are the largest energy consumers in Europe and are responsible for approximately 40% of EU energy consumption and 36% of the greenhouse gas emissions in Europe. Two-thirds of the building consumption is for residential buildings. To achieve energy efficiency, buildings are being integrated with IoT devices through the use of smart IoT services. For instance, a smart space heating service reduces energy consumption by dynamically heating apartments based on indoor and outdoor temperatures. The W3C recommends the use of the Web of Things (WoT) standard to enable IoT interoperability on the Web. However, in the context of a smart building, the ability to search and discover building metadata and IoT devices available in the WoT ecosystems remains a challenge due to the limitation of the current WoT Discovery, which only includes a directory containing only IoT devices metadata without including building metadata. Integrating the IoT device's metadata with building metadata in the same directory can provide better discovery capabilities to the IoT services providers. In this paper, we integrate building metadata into the W3C WoT Discovery through the construction of a Building Description JSON-LD file. This Building Description is integrated into the W3C WoT Discovery and based on the domOS Common Ontology (dCO) to achieve semantic interoperability in smart residential buildings for the WoT IoT ecosystem within the Horizon 2020 domOS project. This integration results in a Thing and Building Description Directory. dCO integrates the SAREF core ontology with the Thing Description ontology, devices, and building metadata. We have implemented and validated the WoT discovery on top of a WoT Thing and Building Description Directory. The WoT Discovery implementation is also made available for the WoT community.",https://doi.org/10.1016/j.procs.2022.09.155,https://www.sciencedirect.com/science/article/pii/S1877050922010377,,,,2022,Web of Things Semantic Interoperability in Smart Buildings,Amir Laadhar and Junior Dongo and Søren Enevoldsen and Frédéric Revaz and Dominique Gabioud and Torben Bach Pedersen and Martin Meyer and Brian Nielsen and Christian Thomsen,article,LAADHAR2022997,Procedia Computer Science,,207,1877-0509,Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 26th International Conference KES2022,,
,"IoT, BOTNET, RNN, Bi-GRU, SMIE",103064,,"The botnet have developed into a severe risk to Internet of Things (IoT) systems as a result of manufacturers ‘insufficient security policies and end users’ lack of security awareness. By default, several ports are open and user credentials are left unmodified. ML and DL strategies have been suggested in numerous latest research for identifying and categorising botnet assaults in the IoT context, but still, it has a few issues like high error susceptibility, working only with a large amount of data, poor quality, and data acquisition. This research provided use of a brand-new IoT botnet detector built on an improved hybrid classifier. The proposed work's main components are ""pre-processing, feature extraction, feature selection, and attack detection."" Following that, the improved Information Gain (IIG) model is used to choose the most reliable characteristics from the received information. To detect an attack, a hybrid classifier is utilized which can be constructed by integrating the optimized Bi-GRU with the Recurrent Neural Network (RNN). To increase the detection accuracy of IoT-BOTNETS, a novel hybrid optimization approach called SMIE (Slime Mould with Immunity Evolution) is created by conceptually integrating two conventional optimization modes: Coronavirus herd immunity optimizer (CHIO) and the Slime mould algorithm. The final output of the hybrid classifier displays the presence or absence of IoT-BOTNET attacks. The projected model's accuracy is 97%, which is 22.6%, 18.5%, 27.8%, 22.6%, and 24.8% higher than the previous models like GWO+ HC, SSO+ HC, WOA+ HC, SMA+ HC, and CHIO+ HC, respectively.",https://doi.org/10.1016/j.cose.2022.103064,https://www.sciencedirect.com/science/article/pii/S0167404822004564,,,,2023,Intelligent IoT-BOTNET attack detection model with optimized hybrid classification model,Balaganesh Bojarajulu and Sarvesh Tanwar and Thipendra Pal Singh,article,BOJARAJULU2023103064,Computers & Security,,126,0167-4048,,,
,"Natural Language Generation, Human evaluation, Recommendations, Literature review, Open science, Ethics",101151,,"Currently, there is little agreement as to how Natural Language Generation (NLG) systems should be evaluated, with a particularly high degree of variation in the way that human evaluation is carried out. This paper provides an overview of how (mostly intrinsic) human evaluation is currently conducted and presents a set of best practices, grounded in the literature. These best practices are also linked to the stages that researchers go through when conducting an evaluation research (planning stage; execution and release stage), and the specific steps in these stages. With this paper, we hope to contribute to the quality and consistency of human evaluations in NLG.",https://doi.org/10.1016/j.csl.2020.101151,https://www.sciencedirect.com/science/article/pii/S088523082030084X,,,,2021,Human evaluation of automatically generated text: Current trends and best practice guidelines,Chris {van der Lee} and Albert Gatt and Emiel {van Miltenburg} and Emiel Krahmer,article,VANDERLEE2021101151,Computer Speech & Language,,67,0885-2308,,,
,"Automotive engine, Multi-stage hybrid algorithm, Assembly line configuration, Process sequence",13-26,,"Engines are the most expensive and technology-intensive components in automobiles, so an optimized configuration of the automotive engine assembly line (AEAL) is anticipated to improve efficiency and reduce cost. The traditional methods for assembly line configuration can mainly work out a proper machine number, but they generally ignore process sequences that could also influence the buffer cost derived from the assignment of divergence and confluence buffers. Simultaneously, how to reduce the number of variables in the algorithm iteration process to improve computational efficiency is rarely considered in the existing studies. To bridge the gaps, this study proposes a multi-stage hybrid algorithm based on a backtracking searching algorithm (BSA) to realize an effective configuration that can further improve production efficiency and reduce equipment cost for sequence-dependent AEALs. First, an AEAL configuration model is developed to involve machine number and process sequence as decision variables and aims to satisfy multiple objectives concerned with equipment cost and cycle time. Then, a multi-stage hybrid algorithm is proposed to efficiently acquire the optimal solutions to machine number and process sequence in multiple stages that can improve computational efficiency. Finally, the effectiveness and superiority of the proposed method are validated via a case study. The numerical results show that the proposed method can effectively improve production efficiency and reduce equipment cost for sequence-dependent AEALs with a better convergence and diversity performance.",https://doi.org/10.1016/j.jmsy.2022.11.014,https://www.sciencedirect.com/science/article/pii/S0278612522002059,,,,2023,Multi-stage hybrid algorithm-enabled optimization of sequence-dependent assembly line configuration for automotive engine,Miao Yang and Congbo Li and Ying Tang and Wei Wu and Yan Lv,article,YANG202313,Journal of Manufacturing Systems,,66,0278-6125,,,
,"Cybersecurity, Deep learning, Adversarial machine learning, Cyber threats, Adversarial examples",122223,,"Over the last few years, the adoption of machine learning in a wide range of domains has been remarkable. Deep learning, in particular, has been extensively used to drive applications and services in specializations such as computer vision, natural language processing, machine translation, and cybersecurity, producing results that are comparable to or even surpass the performance of human experts. Nevertheless, machine learning systems are vulnerable to adversarial attacks, especially in nonstationary environments where actual adversaries exist, such as the cybersecurity domain. In this work, we comprehensively survey and present the latest research on attacks based on adversarial examples against deep learning-based cybersecurity systems, highlighting the risks they pose and promoting efficient countermeasures. To that end, adversarial attack methods are first categorized according to where they occur and the attacker’s goals and capabilities. Then, specific attacks based on adversarial examples and the respective defensive methods are reviewed in detail within the framework of eight principal cybersecurity application categories. Finally, the main trends in recent research are outlined, and the impact of recent advancements in adversarial machine learning is explored to provide guidelines and directions for future research in cybersecurity. In summary, this work is the first to systematically analyze adversarial example-based attacks in the cybersecurity field, discuss possible defenses, and highlight promising directions for future research.",https://doi.org/10.1016/j.eswa.2023.122223,https://www.sciencedirect.com/science/article/pii/S0957417423027252,,,,2024,Adversarial examples: A survey of attacks and defenses in deep learning-enabled cybersecurity systems,Mayra Macas and Chunming Wu and Walter Fuertes,article,MACAS2024122223,Expert Systems with Applications,,238,0957-4174,,,
,"Abtract Syntax Tree (AST), Tree-based convolutional neural networks(TBCNN), Support Vector Machines (SVMs), K-Nearest Neighbors (kNN)",12-25,,"Analyzing source code to solve software engineering problems such as fault prediction, cost, and effort estimation always receives attention of researchers as well as companies. The traditional approaches are based on machine learning, and software metrics obtained by computing standard measures of software projects. However, these methods have faced many challenges due to limitations of using software metrics which were not enough to capture the complexity of programs. To overcome the limitations, this paper aims to solve software engineering problems by exploring information of programs' abstract syntax trees (ASTs) instead of software metrics. We propose two combination models between a tree-based convolutional neural network (TBCNN) and k-Nearest Neighbors (kNN), support vector machines (SVMs) to exploit both structural and semantic ASTs' information. In addition, to deal with high-dimensional data of ASTs, we present several pruning tree techniques which not only reduce the complexity of data but also enhance the performance of classifiers in terms of computational time and accuracy. We survey many machine learning algorithms on different types of program representations including software metrics, sequences, and tree structures. The approaches are evaluated based on classifying 52000 programs written in C language into 104 target labels. The experiments show that the tree-based classifiers dramatically achieve high performance in comparison with those of metrics-based or sequences-based; and two proposed models TBCNN + SVM and TBCNN + kNN rank as the top and the second classifiers. Pruning redundant AST branches leads to not only a substantial reduction in execution time but also an increase in accuracy.",https://doi.org/10.1016/j.datak.2017.07.003,https://www.sciencedirect.com/science/article/pii/S0169023X17300344,,,,2018,Automatically classifying source code using tree-based approaches,Anh Viet Phan and Phuong Ngoc Chau and Minh Le Nguyen and Lam Thu Bui,article,PHAN201812,Data & Knowledge Engineering,,114,0169-023X,Special Issue on Knowledge and Systems Engineering (KSE 2016),,
,"Altmetrics, PlumX, Citations, Readers, Tweets, Longitudinal study",579-589,,"The main objective of this study is to describe the life cycle of altmetric and bibliometric indicators in a sample of publications. Altmetrics (Downloads, Views, Readers, Tweets, and Blog mentions) and bibliometric counts (Citations) (in this study, the indicators will be capitalized to differentiate them from the general language) of 5185 publications (19,186 observations) were extracted from PlumX to observe their distribution according to the publication age. Correlations between these metrics were calculated from month to month to observe the evolution of these relationships. The results showed that mention metrics (Tweets and Blog mentions) are the earliest metrics that become available most quickly and have the shortest life cycle. Next, Readers are the metrics with the highest prevalence and with the second fastest growth. Views and Downloads show a continuous growth, being the indicators with the longest life cycles. Finally, Citations are the slowest indicators and have a low prevalence. Correlations show a strong relationship between mention metrics and Readers and Downloads, and between Readers and Citations. These results enable us to create a schematic diagram of the relationships between these metrics from a longitudinal view.",https://doi.org/10.1016/j.joi.2018.06.001,https://www.sciencedirect.com/science/article/pii/S1751157717302870,,,,2018,The life cycle of altmetric impact: A longitudinal study of six metrics from PlumX,José Luis Ortega,article,ORTEGA2018579,Journal of Informetrics,3,12,1751-1577,,,
,"New materialism, Distant reading, Computerized text analysis, Video games, Blizzard, Copypasta, Memes",102725,,"In 2019, video game giant Blizzard banned a competitive e-sports player who made a pro-Hong Kong statement during a post-game interview. The international game community responded with outrage, organizing both on- and offline actions to provoke change within the organization. This article examines the #BoycottBlizzard gaming counterpublic via deceptively discrete mixed methods: a new materialist investigation of protest gear and a distant reading of a Reddit dataset of 3500 posts between October 7 and 10, 2019. The investigation concludes that gas masks demonstrate nonhuman aleatory agency in the #BoycottBlizzard protest movement, by inserting subversive subtext into costumes and gameplay. Online, protestors relied heavily on other resistance tactics, including using Twitch copypasta spam; this article suggests this form of resistance functions similarly to a sit-in. Finally, the article iconographically tracks the rise and dissemination of a particular meme image representing the movement's appointed mascot, a Chinese climatologist named Mei. Ultimately, the Blitzchung counterpublic achieved only modest success; the player's ban was reversed and his prize money reinstated, but many protestors considered Blizzard's response milquetoast. However, this analysis proposes that the Blitzchung counterpublic likely emboldened the 2021 #BoycottBlizzard movement and may in some measure be responsible for its success.",https://doi.org/10.1016/j.compcom.2022.102725,https://www.sciencedirect.com/science/article/pii/S8755461522000330,,,,2022,"“Our world is worth fighting for”: Gas mask agency, copypasta sit-ins, and the material-discursive practices of the Blitzchung controversy",Elizabeth F. Chamberlain,article,CHAMBERLAIN2022102725,Computers and Composition,,65,8755-4615,,,
,"Feature-based malicious website detection, Web security, Supervised learning, Feature selection",102374,,"Website features and characteristics have shown the ability to detect various web threats – phishing, drive-by downloads, and command and control (C2). Prior research has thoroughly explored the practice of choosing features ahead of time (a priori) and building detection models. However, there is an opportunity to investigate new techniques and features for detection. We perform a comprehensive evaluation of discovering features for malicious website detection versus selecting features a priori. We gather 46,580 features derived from a response to a web request and, through a series of feature selection techniques, discover features for detection and compare their performance to those used in prior research. We build several detection models using unsupervised and supervised learning algorithms over various sampling and feature transformation scenarios. Our approach is evaluated on a diverse dataset composed of common threats on the internet. Overall, we find that discovered features can achieve more efficient and comparable detection performance to a priori features with 66% fewer features and can achieve a Matthews Correlation Coefficient (MCC) of up to 0.9008.",https://doi.org/10.1016/j.cose.2021.102374,https://www.sciencedirect.com/science/article/pii/S016740482100198X,,,,2021,Discovering features for detecting malicious websites: An empirical study,John McGahagan and Darshan Bhansali and Ciro Pinto-Coelho and Michel Cukier,article,MCGAHAGAN2021102374,Computers & Security,,109,0167-4048,,,
,,551-595,CISSP® Study Guide (Fourth Edition),,https://doi.org/10.1016/B978-0-443-18734-6.00010-6,https://www.sciencedirect.com/science/article/pii/B9780443187346000106,,Syngress,978-0-443-18734-6,2023,,,incollection,2023551,,,,,,Eric Conrad and Seth Misenar and Joshua Feldman,Fourth Edition
,"Protein structure, Secondary structure, Nuclear magnetic resonance, NMR structure, Cyclophilin",237-247,,It is a unique trait of the NMR method for protein structure determination that a description of the polypeptide secondary structure can be obtained at an early stage and quite independently of the complete structure calculation. In this paper the procedures used for secondary structure determination are reviewed and placed in perspective relative to the other steps in a complete three-dimensional structure determination. As an illustration the identification of the regular secondary structure elements in human cyclophilin is described.,https://doi.org/10.1016/0014-5793(91)80808-G,https://www.sciencedirect.com/science/article/pii/001457939180808G,,,,1991,Protein secondary structure determination by NMR Application with recombinant human cyclophilin,Kurt Wüthrich and Claus Spitzfaden and Klaus Memmert and Hans Widmer and Gerhard Wider,article,WUTHRICH1991237,FEBS Letters,2,285,0014-5793,,,
,,I-CXLVIII,,,https://doi.org/10.1016/S2213-1779(23)00398-0,https://www.sciencedirect.com/science/article/pii/S2213177923003980,,,,2023,Full issue PDF,,article,2023I,JACC: Heart Failure,7,11,2213-1779,,,
,,21-52,,"This paper describes an experimental study of the inelastic flexural-torsional buckling behaviour of restrained continuous beam-columns typical of those found in multi-storey steel frames. Nine specimens were tested (and five re-tested) under a variety of loading conditions to provide experimental data on the effects of force and moment distribution, continuity, and end restraints. The experimental data will provide benchmark results for future theoretical analyses on the inelastic buckling behaviour of continuous beam-columns. Results presented include failure load combinations, variations of in-plane and out-of-plane displacements with applied load, measurements of geometrical and material imperfections, and results of subsidiary tests to determine the full plastic moment and squash load. A preliminary assessment of present design rules for beam-columns is carried out.",https://doi.org/10.1016/0143-974X(86)90019-2,https://www.sciencedirect.com/science/article/pii/0143974X86900192,,,,1986,Inelastic buckling of continuous steel beam-columns,P.E. Cuk and D.F. Rogers and N.S. Trahair,article,CUK198621,Journal of Constructional Steel Research,1,6,0143-974X,,,
,,227-252,,,https://doi.org/10.1016/0079-6107(76)90011-0,https://www.sciencedirect.com/science/article/pii/0079610776900110,,,,1976,Lac repressor and Lac operator,Benno Müller-Hill,article,MULLERHILL1976227,Progress in Biophysics and Molecular Biology,,30,0079-6107,,,
,,63-72,,,https://doi.org/10.1016/0144-8617(92)90189-W,https://www.sciencedirect.com/science/article/pii/014486179290189W,,,,1992,Bibliography on carbohydrate polymers,,article,199263,Carbohydrate Polymers,1,18,0144-8617,,,
,,133-145,,When a fine powder is filled into a silo the gas trapped by the particles will take an appreciable time to escape and will cause an increase in the lateral pressure on the walls of the silo. A mathematical analysis of the problem is presented and numerical solutions are provided. The theoretical results are compared with model measurements and the implications for hopper design are discussed.,https://doi.org/10.1016/0032-5910(72)80014-7,https://www.sciencedirect.com/science/article/pii/0032591072800147,,,,1972,The effect of the gaseous phase on pressures in a cylindrical silo,J.R. Johanson and A.W. Jenike,article,JOHANSON1972133,Powder Technology,3,5,0032-5910,,,
,,2491-2502,,"Zusammenfassung
From a Pertusaria spec. (lichen) the following chloroxanthones have been isolated and structurally elucidated: 2,4 - dichloro - 3,6 - di - O -methylnorlichexanthone, 2,5 - dichloro - 3,6 - di -O - methyl-norlichexanthone, and 2,4,5 - trichloro - 3,6 - di - O - methylnorlichexanthone. Revised structures are given for thuringione (2,4,5 - trichloro - 3 - O - methylnorlichexanthone), arthothelin (2,4,5 - trichloronorlichexanthone), and vinetorin (5 - chloro - 3 - O - methylnorlichexanthone). The synthesis of 7 - chloronoriichexanthone is described and detailed 13C-NMR data are reported for 9 chloroxanthones. Erythrommone from Haematomma erythromma (Nyl.) Zahlbr. is identical with 2,4,5 - trichloro-3,6 - di - O - acetylnorlichexanthone.",https://doi.org/10.1016/0040-4020(78)88377-X,https://www.sciencedirect.com/science/article/pii/004040207888377X,,,,1978,Struktur und 13C-NMR-spektroskopie von chlorhaltigen flechtenxanthonen,Siegfried Huneck and Gerhard Höfle,article,HUNECK19782491,Tetrahedron,16,34,0040-4020,,,
,,321-336,,"Resume
Sonte´tudie´s les humoacides, les humines extractibles et re´siduelles d'un ne´oranker et d'un pale´orankera`moder pre´leve´s l'una`2600 m, l'autrea`2200 m en Pyre´ne´es, pouvanteˆtre conside´re´s comme des pe´doclimax stationnels et tre`s distincts par leurs caracte`res morphologiques et physico-chimiques d'ensemble, le ne´orankera`moder acide et fulviquee´tant beaucoup plus riche en fer, aluminium, silice que le pale´orankera`moder humique et moins acide. Les fractions humiques ne renferment pas de copule lignique. Elles sont plus riches en Al, Fe, Mg dans le ne´oranker, mais ces me´taux sont plus abondants dans les humoacides que dans les humines bien que celles-ci soient plus riches en cendres totales. Elles diffe`rent quantitativement par les teneurs en me´taux, carbone, azotes divers, sucres et qualitativement par la nature des aminoacides et leuraˆge pre´cise´au14C.
The authors studied humic acids and remaining and extractable humines of a Moder on paleo and neo-rankers at two stations in the Pyrenean mountains at altitudes of 2600 and 2100 meters. Very distinct in their morphological and physio-chemical characters, they can be considered as a stational pedoclimax. The neo-rankers have an acid and fulvic moder and are more rich in iron, aluminium and silica, than the paleo-rankers having a humic and less acid moder. The humic fraction does not contain any lignin core and contains more aluminium, iron and magnesium than humines even though the latter has a higher ash ratio. Quantitatively they differ in their contents of minerals, carbon, different nitrogens and sugar compounds and qualitatively in their contents of amino-acids and in their age determined by C14.",https://doi.org/10.1016/0341-8162(78)90016-4,https://www.sciencedirect.com/science/article/pii/0341816278900164,,,,1978,Caracteristiques des humoacides et des humines de deux rankers Pyreneens,C. Fallek and G. Ghiglione and R. Negre,article,FALLEK1978321,CATENA,3,5,0341-8162,,,
,"Autoradiography, DNA repair, Flow cytometry, Rat hepatocytes, Unscheduled DNA synthesis",147-167,,"An in vitro flow cytometric (FCM) DNA repair assay has been developed and validated by comparison to conventional autoradiography (ARG). Both assays measure unscheduled DNA synthesis (UDS). Cultures of hepatocytes from young male Sprague-Dawley rats were exposed to a battery of 26 chemicals plus bromodeoxyuridine (BrdUrd) or 3H-thymidine (3H-dT) for 18–20 h before harvest. Selection of test chemicals was based upon both their genotoxicity classifications and carcinogenicity bioassay results in male rats. DNA repair in chemically treated cultures was detected flow cytometrically by measuring the uptake of BrdUrd in non-replicating (G1, G2, mitotic and 4C) cells. Intracellular levels of incorporated BrdUrd were visualized by immunochemical labeling with fluorescein isothiocyanate (FITC), and total cellular DNA content was simultaneously estimated by counterstaining samples with the nucleic acid intercalator, propidium iodide (PI). Information was obtained from 104 cells/sample. Since repairing cells incorporate significantly less BrdUrd per unit of time than replicating cells, low intensity BrdUrd-FITC fluorescent signals from repairing cells are readily discriminated from high intensity signals from replicating cells when displayed on linear univariate histograms. Further distinction between repairing and replicating cells was achieved by displaying the DNA contents of all cells on linear bivariate histograms. Thus, repairing cells were resolved without subjecting these cultures to agents which suppress replicative synthesis (e.g, hydroxyurea). Results from these concurrent FCM and ARG investigations include the following: (1) conclusions (DNA repair positive or negative) were in agreement, with one exception, cinnamyl anthranilate, for which cytotoxic doses produced a positive FCM response, but lack of intact hepatocytes in parallel ARG preparations prevented analysis; (2) similar sensitivities for most of the positive chemicals were reported; (3) a high correlation (85%) exists between the reported genotoxicity classification and these DNA repair results in the absence of overt cytotoxicity; (4) a poor correlation exists between these DNA repair results and hepatocarcinogenesis (only 4/11 liver carcinogens tested positive) or overall carcinogenesis in the male rat (only 9/21 carcinogens tested positive). This FCM assay provides a rapid, sensitive, safe and reliable means of identifying agents which induce DNA repair in mammalian cells.",https://doi.org/10.1016/0921-8777(94)90015-9,https://www.sciencedirect.com/science/article/pii/0921877794900159,,,,1994,Validation of a flow cytometric in vitro DNA repair (UDS) assay in rat hepatocytes,Jules R. Selden and Frank Dolbeare and James H. Clair and Judith E. Miller and Katherine McGettigan and John A. DiJohn and Gary R. Dysart and John G. DeLuca,article,SELDEN1994147,Mutation Research/DNA Repair,2,315,0921-8777,,,
,,125-150,,"The emissions of biacetyl after pulsed dye-laser excitation were studied at pressures down to 0.05 mtorr. At all energies the time-resolved fluorescence was composed of a nanosecond and a microsecond component. At “zero” pressure the long lived phosphorescence was absent while the “hot” phosphorescence has the same time characteristics as the slow fluorescence. By increasing the pressure the slow fluorescence was quenched while the milisecond phosphorescence was induced. We determined the low-pressure emission characteristics and the pressure effects as a function of excitation energy. From our data we obtained the parameters describing the intermediate type singlet-triplet coupling, the radiative and non-radiative relaxation rates from the singlet and triplet levels and the cross sections for the slow fluorescence quenching, all as a function of energy. Strong evidence is obtained for the participation of rotational states in the intra-molecular relaxation. The important difference between the situation where the singlet levels are isolated (low energy) and where the singlet level widths overlap (at higher energies) is demonstrated. In the former situation very large fluorescence quenching cross sectios were found. It is further shown that for high energies at least two effective collisions are needed to obtain a thermalized triplet; the mean energy removed per effective collision is 2200 cm−1.",https://doi.org/10.1016/0301-0104(76)80049-3,https://www.sciencedirect.com/science/article/pii/0301010476800493,,,,1976,The electronic relaxation of biacetyl in the vapor phase,Renie {van der Werf} and Jan Kommandeur,article,VANDERWERF1976125,Chemical Physics,2,16,0301-0104,,,
,,875-886,,,https://doi.org/10.1016/S0022-3476(52)80307-5,https://www.sciencedirect.com/science/article/pii/S0022347652803075,,,,1952,Authors index,,article,1952875,The Journal of Pediatrics,6,41,0022-3476,,,
,,35-43,,"The early effects of topical administration of 2% l-epinephrine bitartrate on the dynamics of aqueous humor were studied in 15 vervet monkeys. In 10 animals the eye pressure was not interfered with; in 5 the eye pressure was stabilized at about 22 mmHg using reservoirs. [131I]Albumin was used to determine the net formation of aqueous humor in one eye; [125I]albumin was used in the other eye. The average net rate of aqueous formation in the treated eyes and that in the controls were the same 1·61 ± 0·14 μl/min. The rate of flow into the general circulation was 0·34 ± 0·10 μl/min less in the treated eyes than in the controls. The uveo-scleral drainage was enhanced in the treated eyes. The facility of outflow was 0·35 ± 0·07 μl. min−1. mmHg−1 higher in the treated eyes than in the controls. There was little effect on pseudofacility, probably due to a high arterial blood pressure caused by absorption of the drug. Epinephrine tended to raise the recipient venous pressure. It is suggested that epinephrine has a facility reducing effect that is due to relaxation of the ciliary muscle and a facility increasing effect that may be due to some change in the endothelium of the canal of Schlemm. Since epinephrine has several antagonistic effects the effect on the intraocular pressure can be expected to vary even qualitatively.",https://doi.org/10.1016/S0014-4835(69)80078-3,https://www.sciencedirect.com/science/article/pii/S0014483569800783,,,,1969,Early effects of epinephrine on aqueous humor dynamics in vervet monkeys (Cercopithecus ethiops),Anders Bill,article,BILL196935,Experimental Eye Research,1,8,0014-4835,,,
,,289-307,,"ABSTRACT
The relationship between migration and unemployment duration is examined. Standard job predictors of spell length (replacement income, labor force experience, personal characteristics and economic conditions) are included as control variables alongside measures of migration in a Weibull hazard model. The model is estimated using data from the National Longitudinal Survey of Youth. Young adults who migrated while unemployed had longer durations of unemployment than those who did not migrate. The rate at which they found jobs was also linked to how long they had been unemployed, to being laid off, being African American, to going to college, having a mortgage and of national unemployment conditions.",https://doi.org/10.1111/j.1435-5597.1994.tb00615.x,https://www.sciencedirect.com/science/article/pii/S1056819023003937,,,,1994,MIGRATION AND UNEMPLOYMENT DURATION AMONG YOUNG ADULTS,Adrian J. Bailey,article,BAILEY1994289,Papers in Regional Science,3,73,1056-8190,,,
Food Science and Technology,,353-389,Handbook of Food and Beverage Stability,,https://doi.org/10.1016/B978-0-12-169070-0.50010-8,https://www.sciencedirect.com/science/article/pii/B9780121690700500108,San Diego,Academic Press,978-0-12-169070-0,1986,CHAPTER 5 - SHELF-LIFE OF FRUITS,DAVID C. LEWIS and TAKAYUKI SHIBAMOTO,incollection,LEWIS1986353,,,,,,GEORGE CHARALAMBOUS,
,,809-821,,"Objectives. The aim of this study was to determine whether esmolol, an ultrashort-acting beta-adrenergic antagonist, possesses cardioprotective properties unrelated to a concomitant decrease in heart rate. Background. Previous studies have demonstrated beneficial effects of beta-adrenergic blocking agents with unchanged heart rates. Methods. The effect of esmolol (100 μg/kg per min) on the response of global cardiovascular and regional myocardial contractile function (sonomicrometry) to pacing-induced tachycardia and acute left ventricular afterloading was assessed in dogs with a critical stenosis of the left anterior descending coronary artery (LAD). These responses were observed at the baseline hemoglobin level (12.5 ± 0.3 g/100 ml) as well as after hemodilution-induced mild regional contractile dysfunction (7.4 ± 0.4 g/100 ml) in the area supplied by this artery (LAD area). Data were analyzed by using a repeated measures multivariate analysis of variance with complete block design treating pacing rate and afterloading, respectively, as the repeated measure. Results. Esmolol decreased the maximal first derivative of left ventricular pressure (dP/dtmax); global cardiovascular and regional myocardial contractile function were otherwise unchanged. Esmolol did not alter the response of global cardiovascular or regional myocardial function to pacing-induced tachycardia or to acute left ventricular afterloading, both at the baseline hemoglobin level as well as during mild hemodilution-induced LAD area contractile dysfunction. Conclusions. At an infusion rate of 100 μg/kg per min we were unable to demonstrate cardioprotective esmolol effects in a canine model of critical coronary stenosis with controlled heart rate and identical loading conditions.",https://doi.org/10.1016/0735-1097(93)90115-H,https://www.sciencedirect.com/science/article/pii/073510979390115H,,,,1993,"Is esmolol cardioprotective? Tolerance of pacing tachycardia, acute afterloading and hemodilution in dogs with coronary stenosis",Donat R. Spahn and Peter E. Frasco and William D. White and L.Richard Smith and Robert L. McRae and Bruce J. Leone,article,SPAHN1993809,Journal of the American College of Cardiology,3,21,0735-1097,,,
,,351-364,,"In the area between the 30 and 40 m isobaths, just north of the Netherlands, a transition from Channel water to central North Sea water is found. Observations obtained in May and June 1986 show a predominantly along-isobath directed sub-tidal current. In the vertical cross-isobath plane a quasi-permanent upwelling zone overlying the steepest bottom slope is inferred from observed cross-isobath currents. In the same area Creutzberg (1985) observed a persistent chlorophyll a (chl a) maximum. Our observations show a chl a maximum extending from the bottom towards the pycnocline over a larger area in cross-isobath direction and with larger amounts of chl a than found by Creutzberg (1985). This chl a maximum is found above a zone of large amounts of benthic particulate organic carbon. The observed chl a distributions are compared with current and density observations via an advection-diffusion equation. Only rough estimates of the terms in this equation are obtained, which indicates that a balance between vertical advection and mixing, i.e. local generation, is most probable. The chl a distribution gives no evidence for an upwelling zone.",https://doi.org/10.1016/0077-7579(90)90043-G,https://www.sciencedirect.com/science/article/pii/007775799090043G,,,,1990,Observations of physical and biological parameters at the transition between the southern and central North Sea,J.J.M. {Van Haren} and J.C.A. Joordens,article,VANHAREN1990351,Netherlands Journal of Sea Research,3,25,0077-7579,,,
,,221-227,,,https://doi.org/10.1016/0144-8617(94)90105-8,https://www.sciencedirect.com/science/article/pii/0144861794901058,,,,1994,Bibliography of carbohydrate polymers,,article,1994221,Carbohydrate Polymers,3,23,0144-8617,,,
,,279-306,,"Side-scan sonar and subbottom profiling, coupled with bottom control through diving and sampling, have revealed new seafloor features in the northern Adriatic Sea and contributed to a better understanding of previously researched morphological and sedimentological features. Reef rock was found to be more significant than the previously known submerged beachrock exposures. Calcareous algae, madreporaria, bryozoa and serpulidae are the dominant reef builders. Single exposures of organic rock protruding above the seafloor range in size from a few cubic decimeters to several hundred thousand cubic meters. Such reefs have been tentatively divided into three types: (a) reef “sensu strictu” where organisms have built the entire feature; (b) cap reef, where the reef rock represents only a hard cap over a sedimentary core; and (c) coating reef, where the organic rock represents a thin coating over other rock types (mainly beachrock). Subbottom reflections both under and within features which at the surface appear to be reefs, confirm the existence of (b). Large beachrock exposures have been found between Lignano and Grado. In at least one case, beachrock seems to have supported reef growth. Other calcareous sandstones have been found in the area, but their thickness coupled with the absence of sedimentary structures and shell remains make it questionable whether the rock should be regarded as beachrock. A discontinuous, dense mattress of dead Posidonia roots has been found covering a large area (ca. 5 by 30 km) northeast of Venice in water depths ranging from 15 to 23 m. Such Posidonia mats are usually covered by a few centimeters of sand and have been cut and eroded by wave-induced turbulence to form “terraces” and a generally irregular bottom morphology. Mattresses of Posidonia roots form a protective cover along the crests of sandwaves south of Caorle in 20 m of water and protect them from wave erosion. Periodic lineations of very coarse sediment spaced 15 to 20 m apart on an otherwise fine, sandy bottom, have been found 20 miles east of Venice in 29 m of water. These are the result of sediment sorting due to exceptional storm waves coming from a southeasterly direction.",https://doi.org/10.1016/0025-3227(82)90085-8,https://www.sciencedirect.com/science/article/pii/0025322782900858,,,,1982,Side-scan sonar and subbottom profiling in the northern Adriatic Sea,Robert S Newton and Antonio Stefanon,article,NEWTON1982279,Marine Geology,3,46,0025-3227,,,
,,829-857,Introduction to Homeland Security (Sixth Edition),,https://doi.org/10.1016/B978-0-12-817137-0.18001-0,https://www.sciencedirect.com/science/article/pii/B9780128171370180010,,Butterworth-Heinemann,978-0-12-817137-0,2021,Index,,incollection,2021829,,,,,,Jane A. Bullock and George D. Haddow and Damon P. Coppola,Sixth Edition
,,237-IN6,,"A technique is described for homografting the full thickness of the cornea in rabbits. It gave excellent results in all experiments using fresh, untreated corneal tissue. Either 7·5% or 15% dimethyl sulphoxide in serum was injected into the anterior chambers of donor eyes. Some of the eyes were suspended in serum containing 7·5% dimethyl sulphoxide, others in serum containing 10% glycerol. They were either kept at 20°C for 1–2 hr, or cooled to −79°C. Grafts of cornea from the unfrozen control eyes gave good results in 27 out of 30 rabbits. Twenty-nine clear grafts were obtained from 41 frozen eyes in which the corneal epithelium had been in contact with glycerol and the endothelium in contact with dimethyl sulphoxide. Twelve of these clear grafts were from 19 eyes kept for 1–2 hr at −79°C. The other 17 clear grafts were from 22 eyes kept for several days, weeks or months at −79°C.",https://doi.org/10.1016/S0014-4835(63)80042-1,https://www.sciencedirect.com/science/article/pii/S0014483563800421,,,,1963,Some experiments on grafting frozen corneal tissue in rabbits,F.O. Mueller and Audrey U. Smith,article,MUELLER1963237,Experimental Eye Research,3,2,0014-4835,,,
,"time-budgeting, foraging strategy, parrotfish, , Jamaica",159-177,,"Quantitative data on the ways in which the different phases of the stoplight parrotfish (Sparisomaviride Bonnaterre) distribute their time among various activities in different habitats are presented. Individuals spent from 84–97% of their diurnal time swimming, feeding, and hovering. Additionally, large adults spent a significant amount of time sheltering among crevices. Phase-related differences in these activities are statistically significant, as are differences in duration and rates of change of the activities. Large individuals spent more time swimming, while small individuals spent more time hovering. In addition, large individuals performed longer bouts of activity and switched activities less frequently than small individuals. Adult males and females spent approximately equal proportions of time in each of the activity states. Stochastic analyses of behavioural sequences show second order Markov chain dependencies, suggesting that preceding activity states affect subsequent behaviour. Possible relationships between behavioural sequencing and the species foraging strategy are discussed, and it is suggested that the sequence of behavioural activities can provide an estimation of the distribution of food resources in the environment.",https://doi.org/10.1016/0022-0981(84)90043-1,https://www.sciencedirect.com/science/article/pii/0022098184900431,,,,1984,"Time-budgeting and foraging strategy of the stoplight parrotfish Sparisoma viride Bonnaterre, in Jamaica",Fred Hanley,article,HANLEY1984159,Journal of Experimental Marine Biology and Ecology,2,83,0022-0981,,,
,,S141-S178,,,https://doi.org/10.1016/j.clml.2018.07.281,https://www.sciencedirect.com/science/article/pii/S2152265018310358,,,,2018,Poster Presentations***Presenter,,article,2018S141,Clinical Lymphoma Myeloma and Leukemia,,18,2152-2650,Proceedings of the Society of Hematologic Oncology 2018 Annual Meeting,,
Advances in Clinical Chemistry,,125-162,,"Publisher Summary
This chapter discusses the biochemical events related to phagocytosing cells. Phagocytosing cells include the polymorphonuclear leukocytes or neutrophils, the mononuclear leukocytes that can give rise to macrophages in tissues, and the eosinophils. Neutrophils are the most abundant phagocytes that ensure the early tissue response to infection. A decrease or increase in a number of leukocyte enzyme activities can be demonstrated in pathological situations, but the specificity of such changes and the way in which enzymes are brought about are not elucidated. The metabolic pathways are studied as multienzyme systems or by characterizing their individual enzymes. The enzymatic equipment of the polymorphonuclear cell is complete and the main metabolic pathways are present in white cells. Biochemical disorders in leukocytes may present a picture of metabolic impairment of the white cells themselves or that of general pathological manifestations in the human organism (Fl). Therefore, leukocytes have become a valuable tool for the study or even the diagnosis of inborn errors and acquired deficiencies and disorders of ubiquitous enzymes and metabolic systems because it can be isolated and purified with relative ease.",https://doi.org/10.1016/S0065-2423(08)60047-5,https://www.sciencedirect.com/science/article/pii/S0065242308600475,,Elsevier,,1981,Biochemical Events Related to Phagocytosing Cells,Michèle Markert and J. Frei,incollection,MARKERT1981125,,,22,0065-2423,,A.L. Latner and Morton K. Schwartz,
Comprehensive Biochemistry,,133-185,Selected Topics in the History of Biochemistry: Exploring the cell Membrane: Conceptual Developments,,https://doi.org/10.1016/B978-0-444-81253-7.50008-0,https://www.sciencedirect.com/science/article/pii/B9780444812537500080,,Elsevier,,1995,Chapter 4 - The Concept of a Solute Pump,A. KLEINZELLER,incollection,KLEINZELLER1995133,,,39,0069-8032,,A. KLEINZELLER,
,,28-37,,"Uptake and efflux of 86Rb by lenses subjected to damage of varying degree have been investigated. Incisions were made through the capsule, anteriorly or posteriorly, with a pointed scalpel. Small incisions did not disturb either uptake or efflux when compared with intact lenses. More severe damage led to impaired efficiency in accumulation and intereased efflux, but additional changes could be superimposed in the presence of ouabain. An isolated preparation of anterior capsule plus epithelium was used in an attempt to differentiate between the ion transporting capabilities of the epithelium and of the fibres. 86Rb could not be concentrated across this membrane and it was concluded that it was excessively leaky, due to the isolation procedure, although ion movements were susceptible to ouabain. Evidence is presented that the fibres are capable of controlling, by means of a sodium pump, their own internal ionic content, but only to the extent that they are protected from the large ionic differential presented in the aqueous humour by the considerably greater pumping capacity of the epithelium.",https://doi.org/10.1016/S0014-4835(70)80055-0,https://www.sciencedirect.com/science/article/pii/S0014483570800550,,,,1970,Ion transport in damaged lenses and by isolated lens epithelium,M.V. Riley,article,RILEY197028,Experimental Eye Research,1,9,0014-4835,,,
,,399-407,,,https://doi.org/10.1016/S0016-0032(37)91187-6,https://www.sciencedirect.com/science/article/pii/S0016003237911876,,,,1837,Mechanics' register,,article,1837399,Journal of the Franklin Institute,6,24,0016-0032,,,
,,183-201,,"In this paper we argue that the quality of decision making in psychoeducational practice is likely to profit considerably from directives derived from a so-called normative diagnostic-prognostic framework, and that a computerized decision-support system is a promising tool for facilitation of the actual use of such directives. Accordingly, we describe the design and function of a knowledge-based system that is intended to support the initial stages of decision making in diagnosis of reading and spelling problems: (a) specifying the child's task performance in concrete behavioral terms, (b) identifying behavioral syndromes in these learning behaviors, and (c) generating candidate explanations, or diagnostic hypotheses, for these behaviors and syndromes. The systematic and formal foundation of the description of learning-behavior problems required for accomplishing these stages is provided by the facet definition approach. We present a mapping sentence that serves to define reading and spelling problems and that at the same time is used as a vehicle for communication between user and system. In order to show the latter function of the facet definition in the user interface of the system, a prototypical implementation of the system is described. Finally, some problems in constructing the required knowledge bases are discussed.",https://doi.org/10.1016/0747-5632(92)90003-W,https://www.sciencedirect.com/science/article/pii/074756329290003W,,,,1992,The development of a knowledge-based system supporting the diagnosis of reading and spelling problems,Edward {van Aarle} and John {van den Bercken},article,VANAARLE1992183,Computers in Human Behavior,2,8,0747-5632,,,
,"Archezoa, Cytoskeleton, , , Protozoa",25-49,,"The ultrastructural appearances of Mastigamoeba punctachora, Mastigamoeba simplex and Mastigella commutansare described. All three species have electron-dense membrane-bounded bodies, suggestive of mitochondrial homologues. All species have a single basal body giving rise to conical arrays of microtubules and to a single ribbon-like microtubular root. The proximal portion of the root is associated with a sheet of dense material. All species have ‘9+2’ flagellar axonemes, with basal bodies composed of triplets of microtubules, but axonemal outer dynein arms appear to be absent. All have a cylinder at the base of the transition zone. The transition zone of Mastigamoeba punctachora is elongate and also contains a column of electron-dense material. Ultrastructural data are compiled and analysed to assess two alternative views that the pelobionts are a primitive group of eukaryotes and the source of the other eukaryotes, or that they are related to eumycetozoan slime moulds.",https://doi.org/10.1078/0932-4739-00780,https://www.sciencedirect.com/science/article/pii/S0932473904700048,,,,2001,"Ultrastructural identities of Mastigamoeba punctachora, Mastigamoeba simplex and Mastigella commutans and assessment of hypotheses of relatedness of the pelobionts (Protista)",Giselle Walker and Alastair G.B. Simpson and Virginia Edgcomb and Mitchell L. Sogin and David J. Patterson,article,WALKER200125,European Journal of Protistology,1,37,0932-4739,,,
,,47-62,,"Nitrogen transport was studied during summer low flows in a 20-km reach of the Nottawasaga River which drains an intensively cropped sand plain which has an underlying shallow water-table aquifer. Nitrogen inputs to the river were measured on days in May to October of 1977-81. These data indicated that about 38% of the daily nitrate input entered the river through ground water. The magnitude of this input is a consequence of widespread contamination of the shallow aquifer by nitrogen fertilizer. Ground water entering the river from springs and seeps near fertilized fields frequently contained more than 10 mg 1−1 of NO3-N. Mass balance studies of nitrogen transport in the river revealed an average daily nitraof 46 ± 23 kg N. This rate of nitrate removal represented about 40% of the ground water input to the river from the sand plain. Analysis of a mass balance for total Kjeldahl nitrogen revealed an essentially balanced budget, whereas chloride showed a small daily gain of about 5%. Laboratory experiments involving the incubation of stream sediment cores and the use of the acetylene block technique suggested that the bulk of the nitrate loss during river transport was caused by denitrification in bottom sediments.",https://doi.org/10.1016/0167-8809(83)90069-5,https://www.sciencedirect.com/science/article/pii/0167880983900695,,,,1983,Denitrification: its importance in a river draining an intensively cropped watershed,A.R. Hill,article,HILL198347,"Agriculture, Ecosystems & Environment",1,10,0167-8809,,,
,,435-454,,"The non-histone messenger RNAs of sea urchin embryos have been separated on oligo(T)-cellulose into fractions containing poly(A) and those entirely lacking poly(A). Proof of the existence of the class of mRNA lacking poly(A) is afforded by the following demonstrations: (1) the pulse-labeled RNA analyzed is bound to polyribosomes and has no non-polysomal contamination, (ii) The methods of extraction, as tested by mixing experiments between cytoplasmic extracts of sea urchin embryo and mammalian tissue culture cells, preclude partial degradation of mRNA containing poly(A) to yield artifactual species lacking poly(A), (iii) The non-histone mRNA lacking poly(A) has a mean sedimentation coefficient of 22 S, as measured in a denaturing solvent. It is shown not to consist of molecular aggregates of the putative histone 9 S mRNA, and its base composition differs markedly from those of both 9 S and ribosomal RNA, but resembles closely that of poly(A)-containing mRNA. (iv) Although the non-histone mRNAs lacking and containing poly(A) have similar base compositions and sizes (approximately 22 S), they differ widely in their nucleotide sequences. Complementary DNA, prepared with reverse transcriptase instructed by poly(A)-containing mRNA, hybridized to a negligible extent with RNA lacking poly(A).",https://doi.org/10.1016/0022-2836(74)90474-4,https://www.sciencedirect.com/science/article/pii/0022283674904744,,,,1974,Co-existence of non-histone messenger RNA species lacking and containing polyadenylic acid in sea urchin embryos,Martin Nemer and Melissa Graham and Lewis M. Dubroff,article,NEMER1974435,Journal of Molecular Biology,3,89,0022-2836,,,
,"Dispersion of current accounts, Incomplete markets, Frictions",477-496,,"We develop a multi-country quantitative model of the global distribution of current account and external balances. Countries accumulate domestic capital and foreign assets to smooth consumption over time against exogenous productivity shocks in the presence of liquidity constraints. In equilibrium, optimal consumption and investment responses to persistent productivity shocks imply a degree of intertemporal substitution across countries that can explain up to one-third of the current account dispersion in the data.",https://doi.org/10.1016/j.red.2012.09.007,https://www.sciencedirect.com/science/article/pii/S1094202512000579,,,,2013,Accounting for global dispersion of current accounts,Yongsung Chang and Sun-Bin Kim and Jaewoo Lee,article,CHANG2013477,Review of Economic Dynamics,3,16,1094-2025,,,
,"IoT digital-forensics, IoT anti-forensics, Anti-anti-forensics techniques, Counter anti-forensics, Internet of things forensics, Internet of Forensics Things, IoT digital forensics investigation, IoT source of evidences, Protecting and preserving IoT evidences",100544,,"Recently, the number of cyber attacks against IoT domains has increased tremendously. This resulted into both human and financial losses at all IoT levels especially individual and organization levels. Recently, cyber-criminals have kept on leveraging new skills and capabilities by conducting anti-forensics activities and employing techniques and tools to cover their tracks to evade any possible detection of the attack’s events, which has targeted either the IoT system or/and its component(s). Consequently, IoT cyber-attacks are becoming more efficient and more sophisticated with higher risks and threat levels based on their more frequent likelihood to occur and their impact. However, traditional security and forensics solutions are no longer enough to prevent nor investigate such cyber attacks, especially in terms of acquiring evidence for attack investigation. Hence, the need for well-defined, sophisticated, and advanced forensics investigation techniques is highly required to prevent anti-forensics techniques and track down cyber criminals. This paper reviews the different forensics and anti-forensics methods that can be applied in the IoT domain including tools, techniques, types, and challenges, while also discussing the rise of the anti-anti-forensics as a new forensics protection mechanism against anti-forensics activities. This would help forensics investigators to better understand the different anti-forensics tools, methods and techniques that cyber criminals employ while launching their attacks. Moreover, the limitations of the current forensics techniques are discussed, especially in terms of issues and challenges. Finally, this paper presents a holistic view from a literature point of view over the forensics domain in general and for IoT in particular.",https://doi.org/10.1016/j.iot.2022.100544,https://www.sciencedirect.com/science/article/pii/S2542660522000464,,,,2022,"Advanced digital forensics and anti-digital forensics for IoT systems: Techniques, limitations and recommendations",Jean-Paul A. Yaacoub and Hassan N. Noura and Ola Salman and Ali Chehab,article,YAACOUB2022100544,Internet of Things,,19,2542-6605,,,
Electromagnetism,,335-467,Permanent Magnet and Electromechanical Devices,"Publisher Summary
This chapter discusses the theory of electromechanical devices, as well as various practical applications. Electromechanical devices convert electrical energy to mechanical energy. Electromechanical devices consist of three subsystems: the electrical drive circuitry, an electromechanical coupling subsystem, and a mechanical subsystem. Electromechanical devices are governed by a coupled system of electrical and mechanical equations. The electrical equations follow from quasi-static field theory, and the mechanical equations follow from Newton's laws. Furthermore, the chapter derives equations of motion for electromechanical devices that execute either linear or rotational motion. These equations are applied to the analysis of various practical devices including magnetic circuit actuators, linear, rotational and resonant actuators, axial-field motors, and stepper motors. The focus is on magnetically linear, singly excited (single pair of electrical terminals), electromechanical devices with a single degree of mechanical freedom.",https://doi.org/10.1016/B978-012269951-1/50006-1,https://www.sciencedirect.com/science/article/pii/B9780122699511500061,San Diego,Academic Press,978-0-12-269951-1,2001,Chapter 5 - Electromechanical Devices,Edward P. Furlani,incollection,FURLANI2001335,,,,,,Edward P. Furlani,
,"Cyanobacteria, , Classification, Revision, ,  sp., , , Cyanobactéries, , Classification, Révision, ,  sp., , ",21-36,,"Summary
As a logical consequence of the definition of a bacterium (Stanier and van Niel, 1962), R. Y. Stanier created the name «cyanobacteria as a replacement for «blue-green algae. As such, cyanobacteria entered the 8th issue of Bergey's Manual of Determinative Bacteriology 1974 as members of the Procaryotae Murray 1968, this kingdom being composed of two divisions, Cyanobacteria and Bacteria. An even tighter integration of cyanobacteria with other bacteria was proposed by Gibbons and Murray (1978) for the next edition of Bergey's Manual. These authors suggested that the cyanobacteria be integrated as an order Cyanobacteriales in the class Photobacteria. However, this proposal was doomed to failure by constrants imposed under present rules of the Bacteriological Code (Lapage et al., 1976), one of which is that the type of an order is the genus upon whose name the higher taxon is based. A genus Cyanobacterium did not exist when Gibbons and Murray made their proposal, and a subsequent special request by the same authors for an exemption from this rule was not granted (Judicial Commission of the International Committee on Systematic Bacteriology, Holt, 1978). We present here a revised classification for unicellular cyanobacteria dividing in one plane wherein we propose, among other changes, the creation of two new genera, Cyanobium and Cyanobaceterium. With the creation of the latter genus, the requirement for recognition of cyanobacteria as a legal order Cyanobacteriales under the Bacteriological Code should be fulfilled. We suggest that the type species of this genus be Cyanobacterium stanieri, in honor of the late Roger Y. Stanier.
Résumé
La définition d'une «bactérie proposée par Stanier et van Niel en 1962 [48] a eu pour conséquence logique la création, par R. Y. Stanier, du nom «cyanobactéries pour remplacer celui d' «algues bleues. C'est sous cette dénomination que ces organismes entrèrent dans la troisième édition du manuel de détermination bactériologique de Bergey en 1974 [4]. Dans ce manuel, les cyanobactéries étaient traitées comme membres des Procaryotae Murray 1968, cet embranchement étant constitué par deux groupes: les Cyanobactéries et les Bactéries. Un rapproachement encore plus étroit des cyanobactéries des autres bactéries a été proposé par Gibbons et Murray [16] pour la prochaine édition du manuel de Bergey. Ces auteurs ont proposé que les cyanobactéries soient intégrées dans la classe des Photobactéries, en tant qu'ordre des Cyanobacteriales. Cette proposition fut refusée comme ne satisfaisant pas les règles du Code Bactériologigue [28], l'une de ces règles étant que le type d'un ordre est le genre sous le nom duquel le taxon d'ordre plus élevé est basé. Le genre Cyanobacterium n'existait pas lorsque Gibbons et Murray ont fait leur proposition, et une demande ultérieure d'exception à cette règle [17] fut également refusée. Nous proposons ici une nouvelle classification des cyanobactéries unicellulaires qui se divisent sur un seul plan. Entre autres changements, nous proposons la création de deux nouveaux genres: Cyanobium et Cyanobacterium. La création de ce dernier genre devrait lever l'objection qui empêchait de reconnaître les Cyanobacteriales comme ordre légitime suivant les règles du Code Bactériologique. Nous proposons que l'espèce type de ce genre soit appelée Cyanobacterium stanieri pour honorer la mémoire de Roger Y. Stanier.",https://doi.org/10.1016/S0769-2609(83)80094-5,https://www.sciencedirect.com/science/article/pii/S0769260983800945,,,,1983,The cyanobacteriales: A legitimate order based on the type strain Cyanobacterium stanieri?,R. Rippka and G. Cohen-Bazire,article,RIPPKA198321,Annales de l'Institut Pasteur / Microbiologie,"1, Supplement B",134,0769-2609,,,
,,150-159,,,https://doi.org/10.1016/0304-4165(71)90103-6,https://www.sciencedirect.com/science/article/pii/0304416571901036,,,,1971,Stimulation by estrogens of ornithine and S-adenosylmethionine decarboxylases in the immature rat uterus,Alvin M. Kaye and Isaac Icekson and H.R. Lindner,article,KAYE1971150,Biochimica et Biophysica Acta (BBA) - General Subjects,1,252,0304-4165,,,
,,1075-1085,,"In shallow land drainage channels day-time solar heating during the summer produced vertical temperature and density gradients. These facilitated the development of marked gradients of dissolved oxygen, with maximum sub-surface values exceeding 300% air saturation and deoxygenated water near the sediments. Night-time cooling promoted mixing of the water column. Rates of community photosynthesis and respiration, calculated from dissolved oxygen distributions by two methods, were high.",https://doi.org/10.1016/0043-1354(81)90075-0,https://www.sciencedirect.com/science/article/pii/0043135481900750,,,,1981,The ecology of a land drainage channel—I. Oxygen balance,E.J.P. Marshall,article,MARSHALL19811075,Water Research,9,15,0043-1354,,,
,,255-290,,,https://doi.org/10.1016/0304-3479(86)90018-9,https://www.sciencedirect.com/science/article/pii/0304347986900189,,,,1986,Мотив несостоявшегося счастья у Достоевского и Островского: (Об одной возможной перекличке),В.Н. Топоров,article,TOPOROV1986255,Russian Literature,3,19,0304-3479,F.M. Dostoevskij,,
,"Metronidazole, Nitrogenase, Hydrogenase, Photosynthesis, (Anabaena, Scenedesmus)",43-53,,"Metronidazole (2-methyl-5-nitroimidazole-1-ethanol) at 1–2 mM levels has been shown to be a selective inhibitor of nitrogenase activity in Anabaena. Two constitutive hydrogenases and photosynthesis are insensitive to metronidazole at these same concentrations. At higher concentrations metronidazole inhibits photosynthesis in Anabaena while photoreduction and to a lesser extent photohydrogen production are retarded in Scenedesmus. Respiration is slightly stimulated at high metronidazole levels in both algae. The reductant source for nitrogenase in Anabaena and photohydrogen production and photoreduction electron transport in Scenedesmus are discussed. Due to the activity of metronidazole as a selective inhibitor of ferredoxin-associated processes, it should prove to be useful in N2 fixation studies and in distinguishing between ferredoxin-linked reactions of different sensitivities and other activities not associated with low reduction potential components.",https://doi.org/10.1016/0005-2728(79)90168-3,https://www.sciencedirect.com/science/article/pii/0005272879901683,,,,1979,"The differential action of metronidazole on nitrogen fixation, hydrogen metabolism, photosynthesis and respiration in Anabaena and Scenedesmus",Richard M. Tetley and Norman I. Bishop,article,TETLEY197943,Biochimica et Biophysica Acta (BBA) - Bioenergetics,1,546,0005-2728,,,
,,1337-1355,,"The geochemistry of the REE (rare earth elements) in oceanic sediments is discussed, based mainly on samples from DSDP Holes 530A and 530B, Leg 75, and Hole 525A, Leg 74. The proposed mechanisms for incorporation of the REE into the marine carbonate phases are adsorption, chiefly onto the carbonate minerals and on Sc, Hf, and Ta-rich Fe-Mn hydroxide flocs as carbonate coatings. The Ce anomaly of marine carbonate was used as an indicator of paleo-ocean water redox conditions: the bottom water of the Angola Basin was in a reducing condition in the Cretaceous. At ca. 54 My, the South Atlantic water condition became oxidizing, similar to the present seawater redox condition. This change was related to the improvement of circulation due to the widening of South Atlantic and the subsidence of water circulation barriers such as the Walvis Ridge and perhaps the Romanche Fracture Zone. The younger (Eocene-Recent) and older (Albian-Santonian) argillaceous sedimentary rocks from 530A (denoted as YSAB and OSAB respectively) show different degrees of Eu depletion with a transition period in between. The REE patterns of OSAB suggest a basaltic origin. The possible sources are Kaoko basalt in Southwest Africa or Namibia and the basaltic Walvis Ridge itself. The decrease in the area covered by Kaoko basalt due to erosion, the subsidence of the Walvis Ridge, and the improvement of water circulation led to changes in the Eu anomaly from Campanian to Paleocene, and resulted in the YSAB REE pattern. Changes in the Sm/Eu, La/Th, Th/Yb, Ti/Al2O3, FeO/Al2O3, and Hf/Al2O3 ratios suggest changes of average source rock composition from and esite to granodiorite. The REE abundances and patterns of younger sediments in the Angola Basin (YSAB) are very similar to those observed in NASC, PAAS, and ES sediments. The YSAB REE abundances and patterns may represent the average REE distribution of the exposed African continental crust. The strong resemblance of REE distributions of YSAB, NASC, PAAS and ES suggests thorough REE mixing from different sources and the uniformity of the average crustal compositions of different continents: Africa, North America, Australia, and Europe",https://doi.org/10.1016/0016-7037(86)90310-8,https://www.sciencedirect.com/science/article/pii/0016703786903108,,,,1986,Rare earth element geochemistry of South Atlantic deep sea sediments: Ce anomaly change at ~54 My,Y.L. Wang and Y.-G. Liu and R.A. Schmitt,article,WANG19861337,Geochimica et Cosmochimica Acta,7,50,0016-7037,,,
,,899-924,Modeling and Simulation of Computer Networks and Systems,,https://doi.org/10.1016/B978-0-12-800887-4.00041-9,https://www.sciencedirect.com/science/article/pii/B9780128008874000419,Boston,Morgan Kaufmann,978-0-12-800887-4,2015,Index,,incollection,2015899,,,,,,Mohammad S. Obaidat and Petros Nicopolitidis and Faouzi Zarai,
,,A51-A56,,,https://doi.org/10.1016/j.revmed.2016.09.015,https://www.sciencedirect.com/science/article/pii/S0248866316305549,,,,2016,Les microangiopathies thrombotiques de la grossesse,,article,2016A51,La Revue de Médecine Interne,,37,0248-8663,"74eme congrès français de médecine interne, Deauville - 8-10 décembre 2016",,
,,215-227,,"In this paper we begin to study the order structure of topological -algebras of unbounded operators in Hilbert space with the investigation of the normality and the bounded decomposition property of the cones. We prove that for a large class of topological -algebras the normality of the wedge of positive elements is necessary and sufficient for a topological -algebra to be algebraically and topologically isomorphic to a -algebra of unbounded operators equipped with the uniform topology. From this theorem we obtain some corollaries, so for instance, well-known results of Lassner, Brooks and Grothendieck.",https://doi.org/10.1016/0034-4877(75)90028-2,https://www.sciencedirect.com/science/article/pii/0034487775900282,,,,1975,The order structure of topological -algebras of unbounded operators I,Konrad Schmüdgen,article,SCHMUDGEN1975215,Reports on Mathematical Physics,2,7,0034-4877,,,
,,717-720,,"From 1955 to 1988, 56 patients 21 years old or younger underwent surgical treatment for renovascular hypertension at our clinic. The cause of renal artery disease was fibrous dysplasia in 53 patients, Takayasu’s arteritis in 2 or an arterial aneurysm in 1. Bilateral or branch renal artery disease, and extrarenal arterial disease were present in 16, 23 and 11 patients, respectively. The results of 28 patients treated from 1955 to 1977 (group 1) were compared to those of 28 patients treated from 1978 to 1988 (group 2). Hypertension was cured or improved postoperatively in 83% of the patients from group 1 and in 96% from group 2 (p = 0.07). However, this outcome was achieved through surgical revascularization in only 48% of the patients from group 1 compared to 96% from group 2 (p = 0.0002). A multivariate analysis revealed that the only significant variable related to clinical outcome was the era of treatment, which reflects the improved technical efficacy of revascularization during the last decade. Aortorenal bypass and renal autotransplantation have emerged as the preferred revascularization operations. It currently is possible to achieve amelioration of hypertension and preservation of renal function in most young patients with renal artery disease.",https://doi.org/10.1016/S0022-5347(17)39564-2,https://www.sciencedirect.com/science/article/pii/S0022534717395642,,,,1990,Improved Results of Vascular Reconstruction in Pediatric and Young Adult Patients with Renovascular Hypertension,Arturo Martinez and Andrew C. Novick and Robert Cunningham and Marlene Goormastic,article,MARTINEZ1990717,The Journal of Urology,3,144,0022-5347,,,
,,309-331,,"It is difficult to obtain a balanced and accurate picture of medieval views of such topics as childhood, treatment of children, and the nature of family ties, whether of affection or obligation. A significant source of information on these topics, abundant but so far underused, lies in the sermons, pastoral handbooks and biblical commentaries of the period. These are abundant for the thirteenth to fifteenth centuries, allowing the historian to examine the development of ideas over time. One group of late thirteenth century ad status collections, written by friars, is particularly interesting. They were extremely popular throughout the fourteenth century, and therefore represent an important starting point for any study of developing views about the young. Comparison of their views with those of their predecessors, identifies a clear trend towards increased awareness of children as a group with specific characteristics and specific needs. Overall, the writers of these late thirteenth century ad status collections - John of Wales, Guibert de Tournai, Humbert de Romans - show decided reservations about the value of corporal punishment, and a conviction that children are intrinsically good, despite the sins characteristic of their various stages of development. This must call into question some of the conclusions reached by scholars such as Philippe Ariès and Lloyd de Mause.",https://doi.org/10.1016/0304-4181(90)90031-U,https://www.sciencedirect.com/science/article/pii/030441819090031U,,,,1990,Childhood and childrearing in ad status sermons by later thirteenth century friars,Jenny Swanson,article,SWANSON1990309,Journal of Medieval History,4,16,0304-4181,,,
,,157-168,,"Separation of common phospholipids can be affected by dry column chromatography on silica gel. The method involves packing the column with dry gel and developing it in solvent mixtures used for thin-layer chromatography of the same lipids. Solvent is allowed to migrate only to the end of the column; access to the bands of separated material is obtained by using columns with a removable glass front. RF values of lipids on development columns and those on thin-layer plates are nearly identical when the column is packed with thin-layer chromatography gel. Such columns, however, develop very slowly. Columns packed with fine silica gel designed for elution column chromatography develop very rapidly and yield separations that are still quite comparable to those obtainable from thin-layer plates. Such columns are convenient for the purification of phospholipids in amounts of 10 mg to about 10 g. Column design and construction are described in detail.",https://doi.org/10.1016/S0021-9673(00)80929-2,https://www.sciencedirect.com/science/article/pii/S0021967300809292,,,,1977,Dry column chromatography of phospholipids,Robert C. MacDonald and Steven P. Rempas,article,MACDONALD1977157,Journal of Chromatography A,,131,0021-9673,,,
,,217-231,,,https://doi.org/10.1016/0016-0032(57)90509-4,https://www.sciencedirect.com/science/article/pii/0016003257905094,,,,1857,Practical views on the proposed improvement of the Ohio River,W.Milnor Roberts,article,ROBERTS1857217,Journal of the Franklin Institute,4,64,0016-0032,,,
,,481-496,,,https://doi.org/10.1016/0002-1571(72)90053-2,https://www.sciencedirect.com/science/article/pii/0002157172900532,,,,1972,Recently published papers,,article,1972481,Agricultural Meteorology,,10,0002-1571,,,
,,89-103,,"Adult mites from a wild population were exposed to humidity gradients in small tubes at 20, 25, and 30°C. The humidity response was found to be almost entirely due to the steepness of the gradient in evaporation rate and essentially the same in all parts of the range. There is evidence of a negative influence of the higher humidity, but this is definitely of minor importance. The receptor is considered to be an evaporating organ and the possible mechanisms for this type are discussed: osmoreceptors, mechanoreceptors, and thermoreceptors. The similarity between the responses of the mites and of thermoreceptors to rate of change of the stimulus as well as to a constant stimulus makes close comparison possible. It is shown that an evaporating receptor of a size small enough for this mite would be cooled sufficiently to stimulate thermoreceptors and that the rate of water loss would not be too great.",https://doi.org/10.1016/0022-1910(63)90086-6,https://www.sciencedirect.com/science/article/pii/0022191063900866,,,,1963,"Possible humidity receptor mechanisms in the clover mite, Bryobia praetiosa Koch",P.W. Winston,article,WINSTON196389,Journal of Insect Physiology,1,9,0022-1910,,,
,"Human-computer interaction, emotion recognition, facial expression analysis, customized deep neural network, performance evaluation",1310-1318,,"A key development towards enhancing computer-human interaction is emotion recognition. This publication describes a technique called EmoCNN, which uses deep learning techniques to precisely identify and classify human emotions, emphasizing improving model performance using different optimizers. Our research intends to contribute to the creation of more effective systems that improve computer-human interaction by solving the problems associated with emotion recognition. By bridging the gap between humans and robots, accurate emotion detection enables systems to perceive emotions for customized and responsive interactions. AI-powered assistants, chatbots, and social robots all benefit from emotion recognition by providing more responsive, empathic and interesting user experiences. Emotion-aware technologies can also enhance user feedback analysis, human-centered design, and monitoring of mental health. Using a human emotion detection dataset, we carried out comprehensive experiments focusing on the happy, sad, and neutral emotion classes. Constructing a customized EmoCNN model with convolutional layers, a hidden layer, ReLU activation, and max-pooling was the focus of our computational work. We investigated various optimizers and evaluated how they affected accuracy, convergence speed and loss minimization. The results demonstrated that the EmoCNN model, which had been trained using the Adam optimizer, gave the best accuracy in distinguishing between emotions. Our paper provides a comparative analysis, highlighting the superiority of EmoCNN over existing models, showcasing its ability to achieve higher validation accuracy (89%) and more efficient emotion recognition when compared to previous approaches with minimal loss. Our research advances the field of emotional computing by demonstrating how well EmoCNN can identify and categorizes various human emotions. This discovery has significant ramifications for the creation of emotion-aware computers, which can better understand and react to human emotions, enhancing computer-human interaction.",https://doi.org/10.1016/j.procs.2024.04.124,https://www.sciencedirect.com/science/article/pii/S1877050924008007,,,,2024,EmoCNN: Unleashing Human Emotions with Customized CNN Using Different Optimizers,Sahana M and Praneetha Umesh and Ashwini Kodipalli and Trupthi Rao,article,M20241310,Procedia Computer Science,,235,1877-0509,International Conference on Machine Learning and Data Engineering (ICMLDE 2023),,
,,63-78,,,https://doi.org/10.1016/0144-8617(93)90120-S,https://www.sciencedirect.com/science/article/pii/014486179390120S,,,,1993,Bibliography of carbohydrate polymers,,article,199363,Carbohydrate Polymers,1,21,0144-8617,,,
,,243-264,Atomic Physics,,https://doi.org/10.1016/B978-0-444-87057-5.50019-X,https://www.sciencedirect.com/science/article/pii/B978044487057550019X,Amsterdam,Elsevier,978-0-444-87057-5,1987,R-MATRIX METHOD IN ATOMIC PHYSICS,P.G. BURKE,incollection,BURKE1987243,,,,,,Hajime NARUMI and Isao SHIMAMURA,
,,64-86,,"A biophysically based distributed parameter ecohydrological catchment model, TOPOG_IRM, is described which predicts the dynamic interactions between soil-vegetation-atmosphere systems over a catchment. The physiological control on transpiration is formulated using canopy resistance defined as a function of the net assimilation rate, the relative humidity and CO2 concentration at the leaf surface. Rainfall infiltration, runoff and redistribution are simulated with the Richards equation and evapotranspiration is calculated using the Penman-Monteith equation. Two innovative features of the model are (1) coupling of the vegetation-atmosphere system by changing the value of the vapour pressure deficit of air in the canopy, and (2) the plant carbon balance, which allows the simulation of plant growth using a saturation rate kinetics formulation. The model was validated using evapotranspiration, soil moisture and leaf area index measurements from Wagga Wagga, N.S.W., Australia, for a period of 1992–1993. The calculated evapotranspiration was in good agreement with the observations. The soil moisture content at various depths was well simulated for two typical sites. The model also reasonably reproduced leaf area index of wheat and canola for two growing seasons. The success of the model simulations was due to the reasonably realistic treatment of the soil and canopy processes. The sensitivity analysis indicated that (1) the maximum assimilation rate of carbon affects canopy transpiration significantly, and (2) the total drainage is sensitive to the lower boundary conditions and the saturated hydraulic conductivity. TOPOG_IRM is a valuable tool in studying catchment responses under different land management practices. However, the application of the model is limited by the large amount of data required regarding soil and vegetation properties, and their spatial distribution.",https://doi.org/10.1016/S0022-1694(96)03072-7,https://www.sciencedirect.com/science/article/pii/S0022169496030727,,,,1997,Evaluation of a distributed parameter ecohydrological model (TOPOG_IRM) on a small cropping rotation catchment,Warrick R. Dawes and Lu Zhang and Tom J. Hatton and Peter H. Reece and G.T.H. Beale and I. Packer,article,DAWES199764,Journal of Hydrology,1,191,0022-1694,,,
,,1-54-1-72,Mechanical Engineer's Reference Book (Eleventh Edition),,https://doi.org/10.1016/B978-0-408-00083-3.50006-0,https://www.sciencedirect.com/science/article/pii/B9780408000833500060,,Butterworth-Heinemann,978-0-408-00083-3,1973,SYMBOLS AND ABBREVIATIONS,G.R. DARBY,incollection,DARBY19731-54,,,,,,A. PARRISH,Eleventh Edition
,,62-68,,,https://doi.org/10.1016/0014-5793(73)80738-0,https://www.sciencedirect.com/science/article/pii/0014579373807380,,,,1973,Immunological studies on globular and elongated forms of electric eel acetylcholinesterase effects of hydrolytic enzymes,François Rieger and Philippe Benda and Annie Bauman and Jean Rossier,article,RIEGER197362,FEBS Letters,1,32,0014-5793,,,
,"3D house printing technology, Advanced building materials, Energy-exchanging materials, Nanomaterials, Nanotechnology, Property-changing materials, Smart materials",55-104,Smart Buildings,"Thanks to the huge progress in the field of materials science, technology solutions available today for buildings, such as advanced materials, nanomaterials, and smart materials, allow designers to reconcile the architectural features of buildings with the new challenges of energy and environmental efficiency. After a review of future trends in advanced materials for architecture, an in-depth analysis on nanotechnology and its application in the energy, environmental, and construction sectors is provided, focusing on innovative nanoproducts for architecture. A presentation of the new class of highly innovative materials, so-called smart materials, is given, addressing both property-changing materials and energy-exchanging materials, illustrating their properties and their application in the building sector. Finally, the chapter gives an overview on the enormous potential of three-dimensional printing technology for architecture, with a particular focus on the realization of building components, structural elements, and entire buildings.",https://doi.org/10.1016/B978-0-08-100635-1.00002-2,https://www.sciencedirect.com/science/article/pii/B9780081006351000022,,Woodhead Publishing,978-0-08-100972-7,2016,2 - Advanced materials for architecture,Marco Casini,incollection,CASINI201655,,,,,,Marco Casini,
,,350-363,,"A hot and humid environment can increase cardiac work as much as strenuous physical exericse. The environment should, therefore, be made comofortable not only for the patient with heart disease but also for aged people and for patients with debilitating states or any illness in which thermal regulation should be facilitated. There is definite need to consider the hot and humid environment produced by climate, industrial working conditions, or overrcrowding of the sickroom in the treatment of all patients in whom it is discred to reduce cardiac work. Greater use of air conditioning in hospitals, cardiac wards, offices, and homes will assist toward this end. Many important problems concering the influences of the hot and humid environment upon man remain unsolved and should be studied.",https://doi.org/10.1016/0021-9681(56)90039-X,https://www.sciencedirect.com/science/article/pii/002196815690039X,,,,1956,Influence of a hot and humid environment on the patient with coronary heart disease,G.E. Burch,article,BURCH1956350,Journal of Chronic Diseases,4,4,0021-9681,,,
,"Sequential assembly of phycobilisomes, linker polypeptides, allophycocyanin core, phycocyanin, phycoerythrocyanin, ",51-66,,"Five phycocyanin- and two phycoerythrocyanin-associated linker polypeptides were resolved by two-dimensional gel electrophoresis from isolated phycobilisomes of the thermophilic cyanobacterium Mastigocladus laminosus. These linker polypeptides were located in the substructure of the phycobilisome by analysis of isolated high molecular weight allophycocyanin—phycocyanin (AP—PC) complexes and by examination of different phycobilisome “types” induced by alteration of the culture conditions. The core fractions reveal two different rod—core linker polypeptides LRC29.5PC and LRC32PC and one rod linker LR31PC associating the first and the following “trimeric” PC complexes at the profile sides of the core. The “minimal” phycobilisome type with an apparent molecular weight Mr of 4 500 000 is characterized by the occurrence of only one additional rod linker polypeptide LR34.5PC. Further sequential elongation of the rods occurs by PC and phycoerythrocyanin (PEC) “trimers” in cooperation with two low molecular weight linker polypeptides LR11PC and LR11PEC. The structure of the “maximal” phycobilisome with Mr 8 500 000 is completed by the association of PEC “hexamers” via LR34.5PEC. This sequential assembly could be demonstrated by the polypeptide composition of different “intermediate” and “maximal” phycobilisomes. The large number of linker polypeptides and the stoichiometric calculations of core fractions and of different phycobilisome “types” indicate a partial “trimeric” organization of the rod complexes. With respect to polypeptide stoichiometry, the “trimeric” arrangement of PC·LRC29.5/32, PC·LR31, PC·LR11 and PEC·LR11 in the structure of the rods is proposed. The structural and functional consequences of the study are represented in a model of the “maximal” phycobilisome.",https://doi.org/10.1016/1011-1344(93)80040-G,https://www.sciencedirect.com/science/article/pii/101113449380040G,,,,1993,Molecular assembly of the phycobilisomes from the cyanobacterium Mastigocladus laminosus,Wolfgang Reuter and Claudia Nickel-Reuter,article,REUTER199351,Journal of Photochemistry and Photobiology B: Biology,1,18,1011-1344,,,
,,191-209,,Dimethylsulfide (DMS) is the dominating sulfur gas in surface marine waters. The flux of DMS to the atmosphere plays an important role in the natural sulfur cycle and in the formation of acidic components and condensation nucleii in the remote oceanic atmosphere and is likely to be of climatic significance. This article reviews the biologic production and consumption processes of DMS and its precursor dimethylsulfoniopropionate (DMSP) in ocean surface waters. The description of relevant processes in this paper is complemented by rate estimates where such data are available. The literature on a region in the Northeast Atlantic Ocean is reviewed to provide information on DMS and DMSP pools in situ and their regional and seasonal variations.,https://doi.org/10.1016/0924-7963(94)00023-5,https://www.sciencedirect.com/science/article/pii/0924796394000235,,,,1995,Biogenic production and consumption of dimethylsulfide (DMS) and dimethylsulfoniopropionate (DMSP) in the marine epipelagic zone: a review,T. Groene,article,GROENE1995191,Journal of Marine Systems,3,6,0924-7963,,,
,,95-106,,"This paper is devoted to the development of a general methodology for application to the simulation of multicomponent batch distillation with or without chemical reactions. After a survey of the field of batch distillation and dynamic simulation applied to batch distillation, evolutions and trends are reviewed through the presentation of the proposed methodology. This methodology is based on the formulation and development of a rigorous model in comparison with those commonly used in batch distillation. The resulting set of differential-algebraic equations (DAE) is solved using an efficient numerical strategy based on Gear's method, which is especially adapted to deal with DAE systems and numerical features arising in the batch context. Numerical difficulties due to detection of time and state events, the occurrence of discontinuities and start-up policy schemes (involving chemical reactions or not) are emphasized. Original and interesting solutions are proposed to tackle each of these problems. Finally, the flexibility, reliability and efficiency of the proposed methodology are illustrated through academic and industrial case studies, the results of which are compared with plant data.",https://doi.org/10.1016/0923-0467(93)02815-E,https://www.sciencedirect.com/science/article/pii/092304679302815E,,,,1994,Evolutions et tendances en simulation de colonnes de rectification discontinue,Joël Albet and Jean-Marc {Le Lann} and Xavier Joulia and Bernard Koehret,article,ALBET199495,The Chemical Engineering Journal and the Biochemical Engineering Journal,2,54,0923-0467,,,
,"Tin oxide, Gas sensor",1-12,,"A survey is given on the current status and future prospects in research and development of SnO2-based sensors. Atomistic models of molecular recognition are discussed first. They include physisorption, chemisorption, surface reaction, catalytic reaction, grain boundary reaction, bulk reaction and three-phase boundary reaction steps. The influence of contact geometry and crystallinity on the sensor response signal is outlined. A brief summary is given of the current status of sensor research and development with emphasis on ceramic, thick-film and thin-film sensors based on crystalline, polycrystalline and nanocrystalline SnO2. Three different aspects are mentioned in the outline which are expected to lead to significantly improved performances of future sensors: the improved selectivity through the modulation frequency in a.c. measurements, the improved stability through the better control of structures, and the improved selectivity and drift compensation through pattern recognition.",https://doi.org/10.1016/0925-4005(94)01546-T,https://www.sciencedirect.com/science/article/pii/092540059401546T,,,,1995,SnO2 sensors: current status and future prospects,Wolfgang Göpel and Klaus Dieter Schierbaum,article,GOPEL19951,Sensors and Actuators B: Chemical,1,26,0925-4005,,,
,,2099-2110,,"Thirty-five box cores were collected from the continental shelf in the Ross Sea during cruises in January and February, 1983. Pb-210 and Pu-239, 240 geochronologies coupled with biogenic-silica measurements were used to calculate accumulation rates of biogenic silica. Sediment in the southern Ross Sea accumulates at rates ranging from ≤0.6 to 2.7 mm/y, with the highest values occurring in the southwestern Ross Sea. Biogenic-silica content in surface sediments ranges from 2% (by weight) in Sulzberger Bay and the eastern Ross Sea to 41% in the southwestern Ross Sea. Biogenic-silica accumulation in the southwestern Ross Sea averages 2.7 × 10−2 g/cm2/y and is comparable to accumulation rates in high-productivity, upwelling environments from low-latitude continental margins (e.g., Gulf of California, coast of Peru). The total rate of biogenic-silica accumulation in the southern Ross Sea is approximately 0.2 × 1014 g/y, with most of the accumulation occurring in basins (500–1000 m water depth). If biogenic-silica accumulation in the southern Ross Sea continental shelf is typical of other basins on the Antarctic continental shelf, as much as 1.2 × 1014 g/y of silica could be accumulating in these deposits. Biogenic-silica accumulation on the Antarctic continental shelf may account for as much as a fourth of the dissolved silica supplied to the world ocean by rivers and hydrothermal vents.",https://doi.org/10.1016/0016-7037(86)90263-2,https://www.sciencedirect.com/science/article/pii/0016703786902632,,,,1986,Biogenic-silica accumulation in the Ross Sea and the importance of Antarctic continental-shelf deposits in the marine silica budget,P.A Ledford-Hoffman and D.J Demaster and C.A Nittrouer,article,LEDFORDHOFFMAN19862099,Geochimica et Cosmochimica Acta,9,50,0016-7037,,,
,,369-382,,"The effect of noradrenalin on the aqueous dynamics of anaesthetized monkey eyes was studied using the method of perfusion at constant pressure. Values obtained suggest similar changes to those found in rabbits. Noradrenalin injected in normal monkey eyes caused a decrease in intraocular pressure, while the gross facility increased. In denervated eyes the intraocular pressure stayed at the same level as in normal eyes when the same amount of drug was injected, while the gross facility was significantly different. These results suggest that there is an increase in secretion together with an increase in gross facility. Test series in which gross facilities were measured at different pressure differentials, suggested that low facilities resulted from high pressure differentials and vice versa. In those experiments where the reservoir pressure was kept constant at 16 mmHg above P0 for some 20 min, the gross facility increased by some 50%. The results suggest that the law ΔF = C. ΔP, which gives a constant value of C in a fixed system of tubes, cannot be applied to the living monkey eye.",https://doi.org/10.1016/S0014-4835(68)80051-X,https://www.sciencedirect.com/science/article/pii/S001448356880051X,,,,1968,Effect of noradrenalin on intraocular pressure and outflow in cynomolgus monkeys,Friedrich Hoffmann,article,HOFFMANN1968369,Experimental Eye Research,3,7,0014-4835,,,
,"Cloud computing, Computational intelligence, Intrusion detection system, Mobile cloud computing, Security",102582,,"With the increasing utilization of the Internet and its provided services, an increase in cyber-attacks to exploit the information occurs. A technology to store and maintain user's information that is mostly used for its simplicity and low-cost services is cloud computing (CC). Also, a new model of computing that is noteworthy today is mobile cloud computing (MCC) that is used to reduce the limitations of mobile devices by allowing them to offload certain computations to the remote cloud. The cloud environment may consist of critical or essential information of an organization; therefore, to prevent this environment from possible attacks a security solution is needed. An intrusion detection system (IDS) is a solution to these security issues. An IDS is a hardware or software device that can examine all inside and outside network activities and recognize doubtful patterns that may demonstrate a network attack and automatically alert the network (or system) administrator. Because of the ability of an IDS to detect known/unknown (inside/outside) attacks, it is an excellent choice for securing cloud computing. Various methods are used in an intrusion detection system to recognize attacks more accurately. Unlike survey papers presented so far, this paper aims to present a comprehensive survey of intrusion detection systems that use computational intelligence (CI) methods in a (mobile) cloud environment. We firstly provide an overview of CC and MCC paradigms and service models, also reviewing security threats in these contexts. Previous literature is critically surveyed, highlighting the advantages and limitations of previous work. Then we define a taxonomy for IDS and classify CI-based techniques into single and hybrid methods. Finally, we highlight open issues and future directions for research on this topic.",https://doi.org/10.1016/j.jisa.2020.102582,https://www.sciencedirect.com/science/article/pii/S2214212620307523,,,,2020,"Computational intelligence intrusion detection techniques in mobile cloud computing environments: Review, taxonomy, and open research issues",Shahab Shamshirband and Mahdis Fathi and Anthony T. Chronopoulos and Antonio Montieri and Fabio Palumbo and Antonio Pescapè,article,SHAMSHIRBAND2020102582,Journal of Information Security and Applications,,55,2214-2126,,,
,"Heparin, fractionation, highly active heparin fraction",443-458,,"We have studied heparin fractionation using gel filtration and ion-exchange chromatographic methods. The starting material was commercial grade porcine mucosal sodium heparin (PSH). The fractionation was monitored employing synthetic substrates for assaying both antithrombin (with H-D-Phe-Pip-Arg-pNA ; S-2238) and anti-FXa (with Bz-Ileu-Glu-Gly-Arg-pNA ; S-2222) activities. The resulting fractions were evaluated in different amidolytic and coagulation methods used to determine heparin potency by comparison with PSH. By gel filtration of PSH on Ultrogel AcA 54, both strong anti-FXa and antithrombin activities were associated with the fractions eluted in the high molecular weight range (MW ⋍ 20 × 103). These fractions also had potent anticoagulant action when assayed by conventional clotting methods. PSH was also subjected to fractionation by an ion-exchange technique (DEAE-Sephacel) with increasing salt molarity. The patterns for antithrombin and anti-FXa activities were again closely related, if not identical. Four fractions were usually distinguished, with respectively negligible, intermediate, high and very high activities when compared to PSH. The very highly active fraction (HAF), approximately 15% by weight, was eluted at high salt molarity (> 0.8 M NaCl). On a weight basis its anticoagulant activity was ⋍ 2–3 times that of PSH as determined by amidolytic as well as clotting methods. Intravenous injection of HAF to rabbits and dogs (1.0 and 2.5 mg/kg) produced a much stronger anticoagulant response than PSH, also showing an effect which persisted for a longer duration.",https://doi.org/10.1016/0049-3848(82)90086-X,https://www.sciencedirect.com/science/article/pii/004938488290086X,,,,1982,Studies on a highly active anticoagulant fraction of high molecular weight isolated from porcine sodium heparin,E. Sache and M. Maillard and H. Bertrand and M. Maman and M. Kunz and J. Choay and J. Fareed and H. Messmore,article,SACHE1982443,Thrombosis Research,6,25,0049-3848,,,
,,303-313,,"SDRC SUPERB is a general purpose finite element program that performs linear static, dynamic and steady state heat conduction analyses of structures made of isotropic and/or orthotropic elastic materials having temperature dependent properties. The finite element library of SUPERB contains isoparametric plane stress, plane strain, flat plate, curved shell, solid type curved shell and solid elements in addition to conventional beam and spring elements. Linear, quadratic and cubic interpolation functions are available for all isoparametric elements. Independent parameters such as displacements and temperatures are obtained from SUPERB using the stiffness method of analysis. The remaining dependent parameters, such as stresses and strains, are evaluated at element gauss points and extrapolated to nodal locations. Averaged values are given as final output. The graphic capabilities of SUPERB consists of geometry and distorted geometry plotting, and stress, strain and temperature contouring. Contours are plotted at user defined cutting planes for solids and at top, middle or bottom surfaces for plate and shell types of structures. In the first part of this paper, the program capabilities of SUPERB are summarized. Extrapolation techniques used for determining dependent nodal parameters and for contour plotting are explained in the second part of the paper. Behavior of standard, wedge and transition type isoparametric elements and the effect of interpolation function orders on accuracy are discussed in the third part. The results of several illustrative problems are included.",https://doi.org/10.1016/0045-7949(77)90050-5,https://www.sciencedirect.com/science/article/pii/0045794977900505,,,,1977,A general isoparametric finite element program SDRC SUPERB,V.T. Nicolas and E. Citipitioglu,article,NICOLAS1977303,Computers & Structures,2,7,0045-7949,,,
,,111-132,,"Since the 1970's, many field and wind tunnel experiments have been conducted to study pollutant dispersion from roadways. For an at-grade situation, field experiments have revealed that mechanical mixing dominates effects due to ambient stability, that plume rise is important under very low crossroad winds, that regions of large shear enhance the mixing volume, and that the wake region grows rather slowly in the vertical direction. The models that have been developed based on recent experimental results are briefly described. For the street canyon situation, both field and wind tunnel experiments have revealed that ambient stability does not play an important role, that corner vortices near an intersection cause an increase in pollutant concentrations near the bottom corners of the leeside buildings, that in the midsection of a street block the vortex circulation causes high pollutant concentrations to be advected toward and up the leeside wall. No general street canyon models are available except an empirical model for the midsection of the street block. The complicated flow field must first be ascertained before a reliable concentration model can be developed.",https://doi.org/10.1016/0048-9697(82)90081-X,https://www.sciencedirect.com/science/article/pii/004896978290081X,,,,1982,Pollutant dispersion near roadways — Experiments and modeling,David P. Chock,article,CHOCK1982111,Science of The Total Environment,2,25,0048-9697,,,
,,516-529,,"The halogenated benzimidazole derivative 5,6-dichloro-1-β-d-ribofuranosylbenzimidazole (DRB) inhibits reversibly the replication of human adenovirus type 2 (Ad2) and its DNA in human KB cells. Viral DNA replication is almost completely blocked when the drug is added earlier than 4 hr postinfection in concentrations between 50 and 150 μM. Replication of viral DNA in all four size-classes (>100 S, 50–90 S, 34 S, and <20 S) is inhibited. The replication block is reversible upon withdrawal of the inhibitor. When DRB is administered at the time of maximal viral DNA replication, 16–18 hr postinfection, the inhibitor has no apparent effect on viral DNA synthesis. In the presence of 150 μM DRB, synthesis of early virus-specific RNA in the nucleus is reduced by approximately 90% and the appearance of virus-specific RNA sequences in the cytoplasm is reduced by >95%, as demonstrated by DNA-RNA filter hybridization. Thus, the block in viral DNA replication is best explained by the inhibition of the synthesis of early virus-specific RNA.",https://doi.org/10.1016/0042-6822(78)90090-9,https://www.sciencedirect.com/science/article/pii/0042682278900909,,,,1978,"Inhibition of adenovirus replication by 5,6-Dichloro-1-,β-d-ribofuranosylbenzimidazole",Marietta Brötz and Walter Doerfler and Igor Tamm,article,BROTZ1978516,Virology,2,86,0042-6822,,,
Advances in Food and Nutrition Research,,319-370,,"Publisher Summary
The ability of microorganisms to adhere to surfaces has significant implications for food science. Microorganisms attached to plant and animal tissues can affect food safety and spoilage. Microorganisms can adhere firmly and are therefore difficult to remove or inactivate without damaging the underlying tissue. This is not of concern for most processed foods, but it is for foods that are to be sold as raw or minimally processed. Disease outbreaks associated with Salmonella on chicken and fresh produce and Escherichia coli 0157:H7 in apple juice, alfalfa seed sprouts, and lettuce may be related to the inability of sanitizer and washing treatments to remove or inactivate attachedpathogens. Microbial attachment to food contact surfaces is also of significance for food safety and spoilage. Microorganisms attached to processing equipment may escape cleaning and sanitizing procedures and proceed to contaminate processed product. Pathogens originating with raw products can attach to food preparation surfaces, which, if not adequately cleaned before reuse, can serve to recontaminate cooked foods. The ability to attach to and subsequently detach from surfaces is a characteristic of all microorganisms. Attachment is advantageous and perhaps necessary for survival in the natural environment, as it allows microorganisms to exert some control over their nutritional environment, and offers protection from environmental stresses. Attachment is also the initial event in microbial infections, for if a cell fails to adhere it will be carried away from its potential host. Therefore, microbial attachment is a process that has been extensively studied.",https://doi.org/10.1016/S1043-4526(01)43008-7,https://www.sciencedirect.com/science/article/pii/S1043452601430087,,Academic Press,,2001,Microbial attachment to food and food contact surfaces,Joseph F Frank,incollection,FRANK2001319,,,43,1043-4526,,,
,,155-167,,"Twenty-eight independently isolated, spontaneous revertants isolated from temperature-sensitive (ts) mutants of reovirus type 3 representing all the known mutant groups, were examined to determine whether they were intragenic revertants or contained extragenic suppressor mutations. Analysis of the progeny of backcrosses of the revertants to wild type, showed that 25 of the 28 revertants contained is lesions. This result indicated that 25 of the 28 revertants were suppressed pseudorevertants with the suppressor mutation in a gene that could be separated from the parental is lesion by recombination. The nature of the is lesion(s) was examined for a number of the is clones derived from back-crosses. In every case, except one, the parental is lesion was found. In five of the ten suppressed pseudorevertants examined, nonparental is lesions could also be rescued. Two of the nonparental is lesions were in the previously defined recombinant groups. Five of the nonparental is lesions represented a new recombination group or groups since they recombined with the prototype mutants of all of the defined recombination groups. Recombination analysis indicated that the five new mutants fall into two recombination groups for which we propose the designations H and I. The nonparental is lesions rescued from suppressed pseudorevertants may represent suppressor mutations with is phenotype. However, the majority of the suppressor mutations identified had no temperature phenotype and were identified only by their effect on the phenotype of the original is lesion. The fact that a large proportion of revertants were suppressed by extragenic suppressor mutations suggests that mutation events leading to extragenic suppression occur at a much higher frequency than do intragenic events leading to revertant phenotype. These results indicate a general mechanism by which RNA viruses can bypass the effects of deleterious mutations in the absence of intramolecular recombination.",https://doi.org/10.1016/0042-6822(79)90221-6,https://www.sciencedirect.com/science/article/pii/0042682279902216,,,,1979,Revertants of temperature-sensitive mutants of reovirus: Evidence for frequent extragenic suppression,Robert F. Ramig and Bernard N. Fields,article,RAMIG1979155,Virology,1,92,0042-6822,,,
,,317-330,,,https://doi.org/10.1016/S0021-9258(18)50240-4,https://www.sciencedirect.com/science/article/pii/S0021925818502404,,,,1933,DERIVATIVES OF MONOACETONE XYLOSE,P.A. Levene and Albert L. Raymond,article,LEVENE1933317,Journal of Biological Chemistry,1,102,0021-9258,,,
,,379-388,,"A fracture mechanics based analysis has been used to predict the tensile delamination load of tapered laminated plates. Simple laminate examples are used to show the effect of dropped ply thickness, number of delaminating surfaces, and dropped ply axial stiffness on the delamination load. Using these trends and acknowledged guidelines, a design is presented for a complex tapered plate with a view to maximising the onset of delamination.",https://doi.org/10.1016/0263-8223(94)90264-X,https://www.sciencedirect.com/science/article/pii/026382239490264X,,,,1994,A design study into the delamination behaviour of tapered composites,D.M. Thomas and J.P.H. Webber,article,THOMAS1994379,Composite Structures,4,27,0263-8223,,,
,,155-174,,"Results of fossil pollen studies in Eastern, Central and Southern Africa covering the last 32,000 years are surveyed in this paper. This research, conducted between 1951 and 1985, was mostly concentrated in East and Southern Africa, but a number of pollen sequences from intervening sites provide some links between the data of these two regions. In all this immense region, of half the African continent, information from fossil pollen is available only from some 30 sites. In addition to problems with absolute dating, the interpretation of the results in terms of former vegetation poses difficult questions. While it is far too early to draw detailed maps of former vegetation some very general conclusions can be inferred from the data presented. At two sites in East Africa pollen evidence has been found for the existence of a warmer and more humid period from ca. 32,000 to 28,000 yr B.P., an episode known as the Kalambo Interstadial. During the period from ca. 28,000 to 20,000 yr B.P. the climate in East and Central Africa was fairly similar to that during the Holocene moist period. In Southern Africa during the same period palynologic and geologic results indicate that cold episodes occurred while higher rainfall in East Africa, the Kalahari and adjacent regions caused high lake levels. During the last glacial maximum from ca. 20,000 to 16,000–14,000 yr B.P. aridity spread over nearly the whole region. The Zaire rain forest was considerably reduced and the tree line on the East African mountains was depressed by 900–1100 m, indicating a drop in mean temperature of 5–8°C. Lakes in East Africa and the Kalahari dried out, except for the southern Kalahari, its surroundings, and the SW Cape, where humidity was high. The general causes for aridity were the low evaporation at the ocean surface and the strong upwelling of colder waters. More humid conditions which have been postulated for the central part of southern AFrica could have been the result of lower evaporation in lake basins while the penetration of winter rainfall in the area has also been proposed. An abrupt change to warmer and more humid conditions in East Africa at ca. 12,000 yr B.P. reversed all the former processes. Rainfall also penetrated the Kalahari from the NW, NE and SW sides. Remarkable fluctuations in climate at this juncture could be demonstrated by pollen evidence in South Africa only at Aliwal North. During the Holocene, humid conditions persisted in East Africa until ca. 4000 yr B.P., when the climate became drier. Insufficient dated evidence in southern Africa makes it difficult to compare the various climate chronologies. In general the climate may have been wetter until about 4000 B.P. when a dry interval occurred. In East Africa pollen data point to deforestation by man during the last two millennia.",https://doi.org/10.1016/0034-6667(88)90083-8,https://www.sciencedirect.com/science/article/pii/0034666788900838,,,,1988,"A review of late quaternary pollen studies in East, Central and Southern Africa",E.M. {Van Zinderen Bakker} and J.A. Coetzee,article,VANZINDERENBAKKER1988155,Review of Palaeobotany and Palynology,1,55,0034-6667,Quaternary Palynology of Tropical Areas,,
,,67-76,,,https://doi.org/10.1016/0144-8617(93)90167-3,https://www.sciencedirect.com/science/article/pii/0144861793901673,,,,1993,Bibliography of carbohydrate polymers,,article,199367,Carbohydrate Polymers,1,22,0144-8617,,,
,"Natural language processing, Knowledge acquisition, Lexical semantics",1737-1756,,"The category system in Wikipedia can be taken as a conceptual network. We label the semantic relations between categories using methods based on connectivity in the network and lexico-syntactic matching. The result is a large scale taxonomy. For evaluation we propose a method which (1) manually determines the quality of our taxonomy, and (2) automatically compares its coverage with ResearchCyc, one of the largest manually created ontologies, and the lexical database WordNet. Additionally, we perform an extrinsic evaluation by computing semantic similarity between words in benchmarking datasets. The results show that the taxonomy compares favorably in quality and coverage with broad-coverage manually created resources.",https://doi.org/10.1016/j.artint.2011.01.003,https://www.sciencedirect.com/science/article/pii/S000437021100004X,,,,2011,Taxonomy induction based on a collaboratively built knowledge repository,Simone Paolo Ponzetto and Michael Strube,article,PONZETTO20111737,Artificial Intelligence,9,175,0004-3702,,,
,,211-225,,Three independent sources of information are used to analyze the angle dependent potential for NOAr: (a) the glory structure of the total collision cross section; (b) the relative difference in the total collision cross section for two different orientations of NO in the 2Π32 state; (c) the absolute value of the total collision cross section. The sudden approximation employed for the calculation of the various properties is discussed. For NOAr a fit to the total collision cross section data is obtained on the basis of an extended Maitland—Smith potential containing a Pt anisotropy in the repulsion and a P2 anisotropy in the repulsion and attraction. A comparison is made with the theoretical potential for NOAr recently by Nielson et al. and the extended Lennard-Jones potential employed in the earlier analysis. For NOKr and NOXe similar Maitland—Smith potentials are obtained by assuming the Pt anisotropy parameter for these systems to be equal to that for NOAr. In a separate appendix is analyzed which intermolecular distances are probed through measurements of the anisotropy in the total collision cross section.,https://doi.org/10.1016/0301-0104(80)85199-8,https://www.sciencedirect.com/science/article/pii/0301010480851998,,,,1980,"Angle dependent interaction potentials for NOAr, NOKr and NOXe derived from various total collision cross section data",H.H.W. Thuis and S. Stolte and J. Reuss and J.J.H. {Van Den Biesen} and C.J.N. {Van Den Meijdenberg},article,THUIS1980211,Chemical Physics,1,52,0301-0104,,,
,"Information systems spending, Budgets, Software spending, Hardware spending, Information systems costs, Demand for computing",1-16,,"The growth in information systems budgets and in their primary components, hardware and software effort, are analyzed empirically. It is demonstrated that while a large component of the growth is due to technology related factors, these expenditures, and in particular, hardware spending, are sensitive to the growth rate of the economy and fluctuate around the technology-driven growth path due to general business conditions. The validity of the popular belief that software effort (including both software-development and maintenance) represents a growing proportion of information systems expenditures is tested versus the competing view that software effort and hardware expenditures consume relatively constant budget shares. It is shown that after controlling for macroeconomic effects, hardware and software expenditures grow exponentially at the same rate. The analysis also suggests that in the aggregate, it is primarily the hardware outlays that adjust in response to unexpected business conditions.",https://doi.org/10.1016/0167-9236(92)90033-L,https://www.sciencedirect.com/science/article/pii/016792369290033L,,,,1992,An empirical analysis of software and hardware spending,Vijay Gurbaxani and Haim Mendelson,article,GURBAXANI19921,Decision Support Systems,1,8,0167-9236,,,
,,49-81,,"This is a theoretical paper which attempts to study for the first time the effect of high elasticity in flow situations involving elastico-viscous liquids and abrupt changes in geometry. It is argued that implicit rheological models are essential in this exercise and, accordingly, the numerical method of solution is forced to recognise the equations of continuity, the stress equations of motion and the rheological equations as separate equations involving velocity, pressure and stress variables with appropriate boundary conditions on these variables. The present paper is concerned with L-shaped and T-shaped geometries, and the effect of elasticity is assessed by comparing the numerical predictions for an elastic liquid with those for an inelastic liquid with the same “viscosity” behaviour. This comparison is facilitated by a simple limiting procedure outlined in Section 2. The main conclusions from the work are that, in general terms, elasticity works against inertia, reducing the pressure drop caused by the abrupt change in geometry and reducing the area of influence of the bend (for finite Reynolds numbers). So far as the stress fields are concerned most interest centres on the corner region, as one would expect, but there is also a region of normal-stress activity, which is generated by “stretching” rather than “shearing”. In an appendix, some consideration is given to the entry-length and exit-length problems. It is concluded that the overall problem is a complex one, since it depends to a large measure on the criterion one uses for “fully-developed” flow. If a fairly crude criterion is used, fluid elasticity is found to decrease the entry-length and increase the exit-length.",https://doi.org/10.1016/0377-0257(77)80032-3,https://www.sciencedirect.com/science/article/pii/0377025777800323,,,,1977,Long-range memory effects in flows involving abrupt changes in geometry: Part I: flows associated with I-shaped and T-shaped geometries,M.G.N. Perera and K. Walters,article,PERERA197749,Journal of Non-Newtonian Fluid Mechanics,1,2,0377-0257,,,
,,99-113,,"One hectare of undisturbed Amazonian forest, containing about 175 species of trees larger than 10 cm diameter at breast height, was studied to determine the relationship between high-richness forest and the autochthonous litter produced by the forest. Litter samples contained up to 52 species, of which one-third represented epiphytes, vines, and lianas. These modern leaf litter studies from southeast Amazonian Peru indicate that reconstructions of ancient high-diversity forests are possible using autochthonous leaf litter deposits. In comparison to temperate litter samples, however, more sampling must be done to recreate fairly simple descriptors of ancient communities such as species richness and heterogeneity. Samples must be large, relatively closely spaced, and maintained as distinct collecting localities to retrieve the maximum amount of data from rich, angiosperm-dominated localities. There are many advantages justifying more intensive collections. For example, biomass contribution of major life-form categories in the source forest is reflected in leaf litter accumulating under tropical forest canopies. Tropical forests, because of their extreme heterogeneity, also can provide the opportunity to reconstruct individual species characteristics from litter signatures. The relative rarity of most species creates distinct leaf shadows from which the canopy breadth and volume of many individuals can be estimated. The principles derived from modern tropical litter studies can be applied to existing fossil collections; however, their power lies with those collections originating from autochthonous assemblages, for which spatial control during collecting has been maintained, and time averaging has been kept to a minimum. These reflections of community structure available from the leaf litter provide a means for paleobiologists to contribute significantly to the study of community evolution and stability.",https://doi.org/10.1016/0034-6667(94)90129-5,https://www.sciencedirect.com/science/article/pii/0034666794901295,,,,1994,Patterns in tropical leaf litter and implications for angiosperm paleobotany,Robyn J. Burnham,article,BURNHAM199499,Review of Palaeobotany and Palynology,1,81,0034-6667,Fossil Plants as Palaeoenvironmental Indicators,,
,,64-87,,,https://doi.org/10.1016/S0212-6567(14)70071-X,https://www.sciencedirect.com/science/article/pii/S021265671470071X,,,,2014,Parallel sessions: posters,,article,201464,Atención Primaria,,46,0212-6567,2nd World congress of health research,,
,,879-883,,"The microvascular architecture of the human corpus cavernosum penis was studied by scanning electron microscopy of vascular corrosion casts. The corpus cavernosum was supplied by the penile deep artery. It gave off branches to become either arteries distributed within the corpus cavernosum or those directly supplying the corpus spongiosum urethrae. The former arteries further divided into small arteries which fell into two categories: 1) arteries breaking up into capillaries, and 2) arteries draining directly into the cavernous sinuses. The capillaries were collected into venular networks just beneath the tunica albuginea (the subalbugineal venular plexus), while the cavernous sinuses were collected into venules at the periphery of the corpus cavernosum. These postcavernous venules also received venules from the subalbugineal venular plexus, and left the corpus cavernosum. Thus, two circulatory routes are evident within the corpus cavernosum. These findings suggested that the penile erectile cycle is controlled by hemodynamic changes between these two routes within the corpus cavernosum. (J. Urol, 142: 879–883, 1989)",https://doi.org/10.1016/S0022-5347(17)38935-8,https://www.sciencedirect.com/science/article/pii/S0022534717389358,,,,1989,Two Circulatory Routes Within the Human Corpus Cavernosum Penis: A Scanning Electron Microscopic Study of Corrosion Casts,Yoshiaki Banya and Tatsuo Ushiki and Hiroshi Takagane and Hikaru Aoki and Takashi Kubo and Tsutomu Ohhori and Chizuka Ide,article,BANYA1989879,The Journal of Urology,3,142,0022-5347,,,
,,317-357,Penetration Tester's Open Source Toolkit,"Publisher Summary
The chapter discusses the most common vulnerabilities and configuration errors on routers and switches. Routers and switches perform the most fundamental actions on a network. They route and direct packets on a network and enable communications at the lowest layers. No penetration test is complete without including network devices. Before conducting a penetration test on a network device, one must first identify the device. The chapter discusses penetration testing a network device from two aspects: internal and external. The chapter presents a number of tools and techniques to be used in security level of a network device. The chapter primarily focuses on the tools included on the Auditor bootable CD, but where appropriate, other tools are also described, including Windows applications that are both commercial and open source. Different types of scanning tools and techniques are discussed that deal with network devices.",https://doi.org/10.1016/B978-159749021-4/50009-5,https://www.sciencedirect.com/science/article/pii/B9781597490214500095,Burlington,Syngress,978-1-59749-021-4,2005,Chapter 6 - Network Devices,Johnny Long and Aaron W. Bayles and James C. Foster and Chris Hurley and Mike Petruzzi and Noam Rathaus and  SensePost and Mark Wolfgang,incollection,LONG2005317,,,,,,Johnny Long and Aaron W. Bayles and James C. Foster and Chris Hurley and Mike Petruzzi and Noam Rathaus and  SensePost and Mark Wolfgang,
,,449-467,,,https://doi.org/10.1016/0010-406X(67)90445-8,https://www.sciencedirect.com/science/article/pii/0010406X67904458,,,,1967,Biochemical changes in tissues of goldfish acclimated to high and low temperatures—I. protein synthesis,Asit B. Das and C.L. Prosser,article,DAS1967449,Comparative Biochemistry and Physiology,3,21,0010-406X,,,
,,517-536,,"Calcareous stromatolites of the upper Siyeh Limestone (ca. 1.1 ∘ 109 years old) were studied in the central part of Glacier National Park, Montana. The stromatolites, mound- and dome-shaped structures deposited in a shallow, generally submerged, tidally influenced setting, were formed by a combination of in situ carbonate precipitation and organic stabilization of detrital material. Well-developed, 1–4 cm diameter, branched columns occur in a single stromatolite bed. Physical factors, including the size and shape of sediment-surface irregularities upon which the stromatolites developed, the rate of sedimentation between stromatolites, and the water depth, played a major role in controlling stromatolite macrostructure. Deposition of non-organically stabilized detritus on stromatolite growth surfaces inhibited the development of small-diameter columns by smoothing over developing growth features. Columnar structures are absent in stromatolites that contain abundant non-organically stabilized sediment. In contrast, they are well-developed in a stromatolite bed that is relatively deficient in such material. “Molar-tooth” structures are common in the impure dolomitic limestones, and the abundant sheet-shaped forms appear to be sparry-calcite-filled syneresis cracks.",https://doi.org/10.1016/0301-9268(76)90016-4,https://www.sciencedirect.com/science/article/pii/0301926876900164,,,,1976,"Stromatolites of the upper Siyeh Limestone (Middle Proterozoic), Belt Supergroup, Glacier National Park, Montana",Robert J. Horodyski,article,HORODYSKI1976517,Precambrian Research,6,3,0301-9268,,,
,,25-32,,"Uptake of labeled d- and l-glucose has been shown to occur with highly purified brush border membranes from the epithelial cells of rat small intestine using a Millipore filtration technique. An intact glucose carrier system in the isolated membranes was demonstrated as evidenced by the following. (a) d-Glucose was taken up and released faster than l-glucose. (b) Sodium ions increased initial rate and extent of d-glucose uptake 3- to 5-fold; no other cation showed this effect. (c) d-Glucose uptake and release was inhibited by phlorizin. (d) Countertransport of d-glucose was demonstrated. (e) d- and l-glucose reached the same level of uptake after prolonged incubation. (f) Uptake of labeled d-glucose was inhibited by higher concentrations of unlabeled d-galactose and vice versa. Glucose uptake by membrane vesicles represented entry into an intravesicular aqueous space rather than binding to the membrane. Exposure of the membrane to increasing cellobiose concentrations led to osmotic shrinkage of the intravesicular space and decreased glucose uptake. Infinite medium osmolarity and therefore zero intravesicular space resulted in no glucose uptake. Sodium in the medium (but not in the intravesicular spaces) stimulated d-glucose transport. It is concluded that isolated brush border membranes of intestinal epithelial cells retain the glucose carrier system. The reported findings are consistent with the concept that (a) glucose transport across the brush border membrane represents “facilitated diffusion”; (b) the glucose carrier is dependent on sodium ions; and (c) high extracellular, but not intracellular sodium concentrations lead to increased glucose transport.",https://doi.org/10.1016/S0021-9258(19)44440-2,https://www.sciencedirect.com/science/article/pii/S0021925819444402,,,,1973,Glucose Transport in Isolated Brush Border Membrane from Rat Small Intestine,Ulrich Hopfer and Kristine Nelson and Joseph Perrotto and Kurt J. Isselbacher,article,HOPFER197325,Journal of Biological Chemistry,1,248,0021-9258,,,
,,299-322,Biological Solar Energy Conversion,,https://doi.org/10.1016/B978-0-12-500650-7.50028-3,https://www.sciencedirect.com/science/article/pii/B9780125006507500283,,Academic Press,978-0-12-500650-7,1977,"POSSIBLE ROUTES TO INCREASE THE CONVERSION OF SOLAR ENERGY TO FOOD AND FEED BY GRAIN LEGUMES AND CEREAL GRAINS (CROP PRODUCTION): CO2 AND N2 FIXATION, FOLIAR FERTILIZATION, AND ASSIMILATE PARTITIONING",R.W.F. Hardy and U.D. Havelka,incollection,HARDY1977299,,,,,,AKIRA MITSUI and SHIGETOH MIYACHI and ANTHONY {SAN PIETRO} and SABURO TAMURA,
,,566-575,,Chlorella vulgaris growing with ammonium nitrate as nitrogen source preferentially assimilates ammonium. Nitrate assimilation ceases completely when ammonium is added and recommences as soon as ammonium has disappeared. Ammonium does not inhibit nitrate reduction by cells unable to assimilate ammonium because they lack a carbon source. Thus the inhibition is not due to ammonium per se but is connected with its assimilation. The inhibition is not thought to result from competition for reduced pyridine nucleotide because nitrate reductase of Chlorella is specific for DPN while glutamic dehydrogenase is specific for TPN. Nitrite addition also inhibits nitrate assimilation completely but ammonium only partially inhibits nitrite assimilation.,https://doi.org/10.1016/0926-6569(63)90277-3,https://www.sciencedirect.com/science/article/pii/0926656963902773,,,,1963,The inhibition of nitrate assimilation by ammonium in chlorella,P.J. Syrett and I. Morris,article,SYRETT1963566,Biochimica et Biophysica Acta (BBA) - Specialized Section on Enzymological Subjects,,67,0926-6569,,,
,,293-360,,"This report summarizes current developments in the United States and 18 other industrial countries regarding packaging waste. It presents available data concerning the types, amounts, and methods of managing such waste and provides information concerning the policies established or under consideration to reduce the amount of such waste being disposed. The countries discussed are all members of the Organisation for Economic Co-operation and Development (OECD). In recent years, waste disposal capacity has become more scarce in most OECD countries. As a result, waste management policies have focused on efforts to reduce and recycle major components of the waste stream. Packaging represents about one-third of municipal solid waste in many countries. Because of this, measures to reduce the amount and toxicity of packaging and to encourage its recycling are currently being considered in at least 18 OECD countries. In addition, the EC and the Nordic Council are developing programs to address packaging on a regional basis. The report is divided into four main sections. Section I summarizes available information for the OECD countries. The second section discusses waste generation and recycling rates for six types of packaging material: paper, glass, metal, plastic, wood, and composites. The third section discusses key questions raised by the information presented in the report. The fourth briefly discusses packaging waste issues facing the Congress. In general, the report finds, other countries use less packaging than the United States, recycle more of it, and are considering policy measures stronger than the measures generally being considered in America. As noted in detail, other countries have adopted or are developing requirements that: &#x02022;• set mandatory requirements for packaging waste reduction;&#x02022;• require reusable or refillable packaging;&#x02022;• impose taxes to discourage single-use packages;&#x02022;• prohibit the use of non-recyclable packaging,&#x02022;• prohibit or limit disposal of packaging, and&#x02022;• require manufacturers of packaging materials to collect and recycle post-consumer waste. Perhaps the most fundamental issue raised by these approaches is whether local governments will continue to bear responsibility for funding and operating recycling programs or whether all or some of this responsibility might be shifted to industry. To date, this issue has not been joined in the Congress directly; however, there is a growing consensus in other countries concerning the advantages of industry responsibility.",https://doi.org/10.1016/0921-3449(93)90027-D,https://www.sciencedirect.com/science/article/pii/092134499390027D,,,,1993,Recycling and reducing packaging waste: How the United States compares to other countries,James E. McCarthy,article,MCCARTHY1993293,"Resources, Conservation and Recycling",3,8,0921-3449,Packaging Waste,,
,,165-230,Microsoft Windows Security Fundamentals,"Publisher Summary
This chapter focuses on important client security aspects that include least privilege, Internet Explorer (IE) security, security changes in XP Service Pack 2, spyware protection, and the Trusted Platform Module (TPM). It also covers the upcoming client security features in Internet Explorer 7.0 and Windows Vista. The principle of least privilege means that you should a user or a piece of code is given only the privileges it needs to do the job. For administrators, this means that they should have two accounts in an AD domain—one low-privilege account, and another high privilege account. UNIX is the best example that completely follows the principle of least privilege. The tools that administrators and users can use today in Windows 2000, Windows Server 2003, R2, and Windows XP to honor least privilege are RunAs, fast user switching, and third party tolls like dropmyrights and the privilege bar, The chapter also details the Windows XP Service Pack 2 security enhancements that include critical security enhancements for both users and developers. In Windows XP, Microsoft introduced a built-in personal firewall: the Internet Connection Firewall (ICF). XP SP2 offers more security resilience, that is, it increases the level of security and protection even on systems that don't have the latest security patches installed.’. The chapter also details the concept of browser security that highlights intelligent add-on management, pop-up blocking, and hidden IE security changes. Internet Explorer (IE) security zones are a powerful and often neglected security feature of Microsoft's Internet browser. Ensuring proper IE security require defining security zones, identifying security zone web site, customizing and administering the local computer security zone, and controlling security zone configuration settings. The chapter concludes with the malicious mobile code protection (MMC) that deals with protection against MMC annoyances like viruses, spyware, and rootkits.’",https://doi.org/10.1016/B978-155558340-8/50008-3,https://www.sciencedirect.com/science/article/pii/B9781555583408500083,Burlington,Digital Press,978-1-55558-340-8,2007,4 - Aspects of Windows Client Security,Jan {De Clercq} and Guido Grillenmeier,incollection,DECLERCQ2007165,,,,,,Jan {De Clercq} and Guido Grillenmeier,
Survey of Biological Progress,,281-311,,,https://doi.org/10.1016/B978-1-4832-0000-2.50012-3,https://www.sciencedirect.com/science/article/pii/B9781483200002500123,,Elsevier,,1949,Newer Methods in the Rapid Development of Disease-Resistant Vegetables* *Published by permission of the Director of the Hawaii Agricultural Experiment Station as Technical Paper No.160.,W.A. FRAZIER,incollection,FRAZIER1949281,,,1,0081-9697,,GEORGE S. AVERY and E.C. AUCHTER and G.W. BEADLE and HARRIET B. CREIGHTON and W.U. GARDNER and G. EVELYN HUTCHINSON and LINUS PAULING and F.O. SCHMITT and W.M. STANLEY and C.B. {VAN NIEL} and DOUGLAS WHITAKER,
,,v-xxx,,,https://doi.org/10.1016/j.rcot.2011.08.293,https://www.sciencedirect.com/science/article/pii/S1877051711005235,,,,2011,Sommaire,,article,2011v,Revue de Chirurgie Orthopédique et Traumatologique,"7, Supplement ",97,1877-0517,86e Réunion annuelle de la Société française de chirurgie orthopédique et traumatologique,,
,,301-314,,"The European Pharmacopoeia Biological Reference Preparation for Insulin was assayed against the Fourth International Standard for Insulin by 12 European laboratories in collaboration. In addition to the Rabbit Blood Glucose (RBG) assay and the Mouse Convulsion Assay (MCA) of the European Pharmacopoeia, the Mouse Blood Glucose (MBG) assay of the Pharmacopoeia Nordica was used. The MBG was superior to the MCA and not inferior to the RBG with regard to precision and statistical weight per assay and per animal. The 111 valid MCA results were analysed with the full probit procedure, a simplified probit procedure, the logit transformation and the arc sine transformation. The potency estimates calculated with the full probit procedures were approached most closely by those obtained with the arc sine transformation; the simplified probit procedure and the logit transformation yielded results which agreed reasonably well with those of the full probit procedure in most cases, but there were some exceptions for which no explanation was found. The twin cross-over design contributed markedly to the precision of the RBG, but this was not the case for the MBG. A potency of 24·0 i.u. mg−1 was assigned to the European Pharmacopoeia Biological Reference Preparation for Insulin.",https://doi.org/10.1016/S0092-1157(78)80019-5,https://www.sciencedirect.com/science/article/pii/S0092115778800195,,,,1978,The collaborative assay of the european pharmacopoeia biological reference preparation for insulin,D.R. Bangham and H. {de Jonge} and J. {van Noordwijk},article,BANGHAM1978301,Journal of Biological Standardization,4,6,0092-1157,,,
Handbook of Geophysical Exploration: Seismic Exploration,,71-127,Nuclear magnetic resonance petrophysical and logging applications,"Publisher Summary
To understand and/or interpret the results of nuclear magnetic resonance (NMR) logs from borehole measurements, it is imperative to conduct NMR laboratory measurements on brine and/or oil saturated rock samples first. Such measurements can be carried out to almost any desired accuracy using various means not readily available in a logging situation. For example, the measured NMR signals can be conveniently stacked many times to obtain a very high signal to noise ratio. One can study how the level of noise tends to affect the characteristics of the T2 distributions. When the water and oil signals are both present in the measurements, one can soak the core plugs in D2O to remove the water signal, or use the Magic Angle Spinning (MAS) technique to differentiate the two phases in high magnetic field. This chapter discusses the determination of irreducible water saturation, the understanding of oil T2 relaxation times regarding its viscosity and diffusion coefficient, as well as the establishment of permeability estimators, that are important in the laboratory for the understanding, interpretation, and applications of NMR logs to formation evaluation.",https://doi.org/10.1016/S0950-1401(02)80007-6,https://www.sciencedirect.com/science/article/pii/S0950140102800076,,Pergamon,,2002,Chapter 4 Petrophysical NMR measurements,,incollection,200271,,,32,0950-1401,,K.-J. Dunn and D.J. Bergman and G.A. Latorraca,
,,95-108,,,https://doi.org/10.1016/0144-8617(91)90074-M,https://www.sciencedirect.com/science/article/pii/014486179190074M,,,,1991,Bibliography on carbohydrate polymers,,article,199195,Carbohydrate Polymers,1,16,0144-8617,,,
HP Technologies,,133-206,Windows Server 2003 Security Infrastructures,"Publisher Summary
This chapter focuses on the Kerberos authentication protocol, the default authentication protocol of Windows Server 2003. Microsoft introduced Kerberos as the new default authentication protocol for enterprise environments in Windows 2000. Every Windows 2000, Windows XP, and Windows Server 2003 operating system platform includes a client Kerberos authentication provider. Over the past years, Microsoft has been actively involved in the Kerberos standardization process. Microsoft software engineers participated in the creation of several Kerberos-related Internet drafts. The basic Kerberos protocol only deals with authentication. Microsoft's implementation of the protocol also includes extensions for authorization. The Kerberos protocol always deals with three entities: two entities that want to authenticate to one another and one entity that mediates between these two entities, a trusted third party or the key distribution center (KDC). To make Kerberos more scalable, the Kerberos developers included the concept of a KDC that is a trusted third party with which every entity shares a secret key. This key is called the entity's master key. All entities trust the KDC to mediate in their mutual authentication. The KDC also maintains a centralized authentication database containing a copy of every user's master key.",https://doi.org/10.1016/B978-155558283-8/50008-2,https://www.sciencedirect.com/science/article/pii/B9781555582838500082,Burlington,Digital Press,978-1-55558-283-8,2004,5 - Kerberos,Jan De Clercq,incollection,CLERCQ2004133,,,,,,Jan De Clercq,
,,79-100,,Energy equations for partitioning energy utilisation in the bovine animal were written and utilised in a dynamic simulation model of beef animal growth. Mathematical models for the rates of anabolism and catabolism of stored products in the animal's body are presented. Estimates of the parameters used in the models were developed using experimental results and an experimental feeding trial. Computer simulations of a growing beef animal were compared with independent experimental data. Results indicated that the developed model can estimate bovine growth performance and the rates and modes of heat production under varying thermal and nutrient environments.,https://doi.org/10.1016/0308-521X(79)90021-0,https://www.sciencedirect.com/science/article/pii/0308521X79900210,,,,1979,Simulation of energy utilisation of bovine animals,H.M. Keener,article,KEENER197979,Agricultural Systems,2,4,0308-521X,,,
,,12-22,,,https://doi.org/10.1016/S0016-0032(30)90142-1,https://www.sciencedirect.com/science/article/pii/S0016003230901421,,,,1830,English patents,,article,183012,Journal of the Franklin Institute,1,9,0016-0032,,,
,"Pressure injection testing, Transmissivity, Well testing, Borehole testing",481-520,,"A FORTRAN 77 code is presented which gives the user a systematic approach to the collection, storage, and graphical display of results from pressure injection testing of wells and boreholes. Transmissivities are computed using three different formulations: a simple, standard method; one which accounts for unsaturated conditions and the use of one or two packers; and a method which assumes that the majority of the transmissivity is the result of a single, horizontal fracture. Results may be displayed graphically with depth along with the matrix values to detect significant secondary porosity. A methodology is presented for calibrating for head loss in the piping system to maximize the accuracy of computed results. The code takes flow-head loss data either interactively, or from a database holding previous calibration data. The data then are fit with a best-fit polynomial, the order of which is selected by the user. The best fit of the head loss data may be viewed graphically. A set of field collected pressure injection data is presented and analyzed using the code. The results demonstrate the influence that both the computational formulation and the head loss calibration may have on computed results.",https://doi.org/10.1016/0098-3004(94)00094-B,https://www.sciencedirect.com/science/article/pii/009830049400094B,,,,1995,"PACKER—A FORTRAN 77 code for collection, analysis, and display of interval pressure injection test data",G.C. Pasquarell and D.G. Boyer and J.B. Urban,article,PASQUARELL1995481,Computers & Geosciences,4,21,0098-3004,,,
,,67-78,,"Sediments from the Santa Barbara Basin (SBB) of the last 1000 years were analyzed for elemental sulfur (Se), mineral sulfide sulfur (Sm), lipid-based organically bound sulfur (Sx), residual organically bound sulfur (So), total organic carbon (TOC) and total nitrogen (TN). The approximate annual resolution of the time-series data permitted us to evaluate the influence of oceanic variables on the benthic environment and the accumulating varved sediment in the SBB. A bacterial mat community at or near the sediment surface is influencing sediment porosity and the production and distribution of Se. Early diagenesis dampens the amplitude of environmental signals in the geochemical time series. The concentrations of Sm and So increase with burial depth, at the expense of decreasing concentrations of Sx and Se. At depths greater than 5.5 cm, corresponding to an age of 7 years, Sm becomes the largest pool of reduced sulfur. It requires approximately 500 years of primarily bacterially mediated diagenesis, equivalent to a burial depth of ~ 1.4 m, for SBB sediments to gradually approach and finally enter the region assumed to represent typical “normal” marine sediments on a plot of weight percent TOC vs. Sm.",https://doi.org/10.1016/0016-7037(93)90469-D,https://www.sciencedirect.com/science/article/pii/001670379390469D,,,,1993,"Evolutionary changes over the last 1000 years of reduced sulfur phases and organic carbon in varved sediments of the Santa Barbara Basin, California",Arndt Schimmelmann and Miriam Kastner,article,SCHIMMELMANN199367,Geochimica et Cosmochimica Acta,1,57,0016-7037,,,
,"Australia, Benthos, Consumption, Diet, Fish, Macroinvertebrate, Production, Seagrass",107-131,,"Fishes and benthic invertebrates were sampled in seagrass and unvegetated habitats at 14 localities across southern Australia in order to determine any consistent relationships between animal production, fish consumption and environmental parameters over a large spatial scale. Most of the features identified in a related study at Western Port were confirmed over the extended geographic range; however, an exception was that the production of fishes in the smallest size-classes (i.e. <1 g wet weight) was not consistently greater in seagrass habitat than unvegetated habitat. The more important characteristics of seagrass and unvegetated habitat types identified in the extended study were (1) more fish species were associated with seagrass habitat than unvegetated habitat, (2) the majority of small-fish species in both habitat types fed on crustaceans, with relatively few species capable of utilising algae and virtually no species utilising seagrass, (3) the few species that did ingest algae often occurred in high abundance, (4) the size of prey eaten by fishes increased consistently with fish size, with prey length averaging ≈6% of fish length, (5) abundant large fish species generally consumed smaller prey than rarer large fish species at the same body size, (6) greater benthic invertebrate and demersal fish production occurred in seagrass habitat than in unvegetated habitat, (7) most of the production of crustaceans >1-mm sieve size was ingested by fish predators while only a small proportion of non-crustacean benthic production was consumed. Fish production was highly correlated with crustacean production and seagrass biomass, and was negatively correlated with wave exposure (measured as fetch) across the range of sites. The estimated production of crustaceans was highly correlated with the biomass of seagrass material and also with the proportion of particles <63 μm in the sediments. The overall relationships between macrofaunal production (M; mg · m−2 · day−1), macrocrustacean production (C; mg · m−2 · day−1), demersal fish production (D; mg · m−2 · day−1), fetch (F; km), seagrass biomass (L; g · m−2), proportion of particles <63 μm (S;%) and temperature (T; °C) were: ln M = 1.41 + 0.088 ln (L + 1) + 0.38 ln S + 0.89 ln T, ln C = −0.93 + 0.27 ln (L + 1) + 0.22 ln S + 0.89 ln T, ln D = −1.23 − 0.62 ln F + 0.36 ln (L + 1) + 1.04 ln T. These regression equations can be used as models to predict the production of macrofauna, crustaceans and small fishes at unexamined sites. When predictions were compared with estimates of annual production at the eight sites previously examined in Western Port, most predictions lay between 50 and 200% of measured values. Additional work in Australia and overseas should allow these models to be refined.",https://doi.org/10.1016/0022-0981(95)00085-2,https://www.sciencedirect.com/science/article/pii/0022098195000852,,,,1995,"The production and trophic ecology of shallow-water fish assemblages in southern Australia III. General relationships between sediments, seagrasses, invertebrates and fishes",Graham J. Edgar and Craig Shaw,article,EDGAR1995107,Journal of Experimental Marine Biology and Ecology,1,194,0022-0981,,,
,,273-293,,"Multichannel reflection data (Tugolessov et al., 1985) have revealed two deeps in the basement topography of the Black Sea which are filled with sediments from 12 to 15 km thick. The deeps lack the “granitic layer” and are underlain by oceanic-type crust which we assume to be generated by seafloor spreading processes. The age of the deeps was interpreted previously, in a highly controversial manner, as being from the Paleozoic — Early Mesozoic to the Recent. In the paper, age estimations were undertaken using surficial heat flow data, assuming that they are related to deep-seated age-dependent heat flow generated by the cooling oceanic lithosphere, but that they are strongly distorted by the heating of continuously accumulating sediments as well as by additional heat input from radiogenic production within sediments. Using reliable thermophysical parameters of compacting sediments, the distorted heat flow in the sediments was evaluated numerically. This allowed us to estimate the age of the Black Sea deeps floor. The results show that the West Black Sea deep is 130 to 95 m.y. old, and the East Black Sea deep is nearly 110 m.y. old. These figures support an interpretation of the Black Sea deeps as remnants of a Late Mesozoic back-arc basin that evolved behind the Lesser Caucasian — Pontide island arc. The inferred Middle Cretaceous age of the deeps is the first estimate obtained quantitatively, and corresponds well with available heat flow and multichannel reflection data.",https://doi.org/10.1016/0040-1951(92)90326-2,https://www.sciencedirect.com/science/article/pii/0040195192903262,,,,1992,"Age, thermal evolution and history of the Black Sea Basin based on heat flow and multichannel reflection data",A.Ya Golmshtok and L.P Zonenshain and A.A Terekhov and R.V Shainurov,article,GOLMSHTOK1992273,Tectonophysics,3,210,0040-1951,,,
