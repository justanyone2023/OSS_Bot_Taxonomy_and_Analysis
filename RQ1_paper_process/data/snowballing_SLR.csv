title,author,abstract,year,id
An exploratory study of reactions to bot comments on GitHub,"Farah, Juan Carlos and Spaenlehauer, Basile and Lu, Xinyang and Ingram, Sandy and Gillet, Denis","The widespread use of bots to support software development makes social coding platforms such as GitHub a particularly rich source of data for the study of human-bot interaction. Software development bots are used to automate repetitive tasks, interacting with their human counterparts via comments posted on the various discussion interfaces available on such platforms. One type of interaction supported by GitHub involves reacting to comments using predefined emoji. To investigate how users react to bot comments, we conducted an observational study comprising 54 million GitHub comments, with a particular focus on comments that elicited the laugh reaction. The results from our analysis suggest that some reaction types are not equally distributed across human and bot comments and that a bot's design and purpose influence the types of reactions it receives. Furthermore, while the laugh reaction is not exclusively used to express laughter, it can be used to convey humor when a bot behaves unexpectedly. These insights could inform the way bots are designed and help developers equip them with the ability to recognize and recover from unanticipated situations. In turn, bots could better support the communication, collaboration, and productivity of teams using social coding platforms.",2022,1
RABBIT: A tool for identifying bot accounts based on their recent GitHub event history,"Chidambaram, Natarajan and Mens, Tom and Decan, Alexandre","Collaborative software development through GitHub repositories frequently relies on bot accounts to automate repetitive and error-prone tasks. This highlights the need to have accurate and efficient bot identification tools. Several such tools have been proposed in the past, but they tend to rely on a substantial amount of historical data, or they limit themselves to a reduced subset of activity types, making them difficult to use at large scale. To overcome these limitations, we developed RABBIT, an open source command-line tool that queries the GitHub Events API to retrieve the recent events of a given GitHub account and predicts whether the account is a human or a bot. RABBIT is based on an XGBoost classification model that relies on six features related to account activities and achieves high performance, with an AUC, F1 score, precision and recall of 0.92. Compared to the state-of-the-art in bot identification, RABBIT exhibits a similar performance in terms of precision, recall and F1 score, while being more than an order of magnitude faster and requiring considerably less data. This makes RABBIT usable on a large scale, capable of processing several thousand accounts per hour efficiently.",2024,2
On the adoption of a TODO bot on GitHub: a preliminary study,"Mohayeji, Hamid and Ebert, Felipe and Arts, Eric and Constantinou, Eleni and Serebrenik, Alexander","Bots support different software maintenance and evolution activities, such as code review or executing tests. Recently, several bots have been proposed to help developers to keep track of postponed activities, expressed by means of TODO comments: e.g., TODO Bot automatically creates a GitHub issue when a TODO comment is added to a repository, increasing visibility of TODO comments. In this work, we perform a preliminary evaluation of the impact of the TODO Bot on software development practice. We conjecture that the introduction of the TODO Bot would facilitate keeping track of the TODO comments, and hence encourage developers to use more TODO comments in their code changes.To evaluate this conjecture, we analyze all the 2,208 repositories which have at least one GitHub issue created by the TODO Bot. Firstly, we investigate to what extent the bot is being used and describe the repositories using the bot. We observe that the majority (54%) of the repositories which adopted the TODO Bot are new, i.e., were created within less than one month of first issue created by the bot, and from those, more than 60% have the issue created within three days. We observe a statistically significant increase in the number of the TODO comments after the adoption of the bot, however with a small effect size. Our results suggest that the adoption of the TODO Bot encourages developers to introduce TODO comments rendering the postponed decisions more visible. Nevertheless, it does not speed up the process of addressing TODO comments or corresponding GitHub issues.",2022,3
Bot detection in GitHub repositories,"Chidambaram, Natarajan and Mazrae, Pooya Rostami","Contemporary social coding platforms like GitHub promote collaborative development. Many open-source software repositories hosted in these platforms use machine accounts (bots) to automate and facilitate a wide range of effort-intensive and repetitive activities. Determining if an account corresponds to a bot or a human contributor is important for socio-technical development analytics, for example, to understand how humans collaborate and interact in the presence of bots, to assess the positive and negative impact of using bots, to identify the top project contributors, to identify potential bus factors, and so on. Our project aims to include the trained machine learning (ML) classifier from the BoDeGHa bot detection tool as a plugin to the GrimoireLab software development analytics platform. In this work, we present the procedure to form a pipeline for retrieving contribution and contributor data using Perceval, distinguishing bots from humans using BoDeGHa, and visualising the results using Kibana.",2022,4
GFI-bot: automated good first issue recommendation on GitHub,"He, Hao and Su, Haonan and Xiao, Wenxin and He, Runzhi and Zhou, Minghui","To facilitate newcomer onboarding, GitHub recommends the use of ""good first issue"" (GFI) labels to signal issues suitable for newcomers to resolve. However, previous research shows that manually labeled GFIs are scarce and inappropriate, showing a need for automated recommendations. In this paper, we present GFI-Bot (accessible at https://gfibot.io), a proof-of-concept machine learning powered bot for automated GFI recommendation in practice. Project maintainers can configure GFI-Bot to discover and label possible GFIs so that newcomers can easily locate issues for making their first contributions. GFI-Bot also provides a high-quality, up-to-date dataset for advancing GFI recommendation research.",2022,5
Bot or not? Detecting bots in GitHub pull request activity based on comment similarity,"Golzadeh, Mehdi and Legay, Damien and Decan, Alexandre and Mens, Tom","Many empirical studies focus on socio-technical activity in social coding platforms such as GitHub, for example to study the onboarding, abandonment, productivity and collaboration among team members. Such studies face the difficulty that GitHub activity can also be generated automatically by bots of a different nature. It therefore becomes imperative to distinguish such bots from human users. We propose an automated approach to detect bots in GitHub pull request (PR) activity. Relying on the assumption that bots contain repetitive message patterns in their PR comments, we analyse the similarity between multiple messages from the same GitHub identity, using a clustering method that combines the Jaccard and Levenshtein distance. We empirically evaluate our approach by analysing 20,090 PR comments of 250 users and 42 bots in 1,262 GitHub repositories. Our results show that the method is able to clearly separate bots from human users.",2020,6
Exploring How Software Developers Work with Mention Bot in GitHub,"Peng, Zhenhui and Yoo, Jeehoon and Xia, Meng and Kim, Sunghun and Ma, Xiaojuan","Recently, major software development platforms have started to provide automatic reviewer recommendation (ARR) services for pull requests, to improve the collaborative coding review process. However, the user experience of ARR is under-investigated. In this paper, we use a two-stage mixed-methods approach to study how software developers perceive and work with the Facebook mention bot, one of the most popular ARR bots in GitHub. Specifically, in Stage I, we conduct archival analysis on projects employing mention bot and a user survey to investigate the bot's performance. A year later, in Stage II, we revisit these projects and conduct additional surveys and interviews with three user groups: project owners, contributors and reviewers. Results show that developers appreciate mention bot saving their effort, but are bothered by its unstable setting and unbalanced workload allocation. We conclude with design considerations for improving ARR services.",2018,7
On the accuracy of bot detection techniques,"Golzadeh, Mehdi and Decan, Alexandre and Chidambaram, Natarajan","Development bots are often used to automate a wide variety of repetitive tasks in collaborative software development. Such bots are commonly among the most active project contributors in terms of commit activity. As such, tools that analyse contributor activity (e.g., for recognizing and giving credit to project members for their contributions) need to take into account the bots and exclude their activity. While there are a few techniques to detect bots in software repositories, these techniques are not perfect and may miss some bots or may wrongly identify some human accounts as bots. In this paper, we present an exploratory study on the accuracy of bot detection techniques on a set of 540 accounts from 27 GitHub projects. We show that none of the bot detection techniques are accurate enough to detect bots among the 20 most active contributors of each project. We show that combining these techniques drastically increases the accuracy and recall of bot detection. We also highlight the importance of considering bots when attributing contributions to humans, since bots are prevalent among the top contributors and responsible for large proportions of commits.",2022,8
Autonomy Is an Acquired Taste: Exploring Developer Preferences for GitHub Bots,"Ghorbani, Amir and Cassee, Nathan and Robinson, Derek and Alami, Adam and Ernst, Neil A. and Serebrenik, Alexander and W\k{a}sowski, Andrzej","Software bots fulfill an important role in collective software development, and their adoption by developers promises increased productivity. Past research has identified that bots that communicate too often can irritate developers, which affects the utility of the bot. However, it is not clear what other properties of human-bot collaboration affect developers' preferences, or what impact these properties might have. The main idea of this paper is to explore characteristics affecting developer preferences for interactions between humans and bots, in the context of GitHub pull requests. We carried out an exploratory sequential study with interviews and a subsequent vignette-based survey. We find developers generally prefer bots that are personable but show little autonomy, however, more experienced developers tend to prefer more autonomous bots. Based on this empirical evidence, we recommend bot developers increase configuration options for bots so that individual developers and projects can configure bots to best align with their own preferences and project cultures.",2023,9
Use Bots to Improve GitHub Pull-Request Feedback,"Hu, Zhewei and Gehringer, Edward","Rising enrollments make it difficult for instructors and teaching assistants to give adequate feedback on each student's work. In our software engineering course, we have 50-120 students each semester. Our course projects require students to submit GitHub pull requests as deliverables for their open-source software (OSS) projects. We have set up a static code analyzer and a continuous integration service on GitHub to help students check code style and functionality. However, these tools cannot enforce system-specific customized guidelines and do not explicitly display detailed information. In this study, we discuss how we bypass the limitations of existing tools by implementing three Internet bots. The Expertiza Bot can help detect violations of more than 35 system-specific guidelines. The Travis CI Bot can explicitly display instant test execution results on the GitHub pull-request page. The Code Climate Bot can insert pull-request comments to remind students to fix issues detected by the static code analyzer. These bots are either open source or free for OSS projects, and can be easily integrated with GitHub repositories. Our survey results show that more than 70% of students think the advice given by the bots is useful. We tallied the amount of feedback given by the bots and the teaching staff for each GitHub pull request. Results show that bots can provide significantly more feedback (six times more on average) than teaching staff. Bots can also offer more timely feedback than teaching staff and help student contributions avoid more than 33% system-specific guideline violations.",2019,10
Towards s/engineer/bot: principles for program repair bots,"van Tonder, Rijnard and Goues, Claire Le","Of the hundreds of billions of dollars spent on developer wages, up to 25% accounts for fixing bugs. Companies like Google save significant human effort and engineering costs with automatic bug detection tools, yet automatically fixing them is still a nascent endeavour. Very recent work (including our own) demonstrates the feasibility of automatic program repair in practice. As automated repair technology matures, it presents great appeal for integration into developer workflows. We believe software bots are a promising vehicle for realizing this integration, as they bridge the gap between human software development and automated processes. We envision repair bots orchestrating automated refactoring and bug fixing. To this end, we explore what building a repair bot entails. We draw on our understanding of patch generation, validation, and real world software development interactions to identify six principles that bear on engineering repair bots and discuss related design challenges for integrating human workflows. Ultimately, this work aims to foster critical focus and interest for making repair bots a reality.",2019,15
CORMS: a GitHub and Gerrit based hybrid code reviewer recommendation approach for modern code review,"Pandya, Prahar and Tiwari, Saurabh","Modern Code review (MCR) techniques are widely adopted in both open-source software platforms and organizations to ensure the quality of their software products. However, the selection of reviewers for code review is cumbersome with the increasing size of development teams. The recommendation of inappropriate reviewers for code review can take more time and effort to complete the task effectively. In this paper, we extended the baseline of reviewers' recommendation framework - RevFinder - to handle issues with newly created files, retired reviewers, the external validity of results, and the accuracies of the state-of-the-art RevFinder. Our proposed hybrid approach, CORMS, works on similarity analysis to compute similarities among file paths, projects/sub-projects, author information, and prediction models to recommend reviewers based on the subject of the change. We conducted a detailed analysis on the widely used 20 projects of both Gerrit and GitHub to compare our results with RevFinder. Our results reveal that on average, CORMS, can achieve top-1, top-3, top-5, and top-10 accuracies, and Mean Reciprocal Rank (MRR) of 45.1%, 67.5%, 74.6%, 79.9% and 0.58 for the 20 projects, consequently improves the RevFinder approach by 44.9%, 34.4%, 20.8%, 12.3% and 18.4%, respectively.",2022,31
Understanding the Helpfulness of Stale Bot for Pull-Based Development: An Empirical Study of 20 Large Open-Source Projects,"Khatoonabadi, Sayedhassan and Costa, Diego Elias and Mujahid, Suhaib and Shihab, Emad","Pull Requests (PRs) that are neither progressed nor resolved clutter the list of PRs, making it difficult for the maintainers to manage and prioritize unresolved PRs. To automatically track, follow up, and close such inactive PRs, Stale bot was introduced by GitHub. Despite its increasing adoption, there are ongoing debates on whether using Stale bot alleviates or exacerbates the problem of inactive PRs. To better understand if and how Stale bot helps projects in their pull-based development workflow, we perform an empirical study of 20 large and popular open source projects. We find that Stale bot can help deal with a backlog of unresolved PRs, as the projects closed more PRs within the first few months of adoption. Moreover, Stale bot can help improve the efficiency of the PR review process as the projects reviewed PRs that ended up merged and resolved PRs that ended up closed faster after the adoption. However, Stale bot can also negatively affect the contributors, as the projects experienced a considerable decrease in their number of active contributors after the adoption. Therefore, relying solely on Stale bot to deal with inactive PRs may lead to decreased community engagement and an increased probability of contributor abandonment.",2023,32
An Exploratory Study of Bot Commits,"Dey, Tapajit and Vasilescu, Bogdan and Mockus, Audris","Background: Bots help automate many of the tasks performed by software developers and are widely used to commit code in various social coding platforms. At present, it is not clear what types of activities these bots perform and understanding it may help design better bots, and find application areas which might benefit from bot adoption. Aim: We aim to categorize the Bot Commits by the type of change (files added, deleted, or modified), find the more commonly changed file types, and identify the groups of file types that tend to get updated together. Method: 12,326,137 commits made by 461 popular bots (that made at least 1000 commits) were examined to identify the frequency and the type of files added/ deleted/ modified by the commits, and association rule mining was used to identify the types of files modified together. Result: Majority of the bot commits modify an existing file, a few of them add new files, while deletion of a file is very rare. Commits involving more than one type of operation are even rarer. Files containing data, configuration, and documentation are most frequently updated, while HTML is the most common type in terms of the number of files added, deleted, and modified. Files of the type ""Markdown"",""Ignore List"", ""YAML"", ""JSON"" were the types that are updated together with other types of files most frequently. Conclusion: We observe that majority of bot commits involve single file modifications, and bots primarily work with data, configuration, and documentation files. A better understanding if this is a limitation of the bots and, if overcome, would lead to different kinds of bots remains an open question.",2020,33
Between JIRA and GitHub: ASFBot and its influence on human comments in issue trackers,"Moharil, Ambarish and Orlov, Dmitrii and Jameel, Samar and Trouwen, Tristan and Cassee, Nathan and Serebrenik, Alexander","Open-Source Software (OSS) projects have adopted various automations for repetitive tasks in recent years. One common type of automation in OSS is bots. In this exploratory case study, we seek to understand how the adoption of one particular bot (ASFBot) by the Apache Software Foundation (ASF) impacts the discussions in the issue-trackers of these projects. We use the SmartShark dataset to investigate whether the ASFBot affects (i) human comments mentioning pull requests and fixes in issue comments and (ii) the general human comment rate on issues. We apply a regression discontinuity design (RDD) on nine ASF projects that have been active both before and after the ASFBot adoption. Our results indicate (i) an immediate decrease in the number of median comments mentioning pull requests and fixes after the bot adoption, but the trend of a monthly decrease in this comment count is reversed, and (ii) no effect in the number of human comments after the bot adoption. We make an effort to gather first insights in understanding the impact of adopting the ASFBot on the commenting behavior of developers who are working on ASF projects.",2022,36
GitHub-OSS fixit,"Tan, Shin Hwei and Hu, Chunfeng and Li, Ziqiang and Zhang, Xiaowen and Zhou, Ying","Many studies have shown the benefits of introducing open-source projects into teaching Software Engineering (SE) courses. However, there are several limitations of existing studies that limit the wide adaptation of open-source projects in a classroom setting, including (1) the selected project is limited to one particular project, (2) most studies only investigated on its effect on teaching a specific SE concept, and (3) students may make mistakes in their contribution which leads to poor quality code. Meanwhile, software companies have successfully launched programs like Google Summer of Code (GSoC) and FindBugs ""fixit"" to contribute to open-source projects. Inspired by the success of these programs, we propose GitHub-OSS Fixit, a team-based course project where students are taught to contribute to open-source Java projects by fixing bugs reported in GitHub. We described our course outline to teach students SE concepts by encouraging the usages of several automated program analysis tools. We also included the carefully designed instructions that we gave to students for participating in GitHub-OSS Fixit. As all lectures and labs are conducted online, we think that our course design could help in guiding future online SE courses. Overall, our survey results show that students think that GitHub-OSS Fixit could help them to improve many skills and apply the knowledge taught in class. In total, 154 students have submitted 214 pull requests to 24 different Java projects, in which 93 of them have been merged, and 46 have been closed by developers.",2021,38
FixMe: a GitHub bot for detecting and monitoring on-hold self-admitted technical debt,"Phaithoon, Saranphon and Wongnil, Supakarn and Pussawong, Patiphol and Choetkiertikul, Morakot and Ragkhitwetsagul, Chaiyong and Sunetnanta, Thanwadee and Maipradit, Rungroj and Hata, Hideaki and Matsumoto, Kenichi","Self-Admitted Technical Debt (SATD) is a special form of technical debt in which developers intentionally record their hacks in the code by adding comments for attention. Here, we focus on issue-related ""On-hold SATD"", where developers suspend proper implementation due to issues reported inside or outside the project. When the referenced issues are resolved, the On-hold SATD also need to be addressed, but since monitoring these issue reports takes a lot of time and effort, developers may not be aware of the resolved issues and leave the On-hold SATD in the code. In this paper, we propose FixMe, a GitHub bot that helps developers detecting and monitoring On-hold SATD in their repositories and notify them whenever the On-hold SATDs are ready to be fixed (i.e. the referenced issues are resolved). The bot can automatically detect On-hold SATD comments from source code using machine learning techniques and discover referenced issues. When the referenced issues are resolved, developers will be notified by FixMe bot. The evaluation conducted with 11 participants shows that our FixMe bot can support them in dealing with On-hold SATD. FixMe is available at https://www.fixmebot.app/ and FixMe's VDO is at https://youtu.be/YSz9kFxN_YQ.",2022,41
How to design a program repair bot? insights from the repairnator project,"Urli, Simon and Yu, Zhongxing and Seinturier, Lionel and Monperrus, Martin","Program repair research has made tremendous progress over the last few years, and software development bots are now being invented to help developers gain productivity. In this paper, we investigate the concept of a ""program repair bot"" and present Repairnator. The Repairnator bot is an autonomous agent that constantly monitors test failures, reproduces bugs, and runs program repair tools against each reproduced bug. If a patch is found, Repairnator bot reports it to the developers. At the time of writing, Repairnator uses three different program repair systems and has been operating since February 2017. In total, it has studied 11 523 test failures over 1 609 open-source software projects hosted on GitHub, and has generated patches for 15 different bugs. Over months, we hit a number of hard technical challenges and had to make various design and engineering decisions. This gives us a unique experience in this area. In this paper, we reflect upon Repairnator in order to share this knowledge with the automatic program repair community.",2018,43
Exploring ChatGPT for Toxicity Detection in GitHub,"Mishra, Shyamal and Chatterjee, Preetha","Fostering a collaborative and inclusive environment is crucial for the sustained progress of open source development. However, the prevalence of negative discourse, often manifested as toxic comments, poses significant challenges to developer well-being and productivity. To identify such negativity in project communications, especially within large projects, automated toxicity detection models are necessary. To train these models effectively, we need large software engineering-specific toxicity datasets. However, such datasets are limited in availability and often exhibit imbalance (e.g., only 6 in 1000 GitHub issues are toxic) [1], posing challenges for training effective toxicity detection models. To address this problem, we explore a zero-shot LLM (ChatGPT) that is pre-trained on massive datasets but without being fine-tuned specifically for the task of detecting toxicity in software-related text. Our preliminary evaluation indicates that ChatGPT shows promise in detecting toxicity in GitHub, and warrants further investigation. We experimented with various prompts, including those designed for justifying model outputs, thereby enhancing model interpretability and paving the way for potential integration of ChatGPT-enabled toxicity detection into developer communication channels.",2024,47
How do Machine Learning Projects use Continuous Integration Practices? An Empirical Study on GitHub Actions,"Bernardo, Jo\~{a}o Helis and Da Costa, Daniel Alencar and Medeiros, S\'{e}rgio Queiroz de and Kulesza, Uir\'{a}","Continuous Integration (CI) is a well-established practice in traditional software development, but its nuances in the domain of Machine Learning (ML) projects remain relatively unexplored. Given the distinctive nature of ML development, understanding how CI practices are adopted in this context is crucial for tailoring effective approaches. In this study, we conduct a comprehensive analysis of 185 open-source projects on GitHub (93 ML and 92 non-ML projects). Our investigation comprises both quantitative and qualitative dimensions, aiming to uncover differences in CI adoption between ML and non-ML projects. Our findings indicate that ML projects often require longer build duration, and medium-sized ML projects exhibit lower test coverage compared to non-ML projects. Moreover, small and medium-sized ML projects show a higher prevalence of increasing build duration trends compared to their non-ML counterparts. Additionally, our qualitative analysis illuminates the discussions around CI in both ML and non-ML projects, encompassing themes like CI Build Execution and Status, CI Testing, and CI Infrastructure. These insights shed light on the unique challenges faced by ML projects in adopting CI practices effectively.",2024,48
Recommending good first issues in GitHub OSS projects,"Xiao, Wenxin and He, Hao and Xu, Weiwei and Tan, Xin and Dong, Jinhao and Zhou, Minghui","Attracting and retaining newcomers is vital for the sustainability of an open-source software project. However, it is difficult for newcomers to locate suitable development tasks, while existing ""Good First Issues"" (GFI) in GitHub are often insufficient and inappropriate. In this paper, we propose RecGFI, an effective practical approach for the recommendation of good first issues to newcomers, which can be used to relieve maintainers' burden and help newcomers onboard. RecGFI models an issue with features from multiple dimensions (content, background, and dynamics) and uses an XGBoost classifier to generate its probability of being a GFI. To evaluate RecGFI, we collect 53,510 resolved issues among 100 GitHub projects and carefully restore their historical states to build ground truth datasets. Our evaluation shows that RecGFI can achieve up to 0.853 AUC in the ground truth dataset and outperforms alternative models. Our interpretable analysis of the trained model further reveals interesting observations about GFI characteristics. Finally, we report latest issues (without GFI-signaling labels but recommended as GFI by our approach) to project maintainers among which 16 are confirmed as real GFIs and five have been resolved by a newcomer.",2022,53
A Tool for the Definition and Deployment of Platform-Independent Bots on Open Source Projects,"Ait, Adem and C\'{a}novas Izquierdo, Javier Luis and Cabot, Jordi","The development of Open Source Software (OSS) projects is a collaborative process that heavily relies on active contributions by passionate developers. Creating, retaining and nurturing an active community of developers is a challenging task; and finding the appropriate expertise to drive the development process is not always easy. To alleviate this situation, many OSS projects try to use bots to automate some development tasks, thus helping community developers to cope with the daily workload of their projects. However, the techniques and support for developing bots is specific to the code hosting platform where the project is being developed (e.g., GitHub or GitLab). Furthermore, there is no support for orchestrating bots deployed in different platforms nor for building bots that go beyond pure development activities. In this paper, we propose a tool to define and deploy bots for OSS projects, which besides automation tasks they offer a more social facet, improving community interactions. The tool includes a Domain-Specific Language (DSL) which allows defining bots that can be deployed on top of several platforms and that can be triggered by different events (e.g., creation of a new issue or a pull request). We describe the design and the implementation of the tool, and illustrate its use with examples.",2023,61
There’s no Such Thing as a Free Lunch: Lessons Learned from Exploring the Overhead Introduced by the Greenkeeper Dependency Bot in Npm,"Rombaut, Benjamin and Cogo, Filipe R. and Adams, Bram and Hassan, Ahmed E.","Dependency management bots are increasingly being used to support the software development process, for example, to automatically update a dependency when a new version is available. Yet, human intervention is often required to either accept or reject any action or recommendation the bot creates. In this article, our objective is to study the extent to which dependency management bots create additional, and sometimes unnecessary, work for their users. To accomplish this, we analyze 93,196 issue reports opened by Greenkeeper, a popular dependency management bot used in open source software projects in the npm ecosystem. We find that Greenkeeper is responsible for half of all issues reported in client projects, inducing a significant amount of overhead that must be addressed by clients, since many of these issues were created as a result of Greenkeeper taking incorrect action on a dependency update (i.e., false alarms). Reverting a broken dependency update to an older version, which is a potential solution that requires the least overhead and is automatically attempted by Greenkeeper, turns out to not be an effective mechanism. Finally, we observe that 56% of the commits referenced by Greenkeeper issue reports only change the client’s dependency specification file to resolve the issue. Based on our findings, we argue that dependency management bots should (i) be configurable to allow clients to reduce the amount of generated activity by the bots, (ii) take into consideration more sources of information than only the pass/fail status of the client’s build pipeline to help eliminate false alarms, and (iii) provide more effective incentives to encourage clients to resolve dependency issues.",2023,62
BotHunter: an approach to detect software bots in GitHub,"Abdellatif, Ahmad and Wessel, Mairieli and Steinmacher, Igor and Gerosa, Marco A. and Shihab, Emad","Bots have become popular in software projects as they play critical roles, from running tests to fixing bugs/vulnerabilities. However, the large number of software bots adds extra effort to practitioners and researchers to distinguish human accounts from bot accounts to avoid bias in data-driven studies. Researchers developed several approaches to identify bots at specific activity levels (issue/pull request or commit), considering a single repository and disregarding features that showed to be effective in other domains. To address this gap, we propose using a machine learning-based approach to identify the bot accounts regardless of their activity level. We selected and extracted 19 features related to the account's profile information, activities, and comment similarity. Then, we evaluated the performance of five machine learning classifiers using a dataset that has more than 5,000 GitHub accounts. Our results show that the Random Forest classifier performs the best, with an F1-score of 92.4% and AUC of 98.7%. Furthermore, the account profile information (e.g., account login) contains the most relevant features to identify the account type. Finally, we compare the performance of our Random Forest classifier to the state-of-the-art approaches, and our results show that our model outperforms the state-of-the-art techniques in identifying the account type regardless of their activity level.",2022,63
Coding together in a social network: collaboration among GitHub users,"Celi\'{n}ska, Dorota","In this article we investigate developers involved in the creation of Open Source software to identify which characteristics favor innovation in the Open Source community. The results of the analysis show that higher reputation in the community improves the probability of gaining collaborators to a certain degree, but developers are also driven by reciprocity. This is consistent with the concept of gift economy. A significant network effect exists and emerges from standardization, showing that developers using the most popular programming languages in the service are likely to have more collaborators. Providing additional information (valid URL to developer's homepage) improves the chances of finding coworkers. The results can be generalized for the population of mature users of GitHub.",2018,65
Should I stale or should I close? an analysis of a bot that closes abandoned issues and pull requests,"Wessel, Mairieli and Steinmacher, Igor and Wiese, Igor and Gerosa, Marco A.","On GitHub, projects use bots to automate predefined and repetitive tasks related to issues and pull requests. Our research investigates the adoption of the stale bot, which helps maintainers triaging abandoned issues and pull requests. We analyzed the bots' configuration settings and their modifications over time. These settings define the time for tagging issues and pull request as stale and closing them. We collected data from 765 OSS projects hosted on GitHub. Our results indicate that most of the studied projects made no more than three modifications in the configurations file, issues tagged as bug reports are exempt from being considered stale, while the same occurs with pull requests that need some input to be processed.",2019,66
Enhancing developers’ support on pull requests activities with software bots,"Wessel, Mairieli","Software bots are employed to support developers' activities, serving as conduits between developers and other tools. Due to their focus on task automation, bots have become particularly relevant for Open Source Software (OSS) projects hosted on GitHub. While bots are adopted to save development cost, time, and effort, the bots' presence can be disruptive to the community. My research goal is two-fold: (i) identify problems caused by bots that interact in pull requests, and (ii) help bot designers enhance existing bots. Toward this end, we are interviewing maintainers, contributors, and bot developers to understand the problems in the human-bot interaction and how they affect the collaboration in a project. Afterward, we will employ Design Fiction to capture the developers' vision of bots' capabilities, in order to define guidelines for the design of bots on social coding platforms, and derive requirements for a meta-bot to deal with the problems. This work contributes more broadly to the design and use of software bots to enhance developers' collaboration and interaction.",2020,68
RefBot: intelligent software refactoring bot,"Alizadeh, Vahid and Ouali, Mohamed Amine and Kessentini, Marouane and Chater, Meriem","The adoption of refactoring techniques for continuous integration received much less attention from the research community comparing to root-canal refactoring to fix the quality issues in the whole system. Several recent empirical studies show that developers, in practice, are applying refactoring incrementally when they are fixing bugs or adding new features. There is an urgent need for refactoring tools that can support continuous integration and some recent development processes such as DevOps that are based on rapid releases. Furthermore, several studies show that manual refactoring is expensive and existing automated refactoring tools are challenging to configure and integrate into the development pipelines with significant disruption cost.In this paper, we propose, for the first time, an intelligent software refactoring bot, called RefBot. Integrated into the version control system (e.g. GitHub), our bot continuously monitors the software repository, and it is triggered by any ""open"" or ""merge"" action on pull requests. The bot analyzes the files changed during that pull request to identify refactoring opportunities using a set of quality attributes then it will find the best sequence of refactorings to fix the quality issues if any. The bot recommends all these refactorings through an automatically generated pull-request. The developer can review the recommendations and their impacts in a detailed report and select the code changes that he wants to keep or ignore. After this review, the developer can close and approve the merge of the bot's pull request. We quantitatively and qualitatively evaluated the performance and effectiveness of RefBot by a survey conducted with experienced developers who used the bot on both open source and industry projects.",2020,69
Build-A-Bot: Developing A Software Platform For A Modular Mobile Robot,"Kassem, Khaled and Pavlova, Galya and Schlund, Sebastian and Michahelles, Florian","This work aims to create a software platform that can manage dynamic changes in the configuration and functionalities of a modular robot that is currently in development, simulate its final appearance and behavior in augmented reality, and evaluate its usability through a user study. We developed a software platform for a modular collaborative robot where users can add, remove, and swap modules without code changes. The software platform displays possible functions based on the current configuration of modules. To enable 3D interaction with the robot’s digital twin in real-time, we utilized an AR environment with the HoloLens. We conducted a user study with 28 participants without prior knowledge of robotics to evaluate the software’s usability and user experience for non-experts. The study results indicate that the software platform was well-received and user-friendly, with the digital twin in an AR environment providing a realistic robot simulation. Participants’ subjective feedback on usability, user experience, and cognitive workload of different software components was collected, and the analysis showed that the platform is suitable for non-experts. The results showed that our design of the platform and its UI is well-accepted and easy to use, shown by a SUS score of 74.29. We show how we built our software platform, as well as the simulation in AR. Moreover, we propose the practice of using AR simulation to design the software platform before future physical prototype development, in order to test different scenarios, and possibly inform the physical design. Finally, we recommend that future work explores usability with a more diverse set of non-expert users, as well as different tasks.",2024,70
Leveraging Software Bots to Enhance Developers' Collaboration in Online Programming Communities,"Wessel, Mairieli","Software bots are applications that are integrated into human communication channels, serving as an interface between users and other tools. Due to their focus on task automation, bots have become particularly relevant for Open Source Software (OSS) projects hosted on GitHub. While bots are adopted to save developers' costs, time, and effort, the interaction of these bots can be disruptive to the community. My research goal is two-fold: (i) identify problems caused by bots that interact in pull requests, and (ii) help bot designers to enhance existing bots, thereby improving the partnership with contributors and maintainers. Toward this end, we are interviewing developers to understand what are the problems on the human-bot interaction and how they affect human collaboration. Afterwards, we will employ Design Fiction to capture the developers' vision of bots' capabilities, in order to define guidelines for the design of bots on social coding platforms, and derive requirements for a meta-bot to deal with the problems. This work contributes more broadly to the design and use of software bots to enhance developers' collaboration and interaction.",2020,71
"Bots for pull requests: the good, the bad, and the promising","Wessel, Mairieli and Abdellatif, Ahmad and Wiese, Igor and Conte, Tayana and Shihab, Emad and Gerosa, Marco A. and Steinmacher, Igor","Software bots automate tasks within Open Source Software (OSS) projects' pull requests and save reviewing time and effort (""the good""). However, their interactions can be disruptive and noisy and lead to information overload (""the bad""). To identify strategies to overcome such problems, we applied Design Fiction as a participatory method with 32 practitioners. We elicited 22 design strategies for a bot mediator or the pull request user interface (""the promising""). Participants envisioned a separate place in the pull request interface for bot interactions and a bot mediator that can summarize and customize other bots' actions to mitigate noise. We also collected participants' perceptions about a prototype implementing the envisioned strategies. Our design strategies can guide the development of future bots and social coding platforms.",2022,72
Bob or Bot: Exploring ChatGPT's Answers to University Computer Science Assessment,"Richards, Mike and Waugh, Kevin and Slaymaker, Mark and Petre, Marian and Woodthorpe, John and Gooch, Daniel","Cheating has been a long-standing issue in university assessments. However, the release of ChatGPT and other free-to-use generative AI tools has provided a new and distinct method for cheating. Students can run many assessment questions through the tool and generate a superficially compelling answer, which may or may not be accurate.&nbsp;We ran a dual-anonymous “quality assurance” marking exercise across four end-of-module assessments across a distance university computer science (CS) curriculum. Each marker received five ChatGPT-generated scripts alongside 10 student scripts. A total of 90 scripts were marked; every ChatGPT-generated script for the undergraduate modules received at least a passing grade (&gt;40%), with all of the introductory module CS1 scripts receiving a distinction (&gt;85%). None of the ChatGPT-taught postgraduate scripts received a passing grade (&gt;50%). We also present the results of interviewing the markers and of running our sample scripts through a GPT-2 detector and the TurnItIn AI detector, which both identified every ChatGPT-generated script but differed in the number of false positives. As such, we contribute a baseline understanding of how the public release of generative AI is likely to significantly impact quality assurance processes. Our analysis demonstrates that in most cases, across a range of question formats, topics, and study levels, ChatGPT is at least capable of producing adequate answers for undergraduate assessment.",2024,73
Don't Disturb Me: Challenges of Interacting with Software Bots on Open Source Software Projects,"Wessel, Mairieli and Wiese, Igor and Steinmacher, Igor and Gerosa, Marco Aurelio","Software bots are used to streamline tasks in Open Source Software (OSS) projects' pull requests, saving development cost, time, and effort. However, their presence can be disruptive to the community. We identified several challenges caused by bots in pull request interactions by interviewing 21 practitioners, including project maintainers, contributors, and bot developers. In particular, our findings indicate noise as a recurrent and central problem. Noise affects both human communication and development workflow by overwhelming and distracting developers. Our main contribution is a theory of how human developers perceive annoying bot behaviors as noise on social coding platforms. This contribution may help practitioners understand the effects of adopting a bot, and researchers and tool designers may leverage our results to better support human-bot interaction on social coding platforms.",2021,74
The Power of Bots: Characterizing and Understanding Bots in OSS Projects,"Wessel, Mairieli and de Souza, Bruno Mendes and Steinmacher, Igor and Wiese, Igor S. and Polato, Ivanilton and Chaves, Ana Paula and Gerosa, Marco A.","Leveraging the pull request model of social coding platforms, Open Source Software (OSS) integrators review developers' contributions, checking aspects like license, code quality, and testability. Some projects use bots to automate predefined, sometimes repetitive tasks, thereby assisting integrators' and contributors' work. Our research investigates the usage and impact of such bots. We sampled 351 popular projects from GitHub and found that 93 (26%) use bots. We classified the bots, collected metrics from before and after bot adoption, and surveyed 228 developers and integrators. Our results indicate that bots perform numerous tasks. Although integrators reported that bots are useful for maintenance tasks, we did not find a consistent, statistically significant difference between before and after bot adoption across the analyzed projects in terms of number of comments, commits, changed files, and time to close pull requests. Our survey respondents deem the current bots as not smart enough and provided insights into the bots' relevance for specific tasks, challenges, and potential new features. We discuss some of the raised suggestions and challenges in light of the literature in order to help GitHub bot designers reuse and test ideas and technologies already investigated in other contexts.",2018,75
The Inconvenient Side of Software Bots on Pull Requests,"Wessel, Mairieli and Steinmacher, Igor","Software bots are applications that integrate their work with humans' tasks, serving as conduits between users and other tools. Due to their ability to automate tasks, bots have been widely adopted by Open Source Software (OSS) projects hosted on GitHub. Commonly, OSS projects use bots to automate a variety of routine tasks to save time from maintainers and contributors. Although bots can be useful for supporting maintainers' work, sometimes their comments are seen as spams, and are quickly ignored by contributors. In fact, the way that these bots interact on pull requests can be disruptive and perceived as unwelcoming. In this paper, we propose the concept of a meta-bot to deal with current problems on the human-bot interaction on pull requests. Besides providing additional value to this interaction, meta-bot will reduce interruptions and help maintainers and contributors stay aware of important information.",2020,76
Software bots in software engineering: benefits and challenges,"Wessel, Mairieli and Gerosa, Marco A. and Shihab, Emad","Software bots are becoming increasingly popular in software engineering (SE). In this tutorial, we define what a bot is and present several examples. We also discuss the many benefits bots provide to the SE community, including helping in development tasks (such as pull request review and integration) and onboarding newcomers to a project. Finally, we discuss the challenges related to interacting with and developing software bots.",2022,77
Detecting and Characterizing Bots that Commit Code,"Dey, Tapajit and Mousavi, Sara and Ponce, Eduardo and Fry, Tanner and Vasilescu, Bogdan and Filippova, Anna and Mockus, Audris","Background: Some developer activity traditionally performed manually, such as making code commits, opening, managing, or closing issues is increasingly subject to automation in many OSS projects. Specifically, such activity is often performed by tools that react to events or run at specific times. We refer to such automation tools as bots and, in many software mining scenarios related to developer productivity or code quality, it is desirable to identify bots in order to separate their actions from actions of individuals. Aim: Find an automated way of identifying bots and code committed by these bots, and to characterize the types of bots based on their activity patterns. Method and Result: We propose BIMAN, a systematic approach to detect bots using author names, commit messages, files modified by the commit, and projects associated with the commits. For our test data, the value for AUC-ROC was 0.9. We also characterized these bots based on the time patterns of their code commits and the types of files modified, and found that they primarily work with documentation files and web pages, and these files are most prevalent in HTML and JavaScript ecosystems. We have compiled a shareable dataset containing detailed information about 461 bots we found (all of which have more than 1000 commits) and 13,762,430 commits they created.",2020,78
Defining and classifying software bots: a faceted taxonomy,"Lebeuf, Carlene and Zagalsky, Alexey and Foucault, Matthieu and Storey, Margaret-Anne","While bots have been around for many decades, recent technological advancements and the increasing adoption of language-based communication platforms have led to a surge of new software bots, which have become increasingly pervasive in our everyday lives. Although many novel bots are being designed and deployed, the terms used to describe them and their properties are vast, diverse, and often inconsistent. Even the concept of what is or is not a bot is unclear. This hinders our ability to study, understand, design, and classify bots.In this paper, we present a taxonomy of software bots, which focuses on the observable properties and behaviours of software bots, as well as the environments where bots are deployed and designed. We see this taxonomy as a focal point for a discussion in our community so that together we can deeply consider how to evaluate and understand existing bots, as well as how we may design more innovative and productive bots.",2019,79
Summary of the Third International Workshop on Bots in Software Engineering (BotSE 2021),"Wagner, Stefan and Gerosa, Marco A. and Wessel, Mairieli","Bots automate tasks in software engineering projects and interact with software developers. Bots have been proposed, for example, for testing, maintenance, and automating bug fixes. The research community has been discussing these bots in the International Workshop on Bots in Software Engineering (BotSE), collocated with ICSE (the International Conference on Software Engineering). The workshop participants share experiences and challenges, discuss new usages of bots, and map out future directions. In this paper, we present a summary of the 3rd edition of the workshop, which comprised nine papers, one journal-first presentation, and two keynotes, followed by extensive discussion. More details can be found at http://botse.org/",2022,80
"Expecting the unexpected: distilling bot development, challenges, and motivations","Pinheiro, Andr\'{e} M. and Rabello, Caio S. and Furtado, Leonardo B. and Pinto, Gustavo and de Souza, Cleidson R. B.","Software bots are becoming an increasingly popular tool in the software development landscape, which is particularly due to their potential of use in several different contexts. More importantly, software developers interested in transitioning to bot development may have to face challenges intrinsic related to bot software development. However, so far, it is still unclear what is the profile of bot developers, what motivate them, or what challenges do they face when dealing with bot development. To shed an initial light on this direction, we conducted a survey with 43 Github users who have been involved (showing their interest or actively contributing to) in bot software projects.",2019,83
JITBot: an explainable just-in-time defect prediction bot,"Khanan, Chaiyakarn and Luewichana, Worawit and Pruktharathikoon, Krissakorn and Jiarpakdee, Jirayus and Tantithamthavorn, Chakkrit and Choetkiertikul, Morakot and Ragkhitwetsagul, Chaiyong and Sunetnanta, Thanwadee","Just-In-Time (JIT) defect prediction is a classification model that is trained using historical data to predict bug-introducing changes. However, recent studies raised concerns related to the explainability of the predictions of many software analytics applications (i.e., practitioners do not understand why commits are risky and how to improve them). In addition, the adoption of Just-In-Time defect prediction is still limited due to a lack of integration into CI/CD pipelines and modern software development platforms (e.g., GitHub). In this paper, we present an explainable Just-In-Time defect prediction framework to automatically generate feedback to developers by providing the riskiness of each commit, explaining why such commit is risky, and suggesting risk mitigation plans. The proposed framework is integrated into the GitHub CI/CD pipeline as a GitHub application to continuously monitor and analyse a stream of commits in many GitHub repositories. Finally, we discuss the usage scenarios and their implications to practitioners. The VDO demonstration is available at https://jitbot-tool.github.io/",2021,93
Accelerating software engineering research adoption with analysis bots,"Beschastnikh, Ivan and Lungu, Mircea F. and Zhuang, Yanyan","An important part of software engineering (SE) research is to develop new analysis techniques and to integrate these techniques into software development practice. However, since access to developers is non-trivial and research tool adoption is slow, new analyses are typically evaluated as follows: a prototype tool that embeds the analysis is implemented, a set of projects is identified, their revisions are selected, and the tool is run in a controlled environment, rarely involving the developers of the software. As a result, research artifacts are brittle and it is unclear if an analysis tool would actually be adopted.In this paper, we envision harnessing the rich interfaces provided by popular social coding platforms for automated deployment and evaluation of SE research analysis. We propose that SE analyses can be deployed as analysis bots. We focus on two specific benefits of such an approach: (1) analysis bots can help evaluate analysis techniques in a less controlled, and more realistic context, and (2) analysis bots provide an interface for developers to ""subscribe"" to new research techniques without needing to trust the implementation, the developer of the new tool, or to install the analysis tool locally. We outline basic requirements for an analysis bots platform, and present research challenges that would need to be resolved for bots to flourish.",2017,103
Sorry to Bother You Again: Developer Recommendation Choice Architectures for Designing Effective Bots,"Brown, Chris and Parnin, Chris","Software robots, or bots, are useful for automating a wide variety of programming and software development tasks. Despite the advantages of using bots throughout the software engineering process, research shows that developers often face challenges interacting with these systems. To improve automated developer recommendations from bots, this work introduces developer recommendation choice architectures. Choice architecture is a behavioral science concept that suggests the presentation of options impacts the decisions humans make. To evaluate the impact of framing recommendations for software engineers, we examine the impact of one choice architecture, actionability, for improving the design of bot recommendations. We present the results of a preliminary study evaluating this choice architecture in a bot and provide implications for integrating choice architecture into the design of future software engineering bots.",2020,115
Classifying issues into custom labels in GitBot,"Park, Doje and Cho, Heetae and Lee, Seonah","GitBots are bots in Git repositories to automate repetitive tasks that occur in software development, testing and maintenance. GitBots are expected to perform the repetitive tasks that are normally done by humans, such as feedback on issue reports and answers to questions. However, studies on GitBots for labeling issue reports fall short of replacing developers' labeling tasks. Developers still manually attach labels to issues. In this paper, we introduce an issue labeling bot classifying issue reports into custom labels that developers define by themselves so that our bot could attach labels in a similar way to human behavior.",2022,118
The Robots Are Here: Navigating the Generative AI Revolution in Computing Education,"Prather, James and Denny, Paul and Leinonen, Juho and Becker, Brett A. and Albluwi, Ibrahim and Craig, Michelle and Keuning, Hieke and Kiesler, Natalie and Kohn, Tobias and Luxton-Reilly, Andrew and MacNeil, Stephen and Petersen, Andrew and Pettit, Raymond and Reeves, Brent N. and Savelka, Jaromir","Recent advancements in artificial intelligence (AI) and specifically generative AI (GenAI) are threatening to fundamentally reshape computing and society. Largely driven by large language models (LLMs), many tools are now able to interpret and generate both natural language instructions and source code. These capabilities have sparked urgent questions in the computing education community around how educators should adapt their pedagogy to address the challenges and to leverage the opportunities presented by this new technology. In this working group report, we undertake a comprehensive exploration of generative AI in the context of computing education and make five significant contributions. First, we provide a detailed review of the literature on LLMs in computing education and synthesise findings from 71 primary articles, nearly 80% of which have been published in the first 8 months of 2023. Second, we report the findings of a survey of computing students and instructors from across 20 countries, capturing prevailing attitudes towards GenAI/LLMs and their use in computing education contexts. Third, to understand how pedagogy is already changing, we offer insights collected from in-depth interviews with 22 computing educators from five continents. Fourth, we use the ACM Code of Ethics to frame a discussion of ethical issues raised by the use of large language models in computing education, and we provide concrete advice for policy makers, educators, and students. Finally, we benchmark the performance of several current GenAI models/tools on various computing education datasets, and highlight the extent to which the capabilities of current models are rapidly improving.There is little doubt that LLMs and other forms of GenAI will have a profound impact on computing education over the coming years. However, just as the technology will continue to improve, so will our collective knowledge about how to leverage these new models and tools in educational settings. We expect many important conversations around this topic will emerge as the community explores how to provide more effective, inclusive, and personalised learning experiences. Our aim is that this report will serve as a focal point for both researchers and practitioners who are exploring, adapting, using, and evaluating GenAI and LLM-based tools in computing classrooms.",2023,120
Understanding automated code review process and developer experience in industry,"Kim, Hyungjin and Kwon, Yonghwi and Joh, Sangwoo and Kwon, Hyukin and Ryou, Yeonhee and Kim, Taeksu","Code Review Automation can reduce human efforts during code review by automatically providing valuable information to reviewers. Nevertheless, it is a challenge to automate the process for large-scale companies, such as Samsung Electronics, due to their complexity: various development environments, frequent review requests, huge size of software, and diverse process among the teams. In this work, we show how we automated the code review process for those intricate environments, and share some lessons learned during two years of operation. Our unified code review automation system, Code Review Bot, is designed to process review requests holistically regardless of such environments, and checks various quality-assurance items such as potential defects in the code, coding style, test coverage, and open source license violations. Some key findings include: 1) about 60% of issues found by Code Review Bot were reviewed and fixed in advance of product releases, 2) more than 70% of developers gave positive feedback about the system, 3) developers rapidly and actively responded to reviews, and 4) the automation did not much affect the amount or the frequency of human code reviews compared to the internal policy to encourage code review activities. Our findings provide practical evidence that automating code review helps assure software quality.",2022,121
A unified code review automation for large-scale industry with diverse development environments,"Kim, Hyungjin and Kwon, Yonghwi and Kwon, Hyukin and Ryou, Yeonhee and Joh, Sangwoo and Kim, Taeksu and Kim, Chul-Joo","Code Review is an essential activity to ensure the quality of the software in the development process. Code Review Automation with various analyses can reduce human efforts of code review activities. However, it is a challenge to automate the code review process for large-scale companies such as Samsung Electronics due to their complex development environments: many kinds of products, various sizes of software, different version control systems, and diverse code review systems. In this work, we show how we automated the code review process for those intricate environments, and share some lessons learned during two years of operation. Our unified code review automation system, Code Review Bot, is designed to process review requests holistically regardless of such environments. Our findings provide practical evidence that our system motivates developers in Samsung Electronics to improve code quality.",2022,123
BreakBot: analyzing the impact of breaking changes to assist library evolution,"Ochoa, Lina and Degueule, Thomas and Falleri, Jean-R\'{e}my","""If we make this change to our code, how will it impact our clients?"" It is difficult for library maintainers to answer this simple---yet essential!---question when evolving their libraries. Library maintainers are constantly balancing between two opposing positions: make changes at the risk of breaking some of their clients, or avoid changes and maintain compatibility at the cost of immobility and growing technical debt. We argue that the lack of objective usage data and tool support leaves maintainers with their own subjective perception of their community to make these decisions.We introduce BreakBot, a bot that analyses the pull requests of Java libraries on GitHub to identify the breaking changes they introduce and their impact on client projects. Through static analysis of libraries and clients, it extracts and summarizes objective data that enrich the code review process by providing maintainers with the appropriate information to decide whether---and how---changes should be accepted, directly in the pull requests.",2022,126
Repairnator patches programs automatically,"Monperrus, Martin and Urli, Simon and Durieux, Thomas and Martinez, Matias and Baudry, Benoit and Seinturier, Lionel","Repairnator is a bot. It constantly monitors software bugs discovered during continuous integration of open-source software and tries to fix them automatically. If it succeeds in synthesizing a valid patch, Repairnator proposes the patch to the human developers, disguised under a fake human identity. To date, Repairnator has been able to produce patches that were accepted by the human developers and permanently merged into the code base. This is a milestone for human-competitiveness in software engineering research on automatic program repair.",2019,138
An Experience Report on Technical Debt in Pull Requests: Challenges and Lessons Learned,"Karmakar, Shubhashis and Codabux, Zadia and Vidoni, Melina","Background: GitHub is a collaborative platform for global software development, where Pull Requests (PRs) are essential to bridge code changes with version control. However, developers often trade software quality for faster implementation, incurring Technical Debt (TD). When developers undertake reviewers’ roles and evaluate PRs, they can often detect TD instances, leading to either PR rejection or discussions. Aims: We investigated whether Pull Request Comments (PRCs) indicate TD by assessing three large-scale repositories: Spark, Kafka, and React. Method: We combined manual classification with automated detection using machine learning and deep learning models. Results: We classified two datasets and found that 37.7 and 38.7% of PRCs indicate TD, respectively. Our best model achieved F1 = 0.85 when classifying TD during the validation phase. Conclusions: We faced several challenges during this process, which may hint that TD in PRCs is discussed differently from other software artifacts (e.g., code comments, commits, issues, or discussion forums). Thus, we present challenges and lessons learned to assist researchers in pursuing this area of research.",2022,167
PyTy: Repairing Static Type Errors in Python,"Chow, Yiu Wai and Di Grazia, Luca and Pradel, Michael","Gradual typing enables developers to annotate types of their own choosing, offering a flexible middle ground between no type annotations and a fully statically typed language. As more and more code bases get type-annotated, static type checkers detect an increasingly large number of type errors. Unfortunately, fixing these errors requires manual effort, hampering the adoption of gradual typing in practice. This paper presents PyTy, an automated program repair approach targeted at statically detectable type errors in Python. The problem of repairing type errors deserves specific attention because it exposes particular repair patterns, offers a warning message with hints about where and how to apply a fix, and because gradual type checking serves as an automatic way to validate fixes. We addresses this problem through three contributions: (i) an empirical study that investigates how developers fix Python type errors, showing a diverse set of fixing strategies with some recurring patterns; (ii) an approach to automatically extract type error fixes, which enables us to create a dataset of 2,766 error-fix pairs from 176 GitHub repositories, named PyTyDefects; (iii) the first learning-based repair technique for fixing type errors in Python. Motivated by the relative data scarcity of the problem, the neural model at the core of PyTy is trained via cross-lingual transfer learning. Our evaluation shows that PyTy offers fixes for ten frequent categories of type errors, successfully addressing 85.4% of 281 real-world errors. This effectiveness outperforms state-of-the-art large language models asked to repair type errors (by 2.1x) and complements a previous technique aimed at type errors that manifest at runtime. Finally, 20 out of 30 pull requests with PyTy-suggested fixes have been merged by developers, showing the usefulness of PyTy in practice.",2024,169
User-Centric Deployment of Automated Program Repair at Bloomberg,"Williams, David and Callan, James and Kirbas, Serkan and Mechtaev, Sergey and Petke, Justyna and Prideaux-Ghee, Thomas and Sarro, Federica","Automated program repair (APR) tools have unlocked the potential for the rapid rectification of codebase issues. However, to encourage wider adoption of program repair in practice, it is necessary to address the usability concerns related to generating irrelevant or out-of-context patches. When software engineers are presented with patches they deem uninteresting or unhelpful, they are burdened with more ""noise"" in their workflows and become less likely to engage with APR tools in future. This paper presents a novel approach to optimally time, target, and present auto-generated patches to software engineers. To achieve this, we designed, developed, and deployed a new tool dubbed B-Assist, which leverages GitHub's Suggested Changes interface to seamlessly integrate automated suggestions into active pull requests (PRs), as opposed to creating new, potentially distracting PRs. This strategy ensures that suggestions are not only timely, but also contextually relevant and delivered to engineers most familiar with the affected code. Evaluation among Bloomberg software engineers demonstrated their preference for this approach. From our user study, B-Assist's efficacy is evident, with the acceptance rate of patch suggestions being as high as 74.56%; engineers also found the suggestions valuable, giving usefulness ratings of at least 4 out of 5 in 78.2% of cases. Further, this paper sheds light on persisting usability challenges in APR and lays the groundwork for enhancing the user experience in future APR tools.",2024,170
Self-Service Performance Testing Platform for Autonomous Development Teams,"Vasilevskii, Aleksei and Kachur, Oleksandr","In the modern fast paced and highly autonomous software development teams, it's crucial to maintain a sustainable approach to all performance engineering activites, including performance testing. The high degree of autonomy often results in teams building their own frameworks that are not used consistently and may be abandoned due to lack of support or integration with existing infrastructure, processes and tools.To address these challenges, we present a self-service performance testing platform based on open-source software, that supports distributed load generation, historical results storage and a notification system to trigger alerts in Slack messenger. In addition, it integrates with GitHub Actions to enable developers running load tests as part of their CI/CD pipelines.We'd like to share some of the technical solutions and the details of the decision-making process behind the performance testing platform in a scale-up environment, our experience in building this platform and, most importantly, rolling it out to autonomous development teams and onboarding them into the continuous performance improvement process.",2024,176
Measuring and Clustering Heterogeneous Chatbot Designs,"Ca\~{n}izares, Pablo C. and L\'{o}pez-Morales, Jose Mar\'{\i}a and P\'{e}rez-Soler, Sara and Guerra, Esther and de Lara, Juan","Conversational agents, or chatbots, have become popular to access all kind of software services. They provide an intuitive natural language interface for interaction, available from a wide range of channels including social networks, web pages, intelligent speakers or cars. In response to this demand, many chatbot development platforms and tools have emerged. However, they typically lack support to statically measure properties of the chatbots being built, as indicators of their size, complexity, quality or usability. Similarly, there are hardly any mechanisms to compare and cluster chatbots developed with heterogeneous technologies.To overcome this limitation, we propose a suite of 21 metrics for chatbot designs, as well as two clustering methods that help in grouping chatbots along their conversation topics and design features. Both the metrics and the clustering methods are defined on a neutral chatbot design language, becoming independent of the implementation platform. We provide automatic translations of chatbots defined on some major platforms into this neutral notation to perform the measurement and clustering. The approach is supported by our tool Asymob, which we have used to evaluate the metrics and the clustering methods over a set of 259 Dialogflow and Rasa chatbots from open-source repositories. The results open the door to incorporating the metrics within chatbot development processes for the early detection of quality issues, and to exploit clustering to organise large collections of chatbots into significant groups to ease chatbot comprehension, search and comparison.",2024,250
Fine-Grained Just-In-Time Defect Prediction at the Block Level in Infrastructure-as-Code (IaC),"Begoug, Mahi and Chouchen, Moataz and Ouni, Ali and Abdullah Alomar, Eman and Mkaouer, Mohamed Wiem","Infrastructure-as-Code (IaC) is an emerging software engineering practice that leverages source code to facilitate automated configuration of software systems' infrastructure. IaC files are typically complex, containing hundreds of lines of code and dependencies, making them prone to defects, which can result in breaking online services at scale. To help developers early identify and fix IaC defects, research efforts have introduced IaC defect prediction models at the file level. However, the granularity of the proposed approaches remains coarse-grained, requiring developers to inspect hundreds of lines of code in a file, while only a small fragment of code is defective. To alleviate this issue, we introduce a machine-learning-based approach to predict IaC defects at a fine-grained level, focusing on IaC blocks, i.e., small code units that encapsulate specific behaviours within an IaC file. We trained various machine learning algorithms based on a mixture of code, process, and change-level metrics. We evaluated our approach on 19 open-source projects that use Terraform, a widely used IaC tool. The results indicated that there is no single algorithm that consistently outperforms the others in 19 projects. Overall, among the six algorithms, we observed that the LightGBM model achieved a higher average of 0.21 in terms of MCC and 0.71 in terms of AUC. Models analysis reveals that the developer's experience and the relative number of added lines tend to be the most important features. Additionally, we found that blocks belonging to the most frequent types are more prone to defects. Our defect prediction models have also shown sensitivity to concept drift, indicating that IaC practitioners should regularly retrain their models.",2024,281
FLOSS FAQ chatbot project reuse: how to allow nonexperts to develop a chatbot,"de Lacerda, Arthur R. T. and Aguiar, Carla S. R.","FAQ chatbots possess the capability to provide answers to frequently asked questions of a particular service, platform, or system. Currently, FAQ chatbot is the most popular domain of use of dialog assistants. However, developing a chatbot project requires a full-stack team formed by numerous specialists, such as dialog designer, data scientist, software engineer, DevOps, business strategist and experts from the domain, which can be both time and resources consuming. Language processing can be particularly challenging in languages other than English due to the scarcity of training datasets.Most of the requirements of FAQ chatbots are similar, domain-specific, and projects could profit from Open Source Software (OSS) reuse. In this paper, we examine how OSS FAQ chatbot projects can benefit from reuse at the project level (black-box reuse). We present an experience report of a FLOSS FAQ chatbot project developed in Portuguese to an e-government service in Brazil. It comprises of the chatbot distribution service, as well as for analytics tool integrated and deployed on-premises. We identified assets that could be reused as a black-box and the assets that should be customized for a particular application. We categorized these assets in architecture, corpus, dialog flows, machine learning models, and documentation. This paper discusses how automation, pre-configuration, and templates can aid newcomers to develop chatbots in Portuguese without the need for specialized skills required from tools in chatbot architecture. Our main contribution is to highlight the issues non-English FAQ chatbots projects will likely face and the assets that can be reused. It allows non-chatbot experts to develop a quality-assured OSS FAQ chatbot in a shorter project cycle.",2019,294
"GitWaterFlow: a successful branching model and tooling, for achieving continuous delivery with multiple version branches","Rayana, Rayene Ben and Killian, Sylvain and Trangez, Nicolas and Calmettes, Arnaud","Collaborative software development presents organizations with a near-constant flow of day-to-day challenges, and there is no available off-the-shelf solution that covers all needs. This paper provides insight into the hurdles that Scality's Engineering team faced in developing and extending a sophisticated storage solution, while coping with ever-growing development teams, challenging - and regularly shifting - business requirements, and non-trivial new feature development. The authors present a novel combination of a Git-based Version Control and Branching model with a set of innovative tools dubbed GitWaterFlow to cope with the issues encountered, including the need to both support old product versions and to provide time-critical delivery of bug fixes. In the spirit of Continuous Delivery, Scality Release Engineering aims to ensure high quality and stability, to present short and predictable release cycles, and to minimize development disruption. The team's experience with the GitWaterFlow model suggests that the approach has been effective in meeting these goals in the given setting, with room for unceasing fine-tuning and improvement of processes and tools.",2016,311
Artificial Intelligence vs. Software Engineers: An Empirical Study on Performance and Efficiency using ChatGPT,"Nascimento, Nathalia and Alencar, Paulo and Cowan, Donald","In the realm of Software Engineering (SE), automation has become a tangible reality. Artificial Intelligence (AI) has suc-cessfully addressed challenges in project management, mod-eling, testing, and development. Among the latest innova-tions is ChatGPT, an ML-infused chatbot capable of gen-erating programming codes and software testing strategies. Although there is speculation that AI-based computation can boost productivity and even substitute software engineers in software development, empirical evidence supporting such claims is lacking. Moreover, questions remain about their po-tential to address overlooked evaluation metrics like energy efficiency, vulnerability, fairness (i.e., human bias), and safety. This paper probes into these issues with an empirical study, comparing ChatGPT with both novice and expert program-mers using LeetCode contest problems. The investigation focuses on performance and memory-efficiency, while also acknowledging the need for a broader assessment of non-functional requirements. The results suggest that ChatGPT is better than beginners at solving easy and medium prob-lems, but it is not yet proven to beat expert programmers. This paper posits that a comprehensive comparison of soft-ware engineers and AI-based solutions, considering various evaluation criteria, is pivotal in fostering human-machine collaboration, enhancing the reliability of AI-based meth-ods, and understanding task suitability for humans or AI. Furthermore, it facilitates the effective implementation of co-operative work structures and human-in-the-loop processes.",2023,312
A characterization study of testing contributors and their contributions in open source projects.,"Souza, Hugo Henrique Fumero de and Wiese, Igor and Steinmacher, Igor and R\'{e}, Reginaldo","Even though open source projects have some different characteristics from projects in the industry, the commitment of maintainers and contributors to achieve a high level of software quality is constant. Therefore, tests are among the main practices of the communities. Thus, motivating contributors to write new tests and maintain regression tests during testing activities is essential for the project’s health. The objective of our work is to characterize testers and their contributions to open source projects as part of a broad study about testers’ motivation. Thus, we conducted a study with 3,936 repositories and 7 different and important programming languages (C, C++, C#, Java, Javascript, Python, and Ruby), analyzing a total of 4,409,142 contributions to classify contributing members and their contributions. Our results show that test-only contributors exist, regardless of programming language or project. We conclude that, despite the unfavorable scenario, there are contributors who feel motivated and dedicate their time and effort to contribute to new tests or to the evolution of existing tests.",2022,358
CVEfixes: automated collection of vulnerabilities and their fixes from open-source software,"Bhandari, Guru and Naseer, Amara and Moonen, Leon","Data-driven research on the automated discovery and repair of security vulnerabilities in source code requires comprehensive datasets of real-life vulnerable code and their fixes. To assist in such research, we propose a method to automatically collect and curate a comprehensive vulnerability dataset from Common Vulnerabilities and Exposures (CVE) records in the National Vulnerability Database (NVD). We implement our approach in a fully automated dataset collection tool and share an initial release of the resulting vulnerability dataset named CVEfixes. The CVEfixes collection tool automatically fetches all available CVE records from the NVD, gathers the vulnerable code and corresponding fixes from associated open-source repositories, and organizes the collected information in a relational database. Moreover, the dataset is enriched with meta-data such as programming language, and detailed code and security metrics at five levels of abstraction. The collection can easily be repeated to keep up-to-date with newly discovered or patched vulnerabilities. The initial release of CVEfixes spans all published CVEs up to 9 June 2021, covering 5365 CVE records for 1754 open-source projects that were addressed in a total of 5495 vulnerability fixing commits. CVEfixes supports various types of data-driven software security research, such as vulnerability prediction, vulnerability classification, vulnerability severity prediction, analysis of vulnerability-related code changes, and automated vulnerability repair.",2021,373
WhoDo: automating reviewer suggestions at scale,"Asthana, Sumit and Kumar, Rahul and Bhagwan, Ranjita and Bird, Christian and Bansal, Chetan and Maddila, Chandra and Mehta, Sonu and Ashok, B.","Today's software development is distributed and involves continuous changes for new features and yet, their development cycle has to be fast and agile. An important component of enabling this agility is selecting the right reviewers for every code-change - the smallest unit of the development cycle. Modern tool-based code review is proven to be an effective way to achieve appropriate code review of software changes. However, the selection of reviewers in these code review systems is at best manual. As software and teams scale, this poses the challenge of selecting the right reviewers, which in turn determines software quality over time. While previous work has suggested automatic approaches to code reviewer recommendations, it has been limited to retrospective analysis. We not only deploy a reviewer suggestions algorithm - WhoDo - and evaluate its effect but also incorporate load balancing as part of it to address one of its major shortcomings: of recommending experienced developers very frequently. We evaluate the effect of this hybrid recommendation + load balancing system on five repositories within Microsoft. Our results are based around various aspects of a commit and how code review affects that. We attempt to quantitatively answer questions which are supposed to play a vital role in effective code review through our data and substantiate it through qualitative feedback of partner repositories.",2019,651
Is it Enough to Recommend Tasks to Newcomers? Understanding Mentoring on Good First Issues,"Tan, Xin and Chen, Yiran and Wu, Haohua and Zhou, Minghui and Zhang, Li","Newcomers are critical for the success and continuity of open source software (OSS) projects. To attract newcomers and facilitate their onboarding, many OSS projects recommend tasks for newcomers, such as good first issues (GFIs). Previous studies have preliminarily investigated the effects of GFIs and techniques to identify suitable GFIs. However, it is still unclear whether just recommending tasks is enough and how significant mentoring is for newcomers. To better understand mentoring in OSS communities, we analyze the resolution process of 48,402 GFIs from 964 repositories through a mix-method approach. We investigate the extent, the mentorship structures, the discussed topics, and the relevance of expert involvement. We find that ~70% of GFIs have expert participation, with each GFI usually having one expert who makes two comments. Half of GFIs will receive their first expert comment within 8.5 hours after a newcomer comment. Through analysis of the collaboration networks of newcomers and experts, we observe that community mentorship presents four types of structure: centralized mentoring, decentralized mentoring, collaborative mentoring, and distributed mentoring. As for discussed topics, we identify 14 newcomer challenges and 18 expert mentoring content. By fitting the generalized linear models, we find that expert involvement positively correlates with newcomers' successful contributions but negatively correlates with newcomers' retention. Our study manifests the status and significance of mentoring in the OSS projects, which provides rich practical implications for optimizing the mentoring process and helping newcomers contribute smoothly and successfully.",2023,681
What All the PHUZZ Is About: A Coverage-guided Fuzzer for Finding Vulnerabilities in PHP Web Applications,"Neef, Sebastian and Kleissner, Lorenz and Seifert, Jean-Pierre","Coverage-guided fuzz testing has received significant attention from the research community, with a strong focus on binary applications, greatly disregarding other targets, such as web applications. The importance of the World Wide Web in everyone's life cannot be overstated, and to this day, many web applications are developed in PHP. In this work, we address the challenges of applying coverage-guided fuzzing to PHP web applications and introduce Phuzz, a modular fuzzing framework for PHP web applications. Phuzz uses novel approaches to detect more client-side and server-side vulnerability classes than state-of-the-art related work, including SQL injections, remote command injections, insecure deserialization, path traversal, external entity injection, cross-site scripting, and open redirection. We evaluate Phuzz on a diverse set of artificial and real-world web applications with known and unknown vulnerabilities, and compare it against a variety of state-of-the-art fuzzers. In order to show Phuzz' effectiveness, we fuzz over 1,000 API endpoints of the 115 most popular WordPress plugins, resulting in over 20 security issues and 2 new CVE-IDs. Finally, we make the framework publicly available to motivate and encourage further research on web application fuzz testing.",2024,786
"Bots Don’t Mind Waiting, Do They? Comparing the Interaction With Automatically and Manually Created Pull Requests",M. Wyrich; R. Ghit; T. Haller; C. Müller,"As a maintainer of an open source software project, you are usually happy about contributions in the form of pull requests that bring the project a step forward. Past studies have shown that when reviewing a pull request, not only its content is taken into account, but also, for example, the social characteristics of the contributor. Whether a contribution is accepted and how long this takes therefore depends not only on the content of the contribution. What we only have indications for so far, however, is that pull requests from bots may be prioritized lower, even if the bots are explicitly deployed by the development team and are considered useful. One goal of the bot research and development community is to design helpful bots to effectively support software development in a variety of ways. To get closer to this goal, in this GitHub mining study, we examine the measurable differences in how maintainers interact with manually created pull requests from humans compared to those created automatically by bots. About one third of all pull requests on GitHub currently come from bots. While pull requests from humans are accepted and merged in 72.53% of all cases, this applies to only 37.38% of bot pull requests. Furthermore, it takes significantly longer for a bot pull request to be interacted with and for it to be merged, even though they contain fewer changes on average than human pull requests. These results suggest that bots have yet to realize their full potential.",2021,1154
Suggestion Bot: Analyzing the Impact of Automated Suggested Changes on Code Reviews,N. Palvannan; C. Brown,"Peer code reviews are crucial for maintaining the quality of the code in software repositories. Developers have introduced a number of software bots to help with the code review process. Despite the benefits of automating code review tasks, many developers face challenges interacting with these bots due to non-comprehensive feedback and disruptive notifications. In this paper, we analyze how incorporating a bot in software development cycle will decrease turnaround time of pull request. We created a bot called “SUGGESTION BOT” to automatically review the code base using GitHub’s suggested changes functionality in order to solve this issue. A preliminary comparative empirical investigation between the utilization of this bot and manual review procedures was also conducted in this study. We evaluate SUGGESTION BOT concerning its impact on review time and also analyze whether the comments given by the bot are clear and useful for users. Our results provide implications for the design of future systems and improving human-bot interactions for code review.",2023,1163
Guidelines for Developing Bots for GitHub,M. Wessel; A. Zaidman; M. A. Gerosa; I. Steinmacher,"Projects on GitHub rely on the automation provided by software development bots. Nevertheless, the presence of bots can be annoying and disruptive to the community. Backed by multiple studies with practitioners, this article provides guidelines for developing and maintaining software bots.",2023,1177
A ground-truth dataset and classification model for detecting bots in GitHub issue and PR comments,Mehdi Golzadeh and Alexandre Decan and Damien Legay and Tom Mens,"Bots are frequently used in Github repositories to automate repetitive activities that are part of the distributed software development process. They communicate with human actors through comments. While detecting their presence is important for many reasons, no large and representative ground-truth dataset is available, nor are classification models to detect and validate bots on the basis of such a dataset. This paper proposes a ground-truth dataset, based on a manual analysis with high interrater agreement, of pull request and issue comments in 5,000 distinct Github accounts of which 527 have been identified as bots. Using this dataset we propose an automated classification model to detect bots, taking as main features the number of empty and non-empty comments of each account, the number of comment patterns, and the inequality between comments within comment patterns. We obtained a very high weighted average precision, recall and F1-score of 0.98 on a test set containing 40% of the data. We integrated the classification model into an open source command-line tool to allow practitioners to detect which accounts in a given Github repository actually correspond to bots.",2021,1837
SAW-BOT: Proposing Fixes for Static Analysis Warnings with GitHub Suggestions,B. Golsteijn; R. Holdorp; A. Serebrenik,"In this experience report we present SAW-BOT, a bot proposing fixes for static analysis warnings. The bot has been evaluated with five professional software developers by means of a Wizard of Oz experiment, semi-structured interviews and the mTAM questionnaire. We have observed that developers prefer GitHub suggestions to two baseline operation modes. Our study indicates that GitHub suggestions are a viable mechanism for implementing bots proposing fixes for static analysis warnings.",2021,1146
Conversational Bot for Newcomers Onboarding to Open Source Projects,"Dominic, James and Houser, Jada and Steinmacher, Igor and Ritter, Charles and Rodeghero, Paige","This paper targets the problems newcomers face when onboarding to open source projects and the low retention rate of newcomers. Open source software projects are becoming increasingly more popular. Many major companies have started building open source software. Unfortunately, many newcomers only commit once to an open source project before moving on to another project. Even worse, many novices struggle with joining open source communities and end up leaving quickly, sometimes before their first successful contribution. In this paper, we propose a conversational bot that would recommend projects to newcomers and assist in the onboarding to the open source community. The bot would be able to provide helpful resources, such as Stack Overflow related content. It would also be able to recommend human mentors. We believe that this bot would improve newcomers' experience by providing support not only during their first contribution, but by acting as an agent to engage them to the project.",2020,22
Leveraging predictions from multiple repositories to improve bot detection,"Chidambaram, Natarajan and Decan, Alexandre and Golzadeh, Mehdi","Contemporary social coding platforms such as GitHub facilitate collaborative distributed software development. Developers engaged in these platforms often use machine accounts (bots) for automating effort-intensive or repetitive activities. Determining whether a contributor corresponds to a bot or a human account is important in socio-technical studies, for example to assess the positive and negative impact of using bots, analyse the evolution of bots and their usage, identify top human contributors, and so on. BoDeGHa is one of the bot detection tools that have been proposed in the literature. It relies on comment activity within a single repository to predict whether an account is driven by a bot or by a human. This paper presents preliminary results on how the effectiveness of BoDeGHa can be improved by combining the predictions obtained from many repositories at once. We found that doing this not only increases the number of cases for which a prediction can be made, but that many diverging predictions can be fixed this way. These promising, albeit preliminary, results suggest that the ""wisdom of the crowd"" principle can improve the effectiveness of bot detection tools.",2022,27
Explainable software bot contributions: case study of automated bug fixes,"Monperrus, Martin","In a software project, esp. in open-source, a contribution is a valuable piece of work made to the project: writing code, reporting bugs, translating, improving documentation, creating graphics, etc. We are now at the beginning of an exciting era where software bots will make contributions that are of similar nature than those by humans.Dry contributions, with no explanation, are often ignored or rejected, because the contribution is not understandable per se, because they are not put into a larger context, because they are not grounded on idioms shared by the core community of developers.We have been operating a program repair bot called Repairnator for 2 years and noticed the problem of ""dry patches"": a patch that does not say which bug it fixes, or that does not explain the effects of the patch on the system. We envision program repair systems that produce an ""explainable bug fix"": an integrated package of at least 1) a patch, 2) its explanation in natural or controlled language, and 3) a highlight of the behavioral difference with examples.In this paper, we generalize and suggest that software bot contributions must explainable, that they must be put into the context of the global software development conversation.",2019,29
